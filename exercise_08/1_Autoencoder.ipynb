{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "9CALuVmNMNkM"
   },
   "source": [
    "# Autoencoder for MNIST\n",
    "\n",
    "Welcome to this notebook where you'll be training an autoencoder using the MNIST dataset, which comprises handwritten digits. This exercise is the last where we present you with a structured skeleton to work with. However, in following exercises, we will only provide you with the dataset, task, and a test scenario, enabling you to test your skills and compete with your peers on our leaderboards. Get ready to dive in and showcase your deep learning expertise!\n",
    "\n",
    "\n",
    "## Your task:\n",
    "\n",
    "Autoencoders have various applications, including unsupervised pretraining using unlabeled data, followed by fine-tuning the encoder with labeled data. This approach can greatly enhance performance when there is only a little amount of labeled data but a lot of unlabeled data available.\n",
    "\n",
    "In this exercise, you will use the MNIST dataset, consisting of 60,000 images of handwritten digits. However, not all the image labels are available to you. Your first objective is to train an autoencoder to accurately reproduce these unlabeled images.\n",
    "\n",
    "Afterwards, you will transfer the weights of the pretrained encoder and perform fine-tuning on a classifier using the available labeled data. This technique is commonly known as **transfer learning**, which allows you to leverage the knowledge gained from the autoencoder to improve the classification of the handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "XcU9f4APMNkT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# For automatic file reloading as usual\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Xb9dFU2EMNkW"
   },
   "source": [
    "## (Optional) Mount folder in Colab\n",
    "\n",
    "Uncomment the following cell to mount your gdrive if you are using the notebook in google colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "TRr4E4YVMNkW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom google.colab import drive\\nimport os\\ngdrive_path='/content/gdrive/MyDrive/i2dl/exercise_08'\\n\\n# This will mount your google drive under 'MyDrive'\\ndrive.mount('/content/gdrive', force_remount=True)\\n# In order to access the files in this notebook we have to navigate to the correct folder\\nos.chdir(gdrive_path)\\n# Check manually if all files are present\\n\""
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the following lines if you want to use Google Colab\n",
    "# We presume you created a folder \"i2dl\" within your main drive folder, and put the exercise there.\n",
    "# NOTE: terminate all other colab sessions that use GPU!\n",
    "# NOTE 2: Make sure the correct exercise folder (e.g exercise_08) is given.\n",
    "\n",
    "# from google.colab import drive\n",
    "# import os\n",
    "\n",
    "\"\"\"\n",
    "from google.colab import drive\n",
    "import os\n",
    "gdrive_path='/content/gdrive/MyDrive/i2dl/exercise_08'\n",
    "\n",
    "# This will mount your google drive under 'MyDrive'\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "# In order to access the files in this notebook we have to navigate to the correct folder\n",
    "os.chdir(gdrive_path)\n",
    "# Check manually if all files are present\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "JzDQg-kDMNkY"
   },
   "source": [
    "### Set up PyTorch environment in colab\n",
    "- (OPTIONAL) Enable GPU via Runtime --> Change runtime type --> GPU\n",
    "- Uncomment the following cell if you are using the notebook in google colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "pIUdsXeXMNkZ"
   },
   "outputs": [],
   "source": [
    "# Optional: install correct libraries in google colab\n",
    "# !python -m pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchtext==0.12.0+cu113 torchaudio==0.12.0+cu113 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# !python -m pip install tensorboard==2.8.0 > /dev/null\n",
    "# !python -m pip install pytorch-lightning==1.6.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "hEDWAZ7-ZA4E"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "dJCiVLV5o9QO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from exercise_code.image_folder_dataset import ImageFolderDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "from exercise_code.tests.base_tests import bcolors\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' # To prevent the kernel from dying."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "dvaj6myXS7nN"
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Note: Google Colab</h3>\n",
    "    <p>\n",
    "In case you don't have a GPU, you can run this notebook on Google Colab where you can access a GPU for free, but, of course, you can also run this notebook on your CPU.\n",
    "         </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "VWgm75NnS9hr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using the following device:  cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('You are using the following device: ', device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Pm_rTAPnpsUo"
   },
   "source": [
    "## Setup TensorBoard\n",
    "\n",
    "In the previous exercise (Exercise 07), you learned how to use TensorBoard effectively. Let's use it again to enhance the convenience of debugging your network and the training process. Throughout this notebook, feel free to implement additional logs or visualizations into your TensorBoard, further improving your analysis and understanding of the network's behavior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "QbAJFyHkMNke"
   },
   "outputs": [],
   "source": [
    "################# COLAB ONLY #################\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir=./ --port 6006\n",
    "\n",
    "# Use the cmd for less trouble, if you can. From the working directory, run: tensorboard --logdir=./ --port 6006"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "t-Yt2KRiMNkf"
   },
   "source": [
    "# 1. The MNIST Dataset\n",
    "\n",
    "First, let's download the MNIST dataset. As mentioned in the beginning of this notebook, MNIST is a dataset of 60,000 images depicting handwritten digits. However, labeling such a large dataset can be a costly process, leaving us in a challenging situation.\n",
    "\n",
    "To overcome this, a practical approach is to label a small subset of the images. Let's consider a scenario where you have hired another student to perform the labeling task for you. After some time, you have been provided with 300 labeled images. Out of these, 100 images will be used for training, another 100 for validation, and the remaining 100 for testing. Undoubtedly, this poses a challenge due to the limited number of labeled samples.\n",
    "\n",
    "Now, you have the flexibility to define any transforms that you deem necessary, either at this point or at a later stage. However, it's important to note that during the final evaluation on the server, no transformations will be applied to the test set.\n",
    "\n",
    "Feel free to experiment with various transforms as you proceed (you can also pass without any transforms). \n",
    "\n",
    "\n",
    "**Note**: We do **not** apply any transformations to the test set at the time of final evaluation on our server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "U5_eopjbMNkf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found dataset folder. Skipped downloading. If you face issues, please re-download the dataset using\n",
      "'--force_download=True'\n",
      "https://i2dl.vc.in.tum.de/static/data/mnist.zip\n",
      "Found dataset folder. Skipped downloading. If you face issues, please re-download the dataset using\n",
      "'--force_download=True'\n",
      "https://i2dl.vc.in.tum.de/static/data/mnist.zip\n",
      "Found dataset folder. Skipped downloading. If you face issues, please re-download the dataset using\n",
      "'--force_download=True'\n",
      "https://i2dl.vc.in.tum.de/static/data/mnist.zip\n",
      "Found dataset folder. Skipped downloading. If you face issues, please re-download the dataset using\n",
      "'--force_download=True'\n",
      "https://i2dl.vc.in.tum.de/static/data/mnist.zip\n",
      "Found dataset folder. Skipped downloading. If you face issues, please re-download the dataset using\n",
      "'--force_download=True'\n",
      "https://i2dl.vc.in.tum.de/static/data/mnist.zip\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([])\n",
    "\n",
    "########################################################################\n",
    "# TODO: Feel free to define transforms                                 #\n",
    "########################################################################\n",
    "\n",
    "# MNIST mean: 0.1307, std: 0.3081\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Normalize((0.1307), (0.3081)), # Apparently normalizing results in terrible submission results\n",
    "    transforms.RandomPerspective(distortion_scale=0.3, p=0.4),\n",
    "    transforms.RandomApply(torch.nn.ModuleList([\n",
    "     transforms.RandomRotation(degrees=30)]), p=0.4)\n",
    "    \n",
    "    ])\n",
    "\n",
    "########################################################################\n",
    "#                           END OF YOUR CODE                           #\n",
    "########################################################################\n",
    "\n",
    "i2dl_exercises_path = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "mnist_root = os.path.join(i2dl_exercises_path, \"datasets\", \"mnist\")\n",
    "\n",
    "train_100_dataset = ImageFolderDataset(root=mnist_root,images='train_images.pt',labels='train_labels.pt',force_download=False,verbose=True,transform=transform)\n",
    "val_100_dataset = ImageFolderDataset(root=mnist_root,images='val_images.pt',labels='val_labels.pt',force_download=False,verbose=True,transform=transform)\n",
    "test_100_dataset = ImageFolderDataset(root=mnist_root,images='test_images.pt',labels='test_labels.pt',force_download=False,verbose=True,transform=transform)\n",
    "\n",
    "# We also set up the unlabeled images which we will use later\n",
    "unlabeled_train = ImageFolderDataset(root=mnist_root,images='unlabeled_train_images.pt',force_download=False,verbose=True,transform=transform)\n",
    "unlabeled_val = ImageFolderDataset(root=mnist_root,images='unlabeled_val_images.pt',force_download=False,verbose=True,transform=transform)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zwrT1ckAMNkg"
   },
   "source": [
    "The dataset consists of tuples of 28x28 pixel PIL images and a label that is an integer from 0 to 9. \n",
    "\n",
    "Let's turn a few of the images into numpy arrays, to look at their shape and visualize them and see if the labels we paid for are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "k7ct1J2CMNkh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of our greyscale images:  (28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABjYAAAC2CAYAAAB6QLRGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABEKklEQVR4nO3de5zMdR///9cudll7kNOyWMekllRCiE1tDkk5VlcHlKIrlCtJKpGSSn0TUnSgw+VwUVJK1xWFHHNIhUJnp12n7Dou1vv3x/drf97vz5jZmZ3Zz2Ef99tt/nh+duYz7515+uzMfMz7HaWUUgIAAAAAAAAAAOAC0XYPAAAAAAAAAAAAoKA4sQEAAAAAAAAAAFyDExsAAAAAAAAAAMA1OLEBAAAAAAAAAABcgxMbAAAAAAAAAADANTixAQAAAAAAAAAAXIMTGwAAAAAAAAAAwDU4sQEAAAAAAAAAAFyDExsAAAAAAAAAAMA1OLFRCLVq1ZI+ffrYPQwUM/QOdqF7sAO9g13oHuxA72AXugc70DvYhe7BDvQu/Dix4cOvv/4q/fv3lzp16kjp0qUlMTFRWrVqJa+++qocP37c7uEFlJubK8OGDZOUlBQpU6aMNG/eXL788ku7h4UA3Ny7I0eOyMiRI6VDhw5Svnx5iYqKkunTp9s9LBSQm7u3du1aGThwoKSlpUnZsmUlNTVVbrnlFtm2bZvdQ0MAbu7d5s2bpWfPnlKnTh2Ji4uTihUrSps2beTTTz+1e2goADd3zzRmzBiJioqShg0b2j0UBODm3i1ZskSioqJ8XlavXm338BCAm7t31oYNG+Smm26S8uXLS1xcnDRs2FAmTJhg97Dgh5t716dPn/Me86KiomTXrl12DxF+uLl7IiLbt2+X2267TapXry5xcXHSoEEDGT16tBw7dszuocEPt/du/fr10qFDB0lMTJSEhARp166dbNy40e5hFUhJuwfgNJ999pn07NlTYmNjpVevXtKwYUM5efKkLF++XIYOHSqbN2+WqVOn2j1Mv/r06SNz586VwYMHy4UXXijTp0+XG264Qb7++mu5+uqr7R4efHB77/bv3y+jR4+W1NRUady4sSxZssTuIaGA3N69F154QVasWCE9e/aUSy+9VDIzM2XSpElyxRVXyOrVq/mwz6Hc3rs///xTDh8+LL1795aUlBQ5duyYfPjhh3LTTTfJlClTpF+/fnYPEefh9u6da+fOnfLcc89J2bJl7R4KAvBK7x588EFp2rSptq1evXo2jQYF4YXu/e9//5POnTvL5ZdfLiNGjJD4+Hj59ddfZefOnXYPDefh9t71799fMjIytG1KKbn//vulVq1aUq1aNZtGhkDc3r0dO3ZIs2bNJCkpSQYOHCjly5eXVatWyciRI2X9+vUyf/58u4cIH9zeuw0bNsjVV18tNWrUkJEjR8qZM2dk8uTJkp6eLt9++61cdNFFdg/RP4V8v/32m4qPj1cNGjRQu3fvtvx8+/btavz48fm5Zs2aqnfv3kU4wsDWrFmjRESNGzcuf9vx48dV3bp1VYsWLWwcGc7HC707ceKE2rNnj1JKqbVr1yoRUdOmTbN3UAjIC91bsWKFys3N1bZt27ZNxcbGqjvuuMOmUcEfL/TOl9OnT6vGjRuriy66yO6h4Dy81r1bb71VXXvttSo9PV2lpaXZPRychxd69/XXXysRUXPmzLF7KAiCF7qXnZ2tkpOTVdeuXVVeXp7dw0EBeKF3vnzzzTdKRNSYMWPsHgrOwwvdGzNmjBIRtWnTJm17r169lIiogwcP2jQynI8XenfDDTeoCy64QO3fvz9/2+7du1V8fLzq1q2bjSMrGKaiOseLL74oR44ckbfffluqVq1q+Xm9evXkoYceOu/tDx48KI888og0atRI4uPjJTExUTp27Cjff/+95boTJ06UtLQ0iYuLkwsuuECuvPJKmTFjRv7PDx8+LIMHD5ZatWpJbGysVK5cWa6//nrZsGGD399h7ty5UqJECe1/i5YuXVr69u0rq1atkh07dhTkoUAR8kLvYmNjpUqVKkH81nACL3SvZcuWEhMTo2278MILJS0tTX766adADwFs4IXe+VKiRAmpUaOGHDp0KOjbomh4qXvLli2TuXPnyvjx4wt0fdjHS707u4/Tp08X+Pqwjxe6N2PGDMnKypIxY8ZIdHS0HD16VM6cORPEo4Ci5oXe+TJjxgyJioqS22+/Pejbomh4oXs5OTkiIpKcnKxtr1q1qkRHR1ve98J+XujdN998IxkZGVKhQoX8bVWrVpX09HRZsGCBHDlypCAPhW2Yiuocn376qdSpU0datmwZ0u1/++03+fjjj6Vnz55Su3ZtycrKkilTpkh6erps2bJFUlJSRETkzTfflAcffFB69OghDz30kJw4cUJ++OEHWbNmTf4fyvvvv1/mzp0rAwcOlEsuuUQOHDggy5cvl59++kmuuOKK847hu+++k/r160tiYqK2vVmzZiIisnHjRqlRo0ZIvx8iwwu9gzt5tXtKKcnKypK0tLSQfi9Elpd6d/ToUTl+/LhkZ2fLJ598IgsXLpRbb701pN8LkeeV7uXl5cmgQYPk3nvvlUaNGoX0u6DoeKV3IiJ33323HDlyREqUKCGtW7eWcePGyZVXXhnS74XI80L3Fi1aJImJibJr1y7p0qWLbNu2TcqWLSt33XWXvPLKK1K6dOmQfjdEjhd6Zzp16pT85z//kZYtW0qtWrVC+r0QeV7o3jXXXCMvvPCC9O3bV55++mmpUKGCrFy5Ul5//XV58MEHmX7UgbzQu9zcXClTpoxle1xcnJw8eVI2bdokV111VUi/X5Gw+ysjTpGdna1ERN18880Fvo35FaITJ05YviL7+++/q9jYWDV69Oj8bTfffHPAKQOSkpLUgAEDCjyWs9LS0tS1115r2b5582YlIuqNN94Iep+IHK/07lxMReUOXuzeWe+//74SEfX222+HZX8IH6/1rn///kpElIio6Oho1aNHD74i7lBe6t6kSZNUUlKS2rt3r1JKMRWVg3mldytWrFDdu3dXb7/9tpo/f74aO3asqlChgipdurTasGFD0PtD5Hmle5deeqmKi4tTcXFxatCgQerDDz9UgwYNUiKibrvttqD3h8jySu9Mn376qRIRNXny5ELvC5Hhpe4988wzqkyZMvnvMUREPfHEEyHtC5Hlld41atRI1a9fX50+fTp/W25urkpNTVUioubOnRv0PosSU1H9P2e/8pWQkBDyPmJjYyU6+v8+pHl5eXLgwAGJj4+Xiy66SPvqT7ly5WTnzp2ydu3a8+6rXLlysmbNGtm9e3dQYzh+/LjExsZatp/93yzHjx8Pan+ILK/0Du7j1e79/PPPMmDAAGnRooX07t27UPtC+Hmtd4MHD5Yvv/xS3n33XenYsaPk5eXJyZMnQ9oXIssr3Ttw4IA89dRTMmLECKlUqVJovwiKjFd617JlS5k7d67cc889ctNNN8ljjz0mq1evlqioKBk+fHhovxgiyivdO3LkiBw7dkx69eolEyZMkG7dusmECROkf//+MmvWLNm+fXtovxwiwiu9M82YMUNKlSolt9xyS6H2g8jxUvdq1aolbdq0kalTp8qHH34o99xzjzz33HMyadKk4H8pRJRXevfAAw/Itm3bpG/fvrJlyxbZtGmT9OrVS/bs2SMizv8cmRMb/8/ZqZsOHz4c8j7OnDkjr7zyilx44YUSGxsrFStWlEqVKskPP/wg2dnZ+dcbNmyYxMfHS7NmzeTCCy+UAQMGyIoVK7R9vfjii7Jp0yapUaOGNGvWTEaNGiW//fZbwDGUKVNGcnNzLdtPnDiR/3M4h1d6B/fxYvcyMzOlU6dOkpSUlL/eEJzFa71r0KCBZGRkSK9evfLnH+3cubMopUL+/RAZXunek08+KeXLl5dBgwaF/Hug6Hild77Uq1dPbr75Zvn6668lLy8v5N8PkeGV7p197/qPf/xD23522o1Vq1aF/Psh/LzSu3MdOXJE5s+fL+3bt9fmn4ezeKV7s2bNkn79+slbb70l9913n3Tr1k3efvtt6d27twwbNkwOHDgQ8u+H8PNK7+6//355/PHHZcaMGZKWliaNGjWSX3/9VR599FEREYmPjw/59ysSdn9lxElSUlJU3bp1C3x98ytEzzzzjBIRdc8996iZM2eq//73v+rLL79UaWlpKj09XbvtkSNH1KxZs1SfPn1UcnKyEhH11FNPadfZvXu3eu2119TNN9+s4uLiVOnSpdXnn3/ud0wZGRnq4osvtmxftGiREhH1ySefFPj3Q9HwQu/OxVRU7uGl7h06dEhddtllqnz58mrz5s0F/p1Q9LzUO9OUKVOUiKiff/45pNsjstzevW3btqno6Gg1YcIE9fvvv+dfmjdvrurXr69+//13deDAgQL/figabu+dP0OHDlUiorKzs0O6PSLLC927/vrrff5d/emnn5SIqPHjxxf490PR8ELvznV2ituZM2cW+Dawhxe617p1a9WyZUvL9o8++kiJiPryyy8L/PuhaHihd2cdPHhQffPNN+qHH35QSik1fPhwJSKO/3yFExvn6NevnxIRtXLlygJd3yxk48aNVdu2bS3Xq1atmqWQ58rNzVWdOnVSJUqUUMePH/d5naysLFWtWjXVqlUrv2N65JFHVIkSJSxvMMaMGaNERP31119+b4+i54XenYsTG+7hle4dP35ctW7dWsXFxRX4d4F9vNI7X8aPH69ERK1Zsyak2yOy3N69r7/+Wptv2dfloYceKtDvhqLj9t750717d1W6dGnL3NBwBi9077HHHlMiohYvXqxtX7x4sRIR9e9//9vv7VH0vNC7c3Xo0EHFx8ero0ePFvg2sIcXule/fn3VvHlzy/bZs2crEVELFy70e3sUPS/07nyaNm2qqlev7vjXeUxFdY5HH31UypYtK/fee69kZWVZfv7rr7/Kq6++et7blyhRwjL9xJw5c2TXrl3aNvPrYzExMXLJJZeIUkpOnToleXl52leOREQqV64sKSkpPqeZOlePHj0kLy9Ppk6dmr8tNzdXpk2bJs2bN5caNWr4vT2Knhd6B3fyQvfy8vLk1ltvlVWrVsmcOXOkRYsWfq8P+3mhd3v37rVsO3XqlLz33ntSpkwZueSSS/zeHvZwe/caNmwo8+bNs1zS0tIkNTVV5s2bJ3379j3v7WEPt/dORGTfvn2Wbd9//7188skn0q5du/y5oeEsXuje2TUN3n77bW37W2+9JSVLlpRrrrnG7+1R9LzQu7P27dsnixYtkq5du0pcXFyBbgP7eKF79evXl++++062bdumbZ85c6ZER0fLpZde6vf2KHpe6J0vs2fPlrVr18rgwYMd/zqvpN0DcJK6devKjBkz5NZbb5WLL75YevXqJQ0bNpSTJ0/KypUrZc6cOdKnT5/z3v7GG2+U0aNHy9133y0tW7aUH3/8Uf79739LnTp1tOu1a9dOqlSpIq1atZLk5GT56aefZNKkSdKpUydJSEiQQ4cOSfXq1aVHjx7SuHFjiY+Pl0WLFsnatWvl5Zdf9vs7NG/eXHr27CnDhw+XvXv3Sr169eTdd9+VP/74w/KCEM7ghd6JiEyaNEkOHTqUv1DRp59+Kjt37hQRkUGDBklSUlLoDxIiwgvdGzJkiHzyySfSuXNnOXjwoHzwwQfaz++8886QHx9Ehhd6179/f8nJyZE2bdpItWrVJDMzU/7973/Lzz//LC+//LLz5yEtptzevYoVK0qXLl0s28ePHy8i4vNnsJ/beycicuutt0qZMmWkZcuWUrlyZdmyZYtMnTpV4uLi5Pnnnw/Hw4QI8EL3Lr/8crnnnnvknXfekdOnT0t6erosWbJE5syZI8OHD5eUlJRwPFQIIy/07qzZs2fL6dOn5Y477ijMQ4Ii4oXuDR06VBYuXCitW7eWgQMHSoUKFWTBggWycOFCuffeeznmOZAXerds2TIZPXq0tGvXTipUqCCrV6+WadOmSYcOHeShhx4Kx8MUWUX7BRF32LZtm7rvvvtUrVq1VExMjEpISFCtWrVSEydOVCdOnMi/nvkVohMnTqghQ4aoqlWrqjJlyqhWrVqpVatWqfT0dO0rRFOmTFFt2rRRFSpUULGxsapu3bpq6NCh+dNH5ebmqqFDh6rGjRurhIQEVbZsWdW4cWM1efLkAo3/+PHj6pFHHlFVqlRRsbGxqmnTpuqLL74Iy2ODyHF772rWrHneqTF+//33cDxEiBA3dy89Pd3vtCxwLjf3bubMmSojI0MlJyerkiVLqgsuuEBlZGSo+fPnh+3xQeS4uXu+pKenq7S0tJBui6Lj5t69+uqrqlmzZqp8+fKqZMmSqmrVqurOO+9U27dvD9vjg8hxc/eUUurkyZNq1KhRqmbNmqpUqVKqXr166pVXXgnHQ4MIcnvvlFLqqquuUpUrV1anT58u9OOBouP27q1Zs0Z17NhRValSRZUqVUrVr19fjRkzRp06dSosjw8iw829++WXX1S7du1UxYoVVWxsrGrQoIEaO3asys3NDdvjE0lRShnfeQEAAAAAAAAAAHAoZ0+UBQAAAAAAAAAAcA5ObAAAAAAAAAAAANfgxAYAAAAAAAAAAHANTmwAAAAAAAAAAADX4MQGAAAAAAAAAABwjYid2HjttdekVq1aUrp0aWnevLl8++23kborIB+9g13oHuxA72AXugc70DvYhe7BDvQOdqF7sAO9QyiilFIq3DudPXu29OrVS9544w1p3ry5jB8/XubMmSNbt26VypUr+73tmTNnZPfu3ZKQkCBRUVHhHhqKmFJKDh8+LCkpKRIdHdkvCBWmdyJ0z2vc0j165y1u6Z0I3fMat3SP3nmLW3onQve8xi3do3feU1Td45iHc3HMg1045sEOQfVORUCzZs3UgAED8nNeXp5KSUlRY8eODXjbHTt2KBHh4rHLjh07IlE1TWF6pxTd8+rF6d2jd968OL13StE9r16c3j16582L03unFN3z6sXp3aN33r1Eunsc87jY0TulOOZxsad7HPO4hNq7sJ9uO3nypKxfv14yMjLyt0VHR0tGRoasWrXKcv3c3FzJycnJv6jwf4EEDpCQkBDR/QfbOxG6V1w4rXv0rnhwWu9E6F5x4bTu0bviwWm9E6F7xYXTukfvio9Ido9jHs6HYx7swjEPdihI78J+YmP//v2Sl5cnycnJ2vbk5GTJzMy0XH/s2LGSlJSUf0lNTQ33kOAAkf4qWLC9E6F7xYXTukfvigen9U6E7hUXTusevSsenNY7EbpXXDite/Su+Ihk9zjm4Xw45sEuHPNgh4L0LrKT8xXA8OHDJTs7O/+yY8cOu4eEYoLuwQ70Dnahe7ADvYNd6B7sQO9gF7oHO9A72IXu4ayS4d5hxYoVpUSJEpKVlaVtz8rKkipVqliuHxsbK7GxseEeBoqZYHsnQvcQHhzzYAeOebALxzzYgWMe7MIxD3bgmAe7cMyDHTjmoTDC/o2NmJgYadKkiSxevDh/25kzZ2Tx4sXSokWLcN8dICL0Dvahe7ADvYNd6B7sQO9gF7oHO9A72IXuwQ70DoUS5EL1BTJr1iwVGxurpk+frrZs2aL69eunypUrpzIzMwPeNjs72/ZV17mE/5KdnR2JqoWtd0rRPa9enN49eufNi9N7pxTd8+rF6d2jd968OL13StE9r16c3j16591LpLvHMY+LHb1TimMeF3u6xzGPS6i9i8iJDaWUmjhxokpNTVUxMTGqWbNmavXq1QW6HWX05qUo/gArFXrvlKJ7Xr04vXv0zpsXp/dOKbrn1YvTu0fvvHlxeu+UontevTi9e/TOu5ei6B7HPC529E4pjnlc7OkexzwuofQuSimlxEFycnIkKSnJ7mEgzLKzsyUxMdHuYfhF97zJ6d2jd97k9N6J0D2vcnr36J03Ob13InTPq5zePXrnXXQPdqB3sAvdgx0K0ruwr7EBAAAAAAAAAAAQKZzYAAAAAAAAAAAArsGJDQAAAAAAAAAA4Bol7R4AAMCZSpQooeVevXppecSIEVquWbOm3/0tW7bMsm3hwoVafvXVV7Wcm5sbcJwAAACwV1xcnGVb5cqVtWy+tvzrr7+0fOrUqfAPDAAAeBbf2AAAAAAAAAAAAK7BiQ0AAAAAAAAAAOAanNgAAAAAAAAAAACuwRobHtOkSRPLtjZt2mh51qxZWt6zZ09ExwT79ezZU8tmB0REoqP185zmbebOnRv+gcHRzDU13nzzTb/XV0r5/bl5LBIRad26tZYzMjK0/Nhjj2l5w4YNfu8DAAAA4RcVFaXltLQ0LY8bN85ymw4dOmh5/fr1Wr7lllu0/NtvvxVmiABQZLp27WrZZr53bdq0qd99bNu2Tcvvvvuu5Tpjx44NYXRA8cE3NgAAAAAAAAAAgGtwYgMAAAAAAAAAALgGJzYAAAAAAAAAAIBrsMaGw1133XVafuihh7TcuHFjLSckJFj2kZiYqOVHH31UyxMmTNAyc/h5z+DBg7V85syZgLcJtF4CvC8uLs7vzw8cOKDlQOtfXHTRRZZtqampWr722mu1PH/+fC2PHj1ay4HW/UDxFB8fr2Vf89tu3bpVy7t3747omAAgVOXKldOyuZaBuS5aUlKSZR9HjhzR8meffablt956S8uLFi0KdpjwGHNNDfN959SpU7Xsa61H8z3Hxo0btXzw4MFCjBBOkJycrOWsrCwtx8TEWG4TaN0Bc+2VmTNnannUqFFavv766y37MNePDPT+t0SJEn5/Dtxxxx1afv/99y3XycvL0/K+ffu0bPbswgsv1PKTTz5p2afZ/z/++CPgWIHihG9sAAAAAAAAAAAA1+DEBgAAAAAAAAAAcA1ObAAAAAAAAAAAANdgjQ0bPfbYY5ZtnTt31nJaWpqWS5UqpeVAc9qLWOc7rVSpkpYHDRqk5enTp2t5z549Ae8DztaiRQst+1o/w5xH18wofsy5k5cuXaplc77uQPN9Vq1a1bKtZcuWWp49e7bf2zzzzDNaXrlypWWfmzdv9jsOeI95vOrQoYOWR44cabmNOadtenq6ltesWROm0QFA4dSqVUvLffv29Xv9bdu2WbaZr//NOezNY6Cvv9koXipWrKhl8z2jueaGr/cOmZmZWjbXcjx06FAhRgg7NGjQQMvmej1TpkzRcuvWrS376Nixo9/7yMnJ0fKAAQP8Xt/smYh1TQ1zraL//ve/Wm7YsKGWN23a5Pc+4X19+vTRsrm+lbnepIi1q//5z3+0bK4DuGrVKi2bn/+JiHTq1EnLr732mu8BwzPat2+vZfN4BR3f2AAAAAAAAAAAAK7BiQ0AAAAAAAAAAOAanNgAAAAAAAAAAACuwRobEVS3bl0tP/fcc1ru0aOH5Tbm2gd79+7V8sSJE7VszlPqizkn30svvaRlc57x/v37a3nUqFEB7wPOZvbKnHNURCQ6Wj/P6WsdDhQvp06d0nJh55r1tV7PJ598ouWXX35Zy0OGDNGyOd/ziBEjLPu87bbbQh0iXCIuLk7LtWvX1vKzzz6rZfPvnIj1mGfOWc8aGwDcwlxTo1GjRpbrmMc88zh60UUXhX9gcLWrr75ay23bttWyufbjwYMHLfvo1q2bln/99dcwjQ5FpX79+lr+/PPPtWy+ZzQ/8yiIrVu3annw4MFa7tWrl5YXL16sZXONUF/MPi9ZskTL5rpCZt9FRE6ePBnwfuBeCQkJWja7bB6/Bg4caNnHunXr/N6H+bc3KSkp4Lh8rSEDdzGf55iYGC2b71179+6t5Xfeecfv7UVE3nvvPS1/8803Wvby53t8YwMAAAAAAAAAALgGJzYAAAAAAAAAAIBrcGIDAAAAAAAAAAC4BmtshFGtWrW0vGDBAi37muM7kK5du2o5lDm/P/vsMy0//vjjfq//5JNPapk1NtwvKipKy+Y8y76uc9VVV2n5ww8/DP/AUOyZ63gMGzZMy+3bt9eyOW94enp6ZAYGRylbtqyWb7/9di2b62OEMle8r7lKAbuZf5u7dOliuc64ceO0PHToUC3Pmzcv7ONC0apSpYrfn//5559aNv+2+pKbm6vl1atXBz8weFq5cuW0XLp0ab/XN+cIF6FXXmCuzbh582Ytd+zYUcvm2hXm+p6+rFy5Uss5OTla/vLLLwPuI5Dly5dr2VwLoXnz5lr29RlIoM9R4G7mWrPJyclaHj9+vJYDrafhy8yZM7VcrVo1Lfv6zMVc1wbO1qxZM8s2cx3RQJ8Nmz0w93n06FHLbSZMmKBls5/33nuv3/t0M76xAQAAAAAAAAAAXIMTGwAAAAAAAAAAwDU4sQEAAAAAAAAAAFyDExsAAAAAAAAAAMA1WDw8CE2aNNHywIEDtdyrV6+g9udrAecHHnhAy6EsFh6IuRClmeE9Siktm4vAiVj7OHjwYC2bi5ECRcHsbqAMbypfvryWH3nkES0HWoDNlxMnTmh50aJFwQ8MOIe5wLOv11cHDx7U8smTJ7VcsWJFLbdt21bLr732mmWf5uK85sKucL8ePXr4/XlqaqqWa9asablOnTp1/O7ju+++0/KhQ4cKNjh4Ro0aNbR87bXXajkpKUnLK1as0PLUqVMjMzDY6pdfftFy586dtfzee+9p+eGHH9by/v37IzOwQvr222+1fOWVV2r5rrvustzG7Pgff/wR9nGh6DzzzDNaNheQz8zM1PK7774bcJ+lSpXS8uuvv65l83XdDz/8oOUnnnjCss/jx48HvF/Yx3y9X7p0act1zM/fpk+frmVz4e89e/ZouVKlSlpu3Lix5T6efvppv/dx9dVXa3nDhg1aPnbsmGWfbsE3NgAAAAAAAAAAgGsEfWJj2bJl0rlzZ0lJSZGoqCj5+OOPtZ8rpeSpp56SqlWrSpkyZSQjI0O2b98ervGimKJ3sAvdgx3oHexC92AHege70D3Ygd7BLnQPdqB3iKSgT2wcPXpUGjdu7POr8CIiL774okyYMEHeeOMNWbNmjZQtW1bat29vmfIBCAa9g13oHuxA72AXugc70DvYhe7BDvQOdqF7sAO9QyRFqUJMUB4VFSXz5s2TLl26iMj/PcuWkpIiQ4YMyZ//Ojs7W5KTk2X69Oly2223BdxnTk6OZf7OohAXF6flTp06Wa4zZcoULScmJvrd56pVq7S8c+dOLZtzhItY5/HLy8vzex+hMOdDNecSNJUsWfilWLKzswM+XgUVid6J2Ne9omDO6efrn705N6B5nRIlSoR/YEXA6d3zcu/CwZzzu1GjRlreu3ev5TYpKSkRHVNBOL13Iu7qnnl8+vrrr7Wcnp4e9D7NeUTNOewXLlwY9D6dwOndc1PvTLVq1dKyubbLv/71Ly37Wktt4sSJWjbXwzDnx23Xrp2WN23aZNnnsGHDtLxx40Yt+1pXK9yc3jsRd3Xvsssu0/LatWu1bL4mO336tJZzc3Mt+yxbtqzf+zSPq9ddd12gYTqC07vn5N6Z84APGTJEy+b6erGxsVq+/vrrtbx8+fJCj6ly5cpaNte4FLEe07Zs2aLl7OxsLefk5BR6XL6Eq3sc8+xhHmfXrVsX8DbmOhzm39uiwDEvfMz3mZdeeqmWzW8MmO9DfXn11Ve13L9/fy3/9ttvWs7IyNDyn3/+GfA+7MIxr2AaNGhg2fa///1Py+YaPkuXLg3qPsz1MkREvvrqKy2vX79ey48//riWzdd9TlWQ3oV1jY3ff/9dMjMztX+cSUlJ0rx5c8uH/EC40DvYhe7BDvQOdqF7sAO9g13oHuxA72AXugc70DsUVuH/K/45zn7bIDk5WduenJxs+SbCWbm5udr/KorU/6iAd4XSOxG6h8LjmAc7cMyDXTjmwQ4c82AXjnmwA8c82IVjHuzAMQ+FFdZvbIRi7NixkpSUlH+pUaOG3UNCMUH3YAd6B7vQPdiB3sEudA92oHewC92DHegd7EL3cFZYv7FRpUoVERHJysqSqlWr5m/PysqyzGF41vDhw+Xhhx/Ozzk5OUVSyIYNG2q5bt26Wp45c6blNoHWIDh8+LCWn3rqKS27ZQ4ztwmldyL2dc8OZld9zbdtzgVeFHNyu52bjnlucdVVV2m5Xr16No3EuYrjMc88ht1xxx1aNtc2MNfJ8jXXqTm3uK91r87l1jU3wqm4HfPM48/IkSO13KZNGy2b/9Ps+++/t+yzTp06Wr7iiiu03LlzZy2vWbNGy0888YRlnxs2bLBs85LieMxr2rSplgOtc2b+j0ZzLmcR6/os5nHUXKuoZcuWWl65cqXfMXiR1495Z3+/s8z1LMw5rY8ePaplc674gjDXeunatauWBw4cqGVfj/OpU6e0fODAAS3PmTNHyy+88IKW9+/fX6Cx2qU4HvPgDF4/5pnMdQ7++9//atlcS23y5MlaNj8fFBG5++67tbx7924tm6/7zM8QiyO3H/PM12jvvvtuwNuY3TKn3Dp58qTf25trXomIlCpVSsvmZ97mewwvfT4d1m9s1K5dW6pUqSKLFy/O35aTkyNr1qyRFi1a+LxNbGysJCYmahcgGKH0ToTuofA45sEOHPNgF455sAPHPNiFYx7swDEPduGYBztwzENhBf2NjSNHjsgvv/ySn3///XfZuHGjlC9fXlJTU2Xw4MHy7LPPyoUXXii1a9eWESNGSEpKSv6K90Ao6B3sQvdgB3oHu9A92IHewS50D3agd7AL3YMd6B0iKegTG+vWrZO2bdvm57Nf/endu7dMnz5dHn30UTl69Kj069dPDh06JFdffbV88cUXlikfgGDQO9iF7sEO9A52oXuwA72DXege7EDvYBe6BzvQO0RSlDInrrZZTk6OJCUlhX2/cXFxWl66dKmWL7/88oD7MOfQ27Vrl5bNNTWmT58exAiLzooVK7TcvHlzLZtzwvXt27fQ95mdne34r4ZFqntO0LNnTy3PmjXLcp1Aa8gEmt/ZqZzePS/3LhQfffSRlm+66Sa/19+7d69lW0pKSljHFAqn907EW90z19B45513tGyu3SLie17cc50+fVrL5leh161bF8wQi4zTu+fk3plzzz766KNavvLKK7VsvpYcO3aslkuWtP7/oRtvvFHL//jHP7S8efNmLZ87d7CI73U7nMDpvRNxdvdq1qypZXOuZXMthNWrV2u5Y8eOWs7Ozg54n+d+wCAi2hQQIiL/5//8Hy0HWofILk7vnpN7d9FFF2l5woQJWr7++uu1PG/ePC337t1by0eOHLHchznH9/jx47Vs/m015w0319MQsf59Nj/4Mn9u/h7Lly+37DMUdM9dZs+ereXu3bv7vb75N19EZOPGjeEcUkjoXeQ89NBDWh43bpyWzc9DfL2XMD8j7NChg5bN13luQvcKxnxNJiIybdo0LX/33XdaPnHihJbNdf6mTp2q5dGjRwccR0JCgpbN13nt27cPuA8nKEjvwrrGBgAAAAAAAAAAQCRxYgMAAAAAAAAAALgGJzYAAAAAAAAAAIBrBL14uFtNmTJFywVZU8NkzqVszv3ua15RJ7jsssu0nJqa6vf6P/74YwRHAzsMHjxYy2fOnLFcJzo6OuB1gHAz18Mwj1eB1kE4fvx4uIcEFzDXzTJ7Y87ZHQpzfYT09HQtO3WNDfhWpkwZLd9zzz2W65hraiQnJ2t51KhRWjbXqzp48KCW16xZY7kPc62EAwcOaNmcz5nXZMWDud6d2RNzfTzzPUhB1tQwbd261e/PzfXZnLrGBkJ3ySWXaLlOnTpaNt8LmGu/mHOC33nnnZb7eOKJJ7Rsruth3oe5jtDnn39u2efOnTu1fM0112jZXDvBfM0AAL58/PHHWjbXMYiPjw+4j0Brp8H7Fi5caNlmrs+SkZGhZfN956ZNm7T8/PPPa9l8XyMismPHDi2b72vefPPN84zY/fjGBgAAAAAAAAAAcA1ObAAAAAAAAAAAANfgxAYAAAAAAAAAAHANz66x8a9//UvLt99+u9/rHz58WMs333yz5TrmGhtu0bdvXy2bc9qb85SOHz8+0kNCETPnm1dKWa6za9cuLd9yyy0RHROcpXLlypZtVatW1XLHjh21bM7t+NFHH/m9D3PeZBGRXr16adlcA8js6r59+7TcuXNnv/cJb6pdu7aWhwwZEvH7NOcih7uYa6uZr41ErGtNPf3001p+4403tHzo0CEtm689GzRoYLkPcz22BQsWaPm7777TMutdFQ8rV67UsjkP8pgxY7T8999/F/o+T58+reWjR49quWzZsoW+Dzhbo0aNtGy+FtyzZ4+WZ86cqWWzQ77WYalfv76WzfcbX331lZanT5+uZfPfhohIbm6ulsuVK6dl8328eWwHfDG7yNoI3teyZUstz5gxQ8sJCQl+b+9rLcixY8dquXXr1iGODl7Stm1bLXfp0kXLiYmJWjbf2+7fv1/Lu3fvttxHhQoVtPzhhx8GO0zX4q88AAAAAAAAAABwDU5sAAAAAAAAAAAA1+DEBgAAAAAAAAAAcA1ObAAAAAAAAAAAANfw7OLhl156qZZ9LZZ8riVLlmjZrQuF33fffZZt/fr107L5WLAwpfcV5DkP9G8E3pKSkqLlTz/91HKdyy67TMuBOvLEE0/4/fnixYst24JdkPm9997T8pYtW4K6PbyhYcOGWjYXEzeZizyLiCxatEjLNWvW1HLTpk21HBMTo+X4+HjLPs2FoWEf8/kaNmyYls3nW0Tkrbfe0vL777+vZbNHycnJWjYXAvT1t9ZcHHzWrFla3rdvn+U28L6dO3dquX///hG/z71792rZ7Gawf5/hPgsWLNByt27dtGwe42rUqKHl6tWra9n82ywicvDgQS2/+OKLWjYXN/W1IKpp5MiRWh4wYICWc3JytLxjx46A+4T3VKxYUcu++nkuc1H6U6dOhX1MsJf5Ou2NN97QclJSkpZHjx6t5XXr1ml5xIgRlvto3ry5locOHarll19+Wct8Flc8mJ9Z/PTTT36vv3btWr8/3759u2XbV199peW+fftqefLkyVo+evSo3/twE76xAQAAAAAAAAAAXIMTGwAAAAAAAAAAwDU4sQEAAAAAAAAAAFzDs2ts9OrVS8uB5ob/4IMPIjmciKlVq5aWhw8fbrlOiRIltHz48GEtP/3002EfF5zltttu07I5p7dI4Hlz4W7mmhrz58/XcuPGjSM+hoyMDMu2QMfm3377TcvmHOAonrZu3arlv/76S8vmnKFz5syx7MOcu9T8W2h20/xbWrKkZ19CeYI5N/xVV12l5dOnT1tu88cff2g5MzNTy+a6Hf/85z+1fPXVV2t5//79lvt47bXXtLx69WrLdeAt5no8rMUDp4iKitKy+XeuUqVKWjbnhk9ISNDynj17LPcxfvx4LZvvuf/++2+/YzTXSRCxrgFXvnx5LU+dOlXLP//8s9/7gDf17NnT78/N/n/zzTeRHA6KmK+11D766CMtm6/1H3zwQS2br9lMvo5fy5Yt0/Lzzz+v5XfeeUfLBw4c8Hsf8IZg11KZO3euls2ump/diVi7ZK43ZR7zvIRvbAAAAAAAAAAAANfgxAYAAAAAAAAAAHANTmwAAAAAAAAAAADX8OwE0YcOHdJyUlKSPQMJswoVKmh54cKFWvY1l6A5H9uwYcO0PH369PAMDo41ePBgLfua4y86Wj/PGWjtA7jLpEmTtHz55ZcHvM2xY8e0PHr0aC2/++67Wk5LS9OyuY5H2bJlA96nqWrVqlrOzs4Oeh/wno0bN2q5a9euWq5WrZqWfc2v3aNHDy2bazKY85CuWrVKy+Z6VXAWc52VBQsWaPnOO++03MZcn+2iiy7yex+33HKLls2/o76Y88Wbc8Vv3rxZy6dOnQq4TzhLmTJltPzqq69quW/fvkU5HOC89u7dq+X169druW7dulpu0aKFls33E+brPhGRJUuWaNlcl8O8jwsvvFDLvXv3tuyzVatWWl65cqWWX3rpJS3n5eVZ9gFvefvtty3bfHXnXOnp6Vpevnx5WMeEolW5cmUtL1q0KOBtnn32WS2/+eabQd3nt99+a9k2Y8YMLd9+++1abtq0qZa/+OKLoO4TxUOgz+J27txp2bZixQotm5/7mmuXfvnllyGOznn4xgYAAAAAAAAAAHANTmwAAAAAAAAAAADX4MQGAAAAAAAAAABwDc+usWHOlzdu3DibRlI4Dz30kJYvueQSLZvzkBbE999/X6gxwX3MOXF9zdlnzidvZribub5FQZ7ftm3banndunVavuCCC7RszmVr3qev+ed9rfdyrri4OC2PGjVKy8ePH7fcxpzPGe5jdic2NlbL5nzZu3bt8pvr169vuY9rr71Wy+XKldPywYMHtfyf//zH7xjgLObzN2HCBC1Xr17dcpuMjAwtX3HFFVo2/3aWKlXK7xjM9TREREaOHKllc620Rx55RMv79u3zex9wntatW2vZnPfbKSpVqqTlxo0ba5n1Xbxvx44dWjaPk40aNdJyoPXZrrzySsu2119/Xctmr8z3tua6mKdPn7bsc9OmTVqeOHGilnfv3u13nHA/8z3INddcE/A25nsGX+8h4F7NmzfXcp06dSzX+fDDD7X8/PPPa/nkyZNB3aevv5Njx47VsrnGhrkuIGtsIBS+Ps+bPHmyls33OnfddZeWWWMDAAAAAAAAAADABpzYAAAAAAAAAAAArsGJDQAAAAAAAAAA4BqeXWPDFGg++SlTpmi5Ro0aluu88sorQd3njTfeqOWCrIcxYsQILZvzjAby3XffWbZdd911Ws7Ozg5qn3A/cw4+X+samOsf+Jq3D+5lPp8FeX7NOYofe+wxLQ8YMEDLVatW9Xsfvnr3119/afnvv//WsnncbNKkiZaffvppyz67dOnid5+wl7kuQffu3S3X6dSpk5ZzcnL85v3792u5YcOGWr7qqqss91GlShUtHzhwQMvm6wLzPuEuP/74o5aHDBliuc6wYcO03KNHDy2XLl3a73388MMPWp4zZ47lOr/++quW9+7dq2Wzh3C/Y8eO2T0En8xjcUJCgpbnzp1blMOBA2zZskXL5pqV5hpBl156qZZ9vX825/g2Xxua79H37Nmj5aVLl1r2+dJLL2nZfP/LexjvM/8e16xZM+Bt1q9f7zfD3d555x0t+/r8r2fPnhEfh/m6zhyHuQ4XigfzfWe7du20/N577wW1v1q1alm2mWtKmq/zzOOkmf/888+gxuAkfGMDAAAAAAAAAAC4Bic2AAAAAAAAAACAawR1YmPs2LHStGlTSUhIkMqVK0uXLl1k69at2nVOnDghAwYMkAoVKkh8fLx0795dsrKywjpoFD90D3agd7AL3YMd6B3sQvdgB3oHu9A92IHewS50D5EU1ImNpUuXyoABA2T16tXy5ZdfyqlTp6Rdu3Zy9OjR/Ov861//kk8//VTmzJkjS5culd27d0u3bt3CPnAUL3QPdqB3sAvdgx3oHexC92AHege70D3Ygd7BLnQPkRSlCrG61r59+6Ry5cqydOlSadOmjWRnZ0ulSpVkxowZ+Qsu/vzzz3LxxRfLqlWrfC7eacrJyQl6wWxf4uPjtTx79mwtt2/fPuh9mgvpBnroypcvr+UyZcpo2deCRsE+HRs3bvSbRawLZNqxeHh2drYkJiaGbX9O7p4TmYs2++qZ2UfzOiVKlAj/wIpAOLvn5t598cUXWs7IyAh4G3Nh79TU1EKNYfv27ZZtAwcO1PLixYu1/PHHH2v5xhtv1LKv4+imTZu0fPfdd2t5w4YNAcdaWBzzzs98zu666y7Ldd566y2/tylZsmTYx/Xhhx9qedSoUVo2e+VUHPMKxtdj1LdvXy2PHj1ay3///beWp06dqmVzseWff/65MEN0FY55/z9zQcgnnnhCy23btrXcxnydVhTatGmj5SVLlmj5jTfe0PIDDzwQ6SGFhGNe5JgLj7Zq1UrL3bt317KvHjdu3FjL5mtJc8HfTz/9VMvff/99wQZrA7oXOXXr1tWyuShuuXLltPz+++8H3Ofy5cu1fM0114Q0NrvRO98+++wzLXfo0MFyneeee07Lzz//vJbP/ZA9VNWrV9eyuSCz+dowLS2t0PdZVOhewZQtW9ayrVevXloeNmyYlh977DEtly5dWsv//Oc/tVyvXj3LfZjvZc3PvM3Xox988IFlH05UkN4Vao2Nsx+Qn/0Af/369XLq1CntA7MGDRpIamqqrFq1yuc+cnNzJScnR7sAgdA92IHewS50D3agd7AL3YMd6B3sQvdgB3oHu9A9hFPIJzbOnDkjgwcPllatWknDhg1FRCQzM1NiYmIsZ9CTk5MlMzPT537Gjh0rSUlJ+ZcaNWqEOiQUE3QPdqB3sAvdgx3oHexC92AHege70D3Ygd7BLnQP4RbyiY0BAwbIpk2bZNasWYUawPDhwyU7Ozv/smPHjkLtD95H92AHege70D3Ygd7BLnQPdqB3sAvdgx3oHexC9xBuIU1SPXDgQFmwYIEsW7ZMm0OuSpUqcvLkSTl06JB2pi0rK0uqVKnic1+xsbESGxsbyjD8OnLkiJbNOc26du2qZXMeWV+qVaum5UIsT1Jg5pze5j/Wfv36aXnPnj0RH5Od3NA9JzK76msO3Ojo6IDXKa680LsXXnhBy1deeaWWzf8dISJSs2ZNLQd7zNuyZYuWr7vuOst19u3b53cf5voYXbp00fLDDz9suY05V2mFChX83oeTeaF7JrNHn3zyieU6Tz75pJbvuOMOLZvP8bFjx7Rs9srXWizLli3T8sSJE7VcnNZHMHmxd+baa+brJxGRkSNHavnkyZNanjRpkpZff/11LR8+fLgwQ4R4o3u7du3S8hVXXKFlc15lEZGXX35Zy2b3wsF8nXfrrbdq2Tw2f/XVV2Efg1N5oXeRcOrUKS2baxT8+OOPWj5x4oRlH8ePH9cy7y90dM+3W265RcvPPvuslkP5HObSSy/V8n333aflnTt3Br3PhQsXBn0bJ/Bi78x1ZX2tsWGuMWD2zHwvYK5R+csvv2jZ13vMmTNn+h2nuZ5kcePF7pl8jclc83nz5s1aXrBggZbN9ZnN9SVPnz5tuY97771Xy3v37tVyONaQcaqgvrGhlJKBAwfKvHnz5KuvvpLatWtrP2/SpImUKlVK+8e6detW+euvv6RFixbhGTGKJboHO9A72IXuwQ70Dnahe7ADvYNd6B7sQO9gF7qHSArqGxsDBgyQGTNmyPz58yUhISF/rrOkpCQpU6aMJCUlSd++feXhhx+W8uXLS2JiogwaNEhatGhRoFXsgfOhe7ADvYNd6B7sQO9gF7oHO9A72IXuwQ70Dnahe4ikoE5snP3K/TXXXKNtnzZtmvTp00dERF555RWJjo6W7t27S25urrRv314mT54clsGi+KJ7sAO9g13oHuxA72AXugc70DvYhe7BDvQOdqF7iKQoVRQLRQQhJydHkpKSIn4/5nx4bdu21XLnzp0ttzH/EZYuXdrvPvPy8rS8e/duLQ8dOjTgOL/++mstHzhwIOBtnCg7O1sSExPtHoZfRdU9O/Ts2VPLvhZqMuegNw8NJUqUCP/AioDTu2dX766++motf/7555brlC1bVstmJ/78808tP/PMM1qeO3euls21j8IhISHBss2ck/LQoUNajsTc5San907EXce85ORkLTdu3FjL5teZzb+V27dvt+xz69atWjZ74dZ5wJ3evaLqnTkXrTn3sjnPsoj1OX/33Xe1PG7cOC2HMh+3Vzm9dyL2HfPMNTXGjh1ruY65dsFLL72k5f/9739a9rWWwblKlSpl2fb4449r2VxTxlynz1xb0Kmc3j03/a1FcOhe+AwfPlzLwa6pcfDgQcu2+fPna9lcty8cLrnkEi1v27Yt7Pdhone+mZ9V+Fo/8rHHHtPyXXfdpeVKlSpp2VzDz1wzyNffWvO5WblypZbNzxnN96lORvcixzw+xcTEaNlcU+P+++8PuE9zzZiPPvpIy5H4bCYSCtK7oNbYAAAAAAAAAAAAsBMnNgAAAAAAAAAAgGtwYgMAAAAAAAAAALhGUIuHe4k5/7Y5F7yZfalfv76Wb7jhBi0fPnxYy2+//XYwQwQixtfc8dHR0QGvA+8w5/N28nyZ/pjH2fNtg7tlZWVp2ZxvHjBdf/31WjbX1PA1L/IXX3yhZXPBQtbUQCjM1//Vq1e3XKd///5a/vjjj7WcnZ2t5WXLlvm9z3r16lm2XXzxxVo2/1beeeedfvcJAJEyYcIELe/YsUPL06dP93t7c+54kYLNQX+uKVOmaNnX2ge//fablnm/7Bzm+ra+1qY117gdP368lvv27avlbt26ablRo0Za3rt3r+U+PvjgAy2b61m5aU0NFJ1p06YFdf3169dbtm3evFnLp06dKtSY3IRvbAAAAAAAAAAAANfgxAYAAAAAAAAAAHANTmwAAAAAAAAAAADXKLZrbITDtm3b/GbAKebMmeM3AwDgJXXr1tVyXFyclhcvXmy5zYgRI7TM6zqEw/79+7U8aNAgy3XMObjT09O13KlTJy2XLVtWy2lpaVr+66+/LPdhvvYz57Q/ePCg5TYAUBSOHj2qZV/rBJ3r77//1vKkSZMC3sd9990X/MDgabt27dLy6NGj/WbAKTZu3Gj3EByFb2wAAAAAAAAAAADX4MQGAAAAAAAAAABwDU5sAAAAAAAAAAAA12CNDQAAAHjKzJkztbx8+XItm/Nzi4j8+eefER0TcD7m+hbz5s3zmwHAy0aNGuU3AwBwFt/YAAAAAAAAAAAArsGJDQAAAAAAAAAA4Bqc2AAAAAAAAAAAAK7BiQ0AAAAAAAAAAOAaLB4OAAAATzlw4IDfDAAAAABwN76xAQAAAAAAAAAAXIMTGwAAAAAAAAAAwDU4sQEAAAAAAAAAAFyDExsAAAAAAAAAAMA1OLEBAAAAAAAAAABcgxMbAAAAAAAAAADANRx3YkMpZfcQEAFueF7dMEYEz+nPq9PHh9C44Xl1wxgRPKc/r04fH0LjhufVDWNE8Jz+vDp9fAid059bp48PoXH68+r08SF0Tn9unT4+hKYgz6vjTmwcPnzY7iEgAtzwvLphjAie059Xp48PoXHD8+qGMSJ4Tn9enT4+hMYNz6sbxojgOf15dfr4EDqnP7dOHx9C4/Tn1enjQ+ic/tw6fXwITUGe1yjlsNNaZ86ckd27d4tSSlJTU2XHjh2SmJho97BcLScnR2rUqGHLY6mUksOHD0tKSopERzvuPJqG7oUf3QuM3oUfvSsYuhd+dC8wehd+9K5g6F740b3A6F342dk7EbpXnHHMC4zehR/HvIKhe+HnlmNeySIaU4FFR0dL9erVJScnR0REEhMTKWOY2PVYJiUlFfl9hoLuRQ7dOz96Fzn0zj+6Fzl07/zoXeTQO//oXuTQvfOjd5Fj52NJ94o3jnnnR+8ih2Oef3Qvcpx+zHPu6TYAAAAAAAAAAAADJzYAAAAAAAAAAIBrOPbERmxsrIwcOVJiY2PtHorr8VgGh8crfHgsC47HKnx4LIPD4xU+PJYFx2MVPjyWweHxCh8ey4LjsQofHsvg8HiFD49lwfFYhQ+PZXB4vMLHLY+l4xYPBwAAAAAAAAAAOB/HfmMDAAAAAAAAAADAxIkNAAAAAAAAAADgGpzYAAAAAAAAAAAArsGJDQAAAAAAAAAA4BqOPbHx2muvSa1ataR06dLSvHlz+fbbb+0ekuONHTtWmjZtKgkJCVK5cmXp0qWLbN26VbvOiRMnZMCAAVKhQgWJj4+X7t27S1ZWlk0jdh56Fzx6Fx50L3h0r/DoXfDoXXjQveDRvcKjd8Gjd+FB94JH9wqP3gWP3oUH3Qse3Ss8ehc8T/ROOdCsWbNUTEyMeuedd9TmzZvVfffdp8qVK6eysrLsHpqjtW/fXk2bNk1t2rRJbdy4Ud1www0qNTVVHTlyJP86999/v6pRo4ZavHixWrdunbrqqqtUy5YtbRy1c9C70NC7wqN7oaF7hUPvQkPvCo/uhYbuFQ69Cw29Kzy6Fxq6Vzj0LjT0rvDoXmjoXuHQu9B4oXeOPLHRrFkzNWDAgPycl5enUlJS1NixY20clfvs3btXiYhaunSpUkqpQ4cOqVKlSqk5c+bkX+enn35SIqJWrVpl1zAdg96FB70LHt0LD7oXHHoXHvQueHQvPOhecOhdeNC74NG98KB7waF34UHvgkf3woPuBYfehYcbe+e4qahOnjwp69evl4yMjPxt0dHRkpGRIatWrbJxZO6TnZ0tIiLly5cXEZH169fLqVOntMe2QYMGkpqaWuwfW3oXPvQuOHQvfOhewdG78KF3waF74UP3Co7ehQ+9Cw7dCx+6V3D0LnzoXXDoXvjQvYKjd+Hjxt457sTG/v37JS8vT5KTk7XtycnJkpmZadOo3OfMmTMyePBgadWqlTRs2FBERDIzMyUmJkbKlSunXZfHlt6FC70LHt0LD7oXHHoXHvQueHQvPOhecOhdeNC74NG98KB7waF34UHvgkf3woPuBYfehYdbe1fS7gEgMgYMGCCbNm2S5cuX2z0UFCP0Dnahe7ADvYNd6B7sQO9gF7oHO9A72IXuwQ5u7Z3jvrFRsWJFKVGihGWF9aysLKlSpYpNo3KXgQMHyoIFC+Trr7+W6tWr52+vUqWKnDx5Ug4dOqRdn8eW3oUDvQsN3Ss8uhc8eld49C40dK/w6F7w6F3h0bvQ0L3Co3vBo3eFR+9CQ/cKj+4Fj94Vnpt757gTGzExMdKkSRNZvHhx/rYzZ87I4sWLpUWLFjaOzPmUUjJw4ECZN2+efPXVV1K7dm3t502aNJFSpUppj+3WrVvlr7/+KvaPLb0LHb0rHLoXOroXOnoXOnpXOHQvdHQvdPQudPSucOhe6Ohe6Ohd6Ohd4dC90NG90NG70Hmid3atWu7PrFmzVGxsrJo+fbrasmWL6tevnypXrpzKzMy0e2iO9s9//lMlJSWpJUuWqD179uRfjh07ln+d+++/X6WmpqqvvvpKrVu3TrVo0UK1aNHCxlE7B70LDb0rPLoXGrpXOPQuNPSu8OheaOhe4dC70NC7wqN7oaF7hUPvQkPvCo/uhYbuFQ69C40XeufIExtKKTVx4kSVmpqqYmJiVLNmzdTq1avtHpLjiYjPy7Rp0/Kvc/z4cfXAAw+oCy64QMXFxamuXbuqPXv22Ddoh6F3waN34UH3gkf3Co/eBY/ehQfdCx7dKzx6Fzx6Fx50L3h0r/DoXfDoXXjQveDRvcKjd8HzQu+ilFIqPN/9AAAAAAAAAAAAiCzHrbEBAAAAAAAAAABwPpzYAAAAAAAAAAAArsGJDQAAAAAAAAAA4Bqc2AAAAAAAAAAAAK7BiQ0AAAAAAAAAAOAanNgAAAAAAAAAAACuwYkNAAAAAAAAAADgGpzYAAAAAAAAAAAArsGJDQAAAAAAAAAA4Bqc2AAAAAAAAAAAAK7BiQ0AAAAAAAAAAOAanNgAAAAAAAAAAACu8f8BK2aWp+JqAdIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1600x1600 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = (16,16) # Make the figures a bit bigger\n",
    "\n",
    "indices_arr = [83, 98, 92, 99, 78, 97, 90, 95, 93, 96]\n",
    "for i, index in enumerate(indices_arr):\n",
    "    image = np.array(train_100_dataset[index][0].squeeze()) # get the image of the data sample\n",
    "    label = train_100_dataset[index][1] # get the label of the data sample\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    plt.imshow(image, cmap='gray', interpolation='none')\n",
    "    plt.title(\"Class {}\".format(label))\n",
    "    \n",
    "plt.tight_layout()\n",
    "print('The shape of our greyscale images: ', image.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "V9sz_lHyqJoj"
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Note: Starting Simple</h3>\n",
    "    <p>\n",
    "Regardless of the size of the dataset, the first step is to evaluate the performance of a simple classifier. It is advisable to always start with a straightforward approach when tackling a problem and gradually build upon it to determine which changes yield improvements.</p>\n",
    "</div>\n",
    "\n",
    "# 2. A Simple Classifier\n",
    "\n",
    "In `exercise_code/models.py` we prepared all classes for you which you will finalize throughout the notebook to build an Autoencoder and an image classifier with PyTorch.\n",
    "\n",
    "![network_split](img/network_split.png)\n",
    "\n",
    "## 2.1 The Encoder\n",
    "\n",
    "Unlike to previous models, we are going to split up the model into two parts: the `encoder` and the `classifier`. The `classifier` has a fixed task, generating predictions given a one-dimensional input. On the other hand, the `encoder`'s task is to extract meaningful information from the input, enabling the classifier to make accurate decisions. \n",
    "\n",
    "For now, both networks will be similar in design and consist of linear layers coupled with auxiliary layers. This split-up will be relevant later, e.g., by using convolutional layers which are introduced in the lecture. We are going to set up the `encoder` now. \n",
    "\n",
    "Think about a good network architecture. You have complete freedom in this regard and can devise any network structure that you think might be fitting. (\\*)\n",
    "\n",
    "Have a look at the documentation of `torch.nn` at https://pytorch.org/docs/stable/nn.html to learn how to use this module in order to build your network!\n",
    "\n",
    "Then implement your architecture: initialize it in `__init__()` and assign it to `self.model`. This is particularly easy using `nn.Sequential()` where you only have to pass the list of your layers. \n",
    "\n",
    "To make your model customizable and support parameter search, do not use hardcoded hyperparameters - instead, pass them as a simple dictionary `hparams` (here, `n_hidden` is the number of neurons in the hidden layer) when initializing `models`.\n",
    "\n",
    "Here is an simple example:\n",
    "\n",
    "```python\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, self.hparams[\"n_hidden\"]),\n",
    "            nn.ReLU(),            \n",
    "            nn.Linear(self.hparams[\"n_hidden\"], num_classes)\n",
    "        )\n",
    "```\n",
    "\n",
    "Have a look at the forward path in `forward(self, x)`, which is so easy that you don't need to implement it yourself.\n",
    "\n",
    "As PyTorch automatically computes the gradients, that's all you need to do! No need to manually calculate derivatives for the backward paths anymore! :)\n",
    "\n",
    "\n",
    "____\n",
    "\\* *The size of your final model must be less than 20 MB, which is approximately equivalent to 5 Mio. params. Note that this limit is quite lenient, you will probably need much less parameters!*\n",
    "\n",
    "*In order to keep things simple, you should only use fully connected layers for this task as we need to revert the encoder architecture  later on in the notebook.*\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <h3>Task: Implement</h3>\n",
    "    <p>Implement the <code>Encoder</code> class initialization in <code>exercise_code/models.py</code>.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "jNf7FrvwMNki"
   },
   "source": [
    "## 2.2 The Classifier\n",
    "\n",
    "Now let's implement the classifier. The classifier will utilize the encoder that you have defined in the above cell. By looking at `Classifier.forward`, you can see that we are essentially concatenating the `classifier`and the `encoder` together. Therefore, it is crucial to ensure that the input shape of the classifier matches the output shape of the encoder you implemented above\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <h3>Task: Implement</h3>\n",
    "    <p>1. Implement the <code>Classifier</code> class network initialization in <code>exercise_code/models.py</code>.\n",
    "    </p>\n",
    "    <p>2. Define in the next cell your hyperparameters in a dictionary called 'hparams'.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "AawbvD1rMNkj"
   },
   "outputs": [],
   "source": [
    "hparams = {}\n",
    "########################################################################\n",
    "# TODO: Define your hyper parameters here!                             #\n",
    "########################################################################\n",
    "\n",
    "# This is just used for testing the classifier I think, not used for the submission. So keep it reasonable\n",
    "\n",
    "hparams = {    \n",
    "    \"device\" : device,\n",
    "    \"num_workers\" : 8,\n",
    "    \"epochs\" : 200,\n",
    "    \"batch_size\" : 4096,\n",
    "    \n",
    "    \"num_classes\" : 10, # There are 10 digits\n",
    "    \"input_size\" : 28 * 28, # Number of pixels in images\n",
    "    \n",
    "    \"learning_rate\" : 2e-3, # Optimizer\n",
    "    \"weight_decay\" : 1e-5, # ADAM\n",
    "    \n",
    "    \"dropout_p\" : 0.5, # Dropout probability for the classifier, reduces overfitting\n",
    "    \"latent_dim\" : 20, # Encoder output dim, Decode input dim, classifier input dim. If this it too high, overfitting will occur\n",
    "    # \"decoder_hidden\" : 50, # Decoder Hidden\n",
    "    \"encoder_hidden\" : 512, # Encoder Hidden\n",
    "    \"classifier_hidden\" : 2048 # Classifier Hidden\n",
    "}\n",
    "\n",
    "########################################################################\n",
    "#                           END OF YOUR CODE                           #\n",
    "########################################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "bOYbUg8lAmgU"
   },
   "source": [
    "\n",
    "## 2.3 Optimizer\n",
    "Lastly, implement the function `set_optimizer` to define your optimizer. Here the documentation of `torch.optim` at https://pytorch.org/docs/stable/optim.html might be helpful.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <h3>Task: Implement</h3>\n",
    "    <p>Implement the <code>set_optimizer</code> method of the <code>Classifier</code> in <code>exercise_code/models.py</code>.\n",
    "    </p>\n",
    "</div>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xrUfa-a7MNkk"
   },
   "source": [
    "## 2.4 Training & Validation Step\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <h3>Task: Check Code</h3>\n",
    "    <p> Let's take a closer look at the training pipeline outlined below. It is explicitly written here in its entirety to provide you with a comprehensive understanding of its structure. Additionally, you can refer back to this pipeline whenever you encounter any uncertainties or need guidance.\n",
    " </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "NY_lLaNWMNkk"
   },
   "outputs": [],
   "source": [
    " # One of the most crucial things in deep learning is to understand the training pipeline:\n",
    " # 1. Forward()          --> The forward pass of the network, to calculate the currnent loss.\n",
    " # 2. Backward()         --> The backward pass of the network, to calculate the gradients w.r.t the loss, calculated in the previous stage.\n",
    " # 3. Optimizer_step()   --> Update the weights w.r.t thier corresponding gradients and the learnign rate.\n",
    "\n",
    "def create_tqdm_bar(iterable, desc):\n",
    "    return tqdm(enumerate(iterable),total=len(iterable), ncols=150, desc=desc)\n",
    "\n",
    "\n",
    "def train_classifier(classifier, train_loader, val_loader, loss_func, tb_logger, epochs=10, name=\"default\"):\n",
    "    \"\"\"\n",
    "    Train the classifier for a number of epochs.\n",
    "    \"\"\"\n",
    "    optimizer = classifier.optimizer\n",
    "    classifier = classifier.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        training_loss = 0\n",
    "        validation_loss = 0\n",
    "        \n",
    "        # Training stage, where we want to update the parameters.\n",
    "        classifier.train()  # Set the model to training mode\n",
    "        \n",
    "        # Create a progress bar for the training loop.\n",
    "        training_loop = create_tqdm_bar(train_loader, desc=f'Training Epoch [{epoch + 1}/{epochs}]')\n",
    "        for train_iteration, batch in training_loop:\n",
    "            optimizer.zero_grad() # Reset the gradients - VERY important! Otherwise they accumulate.\n",
    "            images, labels = batch # Get the images and labels from the batch, in the fashion we defined in the dataset and dataloader.\n",
    "            images, labels = images.to(device), labels.to(device) # Send the data to the device (GPU or CPU) - it has to be the same device as the model.\n",
    "\n",
    "            # Flatten the images to a vector. This is done because the classifier expects a vector as input.\n",
    "            # Could also be done by reshaping the images in the dataset.\n",
    "            images = images.view(images.shape[0], -1) \n",
    "\n",
    "            pred = classifier(images) # Stage 1: Forward().\n",
    "            loss = loss_func(pred, labels) # Compute the loss over the predictions and the ground truth.\n",
    "            loss.backward()  # Stage 2: Backward().\n",
    "            optimizer.step() # Stage 3: Update the parameters.\n",
    "\n",
    "            training_loss += loss.item()\n",
    "\n",
    "            # Update the progress bar.\n",
    "            training_loop.set_postfix(curr_train_loss = \"{:.8f}\".format(training_loss / (train_iteration + 1)), val_loss = \"{:.8f}\".format(validation_loss))\n",
    "\n",
    "            # Update the tensorboard logger.\n",
    "            tb_logger.add_scalar(f'classifier_{name}/train_loss', loss.item(), epoch * len(train_loader) + train_iteration)\n",
    "            sleep(0.1) # Remove this line if you want to see the progress bar faster.\n",
    "\n",
    "        # Validation stage, where we don't want to update the parameters. Pay attention to the classifier.eval() line\n",
    "        # and \"with torch.no_grad()\" wrapper.\n",
    "        classifier.eval()\n",
    "        val_loop = create_tqdm_bar(val_loader, desc=f'Validation Epoch [{epoch + 1}/{epochs}]')\n",
    "        validation_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for val_iteration, batch in val_loop:\n",
    "                images, labels = batch\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                images = images.view(images.shape[0], -1) \n",
    "                pred = classifier(images)\n",
    "                loss = loss_func(pred, labels)\n",
    "                validation_loss += loss.item()\n",
    "\n",
    "                # Update the progress bar.\n",
    "                val_loop.set_postfix(val_loss = \"{:.8f}\".format(validation_loss / (val_iteration + 1)))\n",
    "\n",
    "                # Update the tensorboard logger.\n",
    "                tb_logger.add_scalar(f'classifier_{name}/val_loss', loss.item(), epoch * len(val_loader) + val_iteration)\n",
    "                sleep(0.1) # Remove this line if you want to see the progress bar faster.\n",
    "        \n",
    "        # This value is used for the progress bar of the training loop.\n",
    "        validation_loss /= len(val_loader)\n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "KVKLlwlyMNkl"
   },
   "source": [
    "## 2.5 Fit Classification Model with Trainer\n",
    "Now it's finally time to train your model.\n",
    "Run the following cell to see the behold the magic of deep learning at play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "uBGavq9cMNkl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [1/200]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, curr_train_loss=3.15424538, val_loss=0.00000000]\n",
      "Validation Epoch [1/200]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.95it/s, val_loss=2.33030915]\n",
      "Training Epoch [2/200]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, curr_train_loss=2.90590954, val_loss=0.00000000]\n",
      "Validation Epoch [2/200]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.91it/s, val_loss=2.27598691]\n",
      "Training Epoch [3/200]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, curr_train_loss=2.45434523, val_loss=0.00000000]\n",
      "Validation Epoch [3/200]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.12it/s, val_loss=2.23471379]\n",
      "Training Epoch [4/200]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  7.08it/s, curr_train_loss=2.96811676, val_loss=0.00000000]\n",
      "Validation Epoch [4/200]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.85it/s, val_loss=2.17974663]\n",
      "Training Epoch [5/200]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, curr_train_loss=2.74886942, val_loss=0.00000000]\n",
      "Validation Epoch [5/200]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.78it/s, val_loss=2.20998740]\n",
      "Training Epoch [6/200]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  6.60it/s, curr_train_loss=2.61148834, val_loss=0.00000000]\n",
      "Validation Epoch [6/200]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, val_loss=2.23471069]\n",
      "Training Epoch [7/200]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  6.36it/s, curr_train_loss=2.45872641, val_loss=0.00000000]\n",
      "Validation Epoch [7/200]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, val_loss=2.20776701]\n",
      "Training Epoch [8/200]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  6.54it/s, curr_train_loss=2.47426820, val_loss=0.00000000]\n",
      "Validation Epoch [8/200]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.64it/s, val_loss=2.19648480]\n",
      "Training Epoch [9/200]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  6.51it/s, curr_train_loss=2.54438615, val_loss=0.00000000]\n",
      "Validation Epoch [9/200]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=2.14260006]\n",
      "Training Epoch [10/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=2.41038752, val_loss=0.00000000]\n",
      "Validation Epoch [10/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.05it/s, val_loss=2.14146686]\n",
      "Training Epoch [11/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.45it/s, curr_train_loss=2.36316776, val_loss=0.00000000]\n",
      "Validation Epoch [11/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.12it/s, val_loss=2.14949989]\n",
      "Training Epoch [12/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, curr_train_loss=2.34737635, val_loss=0.00000000]\n",
      "Validation Epoch [12/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.99it/s, val_loss=2.10022807]\n",
      "Training Epoch [13/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.52it/s, curr_train_loss=2.28264332, val_loss=0.00000000]\n",
      "Validation Epoch [13/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.76it/s, val_loss=2.09667492]\n",
      "Training Epoch [14/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.57it/s, curr_train_loss=2.20672417, val_loss=0.00000000]\n",
      "Validation Epoch [14/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=2.07531428]\n",
      "Training Epoch [15/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.53it/s, curr_train_loss=2.11221576, val_loss=0.00000000]\n",
      "Validation Epoch [15/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.16it/s, val_loss=2.09575200]\n",
      "Training Epoch [16/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.50it/s, curr_train_loss=2.21624947, val_loss=0.00000000]\n",
      "Validation Epoch [16/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, val_loss=2.04400277]\n",
      "Training Epoch [17/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, curr_train_loss=2.25463820, val_loss=0.00000000]\n",
      "Validation Epoch [17/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.98it/s, val_loss=2.07701564]\n",
      "Training Epoch [18/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, curr_train_loss=2.27049780, val_loss=0.00000000]\n",
      "Validation Epoch [18/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.07it/s, val_loss=2.01991105]\n",
      "Training Epoch [19/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.61it/s, curr_train_loss=2.14558983, val_loss=0.00000000]\n",
      "Validation Epoch [19/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, val_loss=2.01110983]\n",
      "Training Epoch [20/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.53it/s, curr_train_loss=2.11780643, val_loss=0.00000000]\n",
      "Validation Epoch [20/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=2.03224206]\n",
      "Training Epoch [21/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.01it/s, curr_train_loss=2.13684678, val_loss=0.00000000]\n",
      "Validation Epoch [21/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.94it/s, val_loss=2.00971341]\n",
      "Training Epoch [22/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, curr_train_loss=2.09755063, val_loss=0.00000000]\n",
      "Validation Epoch [22/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.01it/s, val_loss=1.94103825]\n",
      "Training Epoch [23/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.64it/s, curr_train_loss=2.13854027, val_loss=0.00000000]\n",
      "Validation Epoch [23/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.95it/s, val_loss=2.00875330]\n",
      "Training Epoch [24/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=2.04643202, val_loss=0.00000000]\n",
      "Validation Epoch [24/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.95516706]\n",
      "Training Epoch [25/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.18it/s, curr_train_loss=2.08620429, val_loss=0.00000000]\n",
      "Validation Epoch [25/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.91259420]\n",
      "Training Epoch [26/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=2.01747727, val_loss=0.00000000]\n",
      "Validation Epoch [26/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.79it/s, val_loss=1.96391881]\n",
      "Training Epoch [27/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=1.89774394, val_loss=0.00000000]\n",
      "Validation Epoch [27/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, val_loss=1.91876805]\n",
      "Training Epoch [28/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.68it/s, curr_train_loss=2.02102995, val_loss=0.00000000]\n",
      "Validation Epoch [28/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.90it/s, val_loss=1.87056065]\n",
      "Training Epoch [29/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.36it/s, curr_train_loss=1.93260431, val_loss=0.00000000]\n",
      "Validation Epoch [29/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.75it/s, val_loss=1.93157613]\n",
      "Training Epoch [30/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.56it/s, curr_train_loss=1.99875224, val_loss=0.00000000]\n",
      "Validation Epoch [30/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, val_loss=1.91800249]\n",
      "Training Epoch [31/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.70it/s, curr_train_loss=1.91882932, val_loss=0.00000000]\n",
      "Validation Epoch [31/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.00it/s, val_loss=1.89270020]\n",
      "Training Epoch [32/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.67it/s, curr_train_loss=1.81655431, val_loss=0.00000000]\n",
      "Validation Epoch [32/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, val_loss=1.81305695]\n",
      "Training Epoch [33/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.53it/s, curr_train_loss=1.86643064, val_loss=0.00000000]\n",
      "Validation Epoch [33/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.91it/s, val_loss=1.92281520]\n",
      "Training Epoch [34/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.53it/s, curr_train_loss=1.81187820, val_loss=0.00000000]\n",
      "Validation Epoch [34/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.10it/s, val_loss=1.84944117]\n",
      "Training Epoch [35/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=1.87398529, val_loss=0.00000000]\n",
      "Validation Epoch [35/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.94it/s, val_loss=1.89473820]\n",
      "Training Epoch [36/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.09it/s, curr_train_loss=1.66216207, val_loss=0.00000000]\n",
      "Validation Epoch [36/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.11it/s, val_loss=1.88829541]\n",
      "Training Epoch [37/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.53it/s, curr_train_loss=1.80986369, val_loss=0.00000000]\n",
      "Validation Epoch [37/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.59it/s, val_loss=1.92867601]\n",
      "Training Epoch [38/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.46it/s, curr_train_loss=1.68200779, val_loss=0.00000000]\n",
      "Validation Epoch [38/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=1.84880114]\n",
      "Training Epoch [39/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.88it/s, curr_train_loss=1.65831757, val_loss=0.00000000]\n",
      "Validation Epoch [39/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.01it/s, val_loss=1.77514255]\n",
      "Training Epoch [40/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.58it/s, curr_train_loss=1.94457626, val_loss=0.00000000]\n",
      "Validation Epoch [40/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.38it/s, val_loss=1.80078840]\n",
      "Training Epoch [41/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.50it/s, curr_train_loss=1.79659343, val_loss=0.00000000]\n",
      "Validation Epoch [41/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.68it/s, val_loss=1.75140226]\n",
      "Training Epoch [42/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.64it/s, curr_train_loss=1.61951292, val_loss=0.00000000]\n",
      "Validation Epoch [42/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.90it/s, val_loss=1.75472045]\n",
      "Training Epoch [43/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.56it/s, curr_train_loss=1.71438324, val_loss=0.00000000]\n",
      "Validation Epoch [43/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.78it/s, val_loss=1.73132265]\n",
      "Training Epoch [44/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.46it/s, curr_train_loss=1.89454448, val_loss=0.00000000]\n",
      "Validation Epoch [44/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.96it/s, val_loss=1.75633955]\n",
      "Training Epoch [45/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, curr_train_loss=1.55477643, val_loss=0.00000000]\n",
      "Validation Epoch [45/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.07it/s, val_loss=1.66960561]\n",
      "Training Epoch [46/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, curr_train_loss=1.68809199, val_loss=0.00000000]\n",
      "Validation Epoch [46/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, val_loss=1.70160937]\n",
      "Training Epoch [47/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.54it/s, curr_train_loss=1.66049898, val_loss=0.00000000]\n",
      "Validation Epoch [47/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.70153952]\n",
      "Training Epoch [48/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, curr_train_loss=1.79154325, val_loss=0.00000000]\n",
      "Validation Epoch [48/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.17it/s, val_loss=1.66666043]\n",
      "Training Epoch [49/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.56it/s, curr_train_loss=1.93383718, val_loss=0.00000000]\n",
      "Validation Epoch [49/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.02it/s, val_loss=1.69213283]\n",
      "Training Epoch [50/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.34it/s, curr_train_loss=1.66181636, val_loss=0.00000000]\n",
      "Validation Epoch [50/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.07it/s, val_loss=1.68539536]\n",
      "Training Epoch [51/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.64it/s, curr_train_loss=1.60031521, val_loss=0.00000000]\n",
      "Validation Epoch [51/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, val_loss=1.64954913]\n",
      "Training Epoch [52/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.97it/s, curr_train_loss=1.72830951, val_loss=0.00000000]\n",
      "Validation Epoch [52/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.03it/s, val_loss=1.62377822]\n",
      "Training Epoch [53/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.56it/s, curr_train_loss=1.58574188, val_loss=0.00000000]\n",
      "Validation Epoch [53/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.97it/s, val_loss=1.61149740]\n",
      "Training Epoch [54/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.57it/s, curr_train_loss=1.62667203, val_loss=0.00000000]\n",
      "Validation Epoch [54/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.93it/s, val_loss=1.65266252]\n",
      "Training Epoch [55/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.61it/s, curr_train_loss=1.60392559, val_loss=0.00000000]\n",
      "Validation Epoch [55/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.61it/s, val_loss=1.65733492]\n",
      "Training Epoch [56/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.54it/s, curr_train_loss=1.54290271, val_loss=0.00000000]\n",
      "Validation Epoch [56/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.88it/s, val_loss=1.60433352]\n",
      "Training Epoch [57/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=1.50935197, val_loss=0.00000000]\n",
      "Validation Epoch [57/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=1.62935758]\n",
      "Training Epoch [58/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.59it/s, curr_train_loss=1.36877966, val_loss=0.00000000]\n",
      "Validation Epoch [58/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.62915194]\n",
      "Training Epoch [59/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.53it/s, curr_train_loss=1.52958798, val_loss=0.00000000]\n",
      "Validation Epoch [59/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=1.68470204]\n",
      "Training Epoch [60/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.73it/s, curr_train_loss=1.60962582, val_loss=0.00000000]\n",
      "Validation Epoch [60/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.04it/s, val_loss=1.61297119]\n",
      "Training Epoch [61/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.82it/s, curr_train_loss=1.51482153, val_loss=0.00000000]\n",
      "Validation Epoch [61/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.59725153]\n",
      "Training Epoch [62/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s, curr_train_loss=1.56732726, val_loss=0.00000000]\n",
      "Validation Epoch [62/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.98it/s, val_loss=1.61878812]\n",
      "Training Epoch [63/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.23it/s, curr_train_loss=1.58138931, val_loss=0.00000000]\n",
      "Validation Epoch [63/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=1.64359486]\n",
      "Training Epoch [64/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.24it/s, curr_train_loss=1.33324993, val_loss=0.00000000]\n",
      "Validation Epoch [64/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.79it/s, val_loss=1.47415686]\n",
      "Training Epoch [65/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.28it/s, curr_train_loss=1.40159380, val_loss=0.00000000]\n",
      "Validation Epoch [65/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.77it/s, val_loss=1.61950040]\n",
      "Training Epoch [66/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.38it/s, curr_train_loss=1.36970282, val_loss=0.00000000]\n",
      "Validation Epoch [66/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.70it/s, val_loss=1.60575879]\n",
      "Training Epoch [67/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=1.47621214, val_loss=0.00000000]\n",
      "Validation Epoch [67/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.78it/s, val_loss=1.56382489]\n",
      "Training Epoch [68/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.43it/s, curr_train_loss=1.36275494, val_loss=0.00000000]\n",
      "Validation Epoch [68/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.63it/s, val_loss=1.57406938]\n",
      "Training Epoch [69/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, curr_train_loss=1.36373079, val_loss=0.00000000]\n",
      "Validation Epoch [69/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.04it/s, val_loss=1.62863505]\n",
      "Training Epoch [70/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.67it/s, curr_train_loss=1.54147899, val_loss=0.00000000]\n",
      "Validation Epoch [70/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.57it/s, val_loss=1.55669892]\n",
      "Training Epoch [71/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=1.43901861, val_loss=0.00000000]\n",
      "Validation Epoch [71/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.58721375]\n",
      "Training Epoch [72/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=1.50183141, val_loss=0.00000000]\n",
      "Validation Epoch [72/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, val_loss=1.48406708]\n",
      "Training Epoch [73/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.19it/s, curr_train_loss=1.26682508, val_loss=0.00000000]\n",
      "Validation Epoch [73/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, val_loss=1.55590785]\n",
      "Training Epoch [74/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.16it/s, curr_train_loss=1.48350382, val_loss=0.00000000]\n",
      "Validation Epoch [74/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.84it/s, val_loss=1.56236589]\n",
      "Training Epoch [75/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.12it/s, curr_train_loss=1.35909820, val_loss=0.00000000]\n",
      "Validation Epoch [75/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.84it/s, val_loss=1.56371045]\n",
      "Training Epoch [76/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, curr_train_loss=1.42488801, val_loss=0.00000000]\n",
      "Validation Epoch [76/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.98it/s, val_loss=1.52356541]\n",
      "Training Epoch [77/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=1.29876924, val_loss=0.00000000]\n",
      "Validation Epoch [77/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.50743687]\n",
      "Training Epoch [78/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=1.35439610, val_loss=0.00000000]\n",
      "Validation Epoch [78/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.53294420]\n",
      "Training Epoch [79/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.22it/s, curr_train_loss=1.47198939, val_loss=0.00000000]\n",
      "Validation Epoch [79/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.77it/s, val_loss=1.57722533]\n",
      "Training Epoch [80/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.24it/s, curr_train_loss=1.45091867, val_loss=0.00000000]\n",
      "Validation Epoch [80/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, val_loss=1.56677294]\n",
      "Training Epoch [81/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, curr_train_loss=1.38764095, val_loss=0.00000000]\n",
      "Validation Epoch [81/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.44505048]\n",
      "Training Epoch [82/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, curr_train_loss=1.46290791, val_loss=0.00000000]\n",
      "Validation Epoch [82/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.50406122]\n",
      "Training Epoch [83/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, curr_train_loss=1.34663665, val_loss=0.00000000]\n",
      "Validation Epoch [83/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.51887393]\n",
      "Training Epoch [84/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.59it/s, curr_train_loss=1.24577582, val_loss=0.00000000]\n",
      "Validation Epoch [84/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.49380350]\n",
      "Training Epoch [85/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.53it/s, curr_train_loss=1.25287664, val_loss=0.00000000]\n",
      "Validation Epoch [85/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, val_loss=1.50284970]\n",
      "Training Epoch [86/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=1.23949659, val_loss=0.00000000]\n",
      "Validation Epoch [86/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.74it/s, val_loss=1.47078145]\n",
      "Training Epoch [87/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.94it/s, curr_train_loss=1.40418625, val_loss=0.00000000]\n",
      "Validation Epoch [87/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.09it/s, val_loss=1.54563963]\n",
      "Training Epoch [88/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.42it/s, curr_train_loss=1.53555334, val_loss=0.00000000]\n",
      "Validation Epoch [88/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.79it/s, val_loss=1.55866587]\n",
      "Training Epoch [89/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=1.20089960, val_loss=0.00000000]\n",
      "Validation Epoch [89/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.02it/s, val_loss=1.55545843]\n",
      "Training Epoch [90/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=1.15523708, val_loss=0.00000000]\n",
      "Validation Epoch [90/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.39124680]\n",
      "Training Epoch [91/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=1.17045033, val_loss=0.00000000]\n",
      "Validation Epoch [91/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.63it/s, val_loss=1.41825628]\n",
      "Training Epoch [92/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=1.29437423, val_loss=0.00000000]\n",
      "Validation Epoch [92/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.38333273]\n",
      "Training Epoch [93/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=1.23413336, val_loss=0.00000000]\n",
      "Validation Epoch [93/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.71it/s, val_loss=1.56150091]\n",
      "Training Epoch [94/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.33it/s, curr_train_loss=1.46289682, val_loss=0.00000000]\n",
      "Validation Epoch [94/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.92it/s, val_loss=1.51291418]\n",
      "Training Epoch [95/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=1.26743925, val_loss=0.00000000]\n",
      "Validation Epoch [95/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s, val_loss=1.54913342]\n",
      "Training Epoch [96/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.54it/s, curr_train_loss=1.24155807, val_loss=0.00000000]\n",
      "Validation Epoch [96/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.83it/s, val_loss=1.44765866]\n",
      "Training Epoch [97/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=1.33630419, val_loss=0.00000000]\n",
      "Validation Epoch [97/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.59it/s, val_loss=1.51833332]\n",
      "Training Epoch [98/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.57it/s, curr_train_loss=1.25450420, val_loss=0.00000000]\n",
      "Validation Epoch [98/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.04it/s, val_loss=1.51384890]\n",
      "Training Epoch [99/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, curr_train_loss=1.27843165, val_loss=0.00000000]\n",
      "Validation Epoch [99/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, val_loss=1.39531219]\n",
      "Training Epoch [100/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, curr_train_loss=1.11042488, val_loss=0.00000000]\n",
      "Validation Epoch [100/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.91it/s, val_loss=1.47328770]\n",
      "Training Epoch [101/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.89it/s, curr_train_loss=1.15682268, val_loss=0.00000000]\n",
      "Validation Epoch [101/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.78it/s, val_loss=1.52999163]\n",
      "Training Epoch [102/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=1.21254551, val_loss=0.00000000]\n",
      "Validation Epoch [102/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.16it/s, val_loss=1.41898715]\n",
      "Training Epoch [103/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.69it/s, curr_train_loss=1.15546060, val_loss=0.00000000]\n",
      "Validation Epoch [103/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.63it/s, val_loss=1.43614054]\n",
      "Training Epoch [104/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.26it/s, curr_train_loss=0.97041404, val_loss=0.00000000]\n",
      "Validation Epoch [104/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, val_loss=1.49418104]\n",
      "Training Epoch [105/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.15it/s, curr_train_loss=1.29646564, val_loss=0.00000000]\n",
      "Validation Epoch [105/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.78it/s, val_loss=1.42481089]\n",
      "Training Epoch [106/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, curr_train_loss=1.24250352, val_loss=0.00000000]\n",
      "Validation Epoch [106/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s, val_loss=1.40853715]\n",
      "Training Epoch [107/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.15it/s, curr_train_loss=1.24312675, val_loss=0.00000000]\n",
      "Validation Epoch [107/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, val_loss=1.54930353]\n",
      "Training Epoch [108/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.56it/s, curr_train_loss=1.18209124, val_loss=0.00000000]\n",
      "Validation Epoch [108/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.74it/s, val_loss=1.40283692]\n",
      "Training Epoch [109/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.58it/s, curr_train_loss=1.22012150, val_loss=0.00000000]\n",
      "Validation Epoch [109/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.68it/s, val_loss=1.56498945]\n",
      "Training Epoch [110/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=1.38209391, val_loss=0.00000000]\n",
      "Validation Epoch [110/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.85it/s, val_loss=1.46109831]\n",
      "Training Epoch [111/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, curr_train_loss=1.14754438, val_loss=0.00000000]\n",
      "Validation Epoch [111/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.79it/s, val_loss=1.39350283]\n",
      "Training Epoch [112/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.68it/s, curr_train_loss=1.22778904, val_loss=0.00000000]\n",
      "Validation Epoch [112/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.68it/s, val_loss=1.47492695]\n",
      "Training Epoch [113/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, curr_train_loss=1.21858823, val_loss=0.00000000]\n",
      "Validation Epoch [113/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.46489704]\n",
      "Training Epoch [114/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, curr_train_loss=1.21845806, val_loss=0.00000000]\n",
      "Validation Epoch [114/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.40823603]\n",
      "Training Epoch [115/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, curr_train_loss=1.07405591, val_loss=0.00000000]\n",
      "Validation Epoch [115/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.39779985]\n",
      "Training Epoch [116/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.43it/s, curr_train_loss=1.02929699, val_loss=0.00000000]\n",
      "Validation Epoch [116/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.42013538]\n",
      "Training Epoch [117/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, curr_train_loss=1.36060321, val_loss=0.00000000]\n",
      "Validation Epoch [117/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=1.38990796]\n",
      "Training Epoch [118/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.45it/s, curr_train_loss=1.12780428, val_loss=0.00000000]\n",
      "Validation Epoch [118/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.96it/s, val_loss=1.24431002]\n",
      "Training Epoch [119/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.11it/s, curr_train_loss=1.33989167, val_loss=0.00000000]\n",
      "Validation Epoch [119/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.47587931]\n",
      "Training Epoch [120/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=1.16368711, val_loss=0.00000000]\n",
      "Validation Epoch [120/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=1.43560207]\n",
      "Training Epoch [121/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.28it/s, curr_train_loss=1.19721687, val_loss=0.00000000]\n",
      "Validation Epoch [121/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.44811630]\n",
      "Training Epoch [122/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=1.02577317, val_loss=0.00000000]\n",
      "Validation Epoch [122/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, val_loss=1.53950047]\n",
      "Training Epoch [123/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, curr_train_loss=0.97153521, val_loss=0.00000000]\n",
      "Validation Epoch [123/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=1.46563864]\n",
      "Training Epoch [124/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=1.22131550, val_loss=0.00000000]\n",
      "Validation Epoch [124/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.82it/s, val_loss=1.38336182]\n",
      "Training Epoch [125/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.22it/s, curr_train_loss=1.16085744, val_loss=0.00000000]\n",
      "Validation Epoch [125/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, val_loss=1.45182979]\n",
      "Training Epoch [126/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=1.18311167, val_loss=0.00000000]\n",
      "Validation Epoch [126/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s, val_loss=1.43196321]\n",
      "Training Epoch [127/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, curr_train_loss=0.89910316, val_loss=0.00000000]\n",
      "Validation Epoch [127/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.80it/s, val_loss=1.41032970]\n",
      "Training Epoch [128/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.39it/s, curr_train_loss=0.93538404, val_loss=0.00000000]\n",
      "Validation Epoch [128/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, val_loss=1.34776199]\n",
      "Training Epoch [129/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.95it/s, curr_train_loss=1.24119163, val_loss=0.00000000]\n",
      "Validation Epoch [129/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, val_loss=1.46456265]\n",
      "Training Epoch [130/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.57it/s, curr_train_loss=0.95531458, val_loss=0.00000000]\n",
      "Validation Epoch [130/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.96it/s, val_loss=1.29741812]\n",
      "Training Epoch [131/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.58it/s, curr_train_loss=1.03170121, val_loss=0.00000000]\n",
      "Validation Epoch [131/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.99it/s, val_loss=1.36542356]\n",
      "Training Epoch [132/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.89it/s, curr_train_loss=1.13779926, val_loss=0.00000000]\n",
      "Validation Epoch [132/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.98it/s, val_loss=1.40727413]\n",
      "Training Epoch [133/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.18it/s, curr_train_loss=1.22705281, val_loss=0.00000000]\n",
      "Validation Epoch [133/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, val_loss=1.39939809]\n",
      "Training Epoch [134/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.54it/s, curr_train_loss=1.18712080, val_loss=0.00000000]\n",
      "Validation Epoch [134/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.84it/s, val_loss=1.41637027]\n",
      "Training Epoch [135/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=0.98373383, val_loss=0.00000000]\n",
      "Validation Epoch [135/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.85it/s, val_loss=1.29952228]\n",
      "Training Epoch [136/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.53it/s, curr_train_loss=1.12328112, val_loss=0.00000000]\n",
      "Validation Epoch [136/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.98it/s, val_loss=1.31958354]\n",
      "Training Epoch [137/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=1.22369373, val_loss=0.00000000]\n",
      "Validation Epoch [137/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s, val_loss=1.29641628]\n",
      "Training Epoch [138/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.08it/s, curr_train_loss=1.08135080, val_loss=0.00000000]\n",
      "Validation Epoch [138/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, val_loss=1.32447803]\n",
      "Training Epoch [139/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=1.04644465, val_loss=0.00000000]\n",
      "Validation Epoch [139/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.67it/s, val_loss=1.29124248]\n",
      "Training Epoch [140/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=1.01988399, val_loss=0.00000000]\n",
      "Validation Epoch [140/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.92it/s, val_loss=1.40761995]\n",
      "Training Epoch [141/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.25it/s, curr_train_loss=1.13129532, val_loss=0.00000000]\n",
      "Validation Epoch [141/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, val_loss=1.31797802]\n",
      "Training Epoch [142/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, curr_train_loss=1.16450977, val_loss=0.00000000]\n",
      "Validation Epoch [142/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.59it/s, val_loss=1.30290544]\n",
      "Training Epoch [143/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=1.06467593, val_loss=0.00000000]\n",
      "Validation Epoch [143/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.91it/s, val_loss=1.33756459]\n",
      "Training Epoch [144/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=1.04330683, val_loss=0.00000000]\n",
      "Validation Epoch [144/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.03it/s, val_loss=1.35415328]\n",
      "Training Epoch [145/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=0.83485818, val_loss=0.00000000]\n",
      "Validation Epoch [145/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.91it/s, val_loss=1.14438117]\n",
      "Training Epoch [146/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=0.91148067, val_loss=0.00000000]\n",
      "Validation Epoch [146/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.95it/s, val_loss=1.51842010]\n",
      "Training Epoch [147/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.53it/s, curr_train_loss=0.97141725, val_loss=0.00000000]\n",
      "Validation Epoch [147/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s, val_loss=1.43360317]\n",
      "Training Epoch [148/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=0.88162744, val_loss=0.00000000]\n",
      "Validation Epoch [148/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.62it/s, val_loss=1.23310673]\n",
      "Training Epoch [149/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.66it/s, curr_train_loss=0.83990622, val_loss=0.00000000]\n",
      "Validation Epoch [149/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.77it/s, val_loss=1.34983075]\n",
      "Training Epoch [150/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, curr_train_loss=0.92313415, val_loss=0.00000000]\n",
      "Validation Epoch [150/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.70it/s, val_loss=1.28906417]\n",
      "Training Epoch [151/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.85it/s, curr_train_loss=0.96149939, val_loss=0.00000000]\n",
      "Validation Epoch [151/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.25814104]\n",
      "Training Epoch [152/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=0.81269145, val_loss=0.00000000]\n",
      "Validation Epoch [152/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.32117617]\n",
      "Training Epoch [153/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.27it/s, curr_train_loss=1.09506333, val_loss=0.00000000]\n",
      "Validation Epoch [153/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.45it/s, val_loss=1.31887913]\n",
      "Training Epoch [154/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=1.27550328, val_loss=0.00000000]\n",
      "Validation Epoch [154/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=1.45452058]\n",
      "Training Epoch [155/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=0.82705325, val_loss=0.00000000]\n",
      "Validation Epoch [155/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.80it/s, val_loss=1.38848042]\n",
      "Training Epoch [156/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, curr_train_loss=0.92472577, val_loss=0.00000000]\n",
      "Validation Epoch [156/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.65it/s, val_loss=1.38791668]\n",
      "Training Epoch [157/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=1.07456863, val_loss=0.00000000]\n",
      "Validation Epoch [157/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.39096510]\n",
      "Training Epoch [158/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.39it/s, curr_train_loss=0.99079430, val_loss=0.00000000]\n",
      "Validation Epoch [158/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.27896380]\n",
      "Training Epoch [159/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.42it/s, curr_train_loss=0.89740068, val_loss=0.00000000]\n",
      "Validation Epoch [159/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.03it/s, val_loss=1.33289337]\n",
      "Training Epoch [160/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.06it/s, curr_train_loss=1.10332441, val_loss=0.00000000]\n",
      "Validation Epoch [160/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.02it/s, val_loss=1.33981693]\n",
      "Training Epoch [161/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.32it/s, curr_train_loss=0.95578623, val_loss=0.00000000]\n",
      "Validation Epoch [161/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.37880278]\n",
      "Training Epoch [162/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.04it/s, curr_train_loss=1.14398754, val_loss=0.00000000]\n",
      "Validation Epoch [162/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.79it/s, val_loss=1.32669437]\n",
      "Training Epoch [163/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.64it/s, curr_train_loss=0.92077857, val_loss=0.00000000]\n",
      "Validation Epoch [163/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=1.43639982]\n",
      "Training Epoch [164/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.40it/s, curr_train_loss=1.04353058, val_loss=0.00000000]\n",
      "Validation Epoch [164/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.97it/s, val_loss=1.34670806]\n",
      "Training Epoch [165/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.66it/s, curr_train_loss=1.08314633, val_loss=0.00000000]\n",
      "Validation Epoch [165/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.33909512]\n",
      "Training Epoch [166/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.69it/s, curr_train_loss=0.81240010, val_loss=0.00000000]\n",
      "Validation Epoch [166/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=1.41841459]\n",
      "Training Epoch [167/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=0.88758105, val_loss=0.00000000]\n",
      "Validation Epoch [167/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.34922171]\n",
      "Training Epoch [168/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.56it/s, curr_train_loss=0.92111266, val_loss=0.00000000]\n",
      "Validation Epoch [168/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.79it/s, val_loss=1.44205189]\n",
      "Training Epoch [169/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.85it/s, curr_train_loss=0.79646963, val_loss=0.00000000]\n",
      "Validation Epoch [169/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.78it/s, val_loss=1.24558210]\n",
      "Training Epoch [170/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.90it/s, curr_train_loss=0.79408097, val_loss=0.00000000]\n",
      "Validation Epoch [170/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.69it/s, val_loss=1.27029800]\n",
      "Training Epoch [171/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=1.01864541, val_loss=0.00000000]\n",
      "Validation Epoch [171/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.71it/s, val_loss=1.37873578]\n",
      "Training Epoch [172/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.53it/s, curr_train_loss=0.96862483, val_loss=0.00000000]\n",
      "Validation Epoch [172/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.76it/s, val_loss=1.16507947]\n",
      "Training Epoch [173/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=1.03311312, val_loss=0.00000000]\n",
      "Validation Epoch [173/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.03it/s, val_loss=1.49037230]\n",
      "Training Epoch [174/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.35it/s, curr_train_loss=0.98646677, val_loss=0.00000000]\n",
      "Validation Epoch [174/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, val_loss=1.36934006]\n",
      "Training Epoch [175/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, curr_train_loss=0.96903992, val_loss=0.00000000]\n",
      "Validation Epoch [175/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.95it/s, val_loss=1.47149968]\n",
      "Training Epoch [176/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, curr_train_loss=0.93109202, val_loss=0.00000000]\n",
      "Validation Epoch [176/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.07it/s, val_loss=1.38617063]\n",
      "Training Epoch [177/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=0.91505873, val_loss=0.00000000]\n",
      "Validation Epoch [177/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.04it/s, val_loss=1.29520452]\n",
      "Training Epoch [178/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, curr_train_loss=1.00942600, val_loss=0.00000000]\n",
      "Validation Epoch [178/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.47778213]\n",
      "Training Epoch [179/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.18it/s, curr_train_loss=0.92443132, val_loss=0.00000000]\n",
      "Validation Epoch [179/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.62it/s, val_loss=1.46808469]\n",
      "Training Epoch [180/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=0.95707697, val_loss=0.00000000]\n",
      "Validation Epoch [180/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.57it/s, val_loss=1.48142552]\n",
      "Training Epoch [181/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.33it/s, curr_train_loss=0.84666413, val_loss=0.00000000]\n",
      "Validation Epoch [181/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.01it/s, val_loss=1.45828795]\n",
      "Training Epoch [182/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.74283254, val_loss=0.00000000]\n",
      "Validation Epoch [182/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.93it/s, val_loss=1.49675059]\n",
      "Training Epoch [183/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.36it/s, curr_train_loss=0.53983313, val_loss=0.00000000]\n",
      "Validation Epoch [183/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.66it/s, val_loss=1.45560598]\n",
      "Training Epoch [184/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.54it/s, curr_train_loss=0.90078473, val_loss=0.00000000]\n",
      "Validation Epoch [184/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.02it/s, val_loss=1.45849776]\n",
      "Training Epoch [185/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.37it/s, curr_train_loss=0.75317788, val_loss=0.00000000]\n",
      "Validation Epoch [185/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.00it/s, val_loss=1.46889532]\n",
      "Training Epoch [186/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.55it/s, curr_train_loss=0.89839327, val_loss=0.00000000]\n",
      "Validation Epoch [186/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.64it/s, val_loss=1.39848042]\n",
      "Training Epoch [187/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, curr_train_loss=0.87645704, val_loss=0.00000000]\n",
      "Validation Epoch [187/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.08it/s, val_loss=1.27471411]\n",
      "Training Epoch [188/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, curr_train_loss=1.04745626, val_loss=0.00000000]\n",
      "Validation Epoch [188/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.13it/s, val_loss=1.25864303]\n",
      "Training Epoch [189/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.33it/s, curr_train_loss=0.95107758, val_loss=0.00000000]\n",
      "Validation Epoch [189/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.80it/s, val_loss=1.46723354]\n",
      "Training Epoch [190/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.57it/s, curr_train_loss=0.92527664, val_loss=0.00000000]\n",
      "Validation Epoch [190/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, val_loss=1.30274737]\n",
      "Training Epoch [191/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, curr_train_loss=1.09102094, val_loss=0.00000000]\n",
      "Validation Epoch [191/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.53144181]\n",
      "Training Epoch [192/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.74it/s, curr_train_loss=0.93503076, val_loss=0.00000000]\n",
      "Validation Epoch [192/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, val_loss=1.18033206]\n",
      "Training Epoch [193/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.38it/s, curr_train_loss=0.68728846, val_loss=0.00000000]\n",
      "Validation Epoch [193/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=1.40591872]\n",
      "Training Epoch [194/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.48it/s, curr_train_loss=0.83099884, val_loss=0.00000000]\n",
      "Validation Epoch [194/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.15it/s, val_loss=1.23297238]\n",
      "Training Epoch [195/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.66it/s, curr_train_loss=0.80296737, val_loss=0.00000000]\n",
      "Validation Epoch [195/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.05it/s, val_loss=1.49226058]\n",
      "Training Epoch [196/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.54it/s, curr_train_loss=0.92597795, val_loss=0.00000000]\n",
      "Validation Epoch [196/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, val_loss=1.45703948]\n",
      "Training Epoch [197/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.10it/s, curr_train_loss=1.00858128, val_loss=0.00000000]\n",
      "Validation Epoch [197/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.70it/s, val_loss=1.28290927]\n",
      "Training Epoch [198/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=0.95083255, val_loss=0.00000000]\n",
      "Validation Epoch [198/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.68it/s, val_loss=1.26839769]\n",
      "Training Epoch [199/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, curr_train_loss=0.92738116, val_loss=0.00000000]\n",
      "Validation Epoch [199/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=1.52842319]\n",
      "Training Epoch [200/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.77it/s, curr_train_loss=0.88026458, val_loss=0.00000000]\n",
      "Validation Epoch [200/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.63it/s, val_loss=1.34518051]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training!\n",
      "How did we do? Let's check the accuracy of the defaut classifier on the training and validation sets:\n",
      "Training Acc: 92.0%\n",
      "Validation Acc: 61.0%\n"
     ]
    }
   ],
   "source": [
    "from exercise_code.models import Classifier\n",
    "from exercise_code.models import Encoder\n",
    "\n",
    "# Create the encoder and the classifier.\n",
    "encoder = Encoder(hparams).to(device)\n",
    "classifier = Classifier(hparams, encoder).to(device)\n",
    "\n",
    "# Create a tensorboard logger.\n",
    "# NOTE: In order to see the logs, run the following command in the terminal: tensorboard --logdir=./\n",
    "# Also, in order to reset the logs, delete the logs folder MANUALLY.\n",
    "\n",
    "path = os.path.join('logs', 'cls_logs')\n",
    "num_of_runs = len(os.listdir(path)) if os.path.exists(path) else 0\n",
    "path = os.path.join(path, f'run_{num_of_runs + 1}')\n",
    "\n",
    "tb_logger = SummaryWriter(path)\n",
    "\n",
    "# Train the classifier.\n",
    "labled_train_loader = torch.utils.data.DataLoader(train_100_dataset, batch_size=hparams['batch_size'], shuffle=True)\n",
    "labled_val_loader = torch.utils.data.DataLoader(val_100_dataset, batch_size=hparams['batch_size'], shuffle=False)\n",
    "\n",
    "epochs = hparams.get('epochs', 10)\n",
    "loss_func = nn.CrossEntropyLoss() # The loss function we use for classification.\n",
    "train_classifier(classifier, labled_train_loader, labled_val_loader, loss_func, tb_logger, epochs=epochs, name=\"Default\")\n",
    "\n",
    "print(\"Finished training!\")\n",
    "print(\"How did we do? Let's check the accuracy of the defaut classifier on the training and validation sets:\")\n",
    "print(f\"Training Acc: {classifier.getAcc(labled_train_loader)[1] * 100}%\")\n",
    "print(f\"Validation Acc: {classifier.getAcc(labled_val_loader)[1] * 100}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "i16vmHZXMNkm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. Autoencoder\n",
    "\n",
    "With only a limited number of labeled images, it's challenging to achieve high performance. We have no money left to pay the student to create more labels, and labeling the data ourselves is out of question. A commonly used approach would be to apply data augmentation to maximize the potential of our limited labeled data, but here we provide another way to solve this problem: **transfer learning**.\n",
    "\n",
    "For each input, the autoencoder tries to reproduce the same image as an output. The difficulty behind this task is that the autoencoder has to go through a low dimensional bottleneck, which is called the **latent space**.\n",
    "In other words, the autoencoder learns to represent all the input information in a low dimensional latent space - it learns to compress the input distribution. To train the autoencoder, we use the mean squared error loss, which calculates the discrepancy between the input pixels and the output pixels. The best part is that this loss function doesn't require any labels!\n",
    "\n",
    "By pretraining the autoencoder in this way on the large amount of unlabeled data, we can capture valuable latent representations of the input images. Then, we transfer the weights of the encoder to our classifier, enabling it to benefit from the knowledge learned during the unsupervised pretraining phase. \n",
    "\n",
    "![autoencoder](img/autoencoder.png)\n",
    "\n",
    "After this, our encoder has learned to extract meaningful information from the inputs. We can then transfer its weights\n",
    "to a classifier architecture and finetune it with our labeled data, i.e., instead of initializing our encoder randomly we are re-using the weights of our trained encoder from our autoencoder network. \n",
    "\n",
    "![autoencoder_pretrained](img/pretrained.png)\n",
    "\n",
    "## 3.1 Decoder\n",
    "\n",
    "Before we can train our autoencoder, you have to initialize the your `decoder` architecture. The simplest way is to mirror your encoder architecture which ensure that the `latent space` output of our `encoder` is correctly transformed to our input shape.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <h3>Task: Implement</h3>\n",
    "    <p>Implement the <code>Decoder</code> and <code>Autoencoder</code> class initialization in <code>exercise_code/models.py</code>.</p>\n",
    "    <p>Implemet <code>training_step</code> and <code>validation_step</code> of the autoencoder, following the pipeline we've shown you in train_classifier().</p>\n",
    "    <p>Note the differences between the classificaiton task, and now the regression task!</p>\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "## 3.2 Autoencoder Training\n",
    "\n",
    "Now, we can train the full autoencoder consisting of both en- and decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "xqqdoLDgMNkm"
   },
   "outputs": [],
   "source": [
    "from exercise_code.models import Autoencoder, Encoder, Decoder\n",
    "\n",
    "########################################################################\n",
    "# TODO: Define your hyperparameters here!                              #\n",
    "# Hint: use a large batch_size                                         #\n",
    "########################################################################\n",
    "\n",
    "hparams = {    \n",
    "    \"device\" : device,\n",
    "    \"num_workers\" : 8,\n",
    "    \"epochs\" : 100,\n",
    "    \"batch_size\" : 2048,\n",
    "    \n",
    "    \"num_classes\" : 10, # There are 10 digits\n",
    "    \"input_size\" : 28 * 28, # Number of pixels in images\n",
    "    \n",
    "    \"learning_rate\" : 2e-3, # Optimizer\n",
    "    \"weight_decay\" : 1e-5, # ADAM\n",
    "    \n",
    "    \"dropout_p\" : 0.5, # Dropout probability for the classifier, reduces overfitting\n",
    "    \"latent_dim\" : 20, # Encoder output dim, Decode input dim, classifier input dim. If this it too high, overfitting will occur\n",
    "    \"decoder_hidden\" : 512, # Decoder Hidden\n",
    "    \"encoder_hidden\" : 512, # Encoder Hidden\n",
    "    # \"classifier_hidden\" : 2048 # Classifier Hidden\n",
    "}\n",
    "\n",
    "\n",
    "########################################################################\n",
    "#                           END OF YOUR CODE                           #\n",
    "########################################################################\n",
    "encoder_pretrained = Encoder(hparams).to(device)\n",
    "decoder = Decoder(hparams).to(device)\n",
    "autoencoder = Autoencoder(hparams, encoder_pretrained, decoder).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "uRuIIm8YMNkn"
   },
   "source": [
    "Some tests to check whether we'll accept your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "SoAaC-NqMNkn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Paramters: Your model has \u001b[92m1.078\u001b[0m mio. params.\n",
      "Model accepted!\n"
     ]
    }
   ],
   "source": [
    "from exercise_code.Util import printModelInfo, load_model\n",
    "_ = printModelInfo(autoencoder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "plQwnphtqggl"
   },
   "source": [
    "After implementing the relevant functions - read the following code, and then run it.\n",
    "Keep in mind that an epoch here will take much longer since\n",
    "we are iterating through 5,8600 images instead of just 100.\n",
    "\n",
    "For speed, colab is indeed recommended. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "_uuzXMq6zjbb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [0/100]: 100%|█████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.44261360, val_loss=0.00000000]\n",
      "Validation Epoch [0/100]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.85it/s, val_loss=0.08841546]\n",
      "Training Epoch [1/100]: 100%|█████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.08104732, val_loss=0.08841546]\n",
      "Validation Epoch [1/100]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.43it/s, val_loss=0.07712215]\n",
      "Training Epoch [2/100]: 100%|█████████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.07175236, val_loss=0.07712215]\n",
      "Validation Epoch [2/100]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.71it/s, val_loss=0.06511107]\n",
      "Training Epoch [3/100]: 100%|█████████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.06584603, val_loss=0.06511107]\n",
      "Validation Epoch [3/100]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.62it/s, val_loss=0.06177102]\n",
      "Training Epoch [4/100]: 100%|█████████████████████████████████████████████| 29/29 [00:16<00:00,  1.78it/s, train_loss=0.06341660, val_loss=0.06177102]\n",
      "Validation Epoch [4/100]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.25it/s, val_loss=0.06101518]\n",
      "Training Epoch [5/100]: 100%|█████████████████████████████████████████████| 29/29 [00:16<00:00,  1.78it/s, train_loss=0.06237045, val_loss=0.06101518]\n",
      "Validation Epoch [5/100]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.34it/s, val_loss=0.05979795]\n",
      "Training Epoch [6/100]: 100%|█████████████████████████████████████████████| 29/29 [00:16<00:00,  1.78it/s, train_loss=0.06170241, val_loss=0.05979795]\n",
      "Validation Epoch [6/100]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.84it/s, val_loss=0.05974617]\n",
      "Training Epoch [7/100]: 100%|█████████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.06115982, val_loss=0.05974617]\n",
      "Validation Epoch [7/100]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.20it/s, val_loss=0.05935710]\n",
      "Training Epoch [8/100]: 100%|█████████████████████████████████████████████| 29/29 [00:16<00:00,  1.79it/s, train_loss=0.06089488, val_loss=0.05935710]\n",
      "Validation Epoch [8/100]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.98it/s, val_loss=0.05922895]\n",
      "Training Epoch [9/100]: 100%|█████████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.06044111, val_loss=0.05922895]\n",
      "Validation Epoch [9/100]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.10it/s, val_loss=0.05865547]\n",
      "Training Epoch [10/100]: 100%|████████████████████████████████████████████| 29/29 [00:16<00:00,  1.79it/s, train_loss=0.06009395, val_loss=0.05865547]\n",
      "Validation Epoch [10/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.40it/s, val_loss=0.05873756]\n",
      "Training Epoch [11/100]: 100%|████████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.05978791, val_loss=0.05873756]\n",
      "Validation Epoch [11/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.50it/s, val_loss=0.05844190]\n",
      "Training Epoch [12/100]: 100%|████████████████████████████████████████████| 29/29 [00:16<00:00,  1.79it/s, train_loss=0.05946406, val_loss=0.05844190]\n",
      "Validation Epoch [12/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.14it/s, val_loss=0.05873068]\n",
      "Training Epoch [13/100]: 100%|████████████████████████████████████████████| 29/29 [00:16<00:00,  1.78it/s, train_loss=0.05917735, val_loss=0.05873068]\n",
      "Validation Epoch [13/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.01it/s, val_loss=0.05829345]\n",
      "Training Epoch [14/100]: 100%|████████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.05892363, val_loss=0.05829345]\n",
      "Validation Epoch [14/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.38it/s, val_loss=0.05810227]\n",
      "Training Epoch [15/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.81it/s, train_loss=0.05861268, val_loss=0.05810227]\n",
      "Validation Epoch [15/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.53it/s, val_loss=0.05840192]\n",
      "Training Epoch [16/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.05844648, val_loss=0.05840192]\n",
      "Validation Epoch [16/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.06it/s, val_loss=0.05758840]\n",
      "Training Epoch [17/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.81it/s, train_loss=0.05817917, val_loss=0.05758840]\n",
      "Validation Epoch [17/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.52it/s, val_loss=0.05777849]\n",
      "Training Epoch [18/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.05790427, val_loss=0.05777849]\n",
      "Validation Epoch [18/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.28it/s, val_loss=0.05771145]\n",
      "Training Epoch [19/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.05769691, val_loss=0.05771145]\n",
      "Validation Epoch [19/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.55it/s, val_loss=0.05724261]\n",
      "Training Epoch [20/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.05757193, val_loss=0.05724261]\n",
      "Validation Epoch [20/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.09it/s, val_loss=0.05743042]\n",
      "Training Epoch [21/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.05722334, val_loss=0.05743042]\n",
      "Validation Epoch [21/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.28it/s, val_loss=0.05766170]\n",
      "Training Epoch [22/100]: 100%|████████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.05710448, val_loss=0.05766170]\n",
      "Validation Epoch [22/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.60it/s, val_loss=0.05818833]\n",
      "Training Epoch [23/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.05673529, val_loss=0.05818833]\n",
      "Validation Epoch [23/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.27it/s, val_loss=0.05686045]\n",
      "Training Epoch [24/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.05670009, val_loss=0.05686045]\n",
      "Validation Epoch [24/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.46it/s, val_loss=0.05748986]\n",
      "Training Epoch [25/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.05652392, val_loss=0.05748986]\n",
      "Validation Epoch [25/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.20it/s, val_loss=0.05640425]\n",
      "Training Epoch [26/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.05630689, val_loss=0.05640425]\n",
      "Validation Epoch [26/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.30it/s, val_loss=0.05680325]\n",
      "Training Epoch [27/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.81it/s, train_loss=0.05613716, val_loss=0.05680325]\n",
      "Validation Epoch [27/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.43it/s, val_loss=0.05683192]\n",
      "Training Epoch [28/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.87it/s, train_loss=0.05599467, val_loss=0.05683192]\n",
      "Validation Epoch [28/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.69it/s, val_loss=0.05702764]\n",
      "Training Epoch [29/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.05575206, val_loss=0.05702764]\n",
      "Validation Epoch [29/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.30it/s, val_loss=0.05632176]\n",
      "Training Epoch [30/100]: 100%|████████████████████████████████████████████| 29/29 [00:16<00:00,  1.79it/s, train_loss=0.05558109, val_loss=0.05632176]\n",
      "Validation Epoch [30/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.35it/s, val_loss=0.05631806]\n",
      "Training Epoch [31/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.81it/s, train_loss=0.05529507, val_loss=0.05631806]\n",
      "Validation Epoch [31/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.36it/s, val_loss=0.05540003]\n",
      "Training Epoch [32/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.05515487, val_loss=0.05540003]\n",
      "Validation Epoch [32/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.44it/s, val_loss=0.05587500]\n",
      "Training Epoch [33/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.05495096, val_loss=0.05587500]\n",
      "Validation Epoch [33/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.61it/s, val_loss=0.05608479]\n",
      "Training Epoch [34/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.05480870, val_loss=0.05608479]\n",
      "Validation Epoch [34/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.35it/s, val_loss=0.05492583]\n",
      "Training Epoch [35/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.05451366, val_loss=0.05492583]\n",
      "Validation Epoch [35/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.66it/s, val_loss=0.05551207]\n",
      "Training Epoch [36/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.81it/s, train_loss=0.05438331, val_loss=0.05551207]\n",
      "Validation Epoch [36/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.18it/s, val_loss=0.05533191]\n",
      "Training Epoch [37/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.05423290, val_loss=0.05533191]\n",
      "Validation Epoch [37/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.52it/s, val_loss=0.05549020]\n",
      "Training Epoch [38/100]: 100%|████████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.05400408, val_loss=0.05549020]\n",
      "Validation Epoch [38/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.63it/s, val_loss=0.05518071]\n",
      "Training Epoch [39/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.05389094, val_loss=0.05518071]\n",
      "Validation Epoch [39/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.37it/s, val_loss=0.05409995]\n",
      "Training Epoch [40/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.05370794, val_loss=0.05409995]\n",
      "Validation Epoch [40/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.45it/s, val_loss=0.05359511]\n",
      "Training Epoch [41/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.05360532, val_loss=0.05359511]\n",
      "Validation Epoch [41/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.34it/s, val_loss=0.05415864]\n",
      "Training Epoch [42/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.05344062, val_loss=0.05415864]\n",
      "Validation Epoch [42/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.51it/s, val_loss=0.05465357]\n",
      "Training Epoch [43/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.05341722, val_loss=0.05465357]\n",
      "Validation Epoch [43/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.47it/s, val_loss=0.05388085]\n",
      "Training Epoch [44/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.05327568, val_loss=0.05388085]\n",
      "Validation Epoch [44/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.59it/s, val_loss=0.05423158]\n",
      "Training Epoch [45/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.05309979, val_loss=0.05423158]\n",
      "Validation Epoch [45/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.38it/s, val_loss=0.05348956]\n",
      "Training Epoch [46/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.05296390, val_loss=0.05348956]\n",
      "Validation Epoch [46/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.16it/s, val_loss=0.05368096]\n",
      "Training Epoch [47/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.05289411, val_loss=0.05368096]\n",
      "Validation Epoch [47/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.41it/s, val_loss=0.05333550]\n",
      "Training Epoch [48/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.05275433, val_loss=0.05333550]\n",
      "Validation Epoch [48/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.64it/s, val_loss=0.05335026]\n",
      "Training Epoch [49/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.05259988, val_loss=0.05335026]\n",
      "Validation Epoch [49/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.43it/s, val_loss=0.05300041]\n",
      "Training Epoch [50/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.05240926, val_loss=0.05300041]\n",
      "Validation Epoch [50/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.50it/s, val_loss=0.05325175]\n",
      "Training Epoch [51/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.05231977, val_loss=0.05325175]\n",
      "Validation Epoch [51/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.25it/s, val_loss=0.05291090]\n",
      "Training Epoch [52/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.05218565, val_loss=0.05291090]\n",
      "Validation Epoch [52/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.14it/s, val_loss=0.05165554]\n",
      "Training Epoch [53/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.81it/s, train_loss=0.05179034, val_loss=0.05165554]\n",
      "Validation Epoch [53/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.21it/s, val_loss=0.05150922]\n",
      "Training Epoch [54/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.05162751, val_loss=0.05150922]\n",
      "Validation Epoch [54/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.35it/s, val_loss=0.05119010]\n",
      "Training Epoch [55/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.05128227, val_loss=0.05119010]\n",
      "Validation Epoch [55/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.20it/s, val_loss=0.05052736]\n",
      "Training Epoch [56/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.05095787, val_loss=0.05052736]\n",
      "Validation Epoch [56/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.60it/s, val_loss=0.05072490]\n",
      "Training Epoch [57/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.05063466, val_loss=0.05072490]\n",
      "Validation Epoch [57/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.40it/s, val_loss=0.05055474]\n",
      "Training Epoch [58/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.87it/s, train_loss=0.05044617, val_loss=0.05055474]\n",
      "Validation Epoch [58/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.61it/s, val_loss=0.05001189]\n",
      "Training Epoch [59/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.89it/s, train_loss=0.05012931, val_loss=0.05001189]\n",
      "Validation Epoch [59/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.58it/s, val_loss=0.04964373]\n",
      "Training Epoch [60/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.89it/s, train_loss=0.05001703, val_loss=0.04964373]\n",
      "Validation Epoch [60/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.61it/s, val_loss=0.04992198]\n",
      "Training Epoch [61/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.87it/s, train_loss=0.04970335, val_loss=0.04992198]\n",
      "Validation Epoch [61/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.54it/s, val_loss=0.04926348]\n",
      "Training Epoch [62/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.89it/s, train_loss=0.04950220, val_loss=0.04926348]\n",
      "Validation Epoch [62/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.53it/s, val_loss=0.04952126]\n",
      "Training Epoch [63/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.04929584, val_loss=0.04952126]\n",
      "Validation Epoch [63/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.21it/s, val_loss=0.04880270]\n",
      "Training Epoch [64/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.88it/s, train_loss=0.04916294, val_loss=0.04880270]\n",
      "Validation Epoch [64/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.39it/s, val_loss=0.04796399]\n",
      "Training Epoch [65/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.88it/s, train_loss=0.04894186, val_loss=0.04796399]\n",
      "Validation Epoch [65/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.57it/s, val_loss=0.04844100]\n",
      "Training Epoch [66/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.88it/s, train_loss=0.04867708, val_loss=0.04844100]\n",
      "Validation Epoch [66/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.29it/s, val_loss=0.04849032]\n",
      "Training Epoch [67/100]: 100%|████████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.04854448, val_loss=0.04849032]\n",
      "Validation Epoch [67/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.01it/s, val_loss=0.04740823]\n",
      "Training Epoch [68/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.04827515, val_loss=0.04740823]\n",
      "Validation Epoch [68/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.37it/s, val_loss=0.04774952]\n",
      "Training Epoch [69/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.04805942, val_loss=0.04774952]\n",
      "Validation Epoch [69/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.50it/s, val_loss=0.04727206]\n",
      "Training Epoch [70/100]: 100%|████████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.04771259, val_loss=0.04727206]\n",
      "Validation Epoch [70/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.52it/s, val_loss=0.04702777]\n",
      "Training Epoch [71/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.04744740, val_loss=0.04702777]\n",
      "Validation Epoch [71/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.76it/s, val_loss=0.04620738]\n",
      "Training Epoch [72/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.04721255, val_loss=0.04620738]\n",
      "Validation Epoch [72/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.41it/s, val_loss=0.04598766]\n",
      "Training Epoch [73/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.04690995, val_loss=0.04598766]\n",
      "Validation Epoch [73/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.15it/s, val_loss=0.04600573]\n",
      "Training Epoch [74/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.04675782, val_loss=0.04600573]\n",
      "Validation Epoch [74/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.45it/s, val_loss=0.04553017]\n",
      "Training Epoch [75/100]: 100%|████████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.04664546, val_loss=0.04553017]\n",
      "Validation Epoch [75/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.17it/s, val_loss=0.04527367]\n",
      "Training Epoch [76/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.04650214, val_loss=0.04527367]\n",
      "Validation Epoch [76/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.42it/s, val_loss=0.04544880]\n",
      "Training Epoch [77/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.04625417, val_loss=0.04544880]\n",
      "Validation Epoch [77/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.54it/s, val_loss=0.04482589]\n",
      "Training Epoch [78/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.04598651, val_loss=0.04482589]\n",
      "Validation Epoch [78/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.27it/s, val_loss=0.04511024]\n",
      "Training Epoch [79/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.04597007, val_loss=0.04511024]\n",
      "Validation Epoch [79/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.42it/s, val_loss=0.04435162]\n",
      "Training Epoch [80/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.04579858, val_loss=0.04435162]\n",
      "Validation Epoch [80/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.21it/s, val_loss=0.04460545]\n",
      "Training Epoch [81/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.04569297, val_loss=0.04460545]\n",
      "Validation Epoch [81/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.44it/s, val_loss=0.04460886]\n",
      "Training Epoch [82/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.04546292, val_loss=0.04460886]\n",
      "Validation Epoch [82/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.91it/s, val_loss=0.04391280]\n",
      "Training Epoch [83/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.04542169, val_loss=0.04391280]\n",
      "Validation Epoch [83/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.36it/s, val_loss=0.04405554]\n",
      "Training Epoch [84/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.04528219, val_loss=0.04405554]\n",
      "Validation Epoch [84/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.28it/s, val_loss=0.04376023]\n",
      "Training Epoch [85/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.04502578, val_loss=0.04376023]\n",
      "Validation Epoch [85/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.19it/s, val_loss=0.04347726]\n",
      "Training Epoch [86/100]: 100%|████████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.04492889, val_loss=0.04347726]\n",
      "Validation Epoch [86/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.75it/s, val_loss=0.04385025]\n",
      "Training Epoch [87/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.04484464, val_loss=0.04385025]\n",
      "Validation Epoch [87/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.48it/s, val_loss=0.04342964]\n",
      "Training Epoch [88/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.04477390, val_loss=0.04342964]\n",
      "Validation Epoch [88/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.42it/s, val_loss=0.04326429]\n",
      "Training Epoch [89/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.04464040, val_loss=0.04326429]\n",
      "Validation Epoch [89/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.38it/s, val_loss=0.04288118]\n",
      "Training Epoch [90/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.04455851, val_loss=0.04288118]\n",
      "Validation Epoch [90/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.44it/s, val_loss=0.04272873]\n",
      "Training Epoch [91/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.04445708, val_loss=0.04272873]\n",
      "Validation Epoch [91/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.07it/s, val_loss=0.04330875]\n",
      "Training Epoch [92/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.04424510, val_loss=0.04330875]\n",
      "Validation Epoch [92/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.74it/s, val_loss=0.04285999]\n",
      "Training Epoch [93/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.04418804, val_loss=0.04285999]\n",
      "Validation Epoch [93/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.29it/s, val_loss=0.04249678]\n",
      "Training Epoch [94/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.04404612, val_loss=0.04249678]\n",
      "Validation Epoch [94/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.59it/s, val_loss=0.04261863]\n",
      "Training Epoch [95/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.04396975, val_loss=0.04261863]\n",
      "Validation Epoch [95/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.33it/s, val_loss=0.04157568]\n",
      "Training Epoch [96/100]: 100%|████████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.04375353, val_loss=0.04157568]\n",
      "Validation Epoch [96/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.60it/s, val_loss=0.04242034]\n",
      "Training Epoch [97/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.04374808, val_loss=0.04242034]\n",
      "Validation Epoch [97/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.42it/s, val_loss=0.04194134]\n",
      "Training Epoch [98/100]: 100%|████████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.04360954, val_loss=0.04194134]\n",
      "Validation Epoch [98/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.61it/s, val_loss=0.04232203]\n",
      "Training Epoch [99/100]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.04355697, val_loss=0.04232203]\n",
      "Validation Epoch [99/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.51it/s, val_loss=0.04187918]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_pretrained = Encoder(hparams).to(device)\n",
    "decoder = Decoder(hparams).to(device)\n",
    "autoencoder = Autoencoder(hparams, encoder_pretrained, decoder).to(device)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, loss_func, tb_logger, epochs=10, name='Autoencoder'):\n",
    "    \n",
    "    optimizer = model.optimizer\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=epochs * len(train_loader) / 5, gamma=0.7)\n",
    "    validation_loss = 0\n",
    "    model = model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Train\n",
    "        training_loop = create_tqdm_bar(train_loader, desc=f'Training Epoch [{epoch}/{epochs}]')\n",
    "        training_loss = 0\n",
    "        for train_iteration, batch in training_loop:\n",
    "            \n",
    "            loss = model.training_step(batch, loss_func) # You need to implement this function.\n",
    "            training_loss += loss.item()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Update the progress bar.\n",
    "            training_loop.set_postfix(train_loss = \"{:.8f}\".format(training_loss / (train_iteration + 1)), val_loss = \"{:.8f}\".format(validation_loss))\n",
    "\n",
    "            # Update the tensorboard logger.\n",
    "            tb_logger.add_scalar(f'{name}/train_loss', loss.item(), epoch * len(train_loader) + train_iteration)\n",
    "\n",
    "        # Validation\n",
    "        val_loop = create_tqdm_bar(val_loader, desc=f'Validation Epoch [{epoch}/{epochs}]')\n",
    "        validation_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for val_iteration, batch in val_loop:\n",
    "                loss = model.validation_step(batch, loss_func) # You need to implement this function.\n",
    "                validation_loss += loss.item()\n",
    "\n",
    "                # Update the progress bar.\n",
    "                val_loop.set_postfix(val_loss = \"{:.8f}\".format(validation_loss / (val_iteration + 1)))\n",
    "\n",
    "                # Update the tensorboard logger.\n",
    "                tb_logger.add_scalar(f'{name}/val_loss', validation_loss / (val_iteration + 1), epoch * len(val_loader) + val_iteration)\n",
    "        # This value is for the progress bar of the training loop.\n",
    "        validation_loss /= len(val_loader)\n",
    "\n",
    "# Creat a tensorboard logger.\n",
    "# NOTE: In order to see the logs, run the following command in the terminal: tensorboard --logdir=./\n",
    "# Also, in order to reset the logs, delete the logs folder MANUALLY.\n",
    "\n",
    "path = os.path.join('logs', 'ae_logs')\n",
    "num_of_runs = len(os.listdir(path)) if os.path.exists(path) else 0\n",
    "path = os.path.join(path, f'run_{num_of_runs + 1}')\n",
    "tb_logger = SummaryWriter(path)\n",
    "\n",
    "# Train the classifier.\n",
    "unlabled_train_loader = torch.utils.data.DataLoader(unlabeled_train, batch_size=hparams['batch_size'], shuffle=True)\n",
    "unlabled_val_loader = torch.utils.data.DataLoader(unlabeled_val, batch_size=hparams['batch_size'], shuffle=False)\n",
    "\n",
    "epochs = hparams.get('epochs', 5)\n",
    "loss_func = nn.MSELoss() # The loss function we use for regression (Could also be nn.L1Loss()).\n",
    "train_model(autoencoder, unlabled_train_loader, unlabled_val_loader, loss_func, tb_logger, epochs=epochs, name='Autoencoder')\n",
    "\n",
    "print(\"Finished training!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "vdgiYWy4MNkq"
   },
   "source": [
    "Once trained, let's have a look at the reconstructed validation images (If you have not already looked at them in TensorBoard)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "a991mKcyMNkq"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1600 with 64 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reconstructions = autoencoder.getReconstructions(unlabled_val_loader)\n",
    "for i in range(64):\n",
    "    plt.subplot(8,8,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(reconstructions[i], cmap='gray', interpolation='none')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "R2hrP5b1MNkr"
   },
   "source": [
    "# 4. Transfer Learning\n",
    "\n",
    "## 4.1 The pretrained Classifier\n",
    "\n",
    "Now we initialize another classifier but this time with the pretrained encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "OELYQAUmMNkr"
   },
   "outputs": [],
   "source": [
    "from exercise_code.models import Classifier\n",
    "from copy import deepcopy\n",
    "\n",
    "hparams = {}\n",
    "########################################################################\n",
    "# TODO: Define your hyperparameters here!                             #\n",
    "########################################################################\n",
    "\n",
    "hparams = {    \n",
    "    \"device\" : device,\n",
    "    \"num_workers\" : 8,\n",
    "    \"epochs\" : 800,\n",
    "    \"batch_size\" : 2048,\n",
    "    \n",
    "    \"num_classes\" : 10, # There are 10 digits\n",
    "    \"input_size\" : 28 * 28, # Number of pixels in images\n",
    "    \n",
    "    \"learning_rate\" : 2e-3, # Optimizer\n",
    "    \"weight_decay\" : 1e-5, # ADAM\n",
    "    \n",
    "    \"dropout_p\" : 0.5, # Dropout probability for the classifier, reduces overfitting\n",
    "    \"latent_dim\" : 20, # Encoder output dim, Decode input dim, classifier input dim. If this it too high, overfitting will occur\n",
    "    \"decoder_hidden\" : 512, # Decoder Hidden\n",
    "    \"encoder_hidden\" : 512, # Encoder Hidden\n",
    "    \"classifier_hidden\" : 2048 # Classifier Hidden\n",
    "}\n",
    "\n",
    "########################################################################\n",
    "#                           END OF YOUR CODE                           #\n",
    "########################################################################\n",
    "\n",
    "encoder_pretrained_copy = deepcopy(encoder_pretrained)\n",
    "classifier_pretrained = Classifier(hparams, encoder_pretrained_copy).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "R8FUtih6MNks"
   },
   "source": [
    "Let's define another trainer that will utilize the pretrained classifier, allowing us to compare its performance with the classifier trained only on the labeled data. To achieve a reasonable result, you may need to optimize the parameters you defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "Mx_euorWMNks"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [1/800]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  7.68it/s, curr_train_loss=2.48013711, val_loss=0.00000000]\n",
      "Validation Epoch [1/800]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, val_loss=2.36463547]\n",
      "Training Epoch [2/800]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  6.62it/s, curr_train_loss=2.35774755, val_loss=0.00000000]\n",
      "Validation Epoch [2/800]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.51it/s, val_loss=2.34243059]\n",
      "Training Epoch [3/800]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  6.57it/s, curr_train_loss=2.39393520, val_loss=0.00000000]\n",
      "Validation Epoch [3/800]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, val_loss=2.31539297]\n",
      "Training Epoch [4/800]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  6.37it/s, curr_train_loss=2.29259419, val_loss=0.00000000]\n",
      "Validation Epoch [4/800]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, val_loss=2.30373478]\n",
      "Training Epoch [5/800]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  6.71it/s, curr_train_loss=2.22235417, val_loss=0.00000000]\n",
      "Validation Epoch [5/800]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.77it/s, val_loss=2.29915071]\n",
      "Training Epoch [6/800]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  6.58it/s, curr_train_loss=2.21389627, val_loss=0.00000000]\n",
      "Validation Epoch [6/800]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, val_loss=2.28107119]\n",
      "Training Epoch [7/800]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  6.61it/s, curr_train_loss=2.17922974, val_loss=0.00000000]\n",
      "Validation Epoch [7/800]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.15it/s, val_loss=2.26735544]\n",
      "Training Epoch [8/800]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  6.49it/s, curr_train_loss=2.20331144, val_loss=0.00000000]\n",
      "Validation Epoch [8/800]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.98it/s, val_loss=2.26811814]\n",
      "Training Epoch [9/800]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  6.70it/s, curr_train_loss=2.19401574, val_loss=0.00000000]\n",
      "Validation Epoch [9/800]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, val_loss=2.26829553]\n",
      "Training Epoch [10/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.42it/s, curr_train_loss=2.22048283, val_loss=0.00000000]\n",
      "Validation Epoch [10/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.02it/s, val_loss=2.21890569]\n",
      "Training Epoch [11/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.64it/s, curr_train_loss=2.17668104, val_loss=0.00000000]\n",
      "Validation Epoch [11/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.16it/s, val_loss=2.22480083]\n",
      "Training Epoch [12/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.54it/s, curr_train_loss=2.11144400, val_loss=0.00000000]\n",
      "Validation Epoch [12/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.93it/s, val_loss=2.21798038]\n",
      "Training Epoch [13/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.60it/s, curr_train_loss=2.08980083, val_loss=0.00000000]\n",
      "Validation Epoch [13/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, val_loss=2.19267941]\n",
      "Training Epoch [14/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.46it/s, curr_train_loss=2.17404914, val_loss=0.00000000]\n",
      "Validation Epoch [14/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.59it/s, val_loss=2.19036818]\n",
      "Training Epoch [15/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.53it/s, curr_train_loss=2.14139247, val_loss=0.00000000]\n",
      "Validation Epoch [15/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.10it/s, val_loss=2.19571018]\n",
      "Training Epoch [16/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.85it/s, curr_train_loss=2.09976268, val_loss=0.00000000]\n",
      "Validation Epoch [16/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.82it/s, val_loss=2.19915605]\n",
      "Training Epoch [17/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.57it/s, curr_train_loss=2.04166698, val_loss=0.00000000]\n",
      "Validation Epoch [17/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.07it/s, val_loss=2.17091298]\n",
      "Training Epoch [18/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.50it/s, curr_train_loss=2.00318694, val_loss=0.00000000]\n",
      "Validation Epoch [18/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.05it/s, val_loss=2.17827249]\n",
      "Training Epoch [19/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.50it/s, curr_train_loss=2.03692484, val_loss=0.00000000]\n",
      "Validation Epoch [19/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.15it/s, val_loss=2.11143231]\n",
      "Training Epoch [20/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.50it/s, curr_train_loss=2.02145791, val_loss=0.00000000]\n",
      "Validation Epoch [20/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, val_loss=2.11532307]\n",
      "Training Epoch [21/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.77it/s, curr_train_loss=1.94941401, val_loss=0.00000000]\n",
      "Validation Epoch [21/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.99it/s, val_loss=2.12469125]\n",
      "Training Epoch [22/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.50it/s, curr_train_loss=1.92043209, val_loss=0.00000000]\n",
      "Validation Epoch [22/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.60it/s, val_loss=2.10215735]\n",
      "Training Epoch [23/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.44it/s, curr_train_loss=2.03439045, val_loss=0.00000000]\n",
      "Validation Epoch [23/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, val_loss=2.07806587]\n",
      "Training Epoch [24/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.63it/s, curr_train_loss=1.99312878, val_loss=0.00000000]\n",
      "Validation Epoch [24/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.91it/s, val_loss=2.06421804]\n",
      "Training Epoch [25/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.18it/s, curr_train_loss=2.09629011, val_loss=0.00000000]\n",
      "Validation Epoch [25/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.82it/s, val_loss=2.05415535]\n",
      "Training Epoch [26/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, curr_train_loss=1.97732604, val_loss=0.00000000]\n",
      "Validation Epoch [26/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.01it/s, val_loss=1.99545085]\n",
      "Training Epoch [27/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.06it/s, curr_train_loss=1.92299974, val_loss=0.00000000]\n",
      "Validation Epoch [27/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, val_loss=2.04774570]\n",
      "Training Epoch [28/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, curr_train_loss=1.93599808, val_loss=0.00000000]\n",
      "Validation Epoch [28/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.95833743]\n",
      "Training Epoch [29/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.54it/s, curr_train_loss=1.99385130, val_loss=0.00000000]\n",
      "Validation Epoch [29/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.95857000]\n",
      "Training Epoch [30/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.96it/s, curr_train_loss=1.86448133, val_loss=0.00000000]\n",
      "Validation Epoch [30/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.99it/s, val_loss=1.98512053]\n",
      "Training Epoch [31/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.52it/s, curr_train_loss=1.87889636, val_loss=0.00000000]\n",
      "Validation Epoch [31/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.89it/s, val_loss=1.94545043]\n",
      "Training Epoch [32/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.59it/s, curr_train_loss=1.96364450, val_loss=0.00000000]\n",
      "Validation Epoch [32/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.73it/s, val_loss=1.96447062]\n",
      "Training Epoch [33/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.49it/s, curr_train_loss=1.84747434, val_loss=0.00000000]\n",
      "Validation Epoch [33/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.99it/s, val_loss=1.90827250]\n",
      "Training Epoch [34/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.38it/s, curr_train_loss=1.96102107, val_loss=0.00000000]\n",
      "Validation Epoch [34/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, val_loss=1.91525805]\n",
      "Training Epoch [35/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.70it/s, curr_train_loss=1.91646910, val_loss=0.00000000]\n",
      "Validation Epoch [35/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.92it/s, val_loss=1.93693447]\n",
      "Training Epoch [36/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.70it/s, curr_train_loss=1.84421647, val_loss=0.00000000]\n",
      "Validation Epoch [36/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.83it/s, val_loss=1.94304609]\n",
      "Training Epoch [37/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.60it/s, curr_train_loss=1.77883840, val_loss=0.00000000]\n",
      "Validation Epoch [37/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.13it/s, val_loss=1.91276813]\n",
      "Training Epoch [38/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.52it/s, curr_train_loss=1.82151854, val_loss=0.00000000]\n",
      "Validation Epoch [38/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.09it/s, val_loss=1.86453831]\n",
      "Training Epoch [39/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.52it/s, curr_train_loss=1.83083630, val_loss=0.00000000]\n",
      "Validation Epoch [39/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.13it/s, val_loss=1.82922029]\n",
      "Training Epoch [40/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.48it/s, curr_train_loss=1.78969312, val_loss=0.00000000]\n",
      "Validation Epoch [40/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.90it/s, val_loss=1.83938801]\n",
      "Training Epoch [41/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.59it/s, curr_train_loss=1.70344865, val_loss=0.00000000]\n",
      "Validation Epoch [41/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.82784283]\n",
      "Training Epoch [42/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=1.60246825, val_loss=0.00000000]\n",
      "Validation Epoch [42/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.84it/s, val_loss=1.81499326]\n",
      "Training Epoch [43/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=1.66469467, val_loss=0.00000000]\n",
      "Validation Epoch [43/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.78it/s, val_loss=1.78739619]\n",
      "Training Epoch [44/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.06it/s, curr_train_loss=1.54382670, val_loss=0.00000000]\n",
      "Validation Epoch [44/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=1.75848699]\n",
      "Training Epoch [45/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=1.70071423, val_loss=0.00000000]\n",
      "Validation Epoch [45/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.79632127]\n",
      "Training Epoch [46/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, curr_train_loss=1.59261751, val_loss=0.00000000]\n",
      "Validation Epoch [46/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.13it/s, val_loss=1.75433695]\n",
      "Training Epoch [47/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=1.60582018, val_loss=0.00000000]\n",
      "Validation Epoch [47/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, val_loss=1.72655964]\n",
      "Training Epoch [48/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=1.73627234, val_loss=0.00000000]\n",
      "Validation Epoch [48/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.81600881]\n",
      "Training Epoch [49/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.58it/s, curr_train_loss=1.57053256, val_loss=0.00000000]\n",
      "Validation Epoch [49/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.06it/s, val_loss=1.74668920]\n",
      "Training Epoch [50/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=1.64216614, val_loss=0.00000000]\n",
      "Validation Epoch [50/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=1.69883037]\n",
      "Training Epoch [51/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.46it/s, curr_train_loss=1.53129232, val_loss=0.00000000]\n",
      "Validation Epoch [51/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.93it/s, val_loss=1.75542033]\n",
      "Training Epoch [52/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.20it/s, curr_train_loss=1.57611346, val_loss=0.00000000]\n",
      "Validation Epoch [52/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.95it/s, val_loss=1.68054271]\n",
      "Training Epoch [53/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.59it/s, curr_train_loss=1.58244979, val_loss=0.00000000]\n",
      "Validation Epoch [53/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.88it/s, val_loss=1.69866288]\n",
      "Training Epoch [54/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=1.77932072, val_loss=0.00000000]\n",
      "Validation Epoch [54/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.68213975]\n",
      "Training Epoch [55/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.15it/s, curr_train_loss=1.53121078, val_loss=0.00000000]\n",
      "Validation Epoch [55/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.63450730]\n",
      "Training Epoch [56/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.50it/s, curr_train_loss=1.35581350, val_loss=0.00000000]\n",
      "Validation Epoch [56/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, val_loss=1.65672481]\n",
      "Training Epoch [57/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.57it/s, curr_train_loss=1.51191759, val_loss=0.00000000]\n",
      "Validation Epoch [57/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s, val_loss=1.53740788]\n",
      "Training Epoch [58/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.58it/s, curr_train_loss=1.48282623, val_loss=0.00000000]\n",
      "Validation Epoch [58/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.20it/s, val_loss=1.59644651]\n",
      "Training Epoch [59/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.46it/s, curr_train_loss=1.34696126, val_loss=0.00000000]\n",
      "Validation Epoch [59/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, val_loss=1.65530121]\n",
      "Training Epoch [60/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.54it/s, curr_train_loss=1.34254169, val_loss=0.00000000]\n",
      "Validation Epoch [60/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, val_loss=1.57344580]\n",
      "Training Epoch [61/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.94it/s, curr_train_loss=1.50954580, val_loss=0.00000000]\n",
      "Validation Epoch [61/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.60it/s, val_loss=1.59901083]\n",
      "Training Epoch [62/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.93it/s, curr_train_loss=1.28457475, val_loss=0.00000000]\n",
      "Validation Epoch [62/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.08it/s, val_loss=1.51420283]\n",
      "Training Epoch [63/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.53it/s, curr_train_loss=1.36596501, val_loss=0.00000000]\n",
      "Validation Epoch [63/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.97it/s, val_loss=1.45672894]\n",
      "Training Epoch [64/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.58it/s, curr_train_loss=1.29486990, val_loss=0.00000000]\n",
      "Validation Epoch [64/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, val_loss=1.49920321]\n",
      "Training Epoch [65/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.52it/s, curr_train_loss=1.55752718, val_loss=0.00000000]\n",
      "Validation Epoch [65/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.09it/s, val_loss=1.51393604]\n",
      "Training Epoch [66/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.70it/s, curr_train_loss=1.53820109, val_loss=0.00000000]\n",
      "Validation Epoch [66/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.82it/s, val_loss=1.51949704]\n",
      "Training Epoch [67/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.41it/s, curr_train_loss=1.61045563, val_loss=0.00000000]\n",
      "Validation Epoch [67/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.02it/s, val_loss=1.49426305]\n",
      "Training Epoch [68/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.82it/s, curr_train_loss=1.49949086, val_loss=0.00000000]\n",
      "Validation Epoch [68/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.04it/s, val_loss=1.51910841]\n",
      "Training Epoch [69/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.53it/s, curr_train_loss=1.47824824, val_loss=0.00000000]\n",
      "Validation Epoch [69/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.83it/s, val_loss=1.60080457]\n",
      "Training Epoch [70/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.44it/s, curr_train_loss=1.22532296, val_loss=0.00000000]\n",
      "Validation Epoch [70/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, val_loss=1.48918986]\n",
      "Training Epoch [71/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, curr_train_loss=1.41498852, val_loss=0.00000000]\n",
      "Validation Epoch [71/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.51422322]\n",
      "Training Epoch [72/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, curr_train_loss=1.26794434, val_loss=0.00000000]\n",
      "Validation Epoch [72/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.98it/s, val_loss=1.46148145]\n",
      "Training Epoch [73/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=1.35867691, val_loss=0.00000000]\n",
      "Validation Epoch [73/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, val_loss=1.58834314]\n",
      "Training Epoch [74/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.06it/s, curr_train_loss=1.17890394, val_loss=0.00000000]\n",
      "Validation Epoch [74/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.50492847]\n",
      "Training Epoch [75/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=1.29648960, val_loss=0.00000000]\n",
      "Validation Epoch [75/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=1.58714879]\n",
      "Training Epoch [76/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.46it/s, curr_train_loss=1.39457595, val_loss=0.00000000]\n",
      "Validation Epoch [76/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.01it/s, val_loss=1.51082766]\n",
      "Training Epoch [77/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.34it/s, curr_train_loss=1.21321034, val_loss=0.00000000]\n",
      "Validation Epoch [77/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.41331637]\n",
      "Training Epoch [78/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.58it/s, curr_train_loss=1.38735843, val_loss=0.00000000]\n",
      "Validation Epoch [78/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, val_loss=1.46037984]\n",
      "Training Epoch [79/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, curr_train_loss=1.30926847, val_loss=0.00000000]\n",
      "Validation Epoch [79/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.65it/s, val_loss=1.44687855]\n",
      "Training Epoch [80/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=1.15745366, val_loss=0.00000000]\n",
      "Validation Epoch [80/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.53598070]\n",
      "Training Epoch [81/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.55it/s, curr_train_loss=1.16116190, val_loss=0.00000000]\n",
      "Validation Epoch [81/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s, val_loss=1.55611432]\n",
      "Training Epoch [82/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, curr_train_loss=1.35604918, val_loss=0.00000000]\n",
      "Validation Epoch [82/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.06it/s, val_loss=1.40312231]\n",
      "Training Epoch [83/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=1.40879452, val_loss=0.00000000]\n",
      "Validation Epoch [83/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.91it/s, val_loss=1.38973844]\n",
      "Training Epoch [84/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.97it/s, curr_train_loss=1.48782015, val_loss=0.00000000]\n",
      "Validation Epoch [84/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.74it/s, val_loss=1.47568989]\n",
      "Training Epoch [85/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.53it/s, curr_train_loss=1.32995498, val_loss=0.00000000]\n",
      "Validation Epoch [85/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=1.33478558]\n",
      "Training Epoch [86/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=1.17266536, val_loss=0.00000000]\n",
      "Validation Epoch [86/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, val_loss=1.51794124]\n",
      "Training Epoch [87/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=1.15122366, val_loss=0.00000000]\n",
      "Validation Epoch [87/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.72it/s, val_loss=1.35075867]\n",
      "Training Epoch [88/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.67it/s, curr_train_loss=1.21468377, val_loss=0.00000000]\n",
      "Validation Epoch [88/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s, val_loss=1.50549328]\n",
      "Training Epoch [89/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=1.13840473, val_loss=0.00000000]\n",
      "Validation Epoch [89/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.27748418]\n",
      "Training Epoch [90/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.14it/s, curr_train_loss=1.31325293, val_loss=0.00000000]\n",
      "Validation Epoch [90/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.95it/s, val_loss=1.33687901]\n",
      "Training Epoch [91/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.19it/s, curr_train_loss=1.22618985, val_loss=0.00000000]\n",
      "Validation Epoch [91/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.88it/s, val_loss=1.37820935]\n",
      "Training Epoch [92/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.52it/s, curr_train_loss=1.26856768, val_loss=0.00000000]\n",
      "Validation Epoch [92/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.67it/s, val_loss=1.33990657]\n",
      "Training Epoch [93/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.68it/s, curr_train_loss=1.08870053, val_loss=0.00000000]\n",
      "Validation Epoch [93/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.79it/s, val_loss=1.36413884]\n",
      "Training Epoch [94/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.39it/s, curr_train_loss=1.34020090, val_loss=0.00000000]\n",
      "Validation Epoch [94/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.36it/s, val_loss=1.40971589]\n",
      "Training Epoch [95/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.54it/s, curr_train_loss=1.28558004, val_loss=0.00000000]\n",
      "Validation Epoch [95/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.00it/s, val_loss=1.40608525]\n",
      "Training Epoch [96/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.43it/s, curr_train_loss=1.13672209, val_loss=0.00000000]\n",
      "Validation Epoch [96/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.69it/s, val_loss=1.26388323]\n",
      "Training Epoch [97/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.39it/s, curr_train_loss=1.28834474, val_loss=0.00000000]\n",
      "Validation Epoch [97/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.99it/s, val_loss=1.39308214]\n",
      "Training Epoch [98/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.18it/s, curr_train_loss=1.10766828, val_loss=0.00000000]\n",
      "Validation Epoch [98/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.35224307]\n",
      "Training Epoch [99/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=1.01685190, val_loss=0.00000000]\n",
      "Validation Epoch [99/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.02it/s, val_loss=1.39676225]\n",
      "Training Epoch [100/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.49it/s, curr_train_loss=1.05632460, val_loss=0.00000000]\n",
      "Validation Epoch [100/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.05it/s, val_loss=1.31564403]\n",
      "Training Epoch [101/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.36it/s, curr_train_loss=1.29878891, val_loss=0.00000000]\n",
      "Validation Epoch [101/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.01it/s, val_loss=1.32969999]\n",
      "Training Epoch [102/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, curr_train_loss=1.29612875, val_loss=0.00000000]\n",
      "Validation Epoch [102/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=1.36708438]\n",
      "Training Epoch [103/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=1.22160292, val_loss=0.00000000]\n",
      "Validation Epoch [103/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.76it/s, val_loss=1.31766176]\n",
      "Training Epoch [104/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, curr_train_loss=1.24850225, val_loss=0.00000000]\n",
      "Validation Epoch [104/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.71it/s, val_loss=1.23144305]\n",
      "Training Epoch [105/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.16it/s, curr_train_loss=1.14278221, val_loss=0.00000000]\n",
      "Validation Epoch [105/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.14it/s, val_loss=1.22550821]\n",
      "Training Epoch [106/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.10it/s, curr_train_loss=1.11268890, val_loss=0.00000000]\n",
      "Validation Epoch [106/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.13it/s, val_loss=1.36880291]\n",
      "Training Epoch [107/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=1.07639194, val_loss=0.00000000]\n",
      "Validation Epoch [107/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=1.31724381]\n",
      "Training Epoch [108/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.53it/s, curr_train_loss=1.15429044, val_loss=0.00000000]\n",
      "Validation Epoch [108/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.33869410]\n",
      "Training Epoch [109/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, curr_train_loss=1.10909140, val_loss=0.00000000]\n",
      "Validation Epoch [109/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.04it/s, val_loss=1.38789475]\n",
      "Training Epoch [110/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.25it/s, curr_train_loss=1.00981855, val_loss=0.00000000]\n",
      "Validation Epoch [110/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s, val_loss=1.33562577]\n",
      "Training Epoch [111/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=1.18001091, val_loss=0.00000000]\n",
      "Validation Epoch [111/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.70it/s, val_loss=1.25169921]\n",
      "Training Epoch [112/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=0.93610811, val_loss=0.00000000]\n",
      "Validation Epoch [112/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.02it/s, val_loss=1.35295475]\n",
      "Training Epoch [113/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, curr_train_loss=0.97664857, val_loss=0.00000000]\n",
      "Validation Epoch [113/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, val_loss=1.25198841]\n",
      "Training Epoch [114/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, curr_train_loss=0.90676498, val_loss=0.00000000]\n",
      "Validation Epoch [114/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.79it/s, val_loss=1.24220586]\n",
      "Training Epoch [115/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=1.16435802, val_loss=0.00000000]\n",
      "Validation Epoch [115/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.51it/s, val_loss=1.23623455]\n",
      "Training Epoch [116/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=1.03894198, val_loss=0.00000000]\n",
      "Validation Epoch [116/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.76it/s, val_loss=1.32570171]\n",
      "Training Epoch [117/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.61it/s, curr_train_loss=0.82266927, val_loss=0.00000000]\n",
      "Validation Epoch [117/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.63it/s, val_loss=1.27131593]\n",
      "Training Epoch [118/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.15it/s, curr_train_loss=0.95890707, val_loss=0.00000000]\n",
      "Validation Epoch [118/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=1.27353799]\n",
      "Training Epoch [119/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=1.14038646, val_loss=0.00000000]\n",
      "Validation Epoch [119/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.84it/s, val_loss=1.30315351]\n",
      "Training Epoch [120/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.33it/s, curr_train_loss=1.12109554, val_loss=0.00000000]\n",
      "Validation Epoch [120/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.94it/s, val_loss=1.39450014]\n",
      "Training Epoch [121/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=0.97613066, val_loss=0.00000000]\n",
      "Validation Epoch [121/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.67it/s, val_loss=1.11879277]\n",
      "Training Epoch [122/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.51it/s, curr_train_loss=1.06667018, val_loss=0.00000000]\n",
      "Validation Epoch [122/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.28980708]\n",
      "Training Epoch [123/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, curr_train_loss=0.93104726, val_loss=0.00000000]\n",
      "Validation Epoch [123/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.97it/s, val_loss=1.17371523]\n",
      "Training Epoch [124/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.06it/s, curr_train_loss=1.05323386, val_loss=0.00000000]\n",
      "Validation Epoch [124/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.68it/s, val_loss=1.27637446]\n",
      "Training Epoch [125/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, curr_train_loss=0.92884606, val_loss=0.00000000]\n",
      "Validation Epoch [125/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.59it/s, val_loss=1.22483766]\n",
      "Training Epoch [126/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.41it/s, curr_train_loss=0.97597307, val_loss=0.00000000]\n",
      "Validation Epoch [126/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.88it/s, val_loss=1.22569990]\n",
      "Training Epoch [127/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.56it/s, curr_train_loss=0.83923376, val_loss=0.00000000]\n",
      "Validation Epoch [127/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, val_loss=1.20578277]\n",
      "Training Epoch [128/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.10it/s, curr_train_loss=0.75757670, val_loss=0.00000000]\n",
      "Validation Epoch [128/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=1.27865911]\n",
      "Training Epoch [129/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.56it/s, curr_train_loss=1.10997486, val_loss=0.00000000]\n",
      "Validation Epoch [129/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.95it/s, val_loss=1.30393887]\n",
      "Training Epoch [130/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.42it/s, curr_train_loss=0.77369958, val_loss=0.00000000]\n",
      "Validation Epoch [130/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, val_loss=1.26970279]\n",
      "Training Epoch [131/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, curr_train_loss=1.13679039, val_loss=0.00000000]\n",
      "Validation Epoch [131/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.79it/s, val_loss=1.19395101]\n",
      "Training Epoch [132/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=0.85287642, val_loss=0.00000000]\n",
      "Validation Epoch [132/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.24667287]\n",
      "Training Epoch [133/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=0.93676394, val_loss=0.00000000]\n",
      "Validation Epoch [133/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.12933385]\n",
      "Training Epoch [134/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.60it/s, curr_train_loss=0.74382138, val_loss=0.00000000]\n",
      "Validation Epoch [134/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=1.28028774]\n",
      "Training Epoch [135/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, curr_train_loss=1.04985762, val_loss=0.00000000]\n",
      "Validation Epoch [135/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.68it/s, val_loss=1.08969545]\n",
      "Training Epoch [136/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=1.31754303, val_loss=0.00000000]\n",
      "Validation Epoch [136/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=1.14575100]\n",
      "Training Epoch [137/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, curr_train_loss=0.76248544, val_loss=0.00000000]\n",
      "Validation Epoch [137/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.20561767]\n",
      "Training Epoch [138/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, curr_train_loss=0.97125006, val_loss=0.00000000]\n",
      "Validation Epoch [138/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, val_loss=1.17539978]\n",
      "Training Epoch [139/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, curr_train_loss=0.95886838, val_loss=0.00000000]\n",
      "Validation Epoch [139/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.06it/s, val_loss=1.17940724]\n",
      "Training Epoch [140/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, curr_train_loss=1.03606892, val_loss=0.00000000]\n",
      "Validation Epoch [140/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=1.09100115]\n",
      "Training Epoch [141/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, curr_train_loss=0.88449359, val_loss=0.00000000]\n",
      "Validation Epoch [141/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s, val_loss=1.16880810]\n",
      "Training Epoch [142/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, curr_train_loss=0.88191885, val_loss=0.00000000]\n",
      "Validation Epoch [142/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.91it/s, val_loss=1.24801636]\n",
      "Training Epoch [143/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.59it/s, curr_train_loss=0.71672243, val_loss=0.00000000]\n",
      "Validation Epoch [143/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=1.21213496]\n",
      "Training Epoch [144/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=0.99253982, val_loss=0.00000000]\n",
      "Validation Epoch [144/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.27566230]\n",
      "Training Epoch [145/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  5.63it/s, curr_train_loss=1.10713458, val_loss=0.00000000]\n",
      "Validation Epoch [145/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.35635555]\n",
      "Training Epoch [146/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.92664117, val_loss=0.00000000]\n",
      "Validation Epoch [146/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.10it/s, val_loss=1.17029047]\n",
      "Training Epoch [147/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.76it/s, curr_train_loss=1.05656505, val_loss=0.00000000]\n",
      "Validation Epoch [147/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.02it/s, val_loss=1.24721432]\n",
      "Training Epoch [148/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.09it/s, curr_train_loss=0.90840012, val_loss=0.00000000]\n",
      "Validation Epoch [148/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.76it/s, val_loss=1.30324721]\n",
      "Training Epoch [149/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.85it/s, curr_train_loss=0.98320651, val_loss=0.00000000]\n",
      "Validation Epoch [149/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.06it/s, val_loss=1.02880418]\n",
      "Training Epoch [150/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.37it/s, curr_train_loss=0.79974276, val_loss=0.00000000]\n",
      "Validation Epoch [150/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s, val_loss=1.20618463]\n",
      "Training Epoch [151/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, curr_train_loss=1.08974731, val_loss=0.00000000]\n",
      "Validation Epoch [151/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.95it/s, val_loss=1.05148661]\n",
      "Training Epoch [152/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.63it/s, curr_train_loss=0.80337501, val_loss=0.00000000]\n",
      "Validation Epoch [152/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.48it/s, val_loss=1.10563934]\n",
      "Training Epoch [153/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.51it/s, curr_train_loss=1.04617679, val_loss=0.00000000]\n",
      "Validation Epoch [153/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.26701689]\n",
      "Training Epoch [154/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=0.63304639, val_loss=0.00000000]\n",
      "Validation Epoch [154/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, val_loss=1.15701163]\n",
      "Training Epoch [155/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.35it/s, curr_train_loss=0.84313065, val_loss=0.00000000]\n",
      "Validation Epoch [155/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, val_loss=1.06169271]\n",
      "Training Epoch [156/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.99it/s, curr_train_loss=0.84791201, val_loss=0.00000000]\n",
      "Validation Epoch [156/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, val_loss=1.33528197]\n",
      "Training Epoch [157/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.60it/s, curr_train_loss=0.94927877, val_loss=0.00000000]\n",
      "Validation Epoch [157/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.78it/s, val_loss=1.15526152]\n",
      "Training Epoch [158/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.65it/s, curr_train_loss=1.16208291, val_loss=0.00000000]\n",
      "Validation Epoch [158/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.65it/s, val_loss=1.15758467]\n",
      "Training Epoch [159/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.54it/s, curr_train_loss=0.93672109, val_loss=0.00000000]\n",
      "Validation Epoch [159/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, val_loss=1.14769244]\n",
      "Training Epoch [160/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=0.94186282, val_loss=0.00000000]\n",
      "Validation Epoch [160/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.09it/s, val_loss=1.12046432]\n",
      "Training Epoch [161/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.29it/s, curr_train_loss=1.06804395, val_loss=0.00000000]\n",
      "Validation Epoch [161/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.10it/s, val_loss=1.23222256]\n",
      "Training Epoch [162/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.31it/s, curr_train_loss=0.83254701, val_loss=0.00000000]\n",
      "Validation Epoch [162/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s, val_loss=1.13049972]\n",
      "Training Epoch [163/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.90it/s, curr_train_loss=0.75277048, val_loss=0.00000000]\n",
      "Validation Epoch [163/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=0.99345678]\n",
      "Training Epoch [164/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, curr_train_loss=1.11521316, val_loss=0.00000000]\n",
      "Validation Epoch [164/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.54it/s, val_loss=1.09841120]\n",
      "Training Epoch [165/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.49it/s, curr_train_loss=0.84989309, val_loss=0.00000000]\n",
      "Validation Epoch [165/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.90it/s, val_loss=1.13598704]\n",
      "Training Epoch [166/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.05it/s, curr_train_loss=0.82649159, val_loss=0.00000000]\n",
      "Validation Epoch [166/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s, val_loss=1.02926958]\n",
      "Training Epoch [167/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.43it/s, curr_train_loss=0.94000590, val_loss=0.00000000]\n",
      "Validation Epoch [167/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.71it/s, val_loss=1.22205460]\n",
      "Training Epoch [168/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.64it/s, curr_train_loss=0.62758958, val_loss=0.00000000]\n",
      "Validation Epoch [168/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.80it/s, val_loss=1.18025994]\n",
      "Training Epoch [169/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, curr_train_loss=0.92027122, val_loss=0.00000000]\n",
      "Validation Epoch [169/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.15780628]\n",
      "Training Epoch [170/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.73869574, val_loss=0.00000000]\n",
      "Validation Epoch [170/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.01it/s, val_loss=1.02184153]\n",
      "Training Epoch [171/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.08it/s, curr_train_loss=0.90566695, val_loss=0.00000000]\n",
      "Validation Epoch [171/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.76it/s, val_loss=1.12104130]\n",
      "Training Epoch [172/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.30it/s, curr_train_loss=0.91336137, val_loss=0.00000000]\n",
      "Validation Epoch [172/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.04it/s, val_loss=1.10067046]\n",
      "Training Epoch [173/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.62it/s, curr_train_loss=0.91161591, val_loss=0.00000000]\n",
      "Validation Epoch [173/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.58it/s, val_loss=1.18724144]\n",
      "Training Epoch [174/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.80it/s, curr_train_loss=0.86643630, val_loss=0.00000000]\n",
      "Validation Epoch [174/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.69it/s, val_loss=1.13329363]\n",
      "Training Epoch [175/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.55it/s, curr_train_loss=0.81872469, val_loss=0.00000000]\n",
      "Validation Epoch [175/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.79it/s, val_loss=1.11432636]\n",
      "Training Epoch [176/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=0.79925936, val_loss=0.00000000]\n",
      "Validation Epoch [176/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.80it/s, val_loss=1.06742191]\n",
      "Training Epoch [177/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, curr_train_loss=0.87838686, val_loss=0.00000000]\n",
      "Validation Epoch [177/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.20986772]\n",
      "Training Epoch [178/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.10it/s, curr_train_loss=0.63478863, val_loss=0.00000000]\n",
      "Validation Epoch [178/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.06it/s, val_loss=1.22558999]\n",
      "Training Epoch [179/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=1.04427564, val_loss=0.00000000]\n",
      "Validation Epoch [179/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.15835392]\n",
      "Training Epoch [180/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=0.85811961, val_loss=0.00000000]\n",
      "Validation Epoch [180/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.22283709]\n",
      "Training Epoch [181/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, curr_train_loss=0.68917298, val_loss=0.00000000]\n",
      "Validation Epoch [181/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, val_loss=1.24053419]\n",
      "Training Epoch [182/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.84333551, val_loss=0.00000000]\n",
      "Validation Epoch [182/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=0.99876928]\n",
      "Training Epoch [183/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.51it/s, curr_train_loss=0.77912736, val_loss=0.00000000]\n",
      "Validation Epoch [183/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.92it/s, val_loss=1.09384298]\n",
      "Training Epoch [184/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.63it/s, curr_train_loss=0.75841540, val_loss=0.00000000]\n",
      "Validation Epoch [184/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.17412293]\n",
      "Training Epoch [185/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, curr_train_loss=0.76694542, val_loss=0.00000000]\n",
      "Validation Epoch [185/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.00it/s, val_loss=1.05460811]\n",
      "Training Epoch [186/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.48it/s, curr_train_loss=0.83483404, val_loss=0.00000000]\n",
      "Validation Epoch [186/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.17059672]\n",
      "Training Epoch [187/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.13it/s, curr_train_loss=0.84223777, val_loss=0.00000000]\n",
      "Validation Epoch [187/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.08it/s, val_loss=1.09585345]\n",
      "Training Epoch [188/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.62it/s, curr_train_loss=0.75063777, val_loss=0.00000000]\n",
      "Validation Epoch [188/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.02it/s, val_loss=0.86962485]\n",
      "Training Epoch [189/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, curr_train_loss=0.77724105, val_loss=0.00000000]\n",
      "Validation Epoch [189/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.88it/s, val_loss=1.21607125]\n",
      "Training Epoch [190/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.00it/s, curr_train_loss=1.01577282, val_loss=0.00000000]\n",
      "Validation Epoch [190/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.14it/s, val_loss=1.03985775]\n",
      "Training Epoch [191/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, curr_train_loss=0.80847740, val_loss=0.00000000]\n",
      "Validation Epoch [191/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=0.97885782]\n",
      "Training Epoch [192/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.46it/s, curr_train_loss=1.05818379, val_loss=0.00000000]\n",
      "Validation Epoch [192/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.76it/s, val_loss=1.08481479]\n",
      "Training Epoch [193/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.44it/s, curr_train_loss=0.74623817, val_loss=0.00000000]\n",
      "Validation Epoch [193/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.11595643]\n",
      "Training Epoch [194/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.27it/s, curr_train_loss=0.75871164, val_loss=0.00000000]\n",
      "Validation Epoch [194/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, val_loss=1.02595246]\n",
      "Training Epoch [195/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.52it/s, curr_train_loss=0.73336512, val_loss=0.00000000]\n",
      "Validation Epoch [195/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.06it/s, val_loss=1.14727867]\n",
      "Training Epoch [196/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.64it/s, curr_train_loss=0.53548849, val_loss=0.00000000]\n",
      "Validation Epoch [196/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.69it/s, val_loss=1.22868145]\n",
      "Training Epoch [197/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.31it/s, curr_train_loss=0.85106850, val_loss=0.00000000]\n",
      "Validation Epoch [197/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.58it/s, val_loss=1.09592867]\n",
      "Training Epoch [198/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=0.94075388, val_loss=0.00000000]\n",
      "Validation Epoch [198/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=0.97180796]\n",
      "Training Epoch [199/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, curr_train_loss=0.79454941, val_loss=0.00000000]\n",
      "Validation Epoch [199/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, val_loss=1.24239409]\n",
      "Training Epoch [200/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.61it/s, curr_train_loss=0.75689173, val_loss=0.00000000]\n",
      "Validation Epoch [200/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.22it/s, val_loss=1.33063626]\n",
      "Training Epoch [201/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, curr_train_loss=0.75570136, val_loss=0.00000000]\n",
      "Validation Epoch [201/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, val_loss=1.17027044]\n",
      "Training Epoch [202/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.21it/s, curr_train_loss=0.68715608, val_loss=0.00000000]\n",
      "Validation Epoch [202/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.70it/s, val_loss=1.30313230]\n",
      "Training Epoch [203/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=0.77755654, val_loss=0.00000000]\n",
      "Validation Epoch [203/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.68it/s, val_loss=1.02114642]\n",
      "Training Epoch [204/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, curr_train_loss=0.78135294, val_loss=0.00000000]\n",
      "Validation Epoch [204/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, val_loss=1.11058509]\n",
      "Training Epoch [205/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.63it/s, curr_train_loss=0.87162989, val_loss=0.00000000]\n",
      "Validation Epoch [205/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.70it/s, val_loss=1.21638036]\n",
      "Training Epoch [206/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, curr_train_loss=0.70786023, val_loss=0.00000000]\n",
      "Validation Epoch [206/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.88it/s, val_loss=1.04057217]\n",
      "Training Epoch [207/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.09it/s, curr_train_loss=0.74271333, val_loss=0.00000000]\n",
      "Validation Epoch [207/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.86it/s, val_loss=1.08158326]\n",
      "Training Epoch [208/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.55it/s, curr_train_loss=0.79739106, val_loss=0.00000000]\n",
      "Validation Epoch [208/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.04510903]\n",
      "Training Epoch [209/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.51it/s, curr_train_loss=0.81325537, val_loss=0.00000000]\n",
      "Validation Epoch [209/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.98it/s, val_loss=1.31592894]\n",
      "Training Epoch [210/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.44it/s, curr_train_loss=0.94789946, val_loss=0.00000000]\n",
      "Validation Epoch [210/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.19it/s, val_loss=1.11768603]\n",
      "Training Epoch [211/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.55it/s, curr_train_loss=0.63389850, val_loss=0.00000000]\n",
      "Validation Epoch [211/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.79it/s, val_loss=1.20034719]\n",
      "Training Epoch [212/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, curr_train_loss=0.71444452, val_loss=0.00000000]\n",
      "Validation Epoch [212/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.69it/s, val_loss=1.20984089]\n",
      "Training Epoch [213/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.67it/s, curr_train_loss=0.70613503, val_loss=0.00000000]\n",
      "Validation Epoch [213/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.84it/s, val_loss=1.11092341]\n",
      "Training Epoch [214/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.56it/s, curr_train_loss=0.96653336, val_loss=0.00000000]\n",
      "Validation Epoch [214/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=1.16624594]\n",
      "Training Epoch [215/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.31it/s, curr_train_loss=0.72005278, val_loss=0.00000000]\n",
      "Validation Epoch [215/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.11it/s, val_loss=1.19885111]\n",
      "Training Epoch [216/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.36it/s, curr_train_loss=0.59560633, val_loss=0.00000000]\n",
      "Validation Epoch [216/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.61it/s, val_loss=1.12180746]\n",
      "Training Epoch [217/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=0.71560067, val_loss=0.00000000]\n",
      "Validation Epoch [217/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s, val_loss=1.16676998]\n",
      "Training Epoch [218/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.53it/s, curr_train_loss=0.57586730, val_loss=0.00000000]\n",
      "Validation Epoch [218/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.01005173]\n",
      "Training Epoch [219/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.00it/s, curr_train_loss=0.89818954, val_loss=0.00000000]\n",
      "Validation Epoch [219/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=1.22159827]\n",
      "Training Epoch [220/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, curr_train_loss=0.64161056, val_loss=0.00000000]\n",
      "Validation Epoch [220/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.78it/s, val_loss=1.25102973]\n",
      "Training Epoch [221/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, curr_train_loss=0.85331202, val_loss=0.00000000]\n",
      "Validation Epoch [221/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.07it/s, val_loss=1.04708552]\n",
      "Training Epoch [222/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.54it/s, curr_train_loss=0.73159254, val_loss=0.00000000]\n",
      "Validation Epoch [222/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.79it/s, val_loss=1.14208972]\n",
      "Training Epoch [223/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, curr_train_loss=0.68300766, val_loss=0.00000000]\n",
      "Validation Epoch [223/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.10300243]\n",
      "Training Epoch [224/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, curr_train_loss=0.69876200, val_loss=0.00000000]\n",
      "Validation Epoch [224/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.58it/s, val_loss=1.24615169]\n",
      "Training Epoch [225/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=0.54054040, val_loss=0.00000000]\n",
      "Validation Epoch [225/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.16it/s, val_loss=1.00269771]\n",
      "Training Epoch [226/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.74it/s, curr_train_loss=0.66375697, val_loss=0.00000000]\n",
      "Validation Epoch [226/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.10it/s, val_loss=1.13336790]\n",
      "Training Epoch [227/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.48it/s, curr_train_loss=0.75313157, val_loss=0.00000000]\n",
      "Validation Epoch [227/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, val_loss=1.11950231]\n",
      "Training Epoch [228/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.99it/s, curr_train_loss=0.68775034, val_loss=0.00000000]\n",
      "Validation Epoch [228/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.07306671]\n",
      "Training Epoch [229/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, curr_train_loss=0.75660294, val_loss=0.00000000]\n",
      "Validation Epoch [229/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.74it/s, val_loss=1.14623213]\n",
      "Training Epoch [230/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.05it/s, curr_train_loss=0.67144102, val_loss=0.00000000]\n",
      "Validation Epoch [230/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, val_loss=1.10608196]\n",
      "Training Epoch [231/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.35it/s, curr_train_loss=0.86060369, val_loss=0.00000000]\n",
      "Validation Epoch [231/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, val_loss=1.16494381]\n",
      "Training Epoch [232/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.04it/s, curr_train_loss=0.73801619, val_loss=0.00000000]\n",
      "Validation Epoch [232/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.89it/s, val_loss=1.10787725]\n",
      "Training Epoch [233/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=0.78572989, val_loss=0.00000000]\n",
      "Validation Epoch [233/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.78it/s, val_loss=1.24775779]\n",
      "Training Epoch [234/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, curr_train_loss=0.69273835, val_loss=0.00000000]\n",
      "Validation Epoch [234/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s, val_loss=0.96782660]\n",
      "Training Epoch [235/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, curr_train_loss=0.80183703, val_loss=0.00000000]\n",
      "Validation Epoch [235/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.86it/s, val_loss=1.09294879]\n",
      "Training Epoch [236/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.43it/s, curr_train_loss=0.51440310, val_loss=0.00000000]\n",
      "Validation Epoch [236/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.84it/s, val_loss=1.03541636]\n",
      "Training Epoch [237/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.60it/s, curr_train_loss=0.68148917, val_loss=0.00000000]\n",
      "Validation Epoch [237/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.30325246]\n",
      "Training Epoch [238/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, curr_train_loss=0.62931108, val_loss=0.00000000]\n",
      "Validation Epoch [238/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.70it/s, val_loss=1.18530798]\n",
      "Training Epoch [239/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=0.52204251, val_loss=0.00000000]\n",
      "Validation Epoch [239/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.91it/s, val_loss=1.15846729]\n",
      "Training Epoch [240/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, curr_train_loss=0.79535264, val_loss=0.00000000]\n",
      "Validation Epoch [240/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=0.96033961]\n",
      "Training Epoch [241/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.12it/s, curr_train_loss=0.59949130, val_loss=0.00000000]\n",
      "Validation Epoch [241/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=1.04241931]\n",
      "Training Epoch [242/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, curr_train_loss=0.72334260, val_loss=0.00000000]\n",
      "Validation Epoch [242/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=0.88359046]\n",
      "Training Epoch [243/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.14it/s, curr_train_loss=0.77668983, val_loss=0.00000000]\n",
      "Validation Epoch [243/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=0.99205106]\n",
      "Training Epoch [244/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.34it/s, curr_train_loss=0.62000072, val_loss=0.00000000]\n",
      "Validation Epoch [244/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, val_loss=1.15018451]\n",
      "Training Epoch [245/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, curr_train_loss=0.57418418, val_loss=0.00000000]\n",
      "Validation Epoch [245/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.53it/s, val_loss=1.05852807]\n",
      "Training Epoch [246/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, curr_train_loss=0.74991149, val_loss=0.00000000]\n",
      "Validation Epoch [246/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.60it/s, val_loss=1.08729029]\n",
      "Training Epoch [247/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, curr_train_loss=0.84328187, val_loss=0.00000000]\n",
      "Validation Epoch [247/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=1.13185787]\n",
      "Training Epoch [248/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, curr_train_loss=0.96166521, val_loss=0.00000000]\n",
      "Validation Epoch [248/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, val_loss=1.06859815]\n",
      "Training Epoch [249/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, curr_train_loss=0.70691592, val_loss=0.00000000]\n",
      "Validation Epoch [249/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.18it/s, val_loss=0.97628748]\n",
      "Training Epoch [250/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=0.63351721, val_loss=0.00000000]\n",
      "Validation Epoch [250/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.16194201]\n",
      "Training Epoch [251/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.51it/s, curr_train_loss=0.87332624, val_loss=0.00000000]\n",
      "Validation Epoch [251/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=1.15044940]\n",
      "Training Epoch [252/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.45it/s, curr_train_loss=0.64060056, val_loss=0.00000000]\n",
      "Validation Epoch [252/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.91it/s, val_loss=0.95849097]\n",
      "Training Epoch [253/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.45it/s, curr_train_loss=0.52918279, val_loss=0.00000000]\n",
      "Validation Epoch [253/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=0.98062593]\n",
      "Training Epoch [254/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=0.85827744, val_loss=0.00000000]\n",
      "Validation Epoch [254/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.16061294]\n",
      "Training Epoch [255/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=0.61268049, val_loss=0.00000000]\n",
      "Validation Epoch [255/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s, val_loss=0.94071776]\n",
      "Training Epoch [256/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=0.80328989, val_loss=0.00000000]\n",
      "Validation Epoch [256/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.90it/s, val_loss=1.18447232]\n",
      "Training Epoch [257/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=0.67323935, val_loss=0.00000000]\n",
      "Validation Epoch [257/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s, val_loss=0.91408533]\n",
      "Training Epoch [258/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, curr_train_loss=0.70751655, val_loss=0.00000000]\n",
      "Validation Epoch [258/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.10it/s, val_loss=1.01743436]\n",
      "Training Epoch [259/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=0.61806750, val_loss=0.00000000]\n",
      "Validation Epoch [259/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=1.03538477]\n",
      "Training Epoch [260/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.64it/s, curr_train_loss=0.59921801, val_loss=0.00000000]\n",
      "Validation Epoch [260/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.07it/s, val_loss=1.15867472]\n",
      "Training Epoch [261/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.01it/s, curr_train_loss=0.61750209, val_loss=0.00000000]\n",
      "Validation Epoch [261/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.85it/s, val_loss=1.26807046]\n",
      "Training Epoch [262/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.75it/s, curr_train_loss=0.58627027, val_loss=0.00000000]\n",
      "Validation Epoch [262/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.08it/s, val_loss=1.15521133]\n",
      "Training Epoch [263/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.68it/s, curr_train_loss=0.75135523, val_loss=0.00000000]\n",
      "Validation Epoch [263/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.78it/s, val_loss=1.00685871]\n",
      "Training Epoch [264/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, curr_train_loss=0.54731321, val_loss=0.00000000]\n",
      "Validation Epoch [264/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.61it/s, val_loss=0.95870745]\n",
      "Training Epoch [265/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=0.67517835, val_loss=0.00000000]\n",
      "Validation Epoch [265/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=1.20876098]\n",
      "Training Epoch [266/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, curr_train_loss=0.57095993, val_loss=0.00000000]\n",
      "Validation Epoch [266/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.14789355]\n",
      "Training Epoch [267/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.77it/s, curr_train_loss=0.56941903, val_loss=0.00000000]\n",
      "Validation Epoch [267/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=1.24884534]\n",
      "Training Epoch [268/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=0.75491196, val_loss=0.00000000]\n",
      "Validation Epoch [268/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.12814355]\n",
      "Training Epoch [269/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=0.83692187, val_loss=0.00000000]\n",
      "Validation Epoch [269/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=0.93378282]\n",
      "Training Epoch [270/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, curr_train_loss=0.85166693, val_loss=0.00000000]\n",
      "Validation Epoch [270/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.85it/s, val_loss=1.09955609]\n",
      "Training Epoch [271/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.51it/s, curr_train_loss=0.82674456, val_loss=0.00000000]\n",
      "Validation Epoch [271/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, val_loss=1.10685933]\n",
      "Training Epoch [272/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.31it/s, curr_train_loss=0.64118445, val_loss=0.00000000]\n",
      "Validation Epoch [272/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.97it/s, val_loss=1.16391540]\n",
      "Training Epoch [273/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, curr_train_loss=0.58718914, val_loss=0.00000000]\n",
      "Validation Epoch [273/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, val_loss=0.94291955]\n",
      "Training Epoch [274/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.41it/s, curr_train_loss=0.47543514, val_loss=0.00000000]\n",
      "Validation Epoch [274/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=1.05203772]\n",
      "Training Epoch [275/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=0.65497518, val_loss=0.00000000]\n",
      "Validation Epoch [275/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.72it/s, val_loss=1.31797588]\n",
      "Training Epoch [276/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, curr_train_loss=0.56996530, val_loss=0.00000000]\n",
      "Validation Epoch [276/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.08213794]\n",
      "Training Epoch [277/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, curr_train_loss=0.54887980, val_loss=0.00000000]\n",
      "Validation Epoch [277/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.03it/s, val_loss=1.05507898]\n",
      "Training Epoch [278/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.16it/s, curr_train_loss=0.60670966, val_loss=0.00000000]\n",
      "Validation Epoch [278/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.58it/s, val_loss=0.95033652]\n",
      "Training Epoch [279/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.64it/s, curr_train_loss=0.57407814, val_loss=0.00000000]\n",
      "Validation Epoch [279/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.75it/s, val_loss=1.11062038]\n",
      "Training Epoch [280/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, curr_train_loss=0.58852011, val_loss=0.00000000]\n",
      "Validation Epoch [280/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.72it/s, val_loss=0.89937258]\n",
      "Training Epoch [281/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.41it/s, curr_train_loss=0.58367217, val_loss=0.00000000]\n",
      "Validation Epoch [281/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.66it/s, val_loss=1.04450274]\n",
      "Training Epoch [282/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.03it/s, curr_train_loss=0.66764903, val_loss=0.00000000]\n",
      "Validation Epoch [282/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, val_loss=0.93377388]\n",
      "Training Epoch [283/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.54it/s, curr_train_loss=0.83033186, val_loss=0.00000000]\n",
      "Validation Epoch [283/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, val_loss=0.91251355]\n",
      "Training Epoch [284/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.60it/s, curr_train_loss=0.84654015, val_loss=0.00000000]\n",
      "Validation Epoch [284/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.05it/s, val_loss=1.02008510]\n",
      "Training Epoch [285/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.19it/s, curr_train_loss=0.82426864, val_loss=0.00000000]\n",
      "Validation Epoch [285/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.13it/s, val_loss=1.11882377]\n",
      "Training Epoch [286/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.42it/s, curr_train_loss=0.60949308, val_loss=0.00000000]\n",
      "Validation Epoch [286/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.21118295]\n",
      "Training Epoch [287/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.41it/s, curr_train_loss=0.63176346, val_loss=0.00000000]\n",
      "Validation Epoch [287/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.59it/s, val_loss=0.99151307]\n",
      "Training Epoch [288/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.21it/s, curr_train_loss=0.75282830, val_loss=0.00000000]\n",
      "Validation Epoch [288/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.82it/s, val_loss=0.97484636]\n",
      "Training Epoch [289/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=0.95449948, val_loss=0.00000000]\n",
      "Validation Epoch [289/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.05738580]\n",
      "Training Epoch [290/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=0.53539968, val_loss=0.00000000]\n",
      "Validation Epoch [290/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.80it/s, val_loss=0.86117476]\n",
      "Training Epoch [291/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.57it/s, curr_train_loss=0.58719546, val_loss=0.00000000]\n",
      "Validation Epoch [291/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.88it/s, val_loss=1.06920111]\n",
      "Training Epoch [292/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.84it/s, curr_train_loss=0.85149527, val_loss=0.00000000]\n",
      "Validation Epoch [292/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.50it/s, val_loss=1.13560903]\n",
      "Training Epoch [293/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.45it/s, curr_train_loss=0.42228293, val_loss=0.00000000]\n",
      "Validation Epoch [293/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.16it/s, val_loss=1.11440790]\n",
      "Training Epoch [294/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.63it/s, curr_train_loss=0.46741360, val_loss=0.00000000]\n",
      "Validation Epoch [294/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, val_loss=0.87226111]\n",
      "Training Epoch [295/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.39it/s, curr_train_loss=0.68089408, val_loss=0.00000000]\n",
      "Validation Epoch [295/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.08it/s, val_loss=1.07317829]\n",
      "Training Epoch [296/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.22it/s, curr_train_loss=0.90184885, val_loss=0.00000000]\n",
      "Validation Epoch [296/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.60it/s, val_loss=1.12154830]\n",
      "Training Epoch [297/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.46it/s, curr_train_loss=0.74491876, val_loss=0.00000000]\n",
      "Validation Epoch [297/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.04it/s, val_loss=0.96887726]\n",
      "Training Epoch [298/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  5.64it/s, curr_train_loss=0.68567091, val_loss=0.00000000]\n",
      "Validation Epoch [298/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.55it/s, val_loss=1.32245159]\n",
      "Training Epoch [299/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=0.51406646, val_loss=0.00000000]\n",
      "Validation Epoch [299/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.36it/s, val_loss=1.12665892]\n",
      "Training Epoch [300/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, curr_train_loss=0.48199990, val_loss=0.00000000]\n",
      "Validation Epoch [300/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.19639945]\n",
      "Training Epoch [301/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, curr_train_loss=0.74959493, val_loss=0.00000000]\n",
      "Validation Epoch [301/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.19133484]\n",
      "Training Epoch [302/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, curr_train_loss=0.54025805, val_loss=0.00000000]\n",
      "Validation Epoch [302/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.11154020]\n",
      "Training Epoch [303/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.12it/s, curr_train_loss=0.70212585, val_loss=0.00000000]\n",
      "Validation Epoch [303/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.13it/s, val_loss=1.06887829]\n",
      "Training Epoch [304/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s, curr_train_loss=1.01437426, val_loss=0.00000000]\n",
      "Validation Epoch [304/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.24it/s, val_loss=1.30316877]\n",
      "Training Epoch [305/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.65811276, val_loss=0.00000000]\n",
      "Validation Epoch [305/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.15616620]\n",
      "Training Epoch [306/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, curr_train_loss=0.58983946, val_loss=0.00000000]\n",
      "Validation Epoch [306/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.68it/s, val_loss=1.15962946]\n",
      "Training Epoch [307/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=0.52063406, val_loss=0.00000000]\n",
      "Validation Epoch [307/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s, val_loss=1.34783840]\n",
      "Training Epoch [308/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  5.67it/s, curr_train_loss=0.54276633, val_loss=0.00000000]\n",
      "Validation Epoch [308/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.58it/s, val_loss=1.33629346]\n",
      "Training Epoch [309/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.56it/s, curr_train_loss=0.65168226, val_loss=0.00000000]\n",
      "Validation Epoch [309/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.13394558]\n",
      "Training Epoch [310/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, curr_train_loss=0.74376732, val_loss=0.00000000]\n",
      "Validation Epoch [310/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.18398607]\n",
      "Training Epoch [311/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=0.63903445, val_loss=0.00000000]\n",
      "Validation Epoch [311/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.76it/s, val_loss=1.05794740]\n",
      "Training Epoch [312/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=0.74009001, val_loss=0.00000000]\n",
      "Validation Epoch [312/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.79it/s, val_loss=1.16976583]\n",
      "Training Epoch [313/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.02it/s, curr_train_loss=0.40282062, val_loss=0.00000000]\n",
      "Validation Epoch [313/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.28019488]\n",
      "Training Epoch [314/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=0.63299197, val_loss=0.00000000]\n",
      "Validation Epoch [314/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.13it/s, val_loss=1.15108502]\n",
      "Training Epoch [315/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=0.77564049, val_loss=0.00000000]\n",
      "Validation Epoch [315/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.07it/s, val_loss=1.23716342]\n",
      "Training Epoch [316/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=0.56453466, val_loss=0.00000000]\n",
      "Validation Epoch [316/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=1.10363472]\n",
      "Training Epoch [317/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, curr_train_loss=0.52473336, val_loss=0.00000000]\n",
      "Validation Epoch [317/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.62it/s, val_loss=1.21042323]\n",
      "Training Epoch [318/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, curr_train_loss=0.76844007, val_loss=0.00000000]\n",
      "Validation Epoch [318/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=1.20318043]\n",
      "Training Epoch [319/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.77it/s, curr_train_loss=0.62865752, val_loss=0.00000000]\n",
      "Validation Epoch [319/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.06it/s, val_loss=1.12172329]\n",
      "Training Epoch [320/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=0.62165713, val_loss=0.00000000]\n",
      "Validation Epoch [320/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=1.11512744]\n",
      "Training Epoch [321/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.01it/s, curr_train_loss=0.60775393, val_loss=0.00000000]\n",
      "Validation Epoch [321/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, val_loss=1.14100087]\n",
      "Training Epoch [322/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.06it/s, curr_train_loss=0.38563281, val_loss=0.00000000]\n",
      "Validation Epoch [322/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, val_loss=1.08666313]\n",
      "Training Epoch [323/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s, curr_train_loss=0.48182172, val_loss=0.00000000]\n",
      "Validation Epoch [323/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=1.13449752]\n",
      "Training Epoch [324/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=0.69371122, val_loss=0.00000000]\n",
      "Validation Epoch [324/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.84it/s, val_loss=1.07599282]\n",
      "Training Epoch [325/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.53it/s, curr_train_loss=0.68906516, val_loss=0.00000000]\n",
      "Validation Epoch [325/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=1.13696313]\n",
      "Training Epoch [326/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=0.49083877, val_loss=0.00000000]\n",
      "Validation Epoch [326/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.05it/s, val_loss=1.08219838]\n",
      "Training Epoch [327/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, curr_train_loss=0.73434889, val_loss=0.00000000]\n",
      "Validation Epoch [327/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.58it/s, val_loss=1.06899273]\n",
      "Training Epoch [328/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, curr_train_loss=0.85072052, val_loss=0.00000000]\n",
      "Validation Epoch [328/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.08538425]\n",
      "Training Epoch [329/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.55it/s, curr_train_loss=0.63377357, val_loss=0.00000000]\n",
      "Validation Epoch [329/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.12it/s, val_loss=1.11807323]\n",
      "Training Epoch [330/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, curr_train_loss=0.77004260, val_loss=0.00000000]\n",
      "Validation Epoch [330/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.76it/s, val_loss=1.08095646]\n",
      "Training Epoch [331/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, curr_train_loss=0.57211369, val_loss=0.00000000]\n",
      "Validation Epoch [331/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.34it/s, val_loss=1.25125992]\n",
      "Training Epoch [332/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.09it/s, curr_train_loss=0.56742311, val_loss=0.00000000]\n",
      "Validation Epoch [332/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.21411884]\n",
      "Training Epoch [333/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.55it/s, curr_train_loss=0.51162606, val_loss=0.00000000]\n",
      "Validation Epoch [333/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.10276937]\n",
      "Training Epoch [334/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.94it/s, curr_train_loss=0.57846802, val_loss=0.00000000]\n",
      "Validation Epoch [334/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.87it/s, val_loss=1.12082338]\n",
      "Training Epoch [335/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.40it/s, curr_train_loss=0.53108191, val_loss=0.00000000]\n",
      "Validation Epoch [335/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.12it/s, val_loss=1.10379934]\n",
      "Training Epoch [336/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, curr_train_loss=0.42685795, val_loss=0.00000000]\n",
      "Validation Epoch [336/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.48it/s, val_loss=1.28951716]\n",
      "Training Epoch [337/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=0.52876115, val_loss=0.00000000]\n",
      "Validation Epoch [337/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, val_loss=1.14597619]\n",
      "Training Epoch [338/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, curr_train_loss=0.52984768, val_loss=0.00000000]\n",
      "Validation Epoch [338/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.07779098]\n",
      "Training Epoch [339/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, curr_train_loss=0.64801836, val_loss=0.00000000]\n",
      "Validation Epoch [339/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s, val_loss=1.09058392]\n",
      "Training Epoch [340/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.68it/s, curr_train_loss=0.67490655, val_loss=0.00000000]\n",
      "Validation Epoch [340/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.11it/s, val_loss=1.21757805]\n",
      "Training Epoch [341/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.57it/s, curr_train_loss=0.54099536, val_loss=0.00000000]\n",
      "Validation Epoch [341/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.78it/s, val_loss=1.29241443]\n",
      "Training Epoch [342/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  5.40it/s, curr_train_loss=0.60857552, val_loss=0.00000000]\n",
      "Validation Epoch [342/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.66it/s, val_loss=0.94759423]\n",
      "Training Epoch [343/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.60it/s, curr_train_loss=0.67245901, val_loss=0.00000000]\n",
      "Validation Epoch [343/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.63it/s, val_loss=1.06854594]\n",
      "Training Epoch [344/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.77it/s, curr_train_loss=0.48671800, val_loss=0.00000000]\n",
      "Validation Epoch [344/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.92it/s, val_loss=1.11175990]\n",
      "Training Epoch [345/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.50it/s, curr_train_loss=0.55390131, val_loss=0.00000000]\n",
      "Validation Epoch [345/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.72it/s, val_loss=1.18446565]\n",
      "Training Epoch [346/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.46it/s, curr_train_loss=0.73951834, val_loss=0.00000000]\n",
      "Validation Epoch [346/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.89it/s, val_loss=1.22918177]\n",
      "Training Epoch [347/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.74962348, val_loss=0.00000000]\n",
      "Validation Epoch [347/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s, val_loss=0.88916951]\n",
      "Training Epoch [348/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=0.59269565, val_loss=0.00000000]\n",
      "Validation Epoch [348/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.83it/s, val_loss=1.04507828]\n",
      "Training Epoch [349/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.49551722, val_loss=0.00000000]\n",
      "Validation Epoch [349/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.87it/s, val_loss=0.94732451]\n",
      "Training Epoch [350/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, curr_train_loss=0.74108541, val_loss=0.00000000]\n",
      "Validation Epoch [350/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.03it/s, val_loss=0.98164439]\n",
      "Training Epoch [351/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=0.63692057, val_loss=0.00000000]\n",
      "Validation Epoch [351/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.66it/s, val_loss=1.26111996]\n",
      "Training Epoch [352/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, curr_train_loss=0.64912295, val_loss=0.00000000]\n",
      "Validation Epoch [352/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.20723987]\n",
      "Training Epoch [353/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, curr_train_loss=0.76017958, val_loss=0.00000000]\n",
      "Validation Epoch [353/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.09767711]\n",
      "Training Epoch [354/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=0.65272635, val_loss=0.00000000]\n",
      "Validation Epoch [354/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.06it/s, val_loss=1.10971522]\n",
      "Training Epoch [355/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, curr_train_loss=0.61940205, val_loss=0.00000000]\n",
      "Validation Epoch [355/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=0.98931795]\n",
      "Training Epoch [356/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.64it/s, curr_train_loss=0.69854331, val_loss=0.00000000]\n",
      "Validation Epoch [356/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.65it/s, val_loss=0.95359248]\n",
      "Training Epoch [357/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.14it/s, curr_train_loss=0.72566652, val_loss=0.00000000]\n",
      "Validation Epoch [357/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.00887096]\n",
      "Training Epoch [358/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.51it/s, curr_train_loss=0.51404124, val_loss=0.00000000]\n",
      "Validation Epoch [358/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.51it/s, val_loss=1.09069431]\n",
      "Training Epoch [359/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, curr_train_loss=0.65936983, val_loss=0.00000000]\n",
      "Validation Epoch [359/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.98it/s, val_loss=0.99850762]\n",
      "Training Epoch [360/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=0.56343621, val_loss=0.00000000]\n",
      "Validation Epoch [360/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.01894212]\n",
      "Training Epoch [361/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.99it/s, curr_train_loss=0.45843217, val_loss=0.00000000]\n",
      "Validation Epoch [361/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.16it/s, val_loss=1.19028735]\n",
      "Training Epoch [362/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, curr_train_loss=0.85165435, val_loss=0.00000000]\n",
      "Validation Epoch [362/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s, val_loss=1.05938971]\n",
      "Training Epoch [363/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.64it/s, curr_train_loss=0.78644097, val_loss=0.00000000]\n",
      "Validation Epoch [363/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.20378959]\n",
      "Training Epoch [364/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.85it/s, curr_train_loss=0.53862375, val_loss=0.00000000]\n",
      "Validation Epoch [364/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.18454659]\n",
      "Training Epoch [365/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.96it/s, curr_train_loss=0.59128815, val_loss=0.00000000]\n",
      "Validation Epoch [365/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.60it/s, val_loss=1.16263652]\n",
      "Training Epoch [366/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, curr_train_loss=0.72880155, val_loss=0.00000000]\n",
      "Validation Epoch [366/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.72it/s, val_loss=0.98207617]\n",
      "Training Epoch [367/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, curr_train_loss=0.63354760, val_loss=0.00000000]\n",
      "Validation Epoch [367/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.75it/s, val_loss=1.15434432]\n",
      "Training Epoch [368/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.49it/s, curr_train_loss=0.34888387, val_loss=0.00000000]\n",
      "Validation Epoch [368/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.79it/s, val_loss=0.92290831]\n",
      "Training Epoch [369/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.26it/s, curr_train_loss=0.77550715, val_loss=0.00000000]\n",
      "Validation Epoch [369/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.82it/s, val_loss=0.91330338]\n",
      "Training Epoch [370/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.21it/s, curr_train_loss=0.57326192, val_loss=0.00000000]\n",
      "Validation Epoch [370/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.56it/s, val_loss=1.01730585]\n",
      "Training Epoch [371/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.15it/s, curr_train_loss=0.49752265, val_loss=0.00000000]\n",
      "Validation Epoch [371/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.99it/s, val_loss=1.10264349]\n",
      "Training Epoch [372/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.15it/s, curr_train_loss=0.51532590, val_loss=0.00000000]\n",
      "Validation Epoch [372/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, val_loss=0.86185348]\n",
      "Training Epoch [373/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.62it/s, curr_train_loss=0.48370481, val_loss=0.00000000]\n",
      "Validation Epoch [373/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, val_loss=1.08052301]\n",
      "Training Epoch [374/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.69it/s, curr_train_loss=0.60543388, val_loss=0.00000000]\n",
      "Validation Epoch [374/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.01566625]\n",
      "Training Epoch [375/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, curr_train_loss=0.43470538, val_loss=0.00000000]\n",
      "Validation Epoch [375/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.04271173]\n",
      "Training Epoch [376/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, curr_train_loss=0.54850149, val_loss=0.00000000]\n",
      "Validation Epoch [376/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=1.02287602]\n",
      "Training Epoch [377/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.29it/s, curr_train_loss=0.84343600, val_loss=0.00000000]\n",
      "Validation Epoch [377/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.50it/s, val_loss=0.94082570]\n",
      "Training Epoch [378/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=0.75482786, val_loss=0.00000000]\n",
      "Validation Epoch [378/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.85it/s, val_loss=0.96426821]\n",
      "Training Epoch [379/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=0.58221889, val_loss=0.00000000]\n",
      "Validation Epoch [379/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.85it/s, val_loss=1.17994130]\n",
      "Training Epoch [380/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.51it/s, curr_train_loss=0.39619049, val_loss=0.00000000]\n",
      "Validation Epoch [380/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, val_loss=1.04429090]\n",
      "Training Epoch [381/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.64it/s, curr_train_loss=0.52059370, val_loss=0.00000000]\n",
      "Validation Epoch [381/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=0.95925593]\n",
      "Training Epoch [382/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=0.34576577, val_loss=0.00000000]\n",
      "Validation Epoch [382/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=1.05579948]\n",
      "Training Epoch [383/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.66367036, val_loss=0.00000000]\n",
      "Validation Epoch [383/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.05691099]\n",
      "Training Epoch [384/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=0.51268232, val_loss=0.00000000]\n",
      "Validation Epoch [384/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.93it/s, val_loss=1.10097790]\n",
      "Training Epoch [385/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, curr_train_loss=0.55106944, val_loss=0.00000000]\n",
      "Validation Epoch [385/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.80it/s, val_loss=1.04126966]\n",
      "Training Epoch [386/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, curr_train_loss=0.51891315, val_loss=0.00000000]\n",
      "Validation Epoch [386/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.01it/s, val_loss=1.08670139]\n",
      "Training Epoch [387/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.56it/s, curr_train_loss=0.59647036, val_loss=0.00000000]\n",
      "Validation Epoch [387/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.01it/s, val_loss=1.10798955]\n",
      "Training Epoch [388/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  4.91it/s, curr_train_loss=0.58190441, val_loss=0.00000000]\n",
      "Validation Epoch [388/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=1.05150688]\n",
      "Training Epoch [389/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.56it/s, curr_train_loss=0.39417985, val_loss=0.00000000]\n",
      "Validation Epoch [389/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.28it/s, val_loss=0.92829812]\n",
      "Training Epoch [390/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, curr_train_loss=0.43809974, val_loss=0.00000000]\n",
      "Validation Epoch [390/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.66it/s, val_loss=0.95608401]\n",
      "Training Epoch [391/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, curr_train_loss=0.41028377, val_loss=0.00000000]\n",
      "Validation Epoch [391/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=0.76636606]\n",
      "Training Epoch [392/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  4.88it/s, curr_train_loss=0.57380301, val_loss=0.00000000]\n",
      "Validation Epoch [392/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.13it/s, val_loss=1.01805675]\n",
      "Training Epoch [393/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=0.51091778, val_loss=0.00000000]\n",
      "Validation Epoch [393/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=1.09300876]\n",
      "Training Epoch [394/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.39it/s, curr_train_loss=0.45879322, val_loss=0.00000000]\n",
      "Validation Epoch [394/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.14it/s, val_loss=1.22766960]\n",
      "Training Epoch [395/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=0.45955989, val_loss=0.00000000]\n",
      "Validation Epoch [395/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.10905635]\n",
      "Training Epoch [396/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.37it/s, curr_train_loss=0.73900694, val_loss=0.00000000]\n",
      "Validation Epoch [396/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.17it/s, val_loss=1.08799398]\n",
      "Training Epoch [397/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, curr_train_loss=0.60736620, val_loss=0.00000000]\n",
      "Validation Epoch [397/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.81it/s, val_loss=1.23303914]\n",
      "Training Epoch [398/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.37it/s, curr_train_loss=0.53619820, val_loss=0.00000000]\n",
      "Validation Epoch [398/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.79it/s, val_loss=1.06973660]\n",
      "Training Epoch [399/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=0.74987221, val_loss=0.00000000]\n",
      "Validation Epoch [399/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.66it/s, val_loss=1.22569454]\n",
      "Training Epoch [400/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.80it/s, curr_train_loss=0.60148275, val_loss=0.00000000]\n",
      "Validation Epoch [400/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.11it/s, val_loss=1.13625157]\n",
      "Training Epoch [401/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.56it/s, curr_train_loss=0.57717973, val_loss=0.00000000]\n",
      "Validation Epoch [401/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, val_loss=1.14678073]\n",
      "Training Epoch [402/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.35it/s, curr_train_loss=0.59385061, val_loss=0.00000000]\n",
      "Validation Epoch [402/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.71it/s, val_loss=1.10559094]\n",
      "Training Epoch [403/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.07it/s, curr_train_loss=0.60704917, val_loss=0.00000000]\n",
      "Validation Epoch [403/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.74it/s, val_loss=1.57421339]\n",
      "Training Epoch [404/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.64it/s, curr_train_loss=0.60674167, val_loss=0.00000000]\n",
      "Validation Epoch [404/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.66it/s, val_loss=1.19196856]\n",
      "Training Epoch [405/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.39it/s, curr_train_loss=0.64595693, val_loss=0.00000000]\n",
      "Validation Epoch [405/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.08209956]\n",
      "Training Epoch [406/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, curr_train_loss=0.61395055, val_loss=0.00000000]\n",
      "Validation Epoch [406/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=1.04917288]\n",
      "Training Epoch [407/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.69it/s, curr_train_loss=0.68833953, val_loss=0.00000000]\n",
      "Validation Epoch [407/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, val_loss=1.24073482]\n",
      "Training Epoch [408/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, curr_train_loss=0.54163420, val_loss=0.00000000]\n",
      "Validation Epoch [408/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.06it/s, val_loss=1.43430769]\n",
      "Training Epoch [409/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.42it/s, curr_train_loss=0.51277912, val_loss=0.00000000]\n",
      "Validation Epoch [409/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.17823267]\n",
      "Training Epoch [410/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=0.66240400, val_loss=0.00000000]\n",
      "Validation Epoch [410/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.71it/s, val_loss=1.10127497]\n",
      "Training Epoch [411/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.58it/s, curr_train_loss=0.70322585, val_loss=0.00000000]\n",
      "Validation Epoch [411/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.01it/s, val_loss=1.13983798]\n",
      "Training Epoch [412/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.28it/s, curr_train_loss=0.45315009, val_loss=0.00000000]\n",
      "Validation Epoch [412/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.80it/s, val_loss=1.19791257]\n",
      "Training Epoch [413/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.77it/s, curr_train_loss=0.90694720, val_loss=0.00000000]\n",
      "Validation Epoch [413/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.63it/s, val_loss=1.27607608]\n",
      "Training Epoch [414/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=0.48272946, val_loss=0.00000000]\n",
      "Validation Epoch [414/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=0.89083481]\n",
      "Training Epoch [415/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, curr_train_loss=0.48037919, val_loss=0.00000000]\n",
      "Validation Epoch [415/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=1.27590179]\n",
      "Training Epoch [416/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  5.24it/s, curr_train_loss=0.52358145, val_loss=0.00000000]\n",
      "Validation Epoch [416/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.07it/s, val_loss=1.24282396]\n",
      "Training Epoch [417/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, curr_train_loss=0.93420649, val_loss=0.00000000]\n",
      "Validation Epoch [417/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=0.97184318]\n",
      "Training Epoch [418/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.60it/s, curr_train_loss=0.54250342, val_loss=0.00000000]\n",
      "Validation Epoch [418/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.90it/s, val_loss=1.21814632]\n",
      "Training Epoch [419/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.53it/s, curr_train_loss=0.71986091, val_loss=0.00000000]\n",
      "Validation Epoch [419/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.74it/s, val_loss=1.02782571]\n",
      "Training Epoch [420/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.42it/s, curr_train_loss=0.71161920, val_loss=0.00000000]\n",
      "Validation Epoch [420/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.05218554]\n",
      "Training Epoch [421/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.32it/s, curr_train_loss=0.54217780, val_loss=0.00000000]\n",
      "Validation Epoch [421/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.69it/s, val_loss=1.20351171]\n",
      "Training Epoch [422/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.65it/s, curr_train_loss=0.75851685, val_loss=0.00000000]\n",
      "Validation Epoch [422/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, val_loss=1.21351755]\n",
      "Training Epoch [423/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=0.59092277, val_loss=0.00000000]\n",
      "Validation Epoch [423/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.84it/s, val_loss=1.19339383]\n",
      "Training Epoch [424/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.29it/s, curr_train_loss=0.40815949, val_loss=0.00000000]\n",
      "Validation Epoch [424/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.94it/s, val_loss=1.03338563]\n",
      "Training Epoch [425/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=0.57700056, val_loss=0.00000000]\n",
      "Validation Epoch [425/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.27005649]\n",
      "Training Epoch [426/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=0.62501687, val_loss=0.00000000]\n",
      "Validation Epoch [426/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.07179284]\n",
      "Training Epoch [427/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.75it/s, curr_train_loss=0.61106700, val_loss=0.00000000]\n",
      "Validation Epoch [427/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, val_loss=1.13906217]\n",
      "Training Epoch [428/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.44it/s, curr_train_loss=0.39792168, val_loss=0.00000000]\n",
      "Validation Epoch [428/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.84it/s, val_loss=1.20893896]\n",
      "Training Epoch [429/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.08it/s, curr_train_loss=0.61171579, val_loss=0.00000000]\n",
      "Validation Epoch [429/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.85it/s, val_loss=1.36612737]\n",
      "Training Epoch [430/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.30it/s, curr_train_loss=0.61499780, val_loss=0.00000000]\n",
      "Validation Epoch [430/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.78it/s, val_loss=1.08989668]\n",
      "Training Epoch [431/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.41it/s, curr_train_loss=0.56961668, val_loss=0.00000000]\n",
      "Validation Epoch [431/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.11435544]\n",
      "Training Epoch [432/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.40it/s, curr_train_loss=0.73180884, val_loss=0.00000000]\n",
      "Validation Epoch [432/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.67it/s, val_loss=1.16878843]\n",
      "Training Epoch [433/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=0.57033312, val_loss=0.00000000]\n",
      "Validation Epoch [433/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.66it/s, val_loss=1.16821146]\n",
      "Training Epoch [434/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.40it/s, curr_train_loss=0.44339693, val_loss=0.00000000]\n",
      "Validation Epoch [434/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.28it/s, val_loss=1.09662473]\n",
      "Training Epoch [435/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.05it/s, curr_train_loss=0.50293672, val_loss=0.00000000]\n",
      "Validation Epoch [435/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.92it/s, val_loss=1.04660046]\n",
      "Training Epoch [436/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.81it/s, curr_train_loss=0.71321702, val_loss=0.00000000]\n",
      "Validation Epoch [436/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.94it/s, val_loss=1.02029586]\n",
      "Training Epoch [437/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.81it/s, curr_train_loss=0.46201718, val_loss=0.00000000]\n",
      "Validation Epoch [437/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=1.19623423]\n",
      "Training Epoch [438/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.11it/s, curr_train_loss=0.43438977, val_loss=0.00000000]\n",
      "Validation Epoch [438/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.95it/s, val_loss=1.10114217]\n",
      "Training Epoch [439/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, curr_train_loss=0.38624105, val_loss=0.00000000]\n",
      "Validation Epoch [439/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.85it/s, val_loss=1.06765890]\n",
      "Training Epoch [440/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, curr_train_loss=0.36083332, val_loss=0.00000000]\n",
      "Validation Epoch [440/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.70it/s, val_loss=1.11337245]\n",
      "Training Epoch [441/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=0.80700797, val_loss=0.00000000]\n",
      "Validation Epoch [441/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.76it/s, val_loss=1.05937386]\n",
      "Training Epoch [442/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=0.60097277, val_loss=0.00000000]\n",
      "Validation Epoch [442/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.85it/s, val_loss=1.14667463]\n",
      "Training Epoch [443/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, curr_train_loss=0.68865639, val_loss=0.00000000]\n",
      "Validation Epoch [443/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=1.10233724]\n",
      "Training Epoch [444/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, curr_train_loss=0.43214986, val_loss=0.00000000]\n",
      "Validation Epoch [444/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=1.06205273]\n",
      "Training Epoch [445/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  5.92it/s, curr_train_loss=0.67687416, val_loss=0.00000000]\n",
      "Validation Epoch [445/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.06340909]\n",
      "Training Epoch [446/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.63it/s, curr_train_loss=0.59426075, val_loss=0.00000000]\n",
      "Validation Epoch [446/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, val_loss=1.24247313]\n",
      "Training Epoch [447/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.62it/s, curr_train_loss=0.42649150, val_loss=0.00000000]\n",
      "Validation Epoch [447/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.06it/s, val_loss=1.19690228]\n",
      "Training Epoch [448/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, curr_train_loss=0.34749943, val_loss=0.00000000]\n",
      "Validation Epoch [448/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.95it/s, val_loss=1.00528097]\n",
      "Training Epoch [449/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.54it/s, curr_train_loss=0.54479909, val_loss=0.00000000]\n",
      "Validation Epoch [449/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, val_loss=1.16339409]\n",
      "Training Epoch [450/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.76it/s, curr_train_loss=0.54560912, val_loss=0.00000000]\n",
      "Validation Epoch [450/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.98it/s, val_loss=0.99112296]\n",
      "Training Epoch [451/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=0.49641457, val_loss=0.00000000]\n",
      "Validation Epoch [451/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.84it/s, val_loss=1.13880420]\n",
      "Training Epoch [452/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=0.59074873, val_loss=0.00000000]\n",
      "Validation Epoch [452/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, val_loss=0.99894679]\n",
      "Training Epoch [453/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=0.52476853, val_loss=0.00000000]\n",
      "Validation Epoch [453/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.91it/s, val_loss=1.10336149]\n",
      "Training Epoch [454/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, curr_train_loss=0.46784225, val_loss=0.00000000]\n",
      "Validation Epoch [454/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.57it/s, val_loss=0.96760863]\n",
      "Training Epoch [455/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.14it/s, curr_train_loss=0.53890455, val_loss=0.00000000]\n",
      "Validation Epoch [455/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.69it/s, val_loss=1.14129019]\n",
      "Training Epoch [456/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=0.62954491, val_loss=0.00000000]\n",
      "Validation Epoch [456/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=1.01895976]\n",
      "Training Epoch [457/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=0.51757544, val_loss=0.00000000]\n",
      "Validation Epoch [457/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.85it/s, val_loss=1.09974849]\n",
      "Training Epoch [458/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=0.42773181, val_loss=0.00000000]\n",
      "Validation Epoch [458/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s, val_loss=1.11216748]\n",
      "Training Epoch [459/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, curr_train_loss=0.53570157, val_loss=0.00000000]\n",
      "Validation Epoch [459/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.69it/s, val_loss=1.29751027]\n",
      "Training Epoch [460/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.67it/s, curr_train_loss=0.39917129, val_loss=0.00000000]\n",
      "Validation Epoch [460/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.78it/s, val_loss=0.86942881]\n",
      "Training Epoch [461/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=0.48765677, val_loss=0.00000000]\n",
      "Validation Epoch [461/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.10it/s, val_loss=1.29629886]\n",
      "Training Epoch [462/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.60it/s, curr_train_loss=0.30962327, val_loss=0.00000000]\n",
      "Validation Epoch [462/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.72it/s, val_loss=1.03411376]\n",
      "Training Epoch [463/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, curr_train_loss=0.63356531, val_loss=0.00000000]\n",
      "Validation Epoch [463/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.11109316]\n",
      "Training Epoch [464/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.82it/s, curr_train_loss=0.64356667, val_loss=0.00000000]\n",
      "Validation Epoch [464/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, val_loss=1.12397671]\n",
      "Training Epoch [465/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.30it/s, curr_train_loss=0.74067634, val_loss=0.00000000]\n",
      "Validation Epoch [465/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.72it/s, val_loss=1.33265352]\n",
      "Training Epoch [466/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, curr_train_loss=0.84232557, val_loss=0.00000000]\n",
      "Validation Epoch [466/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.08it/s, val_loss=1.04023933]\n",
      "Training Epoch [467/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=0.57655317, val_loss=0.00000000]\n",
      "Validation Epoch [467/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.20903277]\n",
      "Training Epoch [468/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.09it/s, curr_train_loss=0.41496930, val_loss=0.00000000]\n",
      "Validation Epoch [468/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.72it/s, val_loss=0.99667305]\n",
      "Training Epoch [469/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.55it/s, curr_train_loss=0.29349491, val_loss=0.00000000]\n",
      "Validation Epoch [469/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.76it/s, val_loss=0.95542562]\n",
      "Training Epoch [470/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=0.42639601, val_loss=0.00000000]\n",
      "Validation Epoch [470/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.23781109]\n",
      "Training Epoch [471/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=0.54382139, val_loss=0.00000000]\n",
      "Validation Epoch [471/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=1.09970737]\n",
      "Training Epoch [472/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.51it/s, curr_train_loss=0.66008466, val_loss=0.00000000]\n",
      "Validation Epoch [472/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.01it/s, val_loss=1.17213321]\n",
      "Training Epoch [473/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=0.47036311, val_loss=0.00000000]\n",
      "Validation Epoch [473/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.76it/s, val_loss=1.18887091]\n",
      "Training Epoch [474/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.67it/s, curr_train_loss=0.52154750, val_loss=0.00000000]\n",
      "Validation Epoch [474/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, val_loss=1.26600027]\n",
      "Training Epoch [475/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=0.41268447, val_loss=0.00000000]\n",
      "Validation Epoch [475/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.93it/s, val_loss=1.10649371]\n",
      "Training Epoch [476/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.15it/s, curr_train_loss=0.67772567, val_loss=0.00000000]\n",
      "Validation Epoch [476/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.15586722]\n",
      "Training Epoch [477/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.45it/s, curr_train_loss=0.71382308, val_loss=0.00000000]\n",
      "Validation Epoch [477/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.15it/s, val_loss=1.12702370]\n",
      "Training Epoch [478/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=0.44546565, val_loss=0.00000000]\n",
      "Validation Epoch [478/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=1.07074046]\n",
      "Training Epoch [479/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=0.44598857, val_loss=0.00000000]\n",
      "Validation Epoch [479/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.53it/s, val_loss=1.36539197]\n",
      "Training Epoch [480/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, curr_train_loss=0.58484340, val_loss=0.00000000]\n",
      "Validation Epoch [480/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s, val_loss=1.17517745]\n",
      "Training Epoch [481/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=0.47762448, val_loss=0.00000000]\n",
      "Validation Epoch [481/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.72it/s, val_loss=1.18629396]\n",
      "Training Epoch [482/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, curr_train_loss=0.35238793, val_loss=0.00000000]\n",
      "Validation Epoch [482/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.19929540]\n",
      "Training Epoch [483/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, curr_train_loss=0.36993450, val_loss=0.00000000]\n",
      "Validation Epoch [483/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.68it/s, val_loss=1.06913412]\n",
      "Training Epoch [484/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.06it/s, curr_train_loss=0.47487584, val_loss=0.00000000]\n",
      "Validation Epoch [484/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, val_loss=1.49040055]\n",
      "Training Epoch [485/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.93it/s, curr_train_loss=0.73031366, val_loss=0.00000000]\n",
      "Validation Epoch [485/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s, val_loss=1.22119844]\n",
      "Training Epoch [486/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, curr_train_loss=0.81027824, val_loss=0.00000000]\n",
      "Validation Epoch [486/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.19439805]\n",
      "Training Epoch [487/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, curr_train_loss=0.58776981, val_loss=0.00000000]\n",
      "Validation Epoch [487/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.22883487]\n",
      "Training Epoch [488/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.15it/s, curr_train_loss=0.42921829, val_loss=0.00000000]\n",
      "Validation Epoch [488/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s, val_loss=0.98066849]\n",
      "Training Epoch [489/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.45it/s, curr_train_loss=0.45630574, val_loss=0.00000000]\n",
      "Validation Epoch [489/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.95it/s, val_loss=1.14781272]\n",
      "Training Epoch [490/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, curr_train_loss=0.46673679, val_loss=0.00000000]\n",
      "Validation Epoch [490/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.79it/s, val_loss=1.18633425]\n",
      "Training Epoch [491/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=0.44741154, val_loss=0.00000000]\n",
      "Validation Epoch [491/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.03it/s, val_loss=1.08827400]\n",
      "Training Epoch [492/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=0.35720161, val_loss=0.00000000]\n",
      "Validation Epoch [492/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=0.93221164]\n",
      "Training Epoch [493/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.50it/s, curr_train_loss=0.40416741, val_loss=0.00000000]\n",
      "Validation Epoch [493/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.17it/s, val_loss=0.95626837]\n",
      "Training Epoch [494/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, curr_train_loss=0.48934773, val_loss=0.00000000]\n",
      "Validation Epoch [494/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.09582174]\n",
      "Training Epoch [495/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=0.53711134, val_loss=0.00000000]\n",
      "Validation Epoch [495/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=1.10238600]\n",
      "Training Epoch [496/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, curr_train_loss=0.71192014, val_loss=0.00000000]\n",
      "Validation Epoch [496/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.08it/s, val_loss=1.03089786]\n",
      "Training Epoch [497/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.84it/s, curr_train_loss=0.68315679, val_loss=0.00000000]\n",
      "Validation Epoch [497/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.13it/s, val_loss=0.89004678]\n",
      "Training Epoch [498/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, curr_train_loss=0.49372083, val_loss=0.00000000]\n",
      "Validation Epoch [498/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s, val_loss=1.03285933]\n",
      "Training Epoch [499/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, curr_train_loss=0.48482227, val_loss=0.00000000]\n",
      "Validation Epoch [499/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=0.99589086]\n",
      "Training Epoch [500/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.82it/s, curr_train_loss=0.52899384, val_loss=0.00000000]\n",
      "Validation Epoch [500/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=1.27881289]\n",
      "Training Epoch [501/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  4.97it/s, curr_train_loss=0.36789176, val_loss=0.00000000]\n",
      "Validation Epoch [501/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.73it/s, val_loss=1.05173898]\n",
      "Training Epoch [502/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.93it/s, curr_train_loss=0.58230191, val_loss=0.00000000]\n",
      "Validation Epoch [502/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.67it/s, val_loss=1.16102374]\n",
      "Training Epoch [503/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=0.55776572, val_loss=0.00000000]\n",
      "Validation Epoch [503/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.91it/s, val_loss=1.10752153]\n",
      "Training Epoch [504/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, curr_train_loss=0.54415905, val_loss=0.00000000]\n",
      "Validation Epoch [504/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.59it/s, val_loss=1.12324977]\n",
      "Training Epoch [505/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.69it/s, curr_train_loss=0.65050703, val_loss=0.00000000]\n",
      "Validation Epoch [505/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, val_loss=1.11201215]\n",
      "Training Epoch [506/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.29it/s, curr_train_loss=0.54393113, val_loss=0.00000000]\n",
      "Validation Epoch [506/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.62it/s, val_loss=1.19805634]\n",
      "Training Epoch [507/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=0.47235110, val_loss=0.00000000]\n",
      "Validation Epoch [507/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.04it/s, val_loss=1.37875354]\n",
      "Training Epoch [508/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.44983155, val_loss=0.00000000]\n",
      "Validation Epoch [508/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.62it/s, val_loss=0.99861491]\n",
      "Training Epoch [509/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  5.94it/s, curr_train_loss=0.60005170, val_loss=0.00000000]\n",
      "Validation Epoch [509/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.98it/s, val_loss=1.18982005]\n",
      "Training Epoch [510/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.92it/s, curr_train_loss=0.53861779, val_loss=0.00000000]\n",
      "Validation Epoch [510/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.73it/s, val_loss=1.09600556]\n",
      "Training Epoch [511/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.38it/s, curr_train_loss=0.44762751, val_loss=0.00000000]\n",
      "Validation Epoch [511/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=0.91220856]\n",
      "Training Epoch [512/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.50it/s, curr_train_loss=0.66679835, val_loss=0.00000000]\n",
      "Validation Epoch [512/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.93it/s, val_loss=1.08179164]\n",
      "Training Epoch [513/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=0.44391191, val_loss=0.00000000]\n",
      "Validation Epoch [513/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.71it/s, val_loss=1.18839884]\n",
      "Training Epoch [514/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=0.59580308, val_loss=0.00000000]\n",
      "Validation Epoch [514/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.59it/s, val_loss=1.25002074]\n",
      "Training Epoch [515/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=0.54755300, val_loss=0.00000000]\n",
      "Validation Epoch [515/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, val_loss=0.99871361]\n",
      "Training Epoch [516/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=0.27885965, val_loss=0.00000000]\n",
      "Validation Epoch [516/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.00it/s, val_loss=1.10272074]\n",
      "Training Epoch [517/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=0.36827555, val_loss=0.00000000]\n",
      "Validation Epoch [517/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, val_loss=1.22208035]\n",
      "Training Epoch [518/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.15it/s, curr_train_loss=0.61332047, val_loss=0.00000000]\n",
      "Validation Epoch [518/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.87it/s, val_loss=0.99120218]\n",
      "Training Epoch [519/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.34it/s, curr_train_loss=0.40142551, val_loss=0.00000000]\n",
      "Validation Epoch [519/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.60it/s, val_loss=1.14296210]\n",
      "Training Epoch [520/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=0.63182211, val_loss=0.00000000]\n",
      "Validation Epoch [520/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.60it/s, val_loss=1.15169108]\n",
      "Training Epoch [521/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.04it/s, curr_train_loss=0.39904293, val_loss=0.00000000]\n",
      "Validation Epoch [521/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.95it/s, val_loss=0.97280574]\n",
      "Training Epoch [522/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=0.29699245, val_loss=0.00000000]\n",
      "Validation Epoch [522/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.13531625]\n",
      "Training Epoch [523/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.07it/s, curr_train_loss=0.40466821, val_loss=0.00000000]\n",
      "Validation Epoch [523/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.96it/s, val_loss=1.28650403]\n",
      "Training Epoch [524/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.37it/s, curr_train_loss=0.46944880, val_loss=0.00000000]\n",
      "Validation Epoch [524/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.12890100]\n",
      "Training Epoch [525/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.76it/s, curr_train_loss=0.58682764, val_loss=0.00000000]\n",
      "Validation Epoch [525/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=0.86263925]\n",
      "Training Epoch [526/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.80it/s, curr_train_loss=0.60664845, val_loss=0.00000000]\n",
      "Validation Epoch [526/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.80it/s, val_loss=1.09803295]\n",
      "Training Epoch [527/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.18it/s, curr_train_loss=0.59275204, val_loss=0.00000000]\n",
      "Validation Epoch [527/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.66it/s, val_loss=1.09775364]\n",
      "Training Epoch [528/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.46it/s, curr_train_loss=0.71296418, val_loss=0.00000000]\n",
      "Validation Epoch [528/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.60it/s, val_loss=1.25071728]\n",
      "Training Epoch [529/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=0.36535576, val_loss=0.00000000]\n",
      "Validation Epoch [529/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=0.98791158]\n",
      "Training Epoch [530/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, curr_train_loss=0.40342450, val_loss=0.00000000]\n",
      "Validation Epoch [530/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.68it/s, val_loss=1.18353772]\n",
      "Training Epoch [531/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, curr_train_loss=0.43389267, val_loss=0.00000000]\n",
      "Validation Epoch [531/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.08733404]\n",
      "Training Epoch [532/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=0.38740993, val_loss=0.00000000]\n",
      "Validation Epoch [532/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.79it/s, val_loss=1.18565702]\n",
      "Training Epoch [533/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=0.42670548, val_loss=0.00000000]\n",
      "Validation Epoch [533/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.05it/s, val_loss=1.12240815]\n",
      "Training Epoch [534/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, curr_train_loss=0.55174828, val_loss=0.00000000]\n",
      "Validation Epoch [534/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.95it/s, val_loss=1.17670786]\n",
      "Training Epoch [535/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, curr_train_loss=0.42904931, val_loss=0.00000000]\n",
      "Validation Epoch [535/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.04it/s, val_loss=1.04829764]\n",
      "Training Epoch [536/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, curr_train_loss=0.43089733, val_loss=0.00000000]\n",
      "Validation Epoch [536/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=0.95775962]\n",
      "Training Epoch [537/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, curr_train_loss=0.43377036, val_loss=0.00000000]\n",
      "Validation Epoch [537/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.79it/s, val_loss=1.15647840]\n",
      "Training Epoch [538/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.69it/s, curr_train_loss=0.25730121, val_loss=0.00000000]\n",
      "Validation Epoch [538/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, val_loss=0.92467272]\n",
      "Training Epoch [539/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, curr_train_loss=0.60932636, val_loss=0.00000000]\n",
      "Validation Epoch [539/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.80it/s, val_loss=1.11569071]\n",
      "Training Epoch [540/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.54it/s, curr_train_loss=0.47925517, val_loss=0.00000000]\n",
      "Validation Epoch [540/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.18it/s, val_loss=1.03231084]\n",
      "Training Epoch [541/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.97it/s, curr_train_loss=0.35795230, val_loss=0.00000000]\n",
      "Validation Epoch [541/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.62it/s, val_loss=1.11686862]\n",
      "Training Epoch [542/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=0.52829385, val_loss=0.00000000]\n",
      "Validation Epoch [542/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.76it/s, val_loss=1.06899643]\n",
      "Training Epoch [543/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.32it/s, curr_train_loss=0.63378310, val_loss=0.00000000]\n",
      "Validation Epoch [543/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.13it/s, val_loss=1.05743194]\n",
      "Training Epoch [544/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.12it/s, curr_train_loss=0.55029583, val_loss=0.00000000]\n",
      "Validation Epoch [544/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.69it/s, val_loss=0.98540312]\n",
      "Training Epoch [545/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.69it/s, curr_train_loss=0.38280648, val_loss=0.00000000]\n",
      "Validation Epoch [545/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.65it/s, val_loss=0.97951996]\n",
      "Training Epoch [546/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.68it/s, curr_train_loss=0.70538241, val_loss=0.00000000]\n",
      "Validation Epoch [546/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.78it/s, val_loss=1.07709682]\n",
      "Training Epoch [547/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.32it/s, curr_train_loss=0.34956178, val_loss=0.00000000]\n",
      "Validation Epoch [547/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.62it/s, val_loss=1.10776436]\n",
      "Training Epoch [548/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.34it/s, curr_train_loss=0.38875127, val_loss=0.00000000]\n",
      "Validation Epoch [548/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, val_loss=1.22000635]\n",
      "Training Epoch [549/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, curr_train_loss=0.62157440, val_loss=0.00000000]\n",
      "Validation Epoch [549/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.06it/s, val_loss=0.90490717]\n",
      "Training Epoch [550/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, curr_train_loss=0.35074696, val_loss=0.00000000]\n",
      "Validation Epoch [550/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.08755231]\n",
      "Training Epoch [551/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, curr_train_loss=0.75812358, val_loss=0.00000000]\n",
      "Validation Epoch [551/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.16it/s, val_loss=1.00973690]\n",
      "Training Epoch [552/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.30it/s, curr_train_loss=0.46062255, val_loss=0.00000000]\n",
      "Validation Epoch [552/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.18it/s, val_loss=1.03346086]\n",
      "Training Epoch [553/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.32it/s, curr_train_loss=0.53814983, val_loss=0.00000000]\n",
      "Validation Epoch [553/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.71it/s, val_loss=1.10982585]\n",
      "Training Epoch [554/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, curr_train_loss=0.34693435, val_loss=0.00000000]\n",
      "Validation Epoch [554/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.74it/s, val_loss=1.04650116]\n",
      "Training Epoch [555/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.53it/s, curr_train_loss=0.51845032, val_loss=0.00000000]\n",
      "Validation Epoch [555/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.80it/s, val_loss=1.03619003]\n",
      "Training Epoch [556/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.93it/s, curr_train_loss=0.24027616, val_loss=0.00000000]\n",
      "Validation Epoch [556/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.58it/s, val_loss=1.04635751]\n",
      "Training Epoch [557/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=0.63710862, val_loss=0.00000000]\n",
      "Validation Epoch [557/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.61it/s, val_loss=1.07801616]\n",
      "Training Epoch [558/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.38it/s, curr_train_loss=0.41266242, val_loss=0.00000000]\n",
      "Validation Epoch [558/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.06it/s, val_loss=1.16345179]\n",
      "Training Epoch [559/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.97it/s, curr_train_loss=0.40968689, val_loss=0.00000000]\n",
      "Validation Epoch [559/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.34051836]\n",
      "Training Epoch [560/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=0.36460960, val_loss=0.00000000]\n",
      "Validation Epoch [560/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.61it/s, val_loss=1.18653059]\n",
      "Training Epoch [561/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.99it/s, curr_train_loss=0.43123460, val_loss=0.00000000]\n",
      "Validation Epoch [561/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.38it/s, val_loss=1.17500460]\n",
      "Training Epoch [562/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, curr_train_loss=0.38961652, val_loss=0.00000000]\n",
      "Validation Epoch [562/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.12531996]\n",
      "Training Epoch [563/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.29it/s, curr_train_loss=0.67489928, val_loss=0.00000000]\n",
      "Validation Epoch [563/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, val_loss=1.20293903]\n",
      "Training Epoch [564/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  4.94it/s, curr_train_loss=0.44488809, val_loss=0.00000000]\n",
      "Validation Epoch [564/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.06it/s, val_loss=1.23852968]\n",
      "Training Epoch [565/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.56it/s, curr_train_loss=0.41429147, val_loss=0.00000000]\n",
      "Validation Epoch [565/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.91it/s, val_loss=1.01900399]\n",
      "Training Epoch [566/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.18it/s, curr_train_loss=0.27562591, val_loss=0.00000000]\n",
      "Validation Epoch [566/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.04it/s, val_loss=1.15363538]\n",
      "Training Epoch [567/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=0.44366455, val_loss=0.00000000]\n",
      "Validation Epoch [567/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.25it/s, val_loss=1.16017008]\n",
      "Training Epoch [568/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=0.48423043, val_loss=0.00000000]\n",
      "Validation Epoch [568/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.99it/s, val_loss=1.05173063]\n",
      "Training Epoch [569/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, curr_train_loss=0.40986821, val_loss=0.00000000]\n",
      "Validation Epoch [569/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.55it/s, val_loss=1.14146435]\n",
      "Training Epoch [570/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.96it/s, curr_train_loss=0.41766289, val_loss=0.00000000]\n",
      "Validation Epoch [570/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.71it/s, val_loss=1.22219706]\n",
      "Training Epoch [571/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.11it/s, curr_train_loss=0.36605522, val_loss=0.00000000]\n",
      "Validation Epoch [571/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.23520517]\n",
      "Training Epoch [572/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.58it/s, curr_train_loss=0.40657508, val_loss=0.00000000]\n",
      "Validation Epoch [572/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.50it/s, val_loss=1.15422487]\n",
      "Training Epoch [573/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, curr_train_loss=0.77647918, val_loss=0.00000000]\n",
      "Validation Epoch [573/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.70it/s, val_loss=1.44971526]\n",
      "Training Epoch [574/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=0.49857122, val_loss=0.00000000]\n",
      "Validation Epoch [574/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.09it/s, val_loss=1.21099532]\n",
      "Training Epoch [575/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.18it/s, curr_train_loss=0.51732308, val_loss=0.00000000]\n",
      "Validation Epoch [575/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=1.10454988]\n",
      "Training Epoch [576/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  4.76it/s, curr_train_loss=0.47989175, val_loss=0.00000000]\n",
      "Validation Epoch [576/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.09it/s, val_loss=1.24098468]\n",
      "Training Epoch [577/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.49it/s, curr_train_loss=0.50742048, val_loss=0.00000000]\n",
      "Validation Epoch [577/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, val_loss=1.19536006]\n",
      "Training Epoch [578/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.48it/s, curr_train_loss=0.48896834, val_loss=0.00000000]\n",
      "Validation Epoch [578/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.15916979]\n",
      "Training Epoch [579/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=0.52106100, val_loss=0.00000000]\n",
      "Validation Epoch [579/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s, val_loss=1.29680753]\n",
      "Training Epoch [580/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=0.44233823, val_loss=0.00000000]\n",
      "Validation Epoch [580/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.84it/s, val_loss=1.34654248]\n",
      "Training Epoch [581/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.24it/s, curr_train_loss=0.63170725, val_loss=0.00000000]\n",
      "Validation Epoch [581/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.23459995]\n",
      "Training Epoch [582/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, curr_train_loss=0.31410977, val_loss=0.00000000]\n",
      "Validation Epoch [582/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.12it/s, val_loss=1.05306017]\n",
      "Training Epoch [583/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.32it/s, curr_train_loss=0.40833691, val_loss=0.00000000]\n",
      "Validation Epoch [583/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.84it/s, val_loss=1.05436540]\n",
      "Training Epoch [584/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.71it/s, curr_train_loss=0.46287546, val_loss=0.00000000]\n",
      "Validation Epoch [584/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.07it/s, val_loss=1.18420446]\n",
      "Training Epoch [585/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=0.42080250, val_loss=0.00000000]\n",
      "Validation Epoch [585/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.75it/s, val_loss=0.80976492]\n",
      "Training Epoch [586/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.87it/s, curr_train_loss=0.36372030, val_loss=0.00000000]\n",
      "Validation Epoch [586/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.57it/s, val_loss=1.08506882]\n",
      "Training Epoch [587/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.53it/s, curr_train_loss=0.54718077, val_loss=0.00000000]\n",
      "Validation Epoch [587/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.76it/s, val_loss=1.13566875]\n",
      "Training Epoch [588/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, curr_train_loss=0.39427739, val_loss=0.00000000]\n",
      "Validation Epoch [588/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=1.24298441]\n",
      "Training Epoch [589/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, curr_train_loss=0.35076845, val_loss=0.00000000]\n",
      "Validation Epoch [589/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=0.97498596]\n",
      "Training Epoch [590/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=0.45641941, val_loss=0.00000000]\n",
      "Validation Epoch [590/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.98it/s, val_loss=1.03155112]\n",
      "Training Epoch [591/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.06it/s, curr_train_loss=0.49953982, val_loss=0.00000000]\n",
      "Validation Epoch [591/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.07it/s, val_loss=1.03234088]\n",
      "Training Epoch [592/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=0.70444572, val_loss=0.00000000]\n",
      "Validation Epoch [592/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=0.85271734]\n",
      "Training Epoch [593/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=0.65734154, val_loss=0.00000000]\n",
      "Validation Epoch [593/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.68it/s, val_loss=0.90452957]\n",
      "Training Epoch [594/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, curr_train_loss=0.44086725, val_loss=0.00000000]\n",
      "Validation Epoch [594/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, val_loss=0.98092085]\n",
      "Training Epoch [595/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, curr_train_loss=0.48127201, val_loss=0.00000000]\n",
      "Validation Epoch [595/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=1.00500143]\n",
      "Training Epoch [596/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, curr_train_loss=0.33145142, val_loss=0.00000000]\n",
      "Validation Epoch [596/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.85it/s, val_loss=1.09711432]\n",
      "Training Epoch [597/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.86it/s, curr_train_loss=0.60891593, val_loss=0.00000000]\n",
      "Validation Epoch [597/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.10it/s, val_loss=1.01787627]\n",
      "Training Epoch [598/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=0.51206297, val_loss=0.00000000]\n",
      "Validation Epoch [598/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=1.01208639]\n",
      "Training Epoch [599/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, curr_train_loss=0.50544918, val_loss=0.00000000]\n",
      "Validation Epoch [599/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.83it/s, val_loss=1.01688480]\n",
      "Training Epoch [600/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=0.31500730, val_loss=0.00000000]\n",
      "Validation Epoch [600/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.91it/s, val_loss=1.12606466]\n",
      "Training Epoch [601/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.18it/s, curr_train_loss=0.67632759, val_loss=0.00000000]\n",
      "Validation Epoch [601/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, val_loss=0.94718659]\n",
      "Training Epoch [602/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.47it/s, curr_train_loss=0.49809247, val_loss=0.00000000]\n",
      "Validation Epoch [602/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.61it/s, val_loss=1.00932467]\n",
      "Training Epoch [603/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, curr_train_loss=0.27118096, val_loss=0.00000000]\n",
      "Validation Epoch [603/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=0.98042101]\n",
      "Training Epoch [604/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=0.55741078, val_loss=0.00000000]\n",
      "Validation Epoch [604/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.75it/s, val_loss=0.89039284]\n",
      "Training Epoch [605/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.55it/s, curr_train_loss=0.41170815, val_loss=0.00000000]\n",
      "Validation Epoch [605/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.80it/s, val_loss=0.99985391]\n",
      "Training Epoch [606/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=0.58457541, val_loss=0.00000000]\n",
      "Validation Epoch [606/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=1.15148008]\n",
      "Training Epoch [607/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.13it/s, curr_train_loss=0.53574705, val_loss=0.00000000]\n",
      "Validation Epoch [607/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.13it/s, val_loss=1.13731265]\n",
      "Training Epoch [608/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.31it/s, curr_train_loss=0.54249007, val_loss=0.00000000]\n",
      "Validation Epoch [608/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.74it/s, val_loss=1.34317231]\n",
      "Training Epoch [609/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.81it/s, curr_train_loss=0.62219745, val_loss=0.00000000]\n",
      "Validation Epoch [609/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.33731139]\n",
      "Training Epoch [610/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.15it/s, curr_train_loss=0.41903839, val_loss=0.00000000]\n",
      "Validation Epoch [610/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.79it/s, val_loss=1.04141331]\n",
      "Training Epoch [611/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  4.87it/s, curr_train_loss=0.44309080, val_loss=0.00000000]\n",
      "Validation Epoch [611/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.85it/s, val_loss=1.12702680]\n",
      "Training Epoch [612/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.51it/s, curr_train_loss=0.48160899, val_loss=0.00000000]\n",
      "Validation Epoch [612/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.37065184]\n",
      "Training Epoch [613/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.24it/s, curr_train_loss=0.62051511, val_loss=0.00000000]\n",
      "Validation Epoch [613/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.80it/s, val_loss=1.35983443]\n",
      "Training Epoch [614/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.52it/s, curr_train_loss=0.67416745, val_loss=0.00000000]\n",
      "Validation Epoch [614/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.52it/s, val_loss=1.31286502]\n",
      "Training Epoch [615/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  5.93it/s, curr_train_loss=0.61768627, val_loss=0.00000000]\n",
      "Validation Epoch [615/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.08181906]\n",
      "Training Epoch [616/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, curr_train_loss=0.42431679, val_loss=0.00000000]\n",
      "Validation Epoch [616/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.93it/s, val_loss=1.00588679]\n",
      "Training Epoch [617/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, curr_train_loss=0.64306104, val_loss=0.00000000]\n",
      "Validation Epoch [617/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.07932317]\n",
      "Training Epoch [618/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.03it/s, curr_train_loss=0.71935254, val_loss=0.00000000]\n",
      "Validation Epoch [618/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.95it/s, val_loss=1.14335787]\n",
      "Training Epoch [619/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=0.44894490, val_loss=0.00000000]\n",
      "Validation Epoch [619/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.10177982]\n",
      "Training Epoch [620/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.58it/s, curr_train_loss=0.55818897, val_loss=0.00000000]\n",
      "Validation Epoch [620/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.85it/s, val_loss=1.12495041]\n",
      "Training Epoch [621/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.62it/s, curr_train_loss=0.58390158, val_loss=0.00000000]\n",
      "Validation Epoch [621/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.76it/s, val_loss=1.24086523]\n",
      "Training Epoch [622/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, curr_train_loss=0.35947376, val_loss=0.00000000]\n",
      "Validation Epoch [622/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.85it/s, val_loss=1.18144381]\n",
      "Training Epoch [623/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=0.62944382, val_loss=0.00000000]\n",
      "Validation Epoch [623/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.07886553]\n",
      "Training Epoch [624/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=0.49809849, val_loss=0.00000000]\n",
      "Validation Epoch [624/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, val_loss=1.50872195]\n",
      "Training Epoch [625/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.29it/s, curr_train_loss=0.65658981, val_loss=0.00000000]\n",
      "Validation Epoch [625/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.39it/s, val_loss=1.36630249]\n",
      "Training Epoch [626/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, curr_train_loss=0.46628165, val_loss=0.00000000]\n",
      "Validation Epoch [626/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.08it/s, val_loss=0.86497194]\n",
      "Training Epoch [627/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.14it/s, curr_train_loss=0.52206570, val_loss=0.00000000]\n",
      "Validation Epoch [627/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.93it/s, val_loss=1.20421755]\n",
      "Training Epoch [628/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=0.39460051, val_loss=0.00000000]\n",
      "Validation Epoch [628/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.88it/s, val_loss=1.28886795]\n",
      "Training Epoch [629/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.24it/s, curr_train_loss=0.48977038, val_loss=0.00000000]\n",
      "Validation Epoch [629/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.08it/s, val_loss=1.16597867]\n",
      "Training Epoch [630/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.17it/s, curr_train_loss=0.39033833, val_loss=0.00000000]\n",
      "Validation Epoch [630/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.53it/s, val_loss=1.08877194]\n",
      "Training Epoch [631/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.75it/s, curr_train_loss=0.36860523, val_loss=0.00000000]\n",
      "Validation Epoch [631/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.14it/s, val_loss=1.14510751]\n",
      "Training Epoch [632/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.47it/s, curr_train_loss=0.35189083, val_loss=0.00000000]\n",
      "Validation Epoch [632/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.91it/s, val_loss=1.27356458]\n",
      "Training Epoch [633/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.81it/s, curr_train_loss=0.50083458, val_loss=0.00000000]\n",
      "Validation Epoch [633/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.77it/s, val_loss=1.04852343]\n",
      "Training Epoch [634/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.98it/s, curr_train_loss=0.55301780, val_loss=0.00000000]\n",
      "Validation Epoch [634/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.73it/s, val_loss=1.04396427]\n",
      "Training Epoch [635/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, curr_train_loss=0.40361214, val_loss=0.00000000]\n",
      "Validation Epoch [635/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=1.03560817]\n",
      "Training Epoch [636/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, curr_train_loss=0.45243585, val_loss=0.00000000]\n",
      "Validation Epoch [636/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, val_loss=1.09998655]\n",
      "Training Epoch [637/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.41it/s, curr_train_loss=0.43088368, val_loss=0.00000000]\n",
      "Validation Epoch [637/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.93it/s, val_loss=1.10069072]\n",
      "Training Epoch [638/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=0.32198766, val_loss=0.00000000]\n",
      "Validation Epoch [638/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s, val_loss=1.26162052]\n",
      "Training Epoch [639/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=0.52552021, val_loss=0.00000000]\n",
      "Validation Epoch [639/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.67it/s, val_loss=1.16139913]\n",
      "Training Epoch [640/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.43it/s, curr_train_loss=0.47614315, val_loss=0.00000000]\n",
      "Validation Epoch [640/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.85it/s, val_loss=1.01931155]\n",
      "Training Epoch [641/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.44171172, val_loss=0.00000000]\n",
      "Validation Epoch [641/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s, val_loss=1.13057208]\n",
      "Training Epoch [642/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, curr_train_loss=0.52157736, val_loss=0.00000000]\n",
      "Validation Epoch [642/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=0.91563118]\n",
      "Training Epoch [643/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, curr_train_loss=0.42938796, val_loss=0.00000000]\n",
      "Validation Epoch [643/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.91it/s, val_loss=1.10609066]\n",
      "Training Epoch [644/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.32996058, val_loss=0.00000000]\n",
      "Validation Epoch [644/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.25808108]\n",
      "Training Epoch [645/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, curr_train_loss=0.49412668, val_loss=0.00000000]\n",
      "Validation Epoch [645/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, val_loss=1.39991176]\n",
      "Training Epoch [646/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.05it/s, curr_train_loss=0.56988120, val_loss=0.00000000]\n",
      "Validation Epoch [646/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.03it/s, val_loss=1.15007067]\n",
      "Training Epoch [647/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.45it/s, curr_train_loss=0.44990727, val_loss=0.00000000]\n",
      "Validation Epoch [647/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.98it/s, val_loss=0.90192086]\n",
      "Training Epoch [648/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.22it/s, curr_train_loss=0.58485645, val_loss=0.00000000]\n",
      "Validation Epoch [648/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=0.96881044]\n",
      "Training Epoch [649/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, curr_train_loss=0.52356130, val_loss=0.00000000]\n",
      "Validation Epoch [649/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=1.16243970]\n",
      "Training Epoch [650/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.35it/s, curr_train_loss=0.37722233, val_loss=0.00000000]\n",
      "Validation Epoch [650/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.29it/s, val_loss=1.12267017]\n",
      "Training Epoch [651/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.56it/s, curr_train_loss=0.56547213, val_loss=0.00000000]\n",
      "Validation Epoch [651/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.85it/s, val_loss=1.14556623]\n",
      "Training Epoch [652/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.28it/s, curr_train_loss=0.53247702, val_loss=0.00000000]\n",
      "Validation Epoch [652/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, val_loss=1.08072591]\n",
      "Training Epoch [653/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, curr_train_loss=0.55313265, val_loss=0.00000000]\n",
      "Validation Epoch [653/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.79it/s, val_loss=1.21836245]\n",
      "Training Epoch [654/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, curr_train_loss=0.44943497, val_loss=0.00000000]\n",
      "Validation Epoch [654/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.93it/s, val_loss=1.25104773]\n",
      "Training Epoch [655/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.66it/s, curr_train_loss=0.33300877, val_loss=0.00000000]\n",
      "Validation Epoch [655/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, val_loss=0.98314357]\n",
      "Training Epoch [656/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, curr_train_loss=0.50477123, val_loss=0.00000000]\n",
      "Validation Epoch [656/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, val_loss=1.01297629]\n",
      "Training Epoch [657/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=0.37582210, val_loss=0.00000000]\n",
      "Validation Epoch [657/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.74it/s, val_loss=0.84789091]\n",
      "Training Epoch [658/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.14it/s, curr_train_loss=0.39166778, val_loss=0.00000000]\n",
      "Validation Epoch [658/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.70it/s, val_loss=0.88089997]\n",
      "Training Epoch [659/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.80it/s, curr_train_loss=0.64832956, val_loss=0.00000000]\n",
      "Validation Epoch [659/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.14it/s, val_loss=1.23728549]\n",
      "Training Epoch [660/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, curr_train_loss=0.36949021, val_loss=0.00000000]\n",
      "Validation Epoch [660/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.18547559]\n",
      "Training Epoch [661/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=0.49131095, val_loss=0.00000000]\n",
      "Validation Epoch [661/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.59it/s, val_loss=1.16079831]\n",
      "Training Epoch [662/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.37it/s, curr_train_loss=0.32334819, val_loss=0.00000000]\n",
      "Validation Epoch [662/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.66it/s, val_loss=1.19936895]\n",
      "Training Epoch [663/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.02it/s, curr_train_loss=0.43342048, val_loss=0.00000000]\n",
      "Validation Epoch [663/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.59it/s, val_loss=1.37873960]\n",
      "Training Epoch [664/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.36it/s, curr_train_loss=0.54274833, val_loss=0.00000000]\n",
      "Validation Epoch [664/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.61it/s, val_loss=1.13537252]\n",
      "Training Epoch [665/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, curr_train_loss=0.55506045, val_loss=0.00000000]\n",
      "Validation Epoch [665/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.84it/s, val_loss=1.17106748]\n",
      "Training Epoch [666/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.00it/s, curr_train_loss=0.45898038, val_loss=0.00000000]\n",
      "Validation Epoch [666/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.73it/s, val_loss=0.97313690]\n",
      "Training Epoch [667/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.62it/s, curr_train_loss=0.58981806, val_loss=0.00000000]\n",
      "Validation Epoch [667/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.67it/s, val_loss=0.96011370]\n",
      "Training Epoch [668/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, curr_train_loss=0.42724544, val_loss=0.00000000]\n",
      "Validation Epoch [668/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.98it/s, val_loss=1.17884481]\n",
      "Training Epoch [669/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=0.44205445, val_loss=0.00000000]\n",
      "Validation Epoch [669/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.76it/s, val_loss=1.23317480]\n",
      "Training Epoch [670/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  5.30it/s, curr_train_loss=0.41533133, val_loss=0.00000000]\n",
      "Validation Epoch [670/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.93it/s, val_loss=1.11997509]\n",
      "Training Epoch [671/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, curr_train_loss=0.35499954, val_loss=0.00000000]\n",
      "Validation Epoch [671/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.64it/s, val_loss=1.03739583]\n",
      "Training Epoch [672/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, curr_train_loss=0.38741809, val_loss=0.00000000]\n",
      "Validation Epoch [672/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.30it/s, val_loss=0.94238716]\n",
      "Training Epoch [673/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, curr_train_loss=0.44751221, val_loss=0.00000000]\n",
      "Validation Epoch [673/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.82it/s, val_loss=1.18640113]\n",
      "Training Epoch [674/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  5.35it/s, curr_train_loss=0.51973879, val_loss=0.00000000]\n",
      "Validation Epoch [674/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.91it/s, val_loss=1.14655888]\n",
      "Training Epoch [675/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.18it/s, curr_train_loss=0.38707420, val_loss=0.00000000]\n",
      "Validation Epoch [675/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.11646187]\n",
      "Training Epoch [676/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, curr_train_loss=0.44476086, val_loss=0.00000000]\n",
      "Validation Epoch [676/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=0.87739235]\n",
      "Training Epoch [677/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, curr_train_loss=0.41058087, val_loss=0.00000000]\n",
      "Validation Epoch [677/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.89it/s, val_loss=0.99553943]\n",
      "Training Epoch [678/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=0.53243601, val_loss=0.00000000]\n",
      "Validation Epoch [678/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.54it/s, val_loss=1.00142336]\n",
      "Training Epoch [679/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.65it/s, curr_train_loss=0.48180157, val_loss=0.00000000]\n",
      "Validation Epoch [679/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.59it/s, val_loss=0.98738128]\n",
      "Training Epoch [680/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.95it/s, curr_train_loss=0.34765166, val_loss=0.00000000]\n",
      "Validation Epoch [680/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.74it/s, val_loss=1.04219043]\n",
      "Training Epoch [681/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.16it/s, curr_train_loss=0.40892300, val_loss=0.00000000]\n",
      "Validation Epoch [681/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, val_loss=1.06849253]\n",
      "Training Epoch [682/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.43it/s, curr_train_loss=0.55498576, val_loss=0.00000000]\n",
      "Validation Epoch [682/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.70it/s, val_loss=1.08297181]\n",
      "Training Epoch [683/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.59it/s, curr_train_loss=0.37982655, val_loss=0.00000000]\n",
      "Validation Epoch [683/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.14it/s, val_loss=0.95827127]\n",
      "Training Epoch [684/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.44it/s, curr_train_loss=0.38418120, val_loss=0.00000000]\n",
      "Validation Epoch [684/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.95it/s, val_loss=0.98363793]\n",
      "Training Epoch [685/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.26it/s, curr_train_loss=0.48877040, val_loss=0.00000000]\n",
      "Validation Epoch [685/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.92it/s, val_loss=1.04269743]\n",
      "Training Epoch [686/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.01it/s, curr_train_loss=0.45042405, val_loss=0.00000000]\n",
      "Validation Epoch [686/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.03it/s, val_loss=1.00566173]\n",
      "Training Epoch [687/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, curr_train_loss=0.59766054, val_loss=0.00000000]\n",
      "Validation Epoch [687/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.80it/s, val_loss=1.04139972]\n",
      "Training Epoch [688/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.55it/s, curr_train_loss=0.55813438, val_loss=0.00000000]\n",
      "Validation Epoch [688/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.88it/s, val_loss=0.90149897]\n",
      "Training Epoch [689/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, curr_train_loss=0.38762784, val_loss=0.00000000]\n",
      "Validation Epoch [689/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, val_loss=1.06881392]\n",
      "Training Epoch [690/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=0.46616578, val_loss=0.00000000]\n",
      "Validation Epoch [690/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.73it/s, val_loss=1.17397511]\n",
      "Training Epoch [691/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.01it/s, curr_train_loss=0.39390042, val_loss=0.00000000]\n",
      "Validation Epoch [691/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.64it/s, val_loss=0.99070430]\n",
      "Training Epoch [692/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, curr_train_loss=0.53946435, val_loss=0.00000000]\n",
      "Validation Epoch [692/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.93it/s, val_loss=0.97621286]\n",
      "Training Epoch [693/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.67it/s, curr_train_loss=0.22937536, val_loss=0.00000000]\n",
      "Validation Epoch [693/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.76it/s, val_loss=0.78849226]\n",
      "Training Epoch [694/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.57it/s, curr_train_loss=0.50375956, val_loss=0.00000000]\n",
      "Validation Epoch [694/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=0.94467902]\n",
      "Training Epoch [695/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=0.57899094, val_loss=0.00000000]\n",
      "Validation Epoch [695/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.07it/s, val_loss=1.16209269]\n",
      "Training Epoch [696/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=0.50653911, val_loss=0.00000000]\n",
      "Validation Epoch [696/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.67it/s, val_loss=0.97413772]\n",
      "Training Epoch [697/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=0.54888803, val_loss=0.00000000]\n",
      "Validation Epoch [697/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=1.23131931]\n",
      "Training Epoch [698/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=0.52426457, val_loss=0.00000000]\n",
      "Validation Epoch [698/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.72it/s, val_loss=0.90901190]\n",
      "Training Epoch [699/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.65it/s, curr_train_loss=0.41995507, val_loss=0.00000000]\n",
      "Validation Epoch [699/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.87it/s, val_loss=0.90787971]\n",
      "Training Epoch [700/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=0.48031333, val_loss=0.00000000]\n",
      "Validation Epoch [700/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=0.89217013]\n",
      "Training Epoch [701/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.02it/s, curr_train_loss=0.45787999, val_loss=0.00000000]\n",
      "Validation Epoch [701/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.09360814]\n",
      "Training Epoch [702/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, curr_train_loss=0.29570761, val_loss=0.00000000]\n",
      "Validation Epoch [702/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=0.96110368]\n",
      "Training Epoch [703/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.93it/s, curr_train_loss=0.47694477, val_loss=0.00000000]\n",
      "Validation Epoch [703/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.91it/s, val_loss=1.08902252]\n",
      "Training Epoch [704/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=0.39084962, val_loss=0.00000000]\n",
      "Validation Epoch [704/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.84it/s, val_loss=1.20869613]\n",
      "Training Epoch [705/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=0.41968670, val_loss=0.00000000]\n",
      "Validation Epoch [705/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.06it/s, val_loss=1.04547215]\n",
      "Training Epoch [706/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, curr_train_loss=0.59612119, val_loss=0.00000000]\n",
      "Validation Epoch [706/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.78it/s, val_loss=1.34382081]\n",
      "Training Epoch [707/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.62it/s, curr_train_loss=0.27523768, val_loss=0.00000000]\n",
      "Validation Epoch [707/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.11it/s, val_loss=1.54338837]\n",
      "Training Epoch [708/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.33it/s, curr_train_loss=0.59156317, val_loss=0.00000000]\n",
      "Validation Epoch [708/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.03it/s, val_loss=1.42750394]\n",
      "Training Epoch [709/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=0.54066962, val_loss=0.00000000]\n",
      "Validation Epoch [709/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.75it/s, val_loss=1.21199477]\n",
      "Training Epoch [710/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.85it/s, curr_train_loss=0.48178729, val_loss=0.00000000]\n",
      "Validation Epoch [710/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.59885287]\n",
      "Training Epoch [711/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.68it/s, curr_train_loss=0.40821841, val_loss=0.00000000]\n",
      "Validation Epoch [711/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.04it/s, val_loss=1.01787364]\n",
      "Training Epoch [712/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.49it/s, curr_train_loss=0.37652910, val_loss=0.00000000]\n",
      "Validation Epoch [712/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.25560915]\n",
      "Training Epoch [713/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, curr_train_loss=0.51049316, val_loss=0.00000000]\n",
      "Validation Epoch [713/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.76it/s, val_loss=1.10126913]\n",
      "Training Epoch [714/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, curr_train_loss=0.45280072, val_loss=0.00000000]\n",
      "Validation Epoch [714/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.93it/s, val_loss=0.88070822]\n",
      "Training Epoch [715/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, curr_train_loss=0.47663379, val_loss=0.00000000]\n",
      "Validation Epoch [715/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.05it/s, val_loss=0.92531127]\n",
      "Training Epoch [716/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, curr_train_loss=0.41464892, val_loss=0.00000000]\n",
      "Validation Epoch [716/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.13624549]\n",
      "Training Epoch [717/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=0.52356648, val_loss=0.00000000]\n",
      "Validation Epoch [717/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.21383071]\n",
      "Training Epoch [718/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, curr_train_loss=0.58251536, val_loss=0.00000000]\n",
      "Validation Epoch [718/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.87it/s, val_loss=1.22434413]\n",
      "Training Epoch [719/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, curr_train_loss=0.38385907, val_loss=0.00000000]\n",
      "Validation Epoch [719/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=1.14056408]\n",
      "Training Epoch [720/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=0.53954130, val_loss=0.00000000]\n",
      "Validation Epoch [720/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.86it/s, val_loss=0.72101206]\n",
      "Training Epoch [721/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, curr_train_loss=0.40525189, val_loss=0.00000000]\n",
      "Validation Epoch [721/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.78it/s, val_loss=1.00325680]\n",
      "Training Epoch [722/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, curr_train_loss=0.37186748, val_loss=0.00000000]\n",
      "Validation Epoch [722/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.93it/s, val_loss=0.95427293]\n",
      "Training Epoch [723/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, curr_train_loss=0.59192824, val_loss=0.00000000]\n",
      "Validation Epoch [723/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, val_loss=0.75317895]\n",
      "Training Epoch [724/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, curr_train_loss=0.54933065, val_loss=0.00000000]\n",
      "Validation Epoch [724/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.78it/s, val_loss=0.87499154]\n",
      "Training Epoch [725/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.36922908, val_loss=0.00000000]\n",
      "Validation Epoch [725/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=0.91596705]\n",
      "Training Epoch [726/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, curr_train_loss=0.51532358, val_loss=0.00000000]\n",
      "Validation Epoch [726/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=0.88084114]\n",
      "Training Epoch [727/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, curr_train_loss=0.42357045, val_loss=0.00000000]\n",
      "Validation Epoch [727/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, val_loss=0.88043821]\n",
      "Training Epoch [728/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, curr_train_loss=0.47355852, val_loss=0.00000000]\n",
      "Validation Epoch [728/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.41it/s, val_loss=1.08512700]\n",
      "Training Epoch [729/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.79it/s, curr_train_loss=0.50345021, val_loss=0.00000000]\n",
      "Validation Epoch [729/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s, val_loss=1.03455698]\n",
      "Training Epoch [730/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.66it/s, curr_train_loss=0.58986479, val_loss=0.00000000]\n",
      "Validation Epoch [730/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=0.97658569]\n",
      "Training Epoch [731/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, curr_train_loss=0.51523226, val_loss=0.00000000]\n",
      "Validation Epoch [731/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.85it/s, val_loss=0.89171487]\n",
      "Training Epoch [732/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, curr_train_loss=0.53028345, val_loss=0.00000000]\n",
      "Validation Epoch [732/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.04308975]\n",
      "Training Epoch [733/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s, curr_train_loss=0.47200847, val_loss=0.00000000]\n",
      "Validation Epoch [733/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.21592259]\n",
      "Training Epoch [734/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, curr_train_loss=0.37140620, val_loss=0.00000000]\n",
      "Validation Epoch [734/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.93it/s, val_loss=0.97555673]\n",
      "Training Epoch [735/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=0.41075376, val_loss=0.00000000]\n",
      "Validation Epoch [735/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.97it/s, val_loss=1.17667818]\n",
      "Training Epoch [736/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.83it/s, curr_train_loss=0.43030775, val_loss=0.00000000]\n",
      "Validation Epoch [736/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.18it/s, val_loss=1.01945317]\n",
      "Training Epoch [737/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=0.37622723, val_loss=0.00000000]\n",
      "Validation Epoch [737/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.93it/s, val_loss=0.96972626]\n",
      "Training Epoch [738/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=0.54350126, val_loss=0.00000000]\n",
      "Validation Epoch [738/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=0.73702890]\n",
      "Training Epoch [739/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.48526886, val_loss=0.00000000]\n",
      "Validation Epoch [739/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=0.85728335]\n",
      "Training Epoch [740/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, curr_train_loss=0.37969944, val_loss=0.00000000]\n",
      "Validation Epoch [740/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.07642353]\n",
      "Training Epoch [741/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  4.79it/s, curr_train_loss=0.47983915, val_loss=0.00000000]\n",
      "Validation Epoch [741/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.70it/s, val_loss=1.10786366]\n",
      "Training Epoch [742/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.37it/s, curr_train_loss=0.46249878, val_loss=0.00000000]\n",
      "Validation Epoch [742/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s, val_loss=0.97998267]\n",
      "Training Epoch [743/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.27it/s, curr_train_loss=0.38729417, val_loss=0.00000000]\n",
      "Validation Epoch [743/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, val_loss=1.20562434]\n",
      "Training Epoch [744/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.59it/s, curr_train_loss=0.40724477, val_loss=0.00000000]\n",
      "Validation Epoch [744/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.78it/s, val_loss=0.86614990]\n",
      "Training Epoch [745/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.37it/s, curr_train_loss=0.56551361, val_loss=0.00000000]\n",
      "Validation Epoch [745/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.70it/s, val_loss=1.14458144]\n",
      "Training Epoch [746/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.61it/s, curr_train_loss=0.38655975, val_loss=0.00000000]\n",
      "Validation Epoch [746/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.10it/s, val_loss=0.96047860]\n",
      "Training Epoch [747/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.88it/s, curr_train_loss=0.49554050, val_loss=0.00000000]\n",
      "Validation Epoch [747/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.15it/s, val_loss=1.07657695]\n",
      "Training Epoch [748/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.98it/s, curr_train_loss=0.41986394, val_loss=0.00000000]\n",
      "Validation Epoch [748/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.91it/s, val_loss=1.02289367]\n",
      "Training Epoch [749/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, curr_train_loss=0.48967788, val_loss=0.00000000]\n",
      "Validation Epoch [749/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=1.10984921]\n",
      "Training Epoch [750/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=0.54450548, val_loss=0.00000000]\n",
      "Validation Epoch [750/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.78it/s, val_loss=1.03877926]\n",
      "Training Epoch [751/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.09it/s, curr_train_loss=0.50416201, val_loss=0.00000000]\n",
      "Validation Epoch [751/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.04it/s, val_loss=0.94735926]\n",
      "Training Epoch [752/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.14it/s, curr_train_loss=0.46979704, val_loss=0.00000000]\n",
      "Validation Epoch [752/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.03it/s, val_loss=0.81219220]\n",
      "Training Epoch [753/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.58it/s, curr_train_loss=0.40754437, val_loss=0.00000000]\n",
      "Validation Epoch [753/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.09it/s, val_loss=1.05168200]\n",
      "Training Epoch [754/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  5.89it/s, curr_train_loss=0.57035005, val_loss=0.00000000]\n",
      "Validation Epoch [754/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.93it/s, val_loss=1.17115307]\n",
      "Training Epoch [755/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, curr_train_loss=0.35338715, val_loss=0.00000000]\n",
      "Validation Epoch [755/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.09it/s, val_loss=1.03289270]\n",
      "Training Epoch [756/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.61it/s, curr_train_loss=0.40434539, val_loss=0.00000000]\n",
      "Validation Epoch [756/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.16949630]\n",
      "Training Epoch [757/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  4.60it/s, curr_train_loss=0.38947526, val_loss=0.00000000]\n",
      "Validation Epoch [757/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, val_loss=1.13805509]\n",
      "Training Epoch [758/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.60it/s, curr_train_loss=0.37398830, val_loss=0.00000000]\n",
      "Validation Epoch [758/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=0.92180544]\n",
      "Training Epoch [759/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.51it/s, curr_train_loss=0.36178616, val_loss=0.00000000]\n",
      "Validation Epoch [759/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=0.93676221]\n",
      "Training Epoch [760/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=0.46672454, val_loss=0.00000000]\n",
      "Validation Epoch [760/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.14903045]\n",
      "Training Epoch [761/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, curr_train_loss=0.29918832, val_loss=0.00000000]\n",
      "Validation Epoch [761/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.80it/s, val_loss=1.28715301]\n",
      "Training Epoch [762/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.94it/s, curr_train_loss=0.37698251, val_loss=0.00000000]\n",
      "Validation Epoch [762/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.06it/s, val_loss=1.24826026]\n",
      "Training Epoch [763/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.98it/s, curr_train_loss=0.46848926, val_loss=0.00000000]\n",
      "Validation Epoch [763/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, val_loss=1.08075833]\n",
      "Training Epoch [764/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.26it/s, curr_train_loss=0.62714845, val_loss=0.00000000]\n",
      "Validation Epoch [764/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, val_loss=1.07286084]\n",
      "Training Epoch [765/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=0.37358370, val_loss=0.00000000]\n",
      "Validation Epoch [765/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.12362826]\n",
      "Training Epoch [766/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.55it/s, curr_train_loss=0.26864278, val_loss=0.00000000]\n",
      "Validation Epoch [766/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.04it/s, val_loss=0.88148779]\n",
      "Training Epoch [767/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=0.37271211, val_loss=0.00000000]\n",
      "Validation Epoch [767/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, val_loss=1.23200214]\n",
      "Training Epoch [768/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.89it/s, curr_train_loss=0.44750154, val_loss=0.00000000]\n",
      "Validation Epoch [768/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.12it/s, val_loss=1.32202852]\n",
      "Training Epoch [769/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.51it/s, curr_train_loss=0.42603543, val_loss=0.00000000]\n",
      "Validation Epoch [769/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s, val_loss=0.99741590]\n",
      "Training Epoch [770/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, curr_train_loss=0.30818000, val_loss=0.00000000]\n",
      "Validation Epoch [770/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, val_loss=1.26913786]\n",
      "Training Epoch [771/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.71it/s, curr_train_loss=0.46460143, val_loss=0.00000000]\n",
      "Validation Epoch [771/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=0.92964256]\n",
      "Training Epoch [772/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=0.58413881, val_loss=0.00000000]\n",
      "Validation Epoch [772/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, val_loss=1.05394626]\n",
      "Training Epoch [773/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.18it/s, curr_train_loss=0.56585032, val_loss=0.00000000]\n",
      "Validation Epoch [773/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.79it/s, val_loss=1.26949596]\n",
      "Training Epoch [774/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, curr_train_loss=0.49193168, val_loss=0.00000000]\n",
      "Validation Epoch [774/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.64it/s, val_loss=0.99943924]\n",
      "Training Epoch [775/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, curr_train_loss=0.42105111, val_loss=0.00000000]\n",
      "Validation Epoch [775/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=1.17617667]\n",
      "Training Epoch [776/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.81it/s, curr_train_loss=0.47322217, val_loss=0.00000000]\n",
      "Validation Epoch [776/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.98it/s, val_loss=1.25407147]\n",
      "Training Epoch [777/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.99it/s, curr_train_loss=0.56532085, val_loss=0.00000000]\n",
      "Validation Epoch [777/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.68it/s, val_loss=1.22078788]\n",
      "Training Epoch [778/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.76it/s, curr_train_loss=0.54257542, val_loss=0.00000000]\n",
      "Validation Epoch [778/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.63it/s, val_loss=1.09661305]\n",
      "Training Epoch [779/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=0.37731388, val_loss=0.00000000]\n",
      "Validation Epoch [779/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, val_loss=1.22196710]\n",
      "Training Epoch [780/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.62it/s, curr_train_loss=0.60123354, val_loss=0.00000000]\n",
      "Validation Epoch [780/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, val_loss=1.21414363]\n",
      "Training Epoch [781/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.30it/s, curr_train_loss=0.50886935, val_loss=0.00000000]\n",
      "Validation Epoch [781/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.60it/s, val_loss=1.40725124]\n",
      "Training Epoch [782/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, curr_train_loss=0.52204388, val_loss=0.00000000]\n",
      "Validation Epoch [782/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.46588337]\n",
      "Training Epoch [783/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, curr_train_loss=0.48142374, val_loss=0.00000000]\n",
      "Validation Epoch [783/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.39206898]\n",
      "Training Epoch [784/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, curr_train_loss=0.40370849, val_loss=0.00000000]\n",
      "Validation Epoch [784/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.09it/s, val_loss=1.16259313]\n",
      "Training Epoch [785/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=0.35777593, val_loss=0.00000000]\n",
      "Validation Epoch [785/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.32it/s, val_loss=1.11799848]\n",
      "Training Epoch [786/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.69it/s, curr_train_loss=0.47524101, val_loss=0.00000000]\n",
      "Validation Epoch [786/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=1.36213291]\n",
      "Training Epoch [787/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.36897936, val_loss=0.00000000]\n",
      "Validation Epoch [787/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.05it/s, val_loss=1.04970157]\n",
      "Training Epoch [788/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.13it/s, curr_train_loss=0.27565429, val_loss=0.00000000]\n",
      "Validation Epoch [788/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.33945572]\n",
      "Training Epoch [789/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.76it/s, curr_train_loss=0.43579811, val_loss=0.00000000]\n",
      "Validation Epoch [789/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, val_loss=1.33793712]\n",
      "Training Epoch [790/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=0.44062954, val_loss=0.00000000]\n",
      "Validation Epoch [790/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.16it/s, val_loss=1.12560749]\n",
      "Training Epoch [791/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.22it/s, curr_train_loss=0.49103835, val_loss=0.00000000]\n",
      "Validation Epoch [791/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.75it/s, val_loss=1.08786488]\n",
      "Training Epoch [792/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=0.53863955, val_loss=0.00000000]\n",
      "Validation Epoch [792/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.75it/s, val_loss=1.02857387]\n",
      "Training Epoch [793/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.10it/s, curr_train_loss=0.35215920, val_loss=0.00000000]\n",
      "Validation Epoch [793/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.25790644]\n",
      "Training Epoch [794/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, curr_train_loss=0.42067680, val_loss=0.00000000]\n",
      "Validation Epoch [794/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.99it/s, val_loss=1.31991684]\n",
      "Training Epoch [795/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.32it/s, curr_train_loss=0.37134370, val_loss=0.00000000]\n",
      "Validation Epoch [795/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.69it/s, val_loss=1.17674625]\n",
      "Training Epoch [796/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  5.83it/s, curr_train_loss=0.36164933, val_loss=0.00000000]\n",
      "Validation Epoch [796/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.05it/s, val_loss=0.92749834]\n",
      "Training Epoch [797/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, curr_train_loss=0.33510998, val_loss=0.00000000]\n",
      "Validation Epoch [797/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=0.93087941]\n",
      "Training Epoch [798/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.23it/s, curr_train_loss=0.35673687, val_loss=0.00000000]\n",
      "Validation Epoch [798/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.66it/s, val_loss=1.16308248]\n",
      "Training Epoch [799/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=0.42162904, val_loss=0.00000000]\n",
      "Validation Epoch [799/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.79it/s, val_loss=1.16354632]\n",
      "Training Epoch [800/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, curr_train_loss=0.40715969, val_loss=0.00000000]\n",
      "Validation Epoch [800/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.65it/s, val_loss=1.13346767]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creat a tensorboard logger.\n",
    "# NOTE: In order to see the logs, run the following command in the terminal: tensorboard --logdir=./\n",
    "# Also, in order to reset the logs, delete the logs folder MANUALLY.\n",
    "# Pay attention that if you run this cell mutltiple times, the pretrained_encoder\n",
    "# is not reset, and will keep training from where it stopped. Thus, it could overfit.\n",
    "\n",
    "path = os.path.join('logs', 'pretrained_cls_logs')\n",
    "num_of_runs = len(os.listdir(path)) if os.path.exists(path) else 0\n",
    "path = os.path.join(path, f'run_{num_of_runs + 1}')\n",
    "tb_logger = SummaryWriter(path)\n",
    "\n",
    "batch_size = hparams.get('batch_size', 16)\n",
    "labled_train_loader = torch.utils.data.DataLoader(train_100_dataset, batch_size=batch_size, shuffle=True)\n",
    "labled_val_loader = torch.utils.data.DataLoader(val_100_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "epochs = hparams.get('epochs', 20)\n",
    "loss_func = nn.CrossEntropyLoss() # The loss function we use for classification.\n",
    "train_classifier(classifier_pretrained, labled_train_loader, labled_val_loader, loss_func, tb_logger, epochs=epochs, name='Pretrained')\n",
    "\n",
    "print(\"Finished training!\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "H-pm1MY_MNks"
   },
   "source": [
    "Let's have a look at the validation accuracy of the two different classifiers and compare them. And don't forget that you can also monitor your training in TensorBoard.\n",
    "\n",
    "We will only look at the test accuracy and compare our two classifiers with respect to that in the very end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "-e5Bd9KLMNkt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy when training from scratch: \u001b[92m64.0\u001b[0m%\n",
      "Validation accuracy with pretraining: \u001b[92m73.0\u001b[0m%\n"
     ]
    }
   ],
   "source": [
    "val_acc_scracth = classifier.getAcc(labled_val_loader)[1]*100\n",
    "color = 'green' if val_acc_scracth > 55 else 'red'\n",
    "print(f\"Validation accuracy when training from scratch: {bcolors.colorize(color, val_acc_scracth)}%\")\n",
    "\n",
    "val_acc_pretrained = classifier_pretrained.getAcc(labled_val_loader)[1]*100\n",
    "color = 'green' if val_acc_pretrained > 55 else 'red'\n",
    "print(f\"Validation accuracy with pretraining: {bcolors.colorize(color, val_acc_pretrained)}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zAp2OTyf4_5b"
   },
   "source": [
    "Now that everything is working, feel free to play around with different architectures. As you've seen, it's quite easy to define your model or do adpations there.\n",
    "\n",
    "To pass this submission, you will need to achieve an accuracy of **55%**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OmEYmRT-5S-e"
   },
   "source": [
    "# Save your model & Report Test Accuracy\n",
    "\n",
    "When you are finally done with your **hyperparameter tuning**, achieved **at least 55% validation accuracy** and are happy with your final model, you can save it here.\n",
    "\n",
    "Before that, please check again whether the number of parameters is below 5 Mio and the file size is below 20 MB.\n",
    "\n",
    "Once your final model is saved, we'll finally report the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "S69ETKxD5TcE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy when training from scratch: \u001b[92m65.0\u001b[0m%\n",
      "Test accuracy with pretraining: \u001b[92m88.0\u001b[0m%\n",
      "Validation Accuracy: \u001b[92m70.0\u001b[0m%\n",
      "# Paramters: Your model has \u001b[92m0.602\u001b[0m mio. params.\n",
      "Size: Great! Your model size is \u001b[92m4.6\u001b[0m MB and is less than 20 MB.\n",
      "Your model has been saved and is ready to be submitted.\n"
     ]
    }
   ],
   "source": [
    "from exercise_code.Util import test_and_save\n",
    "test_dl = torch.utils.data.DataLoader(test_100_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "test_acc = classifier.getAcc(test_dl)[1]*100\n",
    "color = 'green' if test_acc > 55 else 'red'\n",
    "print(f\"Test accuracy when training from scratch: {bcolors.colorize(color, test_acc)}%\")\n",
    "\n",
    "test_acc = classifier_pretrained.getAcc(test_dl)[1]*100\n",
    "color = 'green' if test_acc > 55 else 'red'\n",
    "print(f\"Test accuracy with pretraining: {bcolors.colorize(color, test_acc)}%\")\n",
    "\n",
    "test_and_save(classifier_pretrained, labled_val_loader, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "enZCnGL6MNkt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevant folders: ['exercise_code', 'models']\n",
      "notebooks files: ['Optional-BatchNormalization_Dropout.ipynb', '1_Autoencoder.ipynb']\n",
      "Adding folder exercise_code\n",
      "Adding folder models\n",
      "Adding notebook Optional-BatchNormalization_Dropout.ipynb\n",
      "Adding notebook 1_Autoencoder.ipynb\n",
      "Zipping successful! Zip is stored under: /home/timm_pop/Documents/i2dl/output/exercise_08.zip\n"
     ]
    }
   ],
   "source": [
    "# Now zip the folder for upload\n",
    "from exercise_code.submit import submit_exercise\n",
    "\n",
    "submit_exercise('../output/exercise_08')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "7fuo3Tf9MNku",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Congratulations on completing your first autoencoder and successfully transferring the weights to a classifier! It's remarkable how much easier this process becomes with the power of PyTorch, compared to working with plain NumPy, right?\n",
    "\n",
    "To complete the exercise, please submit your final model to [our submission portal](https://i2dl.vc.in.tum.de/) - you should be already familiar with the submission procedure. Next, it is time to get started with some more complex neural networks and tasks in the upcoming exercises. See you next week!\n",
    "\n",
    "# Submission Goals\n",
    "\n",
    "- Goal: Successfully implement a fully connected autoencoder for MNIST with Pytorch and transfer the encoder weights to a classifier.\n",
    "\n",
    "- Passing Criteria: There are no unit tests that check specific components of your code. The only thing that's required to pass the submission, is your model to reach at least **55% accuracy** on __our__ test dataset. The submission system will show you a number between 0 and 100 which corresponds to your accuracy.\n",
    "\n",
    "- Submission start: __June 15, 2023 10:00__\n",
    "- Submission deadline : __June 21, 2023 15:59__ \n",
    "- You can make **$\\infty$** submissions until the deadline. Your __best submission__ will be considered for the bonus."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Ar26mFO5MNku"
   },
   "source": [
    "# [Exercise Review](https://forms.gle/9SYivCPQZdktRDS29)\n",
    "\n",
    "We are always interested in your opinion. Now that you have finished this exercise, we would like you to give us some feedback about the time required to finish the submission and/or work through the notebooks. Please take the short time to fill out our [review form](https://forms.gle/9SYivCPQZdktRDS29) for this exercise so that we can do better next time! :)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "54970da6898dad277dbf355945c2dee7f942d2a31ec1fc1455b6d4f552d07b83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
