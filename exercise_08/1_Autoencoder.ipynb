{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "9CALuVmNMNkM"
   },
   "source": [
    "# Autoencoder for MNIST\n",
    "\n",
    "Welcome to this notebook where you'll be training an autoencoder using the MNIST dataset, which comprises handwritten digits. This exercise is the last where we present you with a structured skeleton to work with. However, in following exercises, we will only provide you with the dataset, task, and a test scenario, enabling you to test your skills and compete with your peers on our leaderboards. Get ready to dive in and showcase your deep learning expertise!\n",
    "\n",
    "\n",
    "## Your task:\n",
    "\n",
    "Autoencoders have various applications, including unsupervised pretraining using unlabeled data, followed by fine-tuning the encoder with labeled data. This approach can greatly enhance performance when there is only a little amount of labeled data but a lot of unlabeled data available.\n",
    "\n",
    "In this exercise, you will use the MNIST dataset, consisting of 60,000 images of handwritten digits. However, not all the image labels are available to you. Your first objective is to train an autoencoder to accurately reproduce these unlabeled images.\n",
    "\n",
    "Afterwards, you will transfer the weights of the pretrained encoder and perform fine-tuning on a classifier using the available labeled data. This technique is commonly known as **transfer learning**, which allows you to leverage the knowledge gained from the autoencoder to improve the classification of the handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XcU9f4APMNkT"
   },
   "outputs": [],
   "source": [
    "# For automatic file reloading as usual\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Xb9dFU2EMNkW"
   },
   "source": [
    "## (Optional) Mount folder in Colab\n",
    "\n",
    "Uncomment the following cell to mount your gdrive if you are using the notebook in google colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "TRr4E4YVMNkW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom google.colab import drive\\nimport os\\ngdrive_path='/content/gdrive/MyDrive/i2dl/exercise_08'\\n\\n# This will mount your google drive under 'MyDrive'\\ndrive.mount('/content/gdrive', force_remount=True)\\n# In order to access the files in this notebook we have to navigate to the correct folder\\nos.chdir(gdrive_path)\\n# Check manually if all files are present\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the following lines if you want to use Google Colab\n",
    "# We presume you created a folder \"i2dl\" within your main drive folder, and put the exercise there.\n",
    "# NOTE: terminate all other colab sessions that use GPU!\n",
    "# NOTE 2: Make sure the correct exercise folder (e.g exercise_08) is given.\n",
    "\n",
    "# from google.colab import drive\n",
    "# import os\n",
    "\n",
    "\"\"\"\n",
    "from google.colab import drive\n",
    "import os\n",
    "gdrive_path='/content/gdrive/MyDrive/i2dl/exercise_08'\n",
    "\n",
    "# This will mount your google drive under 'MyDrive'\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "# In order to access the files in this notebook we have to navigate to the correct folder\n",
    "os.chdir(gdrive_path)\n",
    "# Check manually if all files are present\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "JzDQg-kDMNkY"
   },
   "source": [
    "### Set up PyTorch environment in colab\n",
    "- (OPTIONAL) Enable GPU via Runtime --> Change runtime type --> GPU\n",
    "- Uncomment the following cell if you are using the notebook in google colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pIUdsXeXMNkZ"
   },
   "outputs": [],
   "source": [
    "# Optional: install correct libraries in google colab\n",
    "# !python -m pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchtext==0.12.0+cu113 torchaudio==0.12.0+cu113 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# !python -m pip install tensorboard==2.8.0 > /dev/null\n",
    "# !python -m pip install pytorch-lightning==1.6.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "hEDWAZ7-ZA4E"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dJCiVLV5o9QO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from exercise_code.image_folder_dataset import ImageFolderDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "from exercise_code.tests.base_tests import bcolors\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' # To prevent the kernel from dying."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "dvaj6myXS7nN"
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Note: Google Colab</h3>\n",
    "    <p>\n",
    "In case you don't have a GPU, you can run this notebook on Google Colab where you can access a GPU for free, but, of course, you can also run this notebook on your CPU.\n",
    "         </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VWgm75NnS9hr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using the following device:  cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('You are using the following device: ', device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Pm_rTAPnpsUo"
   },
   "source": [
    "## Setup TensorBoard\n",
    "\n",
    "In the previous exercise (Exercise 07), you learned how to use TensorBoard effectively. Let's use it again to enhance the convenience of debugging your network and the training process. Throughout this notebook, feel free to implement additional logs or visualizations into your TensorBoard, further improving your analysis and understanding of the network's behavior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QbAJFyHkMNke"
   },
   "outputs": [],
   "source": [
    "################# COLAB ONLY #################\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir=./ --port 6006\n",
    "\n",
    "# Use the cmd for less trouble, if you can. From the working directory, run: tensorboard --logdir=./ --port 6006"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "t-Yt2KRiMNkf"
   },
   "source": [
    "# 1. The MNIST Dataset\n",
    "\n",
    "First, let's download the MNIST dataset. As mentioned in the beginning of this notebook, MNIST is a dataset of 60,000 images depicting handwritten digits. However, labeling such a large dataset can be a costly process, leaving us in a challenging situation.\n",
    "\n",
    "To overcome this, a practical approach is to label a small subset of the images. Let's consider a scenario where you have hired another student to perform the labeling task for you. After some time, you have been provided with 300 labeled images. Out of these, 100 images will be used for training, another 100 for validation, and the remaining 100 for testing. Undoubtedly, this poses a challenge due to the limited number of labeled samples.\n",
    "\n",
    "Now, you have the flexibility to define any transforms that you deem necessary, either at this point or at a later stage. However, it's important to note that during the final evaluation on the server, no transformations will be applied to the test set.\n",
    "\n",
    "Feel free to experiment with various transforms as you proceed (you can also pass without any transforms). \n",
    "\n",
    "\n",
    "**Note**: We do **not** apply any transformations to the test set at the time of final evaluation on our server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "U5_eopjbMNkf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found dataset folder. Skipped downloading. If you face issues, please re-download the dataset using\n",
      "'--force_download=True'\n",
      "https://i2dl.vc.in.tum.de/static/data/mnist.zip\n",
      "Found dataset folder. Skipped downloading. If you face issues, please re-download the dataset using\n",
      "'--force_download=True'\n",
      "https://i2dl.vc.in.tum.de/static/data/mnist.zip\n",
      "Found dataset folder. Skipped downloading. If you face issues, please re-download the dataset using\n",
      "'--force_download=True'\n",
      "https://i2dl.vc.in.tum.de/static/data/mnist.zip\n",
      "Found dataset folder. Skipped downloading. If you face issues, please re-download the dataset using\n",
      "'--force_download=True'\n",
      "https://i2dl.vc.in.tum.de/static/data/mnist.zip\n",
      "Found dataset folder. Skipped downloading. If you face issues, please re-download the dataset using\n",
      "'--force_download=True'\n",
      "https://i2dl.vc.in.tum.de/static/data/mnist.zip\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([])\n",
    "\n",
    "########################################################################\n",
    "# TODO: Feel free to define transforms                                 #\n",
    "########################################################################\n",
    "\n",
    "# MNIST mean: 0.1307, std: 0.3081\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Normalize((0.1307), (0.3081)), # Apparently normalizing results in terrible submission results\n",
    "    transforms.RandomPerspective(distortion_scale=0.3, p=0.4),\n",
    "    transforms.RandomApply(torch.nn.ModuleList([\n",
    "     transforms.RandomRotation(degrees=30)]), p=0.4)\n",
    "    \n",
    "    ])\n",
    "\n",
    "########################################################################\n",
    "#                           END OF YOUR CODE                           #\n",
    "########################################################################\n",
    "\n",
    "i2dl_exercises_path = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "mnist_root = os.path.join(i2dl_exercises_path, \"datasets\", \"mnist\")\n",
    "\n",
    "train_100_dataset = ImageFolderDataset(root=mnist_root,images='train_images.pt',labels='train_labels.pt',force_download=False,verbose=True,transform=transform)\n",
    "val_100_dataset = ImageFolderDataset(root=mnist_root,images='val_images.pt',labels='val_labels.pt',force_download=False,verbose=True,transform=transform)\n",
    "test_100_dataset = ImageFolderDataset(root=mnist_root,images='test_images.pt',labels='test_labels.pt',force_download=False,verbose=True,transform=transform)\n",
    "\n",
    "# We also set up the unlabeled images which we will use later\n",
    "unlabeled_train = ImageFolderDataset(root=mnist_root,images='unlabeled_train_images.pt',force_download=False,verbose=True,transform=transform)\n",
    "unlabeled_val = ImageFolderDataset(root=mnist_root,images='unlabeled_val_images.pt',force_download=False,verbose=True,transform=transform)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zwrT1ckAMNkg"
   },
   "source": [
    "The dataset consists of tuples of 28x28 pixel PIL images and a label that is an integer from 0 to 9. \n",
    "\n",
    "Let's turn a few of the images into numpy arrays, to look at their shape and visualize them and see if the labels we paid for are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "k7ct1J2CMNkh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of our greyscale images:  (28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABjYAAAC2CAYAAAB6QLRGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABEKklEQVR4nO3de5zMdR///9cudll7kNOyWMekllRCiE1tDkk5VlcHlKIrlCtJKpGSSn0TUnSgw+VwUVJK1xWFHHNIhUJnp12n7Dou1vv3x/drf97vz5jZmZ3Zz2Ef99tt/nh+duYz7515+uzMfMz7HaWUUgIAAAAAAAAAAOAC0XYPAAAAAAAAAAAAoKA4sQEAAAAAAAAAAFyDExsAAAAAAAAAAMA1OLEBAAAAAAAAAABcgxMbAAAAAAAAAADANTixAQAAAAAAAAAAXIMTGwAAAAAAAAAAwDU4sQEAAAAAAAAAAFyDExsAAAAAAAAAAMA1OLFRCLVq1ZI+ffrYPQwUM/QOdqF7sAO9g13oHuxA72AXugc70DvYhe7BDvQu/Dix4cOvv/4q/fv3lzp16kjp0qUlMTFRWrVqJa+++qocP37c7uEFlJubK8OGDZOUlBQpU6aMNG/eXL788ku7h4UA3Ny7I0eOyMiRI6VDhw5Svnx5iYqKkunTp9s9LBSQm7u3du1aGThwoKSlpUnZsmUlNTVVbrnlFtm2bZvdQ0MAbu7d5s2bpWfPnlKnTh2Ji4uTihUrSps2beTTTz+1e2goADd3zzRmzBiJioqShg0b2j0UBODm3i1ZskSioqJ8XlavXm338BCAm7t31oYNG+Smm26S8uXLS1xcnDRs2FAmTJhg97Dgh5t716dPn/Me86KiomTXrl12DxF+uLl7IiLbt2+X2267TapXry5xcXHSoEEDGT16tBw7dszuocEPt/du/fr10qFDB0lMTJSEhARp166dbNy40e5hFUhJuwfgNJ999pn07NlTYmNjpVevXtKwYUM5efKkLF++XIYOHSqbN2+WqVOn2j1Mv/r06SNz586VwYMHy4UXXijTp0+XG264Qb7++mu5+uqr7R4efHB77/bv3y+jR4+W1NRUady4sSxZssTuIaGA3N69F154QVasWCE9e/aUSy+9VDIzM2XSpElyxRVXyOrVq/mwz6Hc3rs///xTDh8+LL1795aUlBQ5duyYfPjhh3LTTTfJlClTpF+/fnYPEefh9u6da+fOnfLcc89J2bJl7R4KAvBK7x588EFp2rSptq1evXo2jQYF4YXu/e9//5POnTvL5ZdfLiNGjJD4+Hj59ddfZefOnXYPDefh9t71799fMjIytG1KKbn//vulVq1aUq1aNZtGhkDc3r0dO3ZIs2bNJCkpSQYOHCjly5eXVatWyciRI2X9+vUyf/58u4cIH9zeuw0bNsjVV18tNWrUkJEjR8qZM2dk8uTJkp6eLt9++61cdNFFdg/RP4V8v/32m4qPj1cNGjRQu3fvtvx8+/btavz48fm5Zs2aqnfv3kU4wsDWrFmjRESNGzcuf9vx48dV3bp1VYsWLWwcGc7HC707ceKE2rNnj1JKqbVr1yoRUdOmTbN3UAjIC91bsWKFys3N1bZt27ZNxcbGqjvuuMOmUcEfL/TOl9OnT6vGjRuriy66yO6h4Dy81r1bb71VXXvttSo9PV2lpaXZPRychxd69/XXXysRUXPmzLF7KAiCF7qXnZ2tkpOTVdeuXVVeXp7dw0EBeKF3vnzzzTdKRNSYMWPsHgrOwwvdGzNmjBIRtWnTJm17r169lIiogwcP2jQynI8XenfDDTeoCy64QO3fvz9/2+7du1V8fLzq1q2bjSMrGKaiOseLL74oR44ckbfffluqVq1q+Xm9evXkoYceOu/tDx48KI888og0atRI4uPjJTExUTp27Cjff/+95boTJ06UtLQ0iYuLkwsuuECuvPJKmTFjRv7PDx8+LIMHD5ZatWpJbGysVK5cWa6//nrZsGGD399h7ty5UqJECe1/i5YuXVr69u0rq1atkh07dhTkoUAR8kLvYmNjpUqVKkH81nACL3SvZcuWEhMTo2278MILJS0tTX766adADwFs4IXe+VKiRAmpUaOGHDp0KOjbomh4qXvLli2TuXPnyvjx4wt0fdjHS707u4/Tp08X+Pqwjxe6N2PGDMnKypIxY8ZIdHS0HD16VM6cORPEo4Ci5oXe+TJjxgyJioqS22+/Pejbomh4oXs5OTkiIpKcnKxtr1q1qkRHR1ve98J+XujdN998IxkZGVKhQoX8bVWrVpX09HRZsGCBHDlypCAPhW2Yiuocn376qdSpU0datmwZ0u1/++03+fjjj6Vnz55Su3ZtycrKkilTpkh6erps2bJFUlJSRETkzTfflAcffFB69OghDz30kJw4cUJ++OEHWbNmTf4fyvvvv1/mzp0rAwcOlEsuuUQOHDggy5cvl59++kmuuOKK847hu+++k/r160tiYqK2vVmzZiIisnHjRqlRo0ZIvx8iwwu9gzt5tXtKKcnKypK0tLSQfi9Elpd6d/ToUTl+/LhkZ2fLJ598IgsXLpRbb701pN8LkeeV7uXl5cmgQYPk3nvvlUaNGoX0u6DoeKV3IiJ33323HDlyREqUKCGtW7eWcePGyZVXXhnS74XI80L3Fi1aJImJibJr1y7p0qWLbNu2TcqWLSt33XWXvPLKK1K6dOmQfjdEjhd6Zzp16pT85z//kZYtW0qtWrVC+r0QeV7o3jXXXCMvvPCC9O3bV55++mmpUKGCrFy5Ul5//XV58MEHmX7UgbzQu9zcXClTpoxle1xcnJw8eVI2bdokV111VUi/X5Gw+ysjTpGdna1ERN18880Fvo35FaITJ05YviL7+++/q9jYWDV69Oj8bTfffHPAKQOSkpLUgAEDCjyWs9LS0tS1115r2b5582YlIuqNN94Iep+IHK/07lxMReUOXuzeWe+//74SEfX222+HZX8IH6/1rn///kpElIio6Oho1aNHD74i7lBe6t6kSZNUUlKS2rt3r1JKMRWVg3mldytWrFDdu3dXb7/9tpo/f74aO3asqlChgipdurTasGFD0PtD5Hmle5deeqmKi4tTcXFxatCgQerDDz9UgwYNUiKibrvttqD3h8jySu9Mn376qRIRNXny5ELvC5Hhpe4988wzqkyZMvnvMUREPfHEEyHtC5Hlld41atRI1a9fX50+fTp/W25urkpNTVUioubOnRv0PosSU1H9P2e/8pWQkBDyPmJjYyU6+v8+pHl5eXLgwAGJj4+Xiy66SPvqT7ly5WTnzp2ydu3a8+6rXLlysmbNGtm9e3dQYzh+/LjExsZatp/93yzHjx8Pan+ILK/0Du7j1e79/PPPMmDAAGnRooX07t27UPtC+Hmtd4MHD5Yvv/xS3n33XenYsaPk5eXJyZMnQ9oXIssr3Ttw4IA89dRTMmLECKlUqVJovwiKjFd617JlS5k7d67cc889ctNNN8ljjz0mq1evlqioKBk+fHhovxgiyivdO3LkiBw7dkx69eolEyZMkG7dusmECROkf//+MmvWLNm+fXtovxwiwiu9M82YMUNKlSolt9xyS6H2g8jxUvdq1aolbdq0kalTp8qHH34o99xzjzz33HMyadKk4H8pRJRXevfAAw/Itm3bpG/fvrJlyxbZtGmT9OrVS/bs2SMizv8cmRMb/8/ZqZsOHz4c8j7OnDkjr7zyilx44YUSGxsrFStWlEqVKskPP/wg2dnZ+dcbNmyYxMfHS7NmzeTCCy+UAQMGyIoVK7R9vfjii7Jp0yapUaOGNGvWTEaNGiW//fZbwDGUKVNGcnNzLdtPnDiR/3M4h1d6B/fxYvcyMzOlU6dOkpSUlL/eEJzFa71r0KCBZGRkSK9evfLnH+3cubMopUL+/RAZXunek08+KeXLl5dBgwaF/Hug6Hild77Uq1dPbr75Zvn6668lLy8v5N8PkeGV7p197/qPf/xD23522o1Vq1aF/Psh/LzSu3MdOXJE5s+fL+3bt9fmn4ezeKV7s2bNkn79+slbb70l9913n3Tr1k3efvtt6d27twwbNkwOHDgQ8u+H8PNK7+6//355/PHHZcaMGZKWliaNGjWSX3/9VR599FEREYmPjw/59ysSdn9lxElSUlJU3bp1C3x98ytEzzzzjBIRdc8996iZM2eq//73v+rLL79UaWlpKj09XbvtkSNH1KxZs1SfPn1UcnKyEhH11FNPadfZvXu3eu2119TNN9+s4uLiVOnSpdXnn3/ud0wZGRnq4osvtmxftGiREhH1ySefFPj3Q9HwQu/OxVRU7uGl7h06dEhddtllqnz58mrz5s0F/p1Q9LzUO9OUKVOUiKiff/45pNsjstzevW3btqno6Gg1YcIE9fvvv+dfmjdvrurXr69+//13deDAgQL/figabu+dP0OHDlUiorKzs0O6PSLLC927/vrrff5d/emnn5SIqPHjxxf490PR8ELvznV2ituZM2cW+Dawhxe617p1a9WyZUvL9o8++kiJiPryyy8L/PuhaHihd2cdPHhQffPNN+qHH35QSik1fPhwJSKO/3yFExvn6NevnxIRtXLlygJd3yxk48aNVdu2bS3Xq1atmqWQ58rNzVWdOnVSJUqUUMePH/d5naysLFWtWjXVqlUrv2N65JFHVIkSJSxvMMaMGaNERP31119+b4+i54XenYsTG+7hle4dP35ctW7dWsXFxRX4d4F9vNI7X8aPH69ERK1Zsyak2yOy3N69r7/+Wptv2dfloYceKtDvhqLj9t750717d1W6dGnL3NBwBi9077HHHlMiohYvXqxtX7x4sRIR9e9//9vv7VH0vNC7c3Xo0EHFx8ero0ePFvg2sIcXule/fn3VvHlzy/bZs2crEVELFy70e3sUPS/07nyaNm2qqlev7vjXeUxFdY5HH31UypYtK/fee69kZWVZfv7rr7/Kq6++et7blyhRwjL9xJw5c2TXrl3aNvPrYzExMXLJJZeIUkpOnToleXl52leOREQqV64sKSkpPqeZOlePHj0kLy9Ppk6dmr8tNzdXpk2bJs2bN5caNWr4vT2Knhd6B3fyQvfy8vLk1ltvlVWrVsmcOXOkRYsWfq8P+3mhd3v37rVsO3XqlLz33ntSpkwZueSSS/zeHvZwe/caNmwo8+bNs1zS0tIkNTVV5s2bJ3379j3v7WEPt/dORGTfvn2Wbd9//7188skn0q5du/y5oeEsXuje2TUN3n77bW37W2+9JSVLlpRrrrnG7+1R9LzQu7P27dsnixYtkq5du0pcXFyBbgP7eKF79evXl++++062bdumbZ85c6ZER0fLpZde6vf2KHpe6J0vs2fPlrVr18rgwYMd/zqvpN0DcJK6devKjBkz5NZbb5WLL75YevXqJQ0bNpSTJ0/KypUrZc6cOdKnT5/z3v7GG2+U0aNHy9133y0tW7aUH3/8Uf79739LnTp1tOu1a9dOqlSpIq1atZLk5GT56aefZNKkSdKpUydJSEiQQ4cOSfXq1aVHjx7SuHFjiY+Pl0WLFsnatWvl5Zdf9vs7NG/eXHr27CnDhw+XvXv3Sr169eTdd9+VP/74w/KCEM7ghd6JiEyaNEkOHTqUv1DRp59+Kjt37hQRkUGDBklSUlLoDxIiwgvdGzJkiHzyySfSuXNnOXjwoHzwwQfaz++8886QHx9Ehhd6179/f8nJyZE2bdpItWrVJDMzU/7973/Lzz//LC+//LLz5yEtptzevYoVK0qXLl0s28ePHy8i4vNnsJ/beycicuutt0qZMmWkZcuWUrlyZdmyZYtMnTpV4uLi5Pnnnw/Hw4QI8EL3Lr/8crnnnnvknXfekdOnT0t6erosWbJE5syZI8OHD5eUlJRwPFQIIy/07qzZs2fL6dOn5Y477ijMQ4Ii4oXuDR06VBYuXCitW7eWgQMHSoUKFWTBggWycOFCuffeeznmOZAXerds2TIZPXq0tGvXTipUqCCrV6+WadOmSYcOHeShhx4Kx8MUWUX7BRF32LZtm7rvvvtUrVq1VExMjEpISFCtWrVSEydOVCdOnMi/nvkVohMnTqghQ4aoqlWrqjJlyqhWrVqpVatWqfT0dO0rRFOmTFFt2rRRFSpUULGxsapu3bpq6NCh+dNH5ebmqqFDh6rGjRurhIQEVbZsWdW4cWM1efLkAo3/+PHj6pFHHlFVqlRRsbGxqmnTpuqLL74Iy2ODyHF772rWrHneqTF+//33cDxEiBA3dy89Pd3vtCxwLjf3bubMmSojI0MlJyerkiVLqgsuuEBlZGSo+fPnh+3xQeS4uXu+pKenq7S0tJBui6Lj5t69+uqrqlmzZqp8+fKqZMmSqmrVqurOO+9U27dvD9vjg8hxc/eUUurkyZNq1KhRqmbNmqpUqVKqXr166pVXXgnHQ4MIcnvvlFLqqquuUpUrV1anT58u9OOBouP27q1Zs0Z17NhRValSRZUqVUrVr19fjRkzRp06dSosjw8iw829++WXX1S7du1UxYoVVWxsrGrQoIEaO3asys3NDdvjE0lRShnfeQEAAAAAAAAAAHAoZ0+UBQAAAAAAAAAAcA5ObAAAAAAAAAAAANfgxAYAAAAAAAAAAHANTmwAAAAAAAAAAADX4MQGAAAAAAAAAABwjYid2HjttdekVq1aUrp0aWnevLl8++23kborIB+9g13oHuxA72AXugc70DvYhe7BDvQOdqF7sAO9QyiilFIq3DudPXu29OrVS9544w1p3ry5jB8/XubMmSNbt26VypUr+73tmTNnZPfu3ZKQkCBRUVHhHhqKmFJKDh8+LCkpKRIdHdkvCBWmdyJ0z2vc0j165y1u6Z0I3fMat3SP3nmLW3onQve8xi3do3feU1Td45iHc3HMg1045sEOQfVORUCzZs3UgAED8nNeXp5KSUlRY8eODXjbHTt2KBHh4rHLjh07IlE1TWF6pxTd8+rF6d2jd968OL13StE9r16c3j16582L03unFN3z6sXp3aN33r1Eunsc87jY0TulOOZxsad7HPO4hNq7sJ9uO3nypKxfv14yMjLyt0VHR0tGRoasWrXKcv3c3FzJycnJv6jwf4EEDpCQkBDR/QfbOxG6V1w4rXv0rnhwWu9E6F5x4bTu0bviwWm9E6F7xYXTukfvio9Ido9jHs6HYx7swjEPdihI78J+YmP//v2Sl5cnycnJ2vbk5GTJzMy0XH/s2LGSlJSUf0lNTQ33kOAAkf4qWLC9E6F7xYXTukfvigen9U6E7hUXTusevSsenNY7EbpXXDite/Su+Ihk9zjm4Xw45sEuHPNgh4L0LrKT8xXA8OHDJTs7O/+yY8cOu4eEYoLuwQ70Dnahe7ADvYNd6B7sQO9gF7oHO9A72IXu4ayS4d5hxYoVpUSJEpKVlaVtz8rKkipVqliuHxsbK7GxseEeBoqZYHsnQvcQHhzzYAeOebALxzzYgWMe7MIxD3bgmAe7cMyDHTjmoTDC/o2NmJgYadKkiSxevDh/25kzZ2Tx4sXSokWLcN8dICL0Dvahe7ADvYNd6B7sQO9gF7oHO9A72IXuwQ70DoUS5EL1BTJr1iwVGxurpk+frrZs2aL69eunypUrpzIzMwPeNjs72/ZV17mE/5KdnR2JqoWtd0rRPa9enN49eufNi9N7pxTd8+rF6d2jd968OL13StE9r16c3j16591LpLvHMY+LHb1TimMeF3u6xzGPS6i9i8iJDaWUmjhxokpNTVUxMTGqWbNmavXq1QW6HWX05qUo/gArFXrvlKJ7Xr04vXv0zpsXp/dOKbrn1YvTu0fvvHlxeu+UontevTi9e/TOu5ei6B7HPC529E4pjnlc7OkexzwuofQuSimlxEFycnIkKSnJ7mEgzLKzsyUxMdHuYfhF97zJ6d2jd97k9N6J0D2vcnr36J03Ob13InTPq5zePXrnXXQPdqB3sAvdgx0K0ruwr7EBAAAAAAAAAAAQKZzYAAAAAAAAAAAArsGJDQAAAAAAAAAA4Bol7R4AAMCZSpQooeVevXppecSIEVquWbOm3/0tW7bMsm3hwoVafvXVV7Wcm5sbcJwAAACwV1xcnGVb5cqVtWy+tvzrr7+0fOrUqfAPDAAAeBbf2AAAAAAAAAAAAK7BiQ0AAAAAAAAAAOAanNgAAAAAAAAAAACuwRobHtOkSRPLtjZt2mh51qxZWt6zZ09ExwT79ezZU8tmB0REoqP185zmbebOnRv+gcHRzDU13nzzTb/XV0r5/bl5LBIRad26tZYzMjK0/Nhjj2l5w4YNfu8DAAAA4RcVFaXltLQ0LY8bN85ymw4dOmh5/fr1Wr7lllu0/NtvvxVmiABQZLp27WrZZr53bdq0qd99bNu2Tcvvvvuu5Tpjx44NYXRA8cE3NgAAAAAAAAAAgGtwYgMAAAAAAAAAALgGJzYAAAAAAAAAAIBrsMaGw1133XVafuihh7TcuHFjLSckJFj2kZiYqOVHH31UyxMmTNAyc/h5z+DBg7V85syZgLcJtF4CvC8uLs7vzw8cOKDlQOtfXHTRRZZtqampWr722mu1PH/+fC2PHj1ay4HW/UDxFB8fr2Vf89tu3bpVy7t3747omAAgVOXKldOyuZaBuS5aUlKSZR9HjhzR8meffablt956S8uLFi0KdpjwGHNNDfN959SpU7Xsa61H8z3Hxo0btXzw4MFCjBBOkJycrOWsrCwtx8TEWG4TaN0Bc+2VmTNnannUqFFavv766y37MNePDPT+t0SJEn5/Dtxxxx1afv/99y3XycvL0/K+ffu0bPbswgsv1PKTTz5p2afZ/z/++CPgWIHihG9sAAAAAAAAAAAA1+DEBgAAAAAAAAAAcA1ObAAAAAAAAAAAANdgjQ0bPfbYY5ZtnTt31nJaWpqWS5UqpeVAc9qLWOc7rVSpkpYHDRqk5enTp2t5z549Ae8DztaiRQst+1o/w5xH18wofsy5k5cuXaplc77uQPN9Vq1a1bKtZcuWWp49e7bf2zzzzDNaXrlypWWfmzdv9jsOeI95vOrQoYOWR44cabmNOadtenq6ltesWROm0QFA4dSqVUvLffv29Xv9bdu2WbaZr//NOezNY6Cvv9koXipWrKhl8z2jueaGr/cOmZmZWjbXcjx06FAhRgg7NGjQQMvmej1TpkzRcuvWrS376Nixo9/7yMnJ0fKAAQP8Xt/smYh1TQ1zraL//ve/Wm7YsKGWN23a5Pc+4X19+vTRsrm+lbnepIi1q//5z3+0bK4DuGrVKi2bn/+JiHTq1EnLr732mu8BwzPat2+vZfN4BR3f2AAAAAAAAAAAAK7BiQ0AAAAAAAAAAOAanNgAAAAAAAAAAACuwRobEVS3bl0tP/fcc1ru0aOH5Tbm2gd79+7V8sSJE7VszlPqizkn30svvaRlc57x/v37a3nUqFEB7wPOZvbKnHNURCQ6Wj/P6WsdDhQvp06d0nJh55r1tV7PJ598ouWXX35Zy0OGDNGyOd/ziBEjLPu87bbbQh0iXCIuLk7LtWvX1vKzzz6rZfPvnIj1mGfOWc8aGwDcwlxTo1GjRpbrmMc88zh60UUXhX9gcLWrr75ay23bttWyufbjwYMHLfvo1q2bln/99dcwjQ5FpX79+lr+/PPPtWy+ZzQ/8yiIrVu3annw4MFa7tWrl5YXL16sZXONUF/MPi9ZskTL5rpCZt9FRE6ePBnwfuBeCQkJWja7bB6/Bg4caNnHunXr/N6H+bc3KSkp4Lh8rSEDdzGf55iYGC2b71179+6t5Xfeecfv7UVE3nvvPS1/8803Wvby53t8YwMAAAAAAAAAALgGJzYAAAAAAAAAAIBrcGIDAAAAAAAAAAC4BmtshFGtWrW0vGDBAi37muM7kK5du2o5lDm/P/vsMy0//vjjfq//5JNPapk1NtwvKipKy+Y8y76uc9VVV2n5ww8/DP/AUOyZ63gMGzZMy+3bt9eyOW94enp6ZAYGRylbtqyWb7/9di2b62OEMle8r7lKAbuZf5u7dOliuc64ceO0PHToUC3Pmzcv7ONC0apSpYrfn//5559aNv+2+pKbm6vl1atXBz8weFq5cuW0XLp0ab/XN+cIF6FXXmCuzbh582Ytd+zYUcvm2hXm+p6+rFy5Uss5OTla/vLLLwPuI5Dly5dr2VwLoXnz5lr29RlIoM9R4G7mWrPJyclaHj9+vJYDrafhy8yZM7VcrVo1Lfv6zMVc1wbO1qxZM8s2cx3RQJ8Nmz0w93n06FHLbSZMmKBls5/33nuv3/t0M76xAQAAAAAAAAAAXIMTGwAAAAAAAAAAwDU4sQEAAAAAAAAAAFyDExsAAAAAAAAAAMA1WDw8CE2aNNHywIEDtdyrV6+g9udrAecHHnhAy6EsFh6IuRClmeE9Siktm4vAiVj7OHjwYC2bi5ECRcHsbqAMbypfvryWH3nkES0HWoDNlxMnTmh50aJFwQ8MOIe5wLOv11cHDx7U8smTJ7VcsWJFLbdt21bLr732mmWf5uK85sKucL8ePXr4/XlqaqqWa9asablOnTp1/O7ju+++0/KhQ4cKNjh4Ro0aNbR87bXXajkpKUnLK1as0PLUqVMjMzDY6pdfftFy586dtfzee+9p+eGHH9by/v37IzOwQvr222+1fOWVV2r5rrvustzG7Pgff/wR9nGh6DzzzDNaNheQz8zM1PK7774bcJ+lSpXS8uuvv65l83XdDz/8oOUnnnjCss/jx48HvF/Yx3y9X7p0act1zM/fpk+frmVz4e89e/ZouVKlSlpu3Lix5T6efvppv/dx9dVXa3nDhg1aPnbsmGWfbsE3NgAAAAAAAAAAgGsEfWJj2bJl0rlzZ0lJSZGoqCj5+OOPtZ8rpeSpp56SqlWrSpkyZSQjI0O2b98ervGimKJ3sAvdgx3oHexC92AHege70D3Ygd7BLnQPdqB3iKSgT2wcPXpUGjdu7POr8CIiL774okyYMEHeeOMNWbNmjZQtW1bat29vmfIBCAa9g13oHuxA72AXugc70DvYhe7BDvQOdqF7sAO9QyRFqUJMUB4VFSXz5s2TLl26iMj/PcuWkpIiQ4YMyZ//Ojs7W5KTk2X69Oly2223BdxnTk6OZf7OohAXF6flTp06Wa4zZcoULScmJvrd56pVq7S8c+dOLZtzhItY5/HLy8vzex+hMOdDNecSNJUsWfilWLKzswM+XgUVid6J2Ne9omDO6efrn705N6B5nRIlSoR/YEXA6d3zcu/CwZzzu1GjRlreu3ev5TYpKSkRHVNBOL13Iu7qnnl8+vrrr7Wcnp4e9D7NeUTNOewXLlwY9D6dwOndc1PvTLVq1dKyubbLv/71Ly37Wktt4sSJWjbXwzDnx23Xrp2WN23aZNnnsGHDtLxx40Yt+1pXK9yc3jsRd3Xvsssu0/LatWu1bL4mO336tJZzc3Mt+yxbtqzf+zSPq9ddd12gYTqC07vn5N6Z84APGTJEy+b6erGxsVq+/vrrtbx8+fJCj6ly5cpaNte4FLEe07Zs2aLl7OxsLefk5BR6XL6Eq3sc8+xhHmfXrVsX8DbmOhzm39uiwDEvfMz3mZdeeqmWzW8MmO9DfXn11Ve13L9/fy3/9ttvWs7IyNDyn3/+GfA+7MIxr2AaNGhg2fa///1Py+YaPkuXLg3qPsz1MkREvvrqKy2vX79ey48//riWzdd9TlWQ3oV1jY3ff/9dMjMztX+cSUlJ0rx5c8uH/EC40DvYhe7BDvQOdqF7sAO9g13oHuxA72AXugc70DsUVuH/K/45zn7bIDk5WduenJxs+SbCWbm5udr/KorU/6iAd4XSOxG6h8LjmAc7cMyDXTjmwQ4c82AXjnmwA8c82IVjHuzAMQ+FFdZvbIRi7NixkpSUlH+pUaOG3UNCMUH3YAd6B7vQPdiB3sEudA92oHewC92DHegd7EL3cFZYv7FRpUoVERHJysqSqlWr5m/PysqyzGF41vDhw+Xhhx/Ozzk5OUVSyIYNG2q5bt26Wp45c6blNoHWIDh8+LCWn3rqKS27ZQ4ztwmldyL2dc8OZld9zbdtzgVeFHNyu52bjnlucdVVV2m5Xr16No3EuYrjMc88ht1xxx1aNtc2MNfJ8jXXqTm3uK91r87l1jU3wqm4HfPM48/IkSO13KZNGy2b/9Ps+++/t+yzTp06Wr7iiiu03LlzZy2vWbNGy0888YRlnxs2bLBs85LieMxr2rSplgOtc2b+j0ZzLmcR6/os5nHUXKuoZcuWWl65cqXfMXiR1495Z3+/s8z1LMw5rY8ePaplc674gjDXeunatauWBw4cqGVfj/OpU6e0fODAAS3PmTNHyy+88IKW9+/fX6Cx2qU4HvPgDF4/5pnMdQ7++9//atlcS23y5MlaNj8fFBG5++67tbx7924tm6/7zM8QiyO3H/PM12jvvvtuwNuY3TKn3Dp58qTf25trXomIlCpVSsvmZ97mewwvfT4d1m9s1K5dW6pUqSKLFy/O35aTkyNr1qyRFi1a+LxNbGysJCYmahcgGKH0ToTuofA45sEOHPNgF455sAPHPNiFYx7swDEPduGYBztwzENhBf2NjSNHjsgvv/ySn3///XfZuHGjlC9fXlJTU2Xw4MHy7LPPyoUXXii1a9eWESNGSEpKSv6K90Ao6B3sQvdgB3oHu9A92IHewS50D3agd7AL3YMd6B0iKegTG+vWrZO2bdvm57Nf/endu7dMnz5dHn30UTl69Kj069dPDh06JFdffbV88cUXlikfgGDQO9iF7sEO9A52oXuwA72DXege7EDvYBe6BzvQO0RSlDInrrZZTk6OJCUlhX2/cXFxWl66dKmWL7/88oD7MOfQ27Vrl5bNNTWmT58exAiLzooVK7TcvHlzLZtzwvXt27fQ95mdne34r4ZFqntO0LNnTy3PmjXLcp1Aa8gEmt/ZqZzePS/3LhQfffSRlm+66Sa/19+7d69lW0pKSljHFAqn907EW90z19B45513tGyu3SLie17cc50+fVrL5leh161bF8wQi4zTu+fk3plzzz766KNavvLKK7VsvpYcO3aslkuWtP7/oRtvvFHL//jHP7S8efNmLZ87d7CI73U7nMDpvRNxdvdq1qypZXOuZXMthNWrV2u5Y8eOWs7Ozg54n+d+wCAi2hQQIiL/5//8Hy0HWofILk7vnpN7d9FFF2l5woQJWr7++uu1PG/ePC337t1by0eOHLHchznH9/jx47Vs/m015w0319MQsf59Nj/4Mn9u/h7Lly+37DMUdM9dZs+ereXu3bv7vb75N19EZOPGjeEcUkjoXeQ89NBDWh43bpyWzc9DfL2XMD8j7NChg5bN13luQvcKxnxNJiIybdo0LX/33XdaPnHihJbNdf6mTp2q5dGjRwccR0JCgpbN13nt27cPuA8nKEjvwrrGBgAAAAAAAAAAQCRxYgMAAAAAAAAAALgGJzYAAAAAAAAAAIBrBL14uFtNmTJFywVZU8NkzqVszv3ua15RJ7jsssu0nJqa6vf6P/74YwRHAzsMHjxYy2fOnLFcJzo6OuB1gHAz18Mwj1eB1kE4fvx4uIcEFzDXzTJ7Y87ZHQpzfYT09HQtO3WNDfhWpkwZLd9zzz2W65hraiQnJ2t51KhRWjbXqzp48KCW16xZY7kPc62EAwcOaNmcz5nXZMWDud6d2RNzfTzzPUhB1tQwbd261e/PzfXZnLrGBkJ3ySWXaLlOnTpaNt8LmGu/mHOC33nnnZb7eOKJJ7Rsruth3oe5jtDnn39u2efOnTu1fM0112jZXDvBfM0AAL58/PHHWjbXMYiPjw+4j0Brp8H7Fi5caNlmrs+SkZGhZfN956ZNm7T8/PPPa9l8XyMismPHDi2b72vefPPN84zY/fjGBgAAAAAAAAAAcA1ObAAAAAAAAAAAANfgxAYAAAAAAAAAAHANz66x8a9//UvLt99+u9/rHz58WMs333yz5TrmGhtu0bdvXy2bc9qb85SOHz8+0kNCETPnm1dKWa6za9cuLd9yyy0RHROcpXLlypZtVatW1XLHjh21bM7t+NFHH/m9D3PeZBGRXr16adlcA8js6r59+7TcuXNnv/cJb6pdu7aWhwwZEvH7NOcih7uYa6uZr41ErGtNPf3001p+4403tHzo0CEtm689GzRoYLkPcz22BQsWaPm7777TMutdFQ8rV67UsjkP8pgxY7T8999/F/o+T58+reWjR49quWzZsoW+Dzhbo0aNtGy+FtyzZ4+WZ86cqWWzQ77WYalfv76WzfcbX331lZanT5+uZfPfhohIbm6ulsuVK6dl8328eWwHfDG7yNoI3teyZUstz5gxQ8sJCQl+b+9rLcixY8dquXXr1iGODl7Stm1bLXfp0kXLiYmJWjbf2+7fv1/Lu3fvttxHhQoVtPzhhx8GO0zX4q88AAAAAAAAAABwDU5sAAAAAAAAAAAA1+DEBgAAAAAAAAAAcA1ObAAAAAAAAAAAANfw7OLhl156qZZ9LZZ8riVLlmjZrQuF33fffZZt/fr107L5WLAwpfcV5DkP9G8E3pKSkqLlTz/91HKdyy67TMuBOvLEE0/4/fnixYst24JdkPm9997T8pYtW4K6PbyhYcOGWjYXEzeZizyLiCxatEjLNWvW1HLTpk21HBMTo+X4+HjLPs2FoWEf8/kaNmyYls3nW0Tkrbfe0vL777+vZbNHycnJWjYXAvT1t9ZcHHzWrFla3rdvn+U28L6dO3dquX///hG/z71792rZ7Gawf5/hPgsWLNByt27dtGwe42rUqKHl6tWra9n82ywicvDgQS2/+OKLWjYXN/W1IKpp5MiRWh4wYICWc3JytLxjx46A+4T3VKxYUcu++nkuc1H6U6dOhX1MsJf5Ou2NN97QclJSkpZHjx6t5XXr1ml5xIgRlvto3ry5locOHarll19+Wct8Flc8mJ9Z/PTTT36vv3btWr8/3759u2XbV199peW+fftqefLkyVo+evSo3/twE76xAQAAAAAAAAAAXIMTGwAAAAAAAAAAwDU4sQEAAAAAAAAAAFzDs2ts9OrVS8uB5ob/4IMPIjmciKlVq5aWhw8fbrlOiRIltHz48GEtP/3002EfF5zltttu07I5p7dI4Hlz4W7mmhrz58/XcuPGjSM+hoyMDMu2QMfm3377TcvmHOAonrZu3arlv/76S8vmnKFz5syx7MOcu9T8W2h20/xbWrKkZ19CeYI5N/xVV12l5dOnT1tu88cff2g5MzNTy+a6Hf/85z+1fPXVV2t5//79lvt47bXXtLx69WrLdeAt5no8rMUDp4iKitKy+XeuUqVKWjbnhk9ISNDynj17LPcxfvx4LZvvuf/++2+/YzTXSRCxrgFXvnx5LU+dOlXLP//8s9/7gDf17NnT78/N/n/zzTeRHA6KmK+11D766CMtm6/1H3zwQS2br9lMvo5fy5Yt0/Lzzz+v5XfeeUfLBw4c8Hsf8IZg11KZO3euls2ump/diVi7ZK43ZR7zvIRvbAAAAAAAAAAAANfgxAYAAAAAAAAAAHANTmwAAAAAAAAAAADX8OwE0YcOHdJyUlKSPQMJswoVKmh54cKFWvY1l6A5H9uwYcO0PH369PAMDo41ePBgLfua4y86Wj/PGWjtA7jLpEmTtHz55ZcHvM2xY8e0PHr0aC2/++67Wk5LS9OyuY5H2bJlA96nqWrVqlrOzs4Oeh/wno0bN2q5a9euWq5WrZqWfc2v3aNHDy2bazKY85CuWrVKy+Z6VXAWc52VBQsWaPnOO++03MZcn+2iiy7yex+33HKLls2/o76Y88Wbc8Vv3rxZy6dOnQq4TzhLmTJltPzqq69quW/fvkU5HOC89u7dq+X169druW7dulpu0aKFls33E+brPhGRJUuWaNlcl8O8jwsvvFDLvXv3tuyzVatWWl65cqWWX3rpJS3n5eVZ9gFvefvtty3bfHXnXOnp6Vpevnx5WMeEolW5cmUtL1q0KOBtnn32WS2/+eabQd3nt99+a9k2Y8YMLd9+++1abtq0qZa/+OKLoO4TxUOgz+J27txp2bZixQotm5/7mmuXfvnllyGOznn4xgYAAAAAAAAAAHANTmwAAAAAAAAAAADX4MQGAAAAAAAAAABwDc+usWHOlzdu3DibRlI4Dz30kJYvueQSLZvzkBbE999/X6gxwX3MOXF9zdlnzidvZribub5FQZ7ftm3banndunVavuCCC7RszmVr3qev+ed9rfdyrri4OC2PGjVKy8ePH7fcxpzPGe5jdic2NlbL5nzZu3bt8pvr169vuY9rr71Wy+XKldPywYMHtfyf//zH7xjgLObzN2HCBC1Xr17dcpuMjAwtX3HFFVo2/3aWKlXK7xjM9TREREaOHKllc620Rx55RMv79u3zex9wntatW2vZnPfbKSpVqqTlxo0ba5n1Xbxvx44dWjaPk40aNdJyoPXZrrzySsu2119/Xctmr8z3tua6mKdPn7bsc9OmTVqeOHGilnfv3u13nHA/8z3INddcE/A25nsGX+8h4F7NmzfXcp06dSzX+fDDD7X8/PPPa/nkyZNB3aevv5Njx47VsrnGhrkuIGtsIBS+Ps+bPHmyls33OnfddZeWWWMDAAAAAAAAAADABpzYAAAAAAAAAAAArsGJDQAAAAAAAAAA4BqeXWPDFGg++SlTpmi5Ro0aluu88sorQd3njTfeqOWCrIcxYsQILZvzjAby3XffWbZdd911Ws7Ozg5qn3A/cw4+X+samOsf+Jq3D+5lPp8FeX7NOYofe+wxLQ8YMEDLVatW9Xsfvnr3119/afnvv//WsnncbNKkiZaffvppyz67dOnid5+wl7kuQffu3S3X6dSpk5ZzcnL85v3792u5YcOGWr7qqqss91GlShUtHzhwQMvm6wLzPuEuP/74o5aHDBliuc6wYcO03KNHDy2XLl3a73388MMPWp4zZ47lOr/++quW9+7dq2Wzh3C/Y8eO2T0En8xjcUJCgpbnzp1blMOBA2zZskXL5pqV5hpBl156qZZ9vX825/g2Xxua79H37Nmj5aVLl1r2+dJLL2nZfP/LexjvM/8e16xZM+Bt1q9f7zfD3d555x0t+/r8r2fPnhEfh/m6zhyHuQ4XigfzfWe7du20/N577wW1v1q1alm2mWtKmq/zzOOkmf/888+gxuAkfGMDAAAAAAAAAAC4Bic2AAAAAAAAAACAawR1YmPs2LHStGlTSUhIkMqVK0uXLl1k69at2nVOnDghAwYMkAoVKkh8fLx0795dsrKywjpoFD90D3agd7AL3YMd6B3sQvdgB3oHu9A92IHewS50D5EU1ImNpUuXyoABA2T16tXy5ZdfyqlTp6Rdu3Zy9OjR/Ov861//kk8//VTmzJkjS5culd27d0u3bt3CPnAUL3QPdqB3sAvdgx3oHexC92AHege70D3Ygd7BLnQPkRSlCrG61r59+6Ry5cqydOlSadOmjWRnZ0ulSpVkxowZ+Qsu/vzzz3LxxRfLqlWrfC7eacrJyQl6wWxf4uPjtTx79mwtt2/fPuh9mgvpBnroypcvr+UyZcpo2deCRsE+HRs3bvSbRawLZNqxeHh2drYkJiaGbX9O7p4TmYs2++qZ2UfzOiVKlAj/wIpAOLvn5t598cUXWs7IyAh4G3Nh79TU1EKNYfv27ZZtAwcO1PLixYu1/PHHH2v5xhtv1LKv4+imTZu0fPfdd2t5w4YNAcdaWBzzzs98zu666y7Ldd566y2/tylZsmTYx/Xhhx9qedSoUVo2e+VUHPMKxtdj1LdvXy2PHj1ay3///beWp06dqmVzseWff/65MEN0FY55/z9zQcgnnnhCy23btrXcxnydVhTatGmj5SVLlmj5jTfe0PIDDzwQ6SGFhGNe5JgLj7Zq1UrL3bt317KvHjdu3FjL5mtJc8HfTz/9VMvff/99wQZrA7oXOXXr1tWyuShuuXLltPz+++8H3Ofy5cu1fM0114Q0NrvRO98+++wzLXfo0MFyneeee07Lzz//vJbP/ZA9VNWrV9eyuSCz+dowLS2t0PdZVOhewZQtW9ayrVevXloeNmyYlh977DEtly5dWsv//Oc/tVyvXj3LfZjvZc3PvM3Xox988IFlH05UkN4Vao2Nsx+Qn/0Af/369XLq1CntA7MGDRpIamqqrFq1yuc+cnNzJScnR7sAgdA92IHewS50D3agd7AL3YMd6B3sQvdgB3oHu9A9hFPIJzbOnDkjgwcPllatWknDhg1FRCQzM1NiYmIsZ9CTk5MlMzPT537Gjh0rSUlJ+ZcaNWqEOiQUE3QPdqB3sAvdgx3oHexC92AHege70D3Ygd7BLnQP4RbyiY0BAwbIpk2bZNasWYUawPDhwyU7Ozv/smPHjkLtD95H92AHege70D3Ygd7BLnQPdqB3sAvdgx3oHexC9xBuIU1SPXDgQFmwYIEsW7ZMm0OuSpUqcvLkSTl06JB2pi0rK0uqVKnic1+xsbESGxsbyjD8OnLkiJbNOc26du2qZXMeWV+qVaum5UIsT1Jg5pze5j/Wfv36aXnPnj0RH5Od3NA9JzK76msO3Ojo6IDXKa680LsXXnhBy1deeaWWzf8dISJSs2ZNLQd7zNuyZYuWr7vuOst19u3b53cf5voYXbp00fLDDz9suY05V2mFChX83oeTeaF7JrNHn3zyieU6Tz75pJbvuOMOLZvP8bFjx7Rs9srXWizLli3T8sSJE7VcnNZHMHmxd+baa+brJxGRkSNHavnkyZNanjRpkpZff/11LR8+fLgwQ4R4o3u7du3S8hVXXKFlc15lEZGXX35Zy2b3wsF8nXfrrbdq2Tw2f/XVV2Efg1N5oXeRcOrUKS2baxT8+OOPWj5x4oRlH8ePH9cy7y90dM+3W265RcvPPvuslkP5HObSSy/V8n333aflnTt3Br3PhQsXBn0bJ/Bi78x1ZX2tsWGuMWD2zHwvYK5R+csvv2jZ13vMmTNn+h2nuZ5kcePF7pl8jclc83nz5s1aXrBggZbN9ZnN9SVPnz5tuY97771Xy3v37tVyONaQcaqgvrGhlJKBAwfKvHnz5KuvvpLatWtrP2/SpImUKlVK+8e6detW+euvv6RFixbhGTGKJboHO9A72IXuwQ70Dnahe7ADvYNd6B7sQO9gF7qHSArqGxsDBgyQGTNmyPz58yUhISF/rrOkpCQpU6aMJCUlSd++feXhhx+W8uXLS2JiogwaNEhatGhRoFXsgfOhe7ADvYNd6B7sQO9gF7oHO9A72IXuwQ70Dnahe4ikoE5snP3K/TXXXKNtnzZtmvTp00dERF555RWJjo6W7t27S25urrRv314mT54clsGi+KJ7sAO9g13oHuxA72AXugc70DvYhe7BDvQOdqF7iKQoVRQLRQQhJydHkpKSIn4/5nx4bdu21XLnzp0ttzH/EZYuXdrvPvPy8rS8e/duLQ8dOjTgOL/++mstHzhwIOBtnCg7O1sSExPtHoZfRdU9O/Ts2VPLvhZqMuegNw8NJUqUCP/AioDTu2dX766++motf/7555brlC1bVstmJ/78808tP/PMM1qeO3euls21j8IhISHBss2ck/LQoUNajsTc5San907EXce85ORkLTdu3FjL5teZzb+V27dvt+xz69atWjZ74dZ5wJ3evaLqnTkXrTn3sjnPsoj1OX/33Xe1PG7cOC2HMh+3Vzm9dyL2HfPMNTXGjh1ruY65dsFLL72k5f/9739a9rWWwblKlSpl2fb4449r2VxTxlynz1xb0Kmc3j03/a1FcOhe+AwfPlzLwa6pcfDgQcu2+fPna9lcty8cLrnkEi1v27Yt7Pdhone+mZ9V+Fo/8rHHHtPyXXfdpeVKlSpp2VzDz1wzyNffWvO5WblypZbNzxnN96lORvcixzw+xcTEaNlcU+P+++8PuE9zzZiPPvpIy5H4bCYSCtK7oNbYAAAAAAAAAAAAsBMnNgAAAAAAAAAAgGtwYgMAAAAAAAAAALhGUIuHe4k5/7Y5F7yZfalfv76Wb7jhBi0fPnxYy2+//XYwQwQixtfc8dHR0QGvA+8w5/N28nyZ/pjH2fNtg7tlZWVp2ZxvHjBdf/31WjbX1PA1L/IXX3yhZXPBQtbUQCjM1//Vq1e3XKd///5a/vjjj7WcnZ2t5WXLlvm9z3r16lm2XXzxxVo2/1beeeedfvcJAJEyYcIELe/YsUPL06dP93t7c+54kYLNQX+uKVOmaNnX2ge//fablnm/7Bzm+ra+1qY117gdP368lvv27avlbt26ablRo0Za3rt3r+U+PvjgAy2b61m5aU0NFJ1p06YFdf3169dbtm3evFnLp06dKtSY3IRvbAAAAAAAAAAAANfgxAYAAAAAAAAAAHANTmwAAAAAAAAAAADXKLZrbITDtm3b/GbAKebMmeM3AwDgJXXr1tVyXFyclhcvXmy5zYgRI7TM6zqEw/79+7U8aNAgy3XMObjT09O13KlTJy2XLVtWy2lpaVr+66+/LPdhvvYz57Q/ePCg5TYAUBSOHj2qZV/rBJ3r77//1vKkSZMC3sd9990X/MDgabt27dLy6NGj/WbAKTZu3Gj3EByFb2wAAAAAAAAAAADX4MQGAAAAAAAAAABwDU5sAAAAAAAAAAAA12CNDQAAAHjKzJkztbx8+XItm/Nzi4j8+eefER0TcD7m+hbz5s3zmwHAy0aNGuU3AwBwFt/YAAAAAAAAAAAArsGJDQAAAAAAAAAA4Bqc2AAAAAAAAAAAAK7BiQ0AAAAAAAAAAOAaLB4OAAAATzlw4IDfDAAAAABwN76xAQAAAAAAAAAAXIMTGwAAAAAAAAAAwDU4sQEAAAAAAAAAAFyDExsAAAAAAAAAAMA1OLEBAAAAAAAAAABcgxMbAAAAAAAAAADANRx3YkMpZfcQEAFueF7dMEYEz+nPq9PHh9C44Xl1wxgRPKc/r04fH0LjhufVDWNE8Jz+vDp9fAid059bp48PoXH68+r08SF0Tn9unT4+hKYgz6vjTmwcPnzY7iEgAtzwvLphjAie059Xp48PoXHD8+qGMSJ4Tn9enT4+hMYNz6sbxojgOf15dfr4EDqnP7dOHx9C4/Tn1enjQ+ic/tw6fXwITUGe1yjlsNNaZ86ckd27d4tSSlJTU2XHjh2SmJho97BcLScnR2rUqGHLY6mUksOHD0tKSopERzvuPJqG7oUf3QuM3oUfvSsYuhd+dC8wehd+9K5g6F740b3A6F342dk7EbpXnHHMC4zehR/HvIKhe+HnlmNeySIaU4FFR0dL9erVJScnR0REEhMTKWOY2PVYJiUlFfl9hoLuRQ7dOz96Fzn0zj+6Fzl07/zoXeTQO//oXuTQvfOjd5Fj52NJ94o3jnnnR+8ih2Oef3Qvcpx+zHPu6TYAAAAAAAAAAAADJzYAAAAAAAAAAIBrOPbERmxsrIwcOVJiY2PtHorr8VgGh8crfHgsC47HKnx4LIPD4xU+PJYFx2MVPjyWweHxCh8ey4LjsQofHsvg8HiFD49lwfFYhQ+PZXB4vMLHLY+l4xYPBwAAAAAAAAAAOB/HfmMDAAAAAAAAAADAxIkNAAAAAAAAAADgGpzYAAAAAAAAAAAArsGJDQAAAAAAAAAA4BqOPbHx2muvSa1ataR06dLSvHlz+fbbb+0ekuONHTtWmjZtKgkJCVK5cmXp0qWLbN26VbvOiRMnZMCAAVKhQgWJj4+X7t27S1ZWlk0jdh56Fzx6Fx50L3h0r/DoXfDoXXjQveDRvcKjd8Gjd+FB94JH9wqP3gWP3oUH3Qse3Ss8ehc8T/ROOdCsWbNUTEyMeuedd9TmzZvVfffdp8qVK6eysrLsHpqjtW/fXk2bNk1t2rRJbdy4Ud1www0qNTVVHTlyJP86999/v6pRo4ZavHixWrdunbrqqqtUy5YtbRy1c9C70NC7wqN7oaF7hUPvQkPvCo/uhYbuFQ69Cw29Kzy6Fxq6Vzj0LjT0rvDoXmjoXuHQu9B4oXeOPLHRrFkzNWDAgPycl5enUlJS1NixY20clfvs3btXiYhaunSpUkqpQ4cOqVKlSqk5c+bkX+enn35SIqJWrVpl1zAdg96FB70LHt0LD7oXHHoXHvQueHQvPOhecOhdeNC74NG98KB7waF34UHvgkf3woPuBYfehYcbe+e4qahOnjwp69evl4yMjPxt0dHRkpGRIatWrbJxZO6TnZ0tIiLly5cXEZH169fLqVOntMe2QYMGkpqaWuwfW3oXPvQuOHQvfOhewdG78KF3waF74UP3Co7ehQ+9Cw7dCx+6V3D0LnzoXXDoXvjQvYKjd+Hjxt457sTG/v37JS8vT5KTk7XtycnJkpmZadOo3OfMmTMyePBgadWqlTRs2FBERDIzMyUmJkbKlSunXZfHlt6FC70LHt0LD7oXHHoXHvQueHQvPOhecOhdeNC74NG98KB7waF34UHvgkf3woPuBYfehYdbe1fS7gEgMgYMGCCbNm2S5cuX2z0UFCP0Dnahe7ADvYNd6B7sQO9gF7oHO9A72IXuwQ5u7Z3jvrFRsWJFKVGihGWF9aysLKlSpYpNo3KXgQMHyoIFC+Trr7+W6tWr52+vUqWKnDx5Ug4dOqRdn8eW3oUDvQsN3Ss8uhc8eld49C40dK/w6F7w6F3h0bvQ0L3Co3vBo3eFR+9CQ/cKj+4Fj94Vnpt757gTGzExMdKkSRNZvHhx/rYzZ87I4sWLpUWLFjaOzPmUUjJw4ECZN2+efPXVV1K7dm3t502aNJFSpUppj+3WrVvlr7/+KvaPLb0LHb0rHLoXOroXOnoXOnpXOHQvdHQvdPQudPSucOhe6Ohe6Ohd6Ohd4dC90NG90NG70Hmid3atWu7PrFmzVGxsrJo+fbrasmWL6tevnypXrpzKzMy0e2iO9s9//lMlJSWpJUuWqD179uRfjh07ln+d+++/X6WmpqqvvvpKrVu3TrVo0UK1aNHCxlE7B70LDb0rPLoXGrpXOPQuNPSu8OheaOhe4dC70NC7wqN7oaF7hUPvQkPvCo/uhYbuFQ69C40XeufIExtKKTVx4kSVmpqqYmJiVLNmzdTq1avtHpLjiYjPy7Rp0/Kvc/z4cfXAAw+oCy64QMXFxamuXbuqPXv22Ddoh6F3waN34UH3gkf3Co/eBY/ehQfdCx7dKzx6Fzx6Fx50L3h0r/DoXfDoXXjQveDRvcKjd8HzQu+ilFIqPN/9AAAAAAAAAAAAiCzHrbEBAAAAAAAAAABwPpzYAAAAAAAAAAAArsGJDQAAAAAAAAAA4Bqc2AAAAAAAAAAAAK7BiQ0AAAAAAAAAAOAanNgAAAAAAAAAAACuwYkNAAAAAAAAAADgGpzYAAAAAAAAAAAArsGJDQAAAAAAAAAA4Bqc2AAAAAAAAAAAAK7BiQ0AAAAAAAAAAOAanNgAAAAAAAAAAACu8f8BK2aWp+JqAdIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1600x1600 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = (16,16) # Make the figures a bit bigger\n",
    "\n",
    "indices_arr = [83, 98, 92, 99, 78, 97, 90, 95, 93, 96]\n",
    "for i, index in enumerate(indices_arr):\n",
    "    image = np.array(train_100_dataset[index][0].squeeze()) # get the image of the data sample\n",
    "    label = train_100_dataset[index][1] # get the label of the data sample\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    plt.imshow(image, cmap='gray', interpolation='none')\n",
    "    plt.title(\"Class {}\".format(label))\n",
    "    \n",
    "plt.tight_layout()\n",
    "print('The shape of our greyscale images: ', image.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "V9sz_lHyqJoj"
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Note: Starting Simple</h3>\n",
    "    <p>\n",
    "Regardless of the size of the dataset, the first step is to evaluate the performance of a simple classifier. It is advisable to always start with a straightforward approach when tackling a problem and gradually build upon it to determine which changes yield improvements.</p>\n",
    "</div>\n",
    "\n",
    "# 2. A Simple Classifier\n",
    "\n",
    "In `exercise_code/models.py` we prepared all classes for you which you will finalize throughout the notebook to build an Autoencoder and an image classifier with PyTorch.\n",
    "\n",
    "![network_split](img/network_split.png)\n",
    "\n",
    "## 2.1 The Encoder\n",
    "\n",
    "Unlike to previous models, we are going to split up the model into two parts: the `encoder` and the `classifier`. The `classifier` has a fixed task, generating predictions given a one-dimensional input. On the other hand, the `encoder`'s task is to extract meaningful information from the input, enabling the classifier to make accurate decisions. \n",
    "\n",
    "For now, both networks will be similar in design and consist of linear layers coupled with auxiliary layers. This split-up will be relevant later, e.g., by using convolutional layers which are introduced in the lecture. We are going to set up the `encoder` now. \n",
    "\n",
    "Think about a good network architecture. You have complete freedom in this regard and can devise any network structure that you think might be fitting. (\\*)\n",
    "\n",
    "Have a look at the documentation of `torch.nn` at https://pytorch.org/docs/stable/nn.html to learn how to use this module in order to build your network!\n",
    "\n",
    "Then implement your architecture: initialize it in `__init__()` and assign it to `self.model`. This is particularly easy using `nn.Sequential()` where you only have to pass the list of your layers. \n",
    "\n",
    "To make your model customizable and support parameter search, do not use hardcoded hyperparameters - instead, pass them as a simple dictionary `hparams` (here, `n_hidden` is the number of neurons in the hidden layer) when initializing `models`.\n",
    "\n",
    "Here is an simple example:\n",
    "\n",
    "```python\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, self.hparams[\"n_hidden\"]),\n",
    "            nn.ReLU(),            \n",
    "            nn.Linear(self.hparams[\"n_hidden\"], num_classes)\n",
    "        )\n",
    "```\n",
    "\n",
    "Have a look at the forward path in `forward(self, x)`, which is so easy that you don't need to implement it yourself.\n",
    "\n",
    "As PyTorch automatically computes the gradients, that's all you need to do! No need to manually calculate derivatives for the backward paths anymore! :)\n",
    "\n",
    "\n",
    "____\n",
    "\\* *The size of your final model must be less than 20 MB, which is approximately equivalent to 5 Mio. params. Note that this limit is quite lenient, you will probably need much less parameters!*\n",
    "\n",
    "*In order to keep things simple, you should only use fully connected layers for this task as we need to revert the encoder architecture  later on in the notebook.*\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <h3>Task: Implement</h3>\n",
    "    <p>Implement the <code>Encoder</code> class initialization in <code>exercise_code/models.py</code>.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "jNf7FrvwMNki"
   },
   "source": [
    "## 2.2 The Classifier\n",
    "\n",
    "Now let's implement the classifier. The classifier will utilize the encoder that you have defined in the above cell. By looking at `Classifier.forward`, you can see that we are essentially concatenating the `classifier`and the `encoder` together. Therefore, it is crucial to ensure that the input shape of the classifier matches the output shape of the encoder you implemented above\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <h3>Task: Implement</h3>\n",
    "    <p>1. Implement the <code>Classifier</code> class network initialization in <code>exercise_code/models.py</code>.\n",
    "    </p>\n",
    "    <p>2. Define in the next cell your hyperparameters in a dictionary called 'hparams'.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "AawbvD1rMNkj"
   },
   "outputs": [],
   "source": [
    "hparams = {}\n",
    "########################################################################\n",
    "# TODO: Define your hyper parameters here!                             #\n",
    "########################################################################\n",
    "\n",
    "# This is just used for testing the classifier I think, not used for the submission. So keep it reasonable\n",
    "\n",
    "hparams = {    \n",
    "    \"device\" : device,\n",
    "    \"num_workers\" : 8,\n",
    "    \"epochs\" : 200,\n",
    "    \"batch_size\" : 4096,\n",
    "    \n",
    "    \"num_classes\" : 10, # There are 10 digits\n",
    "    \"input_size\" : 28 * 28, # Number of pixels in images\n",
    "    \n",
    "    \"learning_rate\" : 2e-3, # Optimizer\n",
    "    \"weight_decay\" : 1e-5, # ADAM\n",
    "    \n",
    "    \"dropout_p\" : 0.5, # Dropout probability for the classifier, reduces overfitting\n",
    "    \"latent_dim\" : 20, # Encoder output dim, Decode input dim, classifier input dim. If this it too high, overfitting will occur\n",
    "    # \"decoder_hidden\" : 50, # Decoder Hidden\n",
    "    \"encoder_hidden\" : 512, # Encoder Hidden\n",
    "    \"classifier_hidden\" : 2048 # Classifier Hidden\n",
    "}\n",
    "\n",
    "########################################################################\n",
    "#                           END OF YOUR CODE                           #\n",
    "########################################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "bOYbUg8lAmgU"
   },
   "source": [
    "\n",
    "## 2.3 Optimizer\n",
    "Lastly, implement the function `set_optimizer` to define your optimizer. Here the documentation of `torch.optim` at https://pytorch.org/docs/stable/optim.html might be helpful.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <h3>Task: Implement</h3>\n",
    "    <p>Implement the <code>set_optimizer</code> method of the <code>Classifier</code> in <code>exercise_code/models.py</code>.\n",
    "    </p>\n",
    "</div>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xrUfa-a7MNkk"
   },
   "source": [
    "## 2.4 Training & Validation Step\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <h3>Task: Check Code</h3>\n",
    "    <p> Let's take a closer look at the training pipeline outlined below. It is explicitly written here in its entirety to provide you with a comprehensive understanding of its structure. Additionally, you can refer back to this pipeline whenever you encounter any uncertainties or need guidance.\n",
    " </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NY_lLaNWMNkk"
   },
   "outputs": [],
   "source": [
    " # One of the most crucial things in deep learning is to understand the training pipeline:\n",
    " # 1. Forward()          --> The forward pass of the network, to calculate the currnent loss.\n",
    " # 2. Backward()         --> The backward pass of the network, to calculate the gradients w.r.t the loss, calculated in the previous stage.\n",
    " # 3. Optimizer_step()   --> Update the weights w.r.t thier corresponding gradients and the learnign rate.\n",
    "\n",
    "def create_tqdm_bar(iterable, desc):\n",
    "    return tqdm(enumerate(iterable),total=len(iterable), ncols=150, desc=desc)\n",
    "\n",
    "\n",
    "def train_classifier(classifier, train_loader, val_loader, loss_func, tb_logger, epochs=10, name=\"default\"):\n",
    "    \"\"\"\n",
    "    Train the classifier for a number of epochs.\n",
    "    \"\"\"\n",
    "    optimizer = classifier.optimizer\n",
    "    classifier = classifier.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        training_loss = 0\n",
    "        validation_loss = 0\n",
    "        \n",
    "        # Training stage, where we want to update the parameters.\n",
    "        classifier.train()  # Set the model to training mode\n",
    "        \n",
    "        # Create a progress bar for the training loop.\n",
    "        training_loop = create_tqdm_bar(train_loader, desc=f'Training Epoch [{epoch + 1}/{epochs}]')\n",
    "        for train_iteration, batch in training_loop:\n",
    "            optimizer.zero_grad() # Reset the gradients - VERY important! Otherwise they accumulate.\n",
    "            images, labels = batch # Get the images and labels from the batch, in the fashion we defined in the dataset and dataloader.\n",
    "            images, labels = images.to(device), labels.to(device) # Send the data to the device (GPU or CPU) - it has to be the same device as the model.\n",
    "\n",
    "            # Flatten the images to a vector. This is done because the classifier expects a vector as input.\n",
    "            # Could also be done by reshaping the images in the dataset.\n",
    "            images = images.view(images.shape[0], -1) \n",
    "\n",
    "            pred = classifier(images) # Stage 1: Forward().\n",
    "            loss = loss_func(pred, labels) # Compute the loss over the predictions and the ground truth.\n",
    "            loss.backward()  # Stage 2: Backward().\n",
    "            optimizer.step() # Stage 3: Update the parameters.\n",
    "\n",
    "            training_loss += loss.item()\n",
    "\n",
    "            # Update the progress bar.\n",
    "            training_loop.set_postfix(curr_train_loss = \"{:.8f}\".format(training_loss / (train_iteration + 1)), val_loss = \"{:.8f}\".format(validation_loss))\n",
    "\n",
    "            # Update the tensorboard logger.\n",
    "            tb_logger.add_scalar(f'classifier_{name}/train_loss', loss.item(), epoch * len(train_loader) + train_iteration)\n",
    "            sleep(0.1) # Remove this line if you want to see the progress bar faster.\n",
    "\n",
    "        # Validation stage, where we don't want to update the parameters. Pay attention to the classifier.eval() line\n",
    "        # and \"with torch.no_grad()\" wrapper.\n",
    "        classifier.eval()\n",
    "        val_loop = create_tqdm_bar(val_loader, desc=f'Validation Epoch [{epoch + 1}/{epochs}]')\n",
    "        validation_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for val_iteration, batch in val_loop:\n",
    "                images, labels = batch\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                images = images.view(images.shape[0], -1) \n",
    "                pred = classifier(images)\n",
    "                loss = loss_func(pred, labels)\n",
    "                validation_loss += loss.item()\n",
    "\n",
    "                # Update the progress bar.\n",
    "                val_loop.set_postfix(val_loss = \"{:.8f}\".format(validation_loss / (val_iteration + 1)))\n",
    "\n",
    "                # Update the tensorboard logger.\n",
    "                tb_logger.add_scalar(f'classifier_{name}/val_loss', loss.item(), epoch * len(val_loader) + val_iteration)\n",
    "                sleep(0.1) # Remove this line if you want to see the progress bar faster.\n",
    "        \n",
    "        # This value is used for the progress bar of the training loop.\n",
    "        validation_loss /= len(val_loader)\n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "KVKLlwlyMNkl"
   },
   "source": [
    "## 2.5 Fit Classification Model with Trainer\n",
    "Now it's finally time to train your model.\n",
    "Run the following cell to see the behold the magic of deep learning at play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "uBGavq9cMNkl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [1/200]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  7.07it/s, curr_train_loss=3.15424538, val_loss=0.00000000]\n",
      "Validation Epoch [1/200]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.03it/s, val_loss=2.33030915]\n",
      "Training Epoch [2/200]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  7.67it/s, curr_train_loss=2.90590954, val_loss=0.00000000]\n",
      "Validation Epoch [2/200]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.06it/s, val_loss=2.27598691]\n",
      "Training Epoch [3/200]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  6.51it/s, curr_train_loss=2.45434523, val_loss=0.00000000]\n",
      "Validation Epoch [3/200]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, val_loss=2.23471379]\n",
      "Training Epoch [4/200]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=2.96811676, val_loss=0.00000000]\n",
      "Validation Epoch [4/200]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.93it/s, val_loss=2.17974663]\n",
      "Training Epoch [5/200]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, curr_train_loss=2.74886942, val_loss=0.00000000]\n",
      "Validation Epoch [5/200]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.75it/s, val_loss=2.20998740]\n",
      "Training Epoch [6/200]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  7.63it/s, curr_train_loss=2.61148834, val_loss=0.00000000]\n",
      "Validation Epoch [6/200]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.72it/s, val_loss=2.23471069]\n",
      "Training Epoch [7/200]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=2.45872641, val_loss=0.00000000]\n",
      "Validation Epoch [7/200]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=2.20776701]\n",
      "Training Epoch [8/200]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, curr_train_loss=2.47426820, val_loss=0.00000000]\n",
      "Validation Epoch [8/200]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.74it/s, val_loss=2.19648480]\n",
      "Training Epoch [9/200]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=2.54438615, val_loss=0.00000000]\n",
      "Validation Epoch [9/200]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.09it/s, val_loss=2.14260006]\n",
      "Training Epoch [10/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, curr_train_loss=2.41038752, val_loss=0.00000000]\n",
      "Validation Epoch [10/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.03it/s, val_loss=2.14146686]\n",
      "Training Epoch [11/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, curr_train_loss=2.36316776, val_loss=0.00000000]\n",
      "Validation Epoch [11/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.03it/s, val_loss=2.14949989]\n",
      "Training Epoch [12/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.53it/s, curr_train_loss=2.34737635, val_loss=0.00000000]\n",
      "Validation Epoch [12/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.84it/s, val_loss=2.10022807]\n",
      "Training Epoch [13/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=2.28264332, val_loss=0.00000000]\n",
      "Validation Epoch [13/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.68it/s, val_loss=2.09667492]\n",
      "Training Epoch [14/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.51it/s, curr_train_loss=2.20672417, val_loss=0.00000000]\n",
      "Validation Epoch [14/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=2.07531428]\n",
      "Training Epoch [15/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, curr_train_loss=2.11221576, val_loss=0.00000000]\n",
      "Validation Epoch [15/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s, val_loss=2.09575200]\n",
      "Training Epoch [16/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, curr_train_loss=2.21624947, val_loss=0.00000000]\n",
      "Validation Epoch [16/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=2.04400277]\n",
      "Training Epoch [17/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.49it/s, curr_train_loss=2.25463820, val_loss=0.00000000]\n",
      "Validation Epoch [17/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.68it/s, val_loss=2.07701564]\n",
      "Training Epoch [18/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, curr_train_loss=2.27049780, val_loss=0.00000000]\n",
      "Validation Epoch [18/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, val_loss=2.01991105]\n",
      "Training Epoch [19/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.08it/s, curr_train_loss=2.14558983, val_loss=0.00000000]\n",
      "Validation Epoch [19/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, val_loss=2.01110983]\n",
      "Training Epoch [20/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.44it/s, curr_train_loss=2.11780643, val_loss=0.00000000]\n",
      "Validation Epoch [20/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, val_loss=2.03224206]\n",
      "Training Epoch [21/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=2.13684678, val_loss=0.00000000]\n",
      "Validation Epoch [21/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.35it/s, val_loss=2.00971341]\n",
      "Training Epoch [22/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=2.09755063, val_loss=0.00000000]\n",
      "Validation Epoch [22/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=1.94103825]\n",
      "Training Epoch [23/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.54it/s, curr_train_loss=2.13854027, val_loss=0.00000000]\n",
      "Validation Epoch [23/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.71it/s, val_loss=2.00875330]\n",
      "Training Epoch [24/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.27it/s, curr_train_loss=2.04643202, val_loss=0.00000000]\n",
      "Validation Epoch [24/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, val_loss=1.95516706]\n",
      "Training Epoch [25/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, curr_train_loss=2.08620429, val_loss=0.00000000]\n",
      "Validation Epoch [25/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.87it/s, val_loss=1.91259420]\n",
      "Training Epoch [26/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=2.01747727, val_loss=0.00000000]\n",
      "Validation Epoch [26/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.96391881]\n",
      "Training Epoch [27/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, curr_train_loss=1.89774394, val_loss=0.00000000]\n",
      "Validation Epoch [27/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=1.91876805]\n",
      "Training Epoch [28/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.62it/s, curr_train_loss=2.02102995, val_loss=0.00000000]\n",
      "Validation Epoch [28/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s, val_loss=1.87056065]\n",
      "Training Epoch [29/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=1.93260431, val_loss=0.00000000]\n",
      "Validation Epoch [29/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.76it/s, val_loss=1.93157613]\n",
      "Training Epoch [30/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=1.99875224, val_loss=0.00000000]\n",
      "Validation Epoch [30/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.02it/s, val_loss=1.91800249]\n",
      "Training Epoch [31/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.48it/s, curr_train_loss=1.91882932, val_loss=0.00000000]\n",
      "Validation Epoch [31/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.08it/s, val_loss=1.89270020]\n",
      "Training Epoch [32/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.63it/s, curr_train_loss=1.81655431, val_loss=0.00000000]\n",
      "Validation Epoch [32/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.13it/s, val_loss=1.81305695]\n",
      "Training Epoch [33/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=1.86643064, val_loss=0.00000000]\n",
      "Validation Epoch [33/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.92281520]\n",
      "Training Epoch [34/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, curr_train_loss=1.81187820, val_loss=0.00000000]\n",
      "Validation Epoch [34/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.84944117]\n",
      "Training Epoch [35/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, curr_train_loss=1.87398529, val_loss=0.00000000]\n",
      "Validation Epoch [35/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.95it/s, val_loss=1.89473820]\n",
      "Training Epoch [36/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, curr_train_loss=1.66216207, val_loss=0.00000000]\n",
      "Validation Epoch [36/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.65it/s, val_loss=1.88829541]\n",
      "Training Epoch [37/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.53it/s, curr_train_loss=1.80986369, val_loss=0.00000000]\n",
      "Validation Epoch [37/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.71it/s, val_loss=1.92867601]\n",
      "Training Epoch [38/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, curr_train_loss=1.68200779, val_loss=0.00000000]\n",
      "Validation Epoch [38/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.91it/s, val_loss=1.84880114]\n",
      "Training Epoch [39/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.51it/s, curr_train_loss=1.65831757, val_loss=0.00000000]\n",
      "Validation Epoch [39/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.93it/s, val_loss=1.77514255]\n",
      "Training Epoch [40/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, curr_train_loss=1.94457626, val_loss=0.00000000]\n",
      "Validation Epoch [40/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.79it/s, val_loss=1.80078840]\n",
      "Training Epoch [41/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.60it/s, curr_train_loss=1.79659343, val_loss=0.00000000]\n",
      "Validation Epoch [41/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.76it/s, val_loss=1.75140226]\n",
      "Training Epoch [42/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.53it/s, curr_train_loss=1.61951292, val_loss=0.00000000]\n",
      "Validation Epoch [42/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.75472045]\n",
      "Training Epoch [43/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=1.71438324, val_loss=0.00000000]\n",
      "Validation Epoch [43/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.75it/s, val_loss=1.73132265]\n",
      "Training Epoch [44/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=1.89454448, val_loss=0.00000000]\n",
      "Validation Epoch [44/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=1.75633955]\n",
      "Training Epoch [45/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.51it/s, curr_train_loss=1.55477643, val_loss=0.00000000]\n",
      "Validation Epoch [45/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.07it/s, val_loss=1.66960561]\n",
      "Training Epoch [46/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.40it/s, curr_train_loss=1.68809199, val_loss=0.00000000]\n",
      "Validation Epoch [46/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.48it/s, val_loss=1.70160937]\n",
      "Training Epoch [47/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.47it/s, curr_train_loss=1.66049898, val_loss=0.00000000]\n",
      "Validation Epoch [47/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.88it/s, val_loss=1.70153952]\n",
      "Training Epoch [48/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, curr_train_loss=1.79154325, val_loss=0.00000000]\n",
      "Validation Epoch [48/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.06it/s, val_loss=1.66666043]\n",
      "Training Epoch [49/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=1.93383718, val_loss=0.00000000]\n",
      "Validation Epoch [49/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=1.69213283]\n",
      "Training Epoch [50/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=1.66181636, val_loss=0.00000000]\n",
      "Validation Epoch [50/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.68539536]\n",
      "Training Epoch [51/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.57it/s, curr_train_loss=1.60031521, val_loss=0.00000000]\n",
      "Validation Epoch [51/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.84it/s, val_loss=1.64954913]\n",
      "Training Epoch [52/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.56it/s, curr_train_loss=1.72830951, val_loss=0.00000000]\n",
      "Validation Epoch [52/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=1.62377822]\n",
      "Training Epoch [53/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=1.58574188, val_loss=0.00000000]\n",
      "Validation Epoch [53/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.78it/s, val_loss=1.61149740]\n",
      "Training Epoch [54/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.47it/s, curr_train_loss=1.62667203, val_loss=0.00000000]\n",
      "Validation Epoch [54/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.85it/s, val_loss=1.65266252]\n",
      "Training Epoch [55/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=1.60392559, val_loss=0.00000000]\n",
      "Validation Epoch [55/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.64it/s, val_loss=1.65733492]\n",
      "Training Epoch [56/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.56it/s, curr_train_loss=1.54290271, val_loss=0.00000000]\n",
      "Validation Epoch [56/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.78it/s, val_loss=1.60433352]\n",
      "Training Epoch [57/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.24it/s, curr_train_loss=1.50935197, val_loss=0.00000000]\n",
      "Validation Epoch [57/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.72it/s, val_loss=1.62935758]\n",
      "Training Epoch [58/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.51it/s, curr_train_loss=1.36877966, val_loss=0.00000000]\n",
      "Validation Epoch [58/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.95it/s, val_loss=1.62915194]\n",
      "Training Epoch [59/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.57it/s, curr_train_loss=1.52958798, val_loss=0.00000000]\n",
      "Validation Epoch [59/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, val_loss=1.68470204]\n",
      "Training Epoch [60/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.67it/s, curr_train_loss=1.60962582, val_loss=0.00000000]\n",
      "Validation Epoch [60/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.61297119]\n",
      "Training Epoch [61/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.50it/s, curr_train_loss=1.51482153, val_loss=0.00000000]\n",
      "Validation Epoch [61/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.87it/s, val_loss=1.59725153]\n",
      "Training Epoch [62/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.13it/s, curr_train_loss=1.56732726, val_loss=0.00000000]\n",
      "Validation Epoch [62/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.61878812]\n",
      "Training Epoch [63/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=1.58138931, val_loss=0.00000000]\n",
      "Validation Epoch [63/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.04it/s, val_loss=1.64359486]\n",
      "Training Epoch [64/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.11it/s, curr_train_loss=1.33324993, val_loss=0.00000000]\n",
      "Validation Epoch [64/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.84it/s, val_loss=1.47415686]\n",
      "Training Epoch [65/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.44it/s, curr_train_loss=1.40159380, val_loss=0.00000000]\n",
      "Validation Epoch [65/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s, val_loss=1.61950040]\n",
      "Training Epoch [66/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=1.36970282, val_loss=0.00000000]\n",
      "Validation Epoch [66/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.86it/s, val_loss=1.60575879]\n",
      "Training Epoch [67/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.38it/s, curr_train_loss=1.47621214, val_loss=0.00000000]\n",
      "Validation Epoch [67/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.84it/s, val_loss=1.56382489]\n",
      "Training Epoch [68/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.02it/s, curr_train_loss=1.36275494, val_loss=0.00000000]\n",
      "Validation Epoch [68/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.55it/s, val_loss=1.57406938]\n",
      "Training Epoch [69/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.75it/s, curr_train_loss=1.36373079, val_loss=0.00000000]\n",
      "Validation Epoch [69/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.98it/s, val_loss=1.62863505]\n",
      "Training Epoch [70/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=1.54147899, val_loss=0.00000000]\n",
      "Validation Epoch [70/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.80it/s, val_loss=1.55669892]\n",
      "Training Epoch [71/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=1.43901861, val_loss=0.00000000]\n",
      "Validation Epoch [71/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.58721375]\n",
      "Training Epoch [72/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, curr_train_loss=1.50183141, val_loss=0.00000000]\n",
      "Validation Epoch [72/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=1.48406708]\n",
      "Training Epoch [73/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.15it/s, curr_train_loss=1.26682508, val_loss=0.00000000]\n",
      "Validation Epoch [73/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, val_loss=1.55590785]\n",
      "Training Epoch [74/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.29it/s, curr_train_loss=1.48350382, val_loss=0.00000000]\n",
      "Validation Epoch [74/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.56236589]\n",
      "Training Epoch [75/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, curr_train_loss=1.35909820, val_loss=0.00000000]\n",
      "Validation Epoch [75/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.98it/s, val_loss=1.56371045]\n",
      "Training Epoch [76/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, curr_train_loss=1.42488801, val_loss=0.00000000]\n",
      "Validation Epoch [76/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, val_loss=1.52356541]\n",
      "Training Epoch [77/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.28it/s, curr_train_loss=1.29876924, val_loss=0.00000000]\n",
      "Validation Epoch [77/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.83it/s, val_loss=1.50743687]\n",
      "Training Epoch [78/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, curr_train_loss=1.35439610, val_loss=0.00000000]\n",
      "Validation Epoch [78/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.53294420]\n",
      "Training Epoch [79/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.61it/s, curr_train_loss=1.47198939, val_loss=0.00000000]\n",
      "Validation Epoch [79/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.82it/s, val_loss=1.57722533]\n",
      "Training Epoch [80/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.26it/s, curr_train_loss=1.45091867, val_loss=0.00000000]\n",
      "Validation Epoch [80/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.84it/s, val_loss=1.56677294]\n",
      "Training Epoch [81/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=1.38764095, val_loss=0.00000000]\n",
      "Validation Epoch [81/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.98it/s, val_loss=1.44505048]\n",
      "Training Epoch [82/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.86it/s, curr_train_loss=1.46290791, val_loss=0.00000000]\n",
      "Validation Epoch [82/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.07it/s, val_loss=1.50406122]\n",
      "Training Epoch [83/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=1.34663665, val_loss=0.00000000]\n",
      "Validation Epoch [83/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.78it/s, val_loss=1.51887393]\n",
      "Training Epoch [84/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.66it/s, curr_train_loss=1.24577582, val_loss=0.00000000]\n",
      "Validation Epoch [84/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.57it/s, val_loss=1.49380350]\n",
      "Training Epoch [85/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, curr_train_loss=1.25287664, val_loss=0.00000000]\n",
      "Validation Epoch [85/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.11it/s, val_loss=1.50284970]\n",
      "Training Epoch [86/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.40it/s, curr_train_loss=1.23949659, val_loss=0.00000000]\n",
      "Validation Epoch [86/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.92it/s, val_loss=1.47078145]\n",
      "Training Epoch [87/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.60it/s, curr_train_loss=1.40418625, val_loss=0.00000000]\n",
      "Validation Epoch [87/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.07it/s, val_loss=1.54563963]\n",
      "Training Epoch [88/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.71it/s, curr_train_loss=1.53555334, val_loss=0.00000000]\n",
      "Validation Epoch [88/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.72it/s, val_loss=1.55866587]\n",
      "Training Epoch [89/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, curr_train_loss=1.20089960, val_loss=0.00000000]\n",
      "Validation Epoch [89/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.01it/s, val_loss=1.55545843]\n",
      "Training Epoch [90/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=1.15523708, val_loss=0.00000000]\n",
      "Validation Epoch [90/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=1.39124680]\n",
      "Training Epoch [91/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, curr_train_loss=1.17045033, val_loss=0.00000000]\n",
      "Validation Epoch [91/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.79it/s, val_loss=1.41825628]\n",
      "Training Epoch [92/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.44it/s, curr_train_loss=1.29437423, val_loss=0.00000000]\n",
      "Validation Epoch [92/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.07it/s, val_loss=1.38333273]\n",
      "Training Epoch [93/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=1.23413336, val_loss=0.00000000]\n",
      "Validation Epoch [93/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.84it/s, val_loss=1.56150091]\n",
      "Training Epoch [94/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, curr_train_loss=1.46289682, val_loss=0.00000000]\n",
      "Validation Epoch [94/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.86it/s, val_loss=1.51291418]\n",
      "Training Epoch [95/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.39it/s, curr_train_loss=1.26743925, val_loss=0.00000000]\n",
      "Validation Epoch [95/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.82it/s, val_loss=1.54913342]\n",
      "Training Epoch [96/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.58it/s, curr_train_loss=1.24155807, val_loss=0.00000000]\n",
      "Validation Epoch [96/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.82it/s, val_loss=1.44765866]\n",
      "Training Epoch [97/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.43it/s, curr_train_loss=1.33630419, val_loss=0.00000000]\n",
      "Validation Epoch [97/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.86it/s, val_loss=1.51833332]\n",
      "Training Epoch [98/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.68it/s, curr_train_loss=1.25450420, val_loss=0.00000000]\n",
      "Validation Epoch [98/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.12it/s, val_loss=1.51384890]\n",
      "Training Epoch [99/200]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.60it/s, curr_train_loss=1.27843165, val_loss=0.00000000]\n",
      "Validation Epoch [99/200]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.78it/s, val_loss=1.39531219]\n",
      "Training Epoch [100/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.68it/s, curr_train_loss=1.11042488, val_loss=0.00000000]\n",
      "Validation Epoch [100/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.07it/s, val_loss=1.47328770]\n",
      "Training Epoch [101/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.29it/s, curr_train_loss=1.15682268, val_loss=0.00000000]\n",
      "Validation Epoch [101/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, val_loss=1.52999163]\n",
      "Training Epoch [102/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.33it/s, curr_train_loss=1.21254551, val_loss=0.00000000]\n",
      "Validation Epoch [102/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.03it/s, val_loss=1.41898715]\n",
      "Training Epoch [103/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.32it/s, curr_train_loss=1.15546060, val_loss=0.00000000]\n",
      "Validation Epoch [103/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.98it/s, val_loss=1.43614054]\n",
      "Training Epoch [104/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.28it/s, curr_train_loss=0.97041404, val_loss=0.00000000]\n",
      "Validation Epoch [104/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=1.49418104]\n",
      "Training Epoch [105/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.27it/s, curr_train_loss=1.29646564, val_loss=0.00000000]\n",
      "Validation Epoch [105/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.73it/s, val_loss=1.42481089]\n",
      "Training Epoch [106/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.44it/s, curr_train_loss=1.24250352, val_loss=0.00000000]\n",
      "Validation Epoch [106/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.09it/s, val_loss=1.40853715]\n",
      "Training Epoch [107/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.00it/s, curr_train_loss=1.24312675, val_loss=0.00000000]\n",
      "Validation Epoch [107/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=1.54930353]\n",
      "Training Epoch [108/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.43it/s, curr_train_loss=1.18209124, val_loss=0.00000000]\n",
      "Validation Epoch [108/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.81it/s, val_loss=1.40283692]\n",
      "Training Epoch [109/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.48it/s, curr_train_loss=1.22012150, val_loss=0.00000000]\n",
      "Validation Epoch [109/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.72it/s, val_loss=1.56498945]\n",
      "Training Epoch [110/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=1.38209391, val_loss=0.00000000]\n",
      "Validation Epoch [110/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.14it/s, val_loss=1.46109831]\n",
      "Training Epoch [111/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.34it/s, curr_train_loss=1.14754438, val_loss=0.00000000]\n",
      "Validation Epoch [111/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.09it/s, val_loss=1.39350283]\n",
      "Training Epoch [112/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.46it/s, curr_train_loss=1.22778904, val_loss=0.00000000]\n",
      "Validation Epoch [112/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.06it/s, val_loss=1.47492695]\n",
      "Training Epoch [113/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.54it/s, curr_train_loss=1.21858823, val_loss=0.00000000]\n",
      "Validation Epoch [113/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.72it/s, val_loss=1.46489704]\n",
      "Training Epoch [114/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.56it/s, curr_train_loss=1.21845806, val_loss=0.00000000]\n",
      "Validation Epoch [114/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, val_loss=1.40823603]\n",
      "Training Epoch [115/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.60it/s, curr_train_loss=1.07405591, val_loss=0.00000000]\n",
      "Validation Epoch [115/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.05it/s, val_loss=1.39779985]\n",
      "Training Epoch [116/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=1.02929699, val_loss=0.00000000]\n",
      "Validation Epoch [116/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.59it/s, val_loss=1.42013538]\n",
      "Training Epoch [117/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.65it/s, curr_train_loss=1.36060321, val_loss=0.00000000]\n",
      "Validation Epoch [117/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.07it/s, val_loss=1.38990796]\n",
      "Training Epoch [118/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.28it/s, curr_train_loss=1.12780428, val_loss=0.00000000]\n",
      "Validation Epoch [118/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.97it/s, val_loss=1.24431002]\n",
      "Training Epoch [119/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.08it/s, curr_train_loss=1.33989167, val_loss=0.00000000]\n",
      "Validation Epoch [119/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.49it/s, val_loss=1.47587931]\n",
      "Training Epoch [120/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.55it/s, curr_train_loss=1.16368711, val_loss=0.00000000]\n",
      "Validation Epoch [120/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.91it/s, val_loss=1.43560207]\n",
      "Training Epoch [121/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=1.19721687, val_loss=0.00000000]\n",
      "Validation Epoch [121/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=1.44811630]\n",
      "Training Epoch [122/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.62it/s, curr_train_loss=1.02577317, val_loss=0.00000000]\n",
      "Validation Epoch [122/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.09it/s, val_loss=1.53950047]\n",
      "Training Epoch [123/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.52it/s, curr_train_loss=0.97153521, val_loss=0.00000000]\n",
      "Validation Epoch [123/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.87it/s, val_loss=1.46563864]\n",
      "Training Epoch [124/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=1.22131550, val_loss=0.00000000]\n",
      "Validation Epoch [124/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.93it/s, val_loss=1.38336182]\n",
      "Training Epoch [125/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, curr_train_loss=1.16085744, val_loss=0.00000000]\n",
      "Validation Epoch [125/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.03it/s, val_loss=1.45182979]\n",
      "Training Epoch [126/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.63it/s, curr_train_loss=1.18311167, val_loss=0.00000000]\n",
      "Validation Epoch [126/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.43196321]\n",
      "Training Epoch [127/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.74it/s, curr_train_loss=0.89910316, val_loss=0.00000000]\n",
      "Validation Epoch [127/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.41032970]\n",
      "Training Epoch [128/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.94it/s, curr_train_loss=0.93538404, val_loss=0.00000000]\n",
      "Validation Epoch [128/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.08it/s, val_loss=1.34776199]\n",
      "Training Epoch [129/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=1.24119163, val_loss=0.00000000]\n",
      "Validation Epoch [129/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=1.46456265]\n",
      "Training Epoch [130/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.96it/s, curr_train_loss=0.95531458, val_loss=0.00000000]\n",
      "Validation Epoch [130/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=1.29741812]\n",
      "Training Epoch [131/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.64it/s, curr_train_loss=1.03170121, val_loss=0.00000000]\n",
      "Validation Epoch [131/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.75it/s, val_loss=1.36542356]\n",
      "Training Epoch [132/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.49it/s, curr_train_loss=1.13779926, val_loss=0.00000000]\n",
      "Validation Epoch [132/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.07it/s, val_loss=1.40727413]\n",
      "Training Epoch [133/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.52it/s, curr_train_loss=1.22705281, val_loss=0.00000000]\n",
      "Validation Epoch [133/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=1.39939809]\n",
      "Training Epoch [134/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.70it/s, curr_train_loss=1.18712080, val_loss=0.00000000]\n",
      "Validation Epoch [134/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.81it/s, val_loss=1.41637027]\n",
      "Training Epoch [135/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.60it/s, curr_train_loss=0.98373383, val_loss=0.00000000]\n",
      "Validation Epoch [135/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.66it/s, val_loss=1.29952228]\n",
      "Training Epoch [136/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.19it/s, curr_train_loss=1.12328112, val_loss=0.00000000]\n",
      "Validation Epoch [136/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.04it/s, val_loss=1.31958354]\n",
      "Training Epoch [137/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.46it/s, curr_train_loss=1.22369373, val_loss=0.00000000]\n",
      "Validation Epoch [137/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.86it/s, val_loss=1.29641628]\n",
      "Training Epoch [138/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.21it/s, curr_train_loss=1.08135080, val_loss=0.00000000]\n",
      "Validation Epoch [138/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.91it/s, val_loss=1.32447803]\n",
      "Training Epoch [139/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=1.04644465, val_loss=0.00000000]\n",
      "Validation Epoch [139/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.06it/s, val_loss=1.29124248]\n",
      "Training Epoch [140/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, curr_train_loss=1.01988399, val_loss=0.00000000]\n",
      "Validation Epoch [140/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.03it/s, val_loss=1.40761995]\n",
      "Training Epoch [141/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=1.13129532, val_loss=0.00000000]\n",
      "Validation Epoch [141/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s, val_loss=1.31797802]\n",
      "Training Epoch [142/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.59it/s, curr_train_loss=1.16450977, val_loss=0.00000000]\n",
      "Validation Epoch [142/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.99it/s, val_loss=1.30290544]\n",
      "Training Epoch [143/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, curr_train_loss=1.06467593, val_loss=0.00000000]\n",
      "Validation Epoch [143/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.93it/s, val_loss=1.33756459]\n",
      "Training Epoch [144/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.54it/s, curr_train_loss=1.04330683, val_loss=0.00000000]\n",
      "Validation Epoch [144/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.35415328]\n",
      "Training Epoch [145/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, curr_train_loss=0.83485818, val_loss=0.00000000]\n",
      "Validation Epoch [145/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.85it/s, val_loss=1.14438117]\n",
      "Training Epoch [146/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.59it/s, curr_train_loss=0.91148067, val_loss=0.00000000]\n",
      "Validation Epoch [146/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.86it/s, val_loss=1.51842010]\n",
      "Training Epoch [147/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.41it/s, curr_train_loss=0.97141725, val_loss=0.00000000]\n",
      "Validation Epoch [147/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.67it/s, val_loss=1.43360317]\n",
      "Training Epoch [148/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.67it/s, curr_train_loss=0.88162744, val_loss=0.00000000]\n",
      "Validation Epoch [148/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.23310673]\n",
      "Training Epoch [149/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.79it/s, curr_train_loss=0.83990622, val_loss=0.00000000]\n",
      "Validation Epoch [149/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.71it/s, val_loss=1.34983075]\n",
      "Training Epoch [150/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.51it/s, curr_train_loss=0.92313415, val_loss=0.00000000]\n",
      "Validation Epoch [150/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.28906417]\n",
      "Training Epoch [151/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=0.96149939, val_loss=0.00000000]\n",
      "Validation Epoch [151/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.25814104]\n",
      "Training Epoch [152/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=0.81269145, val_loss=0.00000000]\n",
      "Validation Epoch [152/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.01it/s, val_loss=1.32117617]\n",
      "Training Epoch [153/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, curr_train_loss=1.09506333, val_loss=0.00000000]\n",
      "Validation Epoch [153/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.02it/s, val_loss=1.31887913]\n",
      "Training Epoch [154/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, curr_train_loss=1.27550328, val_loss=0.00000000]\n",
      "Validation Epoch [154/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.81it/s, val_loss=1.45452058]\n",
      "Training Epoch [155/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, curr_train_loss=0.82705325, val_loss=0.00000000]\n",
      "Validation Epoch [155/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.82it/s, val_loss=1.38848042]\n",
      "Training Epoch [156/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.36it/s, curr_train_loss=0.92472577, val_loss=0.00000000]\n",
      "Validation Epoch [156/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.11it/s, val_loss=1.38791668]\n",
      "Training Epoch [157/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.54it/s, curr_train_loss=1.07456863, val_loss=0.00000000]\n",
      "Validation Epoch [157/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.96it/s, val_loss=1.39096510]\n",
      "Training Epoch [158/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, curr_train_loss=0.99079430, val_loss=0.00000000]\n",
      "Validation Epoch [158/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.04it/s, val_loss=1.27896380]\n",
      "Training Epoch [159/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.59it/s, curr_train_loss=0.89740068, val_loss=0.00000000]\n",
      "Validation Epoch [159/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, val_loss=1.33289337]\n",
      "Training Epoch [160/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.37it/s, curr_train_loss=1.10332441, val_loss=0.00000000]\n",
      "Validation Epoch [160/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.86it/s, val_loss=1.33981693]\n",
      "Training Epoch [161/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.32it/s, curr_train_loss=0.95578623, val_loss=0.00000000]\n",
      "Validation Epoch [161/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.98it/s, val_loss=1.37880278]\n",
      "Training Epoch [162/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.07it/s, curr_train_loss=1.14398754, val_loss=0.00000000]\n",
      "Validation Epoch [162/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.01it/s, val_loss=1.32669437]\n",
      "Training Epoch [163/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.13it/s, curr_train_loss=0.92077857, val_loss=0.00000000]\n",
      "Validation Epoch [163/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.14it/s, val_loss=1.43639982]\n",
      "Training Epoch [164/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.30it/s, curr_train_loss=1.04353058, val_loss=0.00000000]\n",
      "Validation Epoch [164/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.82it/s, val_loss=1.34670806]\n",
      "Training Epoch [165/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.44it/s, curr_train_loss=1.08314633, val_loss=0.00000000]\n",
      "Validation Epoch [165/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.70it/s, val_loss=1.33909512]\n",
      "Training Epoch [166/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.05it/s, curr_train_loss=0.81240010, val_loss=0.00000000]\n",
      "Validation Epoch [166/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=1.41841459]\n",
      "Training Epoch [167/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, curr_train_loss=0.88758105, val_loss=0.00000000]\n",
      "Validation Epoch [167/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=1.34922171]\n",
      "Training Epoch [168/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=0.92111266, val_loss=0.00000000]\n",
      "Validation Epoch [168/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.72it/s, val_loss=1.44205189]\n",
      "Training Epoch [169/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=0.79646963, val_loss=0.00000000]\n",
      "Validation Epoch [169/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.70it/s, val_loss=1.24558210]\n",
      "Training Epoch [170/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.52it/s, curr_train_loss=0.79408097, val_loss=0.00000000]\n",
      "Validation Epoch [170/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.60it/s, val_loss=1.27029800]\n",
      "Training Epoch [171/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, curr_train_loss=1.01864541, val_loss=0.00000000]\n",
      "Validation Epoch [171/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.37873578]\n",
      "Training Epoch [172/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, curr_train_loss=0.96862483, val_loss=0.00000000]\n",
      "Validation Epoch [172/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.85it/s, val_loss=1.16507947]\n",
      "Training Epoch [173/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=1.03311312, val_loss=0.00000000]\n",
      "Validation Epoch [173/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.49037230]\n",
      "Training Epoch [174/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, curr_train_loss=0.98646677, val_loss=0.00000000]\n",
      "Validation Epoch [174/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=1.36934006]\n",
      "Training Epoch [175/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, curr_train_loss=0.96903992, val_loss=0.00000000]\n",
      "Validation Epoch [175/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, val_loss=1.47149968]\n",
      "Training Epoch [176/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.11it/s, curr_train_loss=0.93109202, val_loss=0.00000000]\n",
      "Validation Epoch [176/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.96it/s, val_loss=1.38617063]\n",
      "Training Epoch [177/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.38it/s, curr_train_loss=0.91505873, val_loss=0.00000000]\n",
      "Validation Epoch [177/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.02it/s, val_loss=1.29520452]\n",
      "Training Epoch [178/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.22it/s, curr_train_loss=1.00942600, val_loss=0.00000000]\n",
      "Validation Epoch [178/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.84it/s, val_loss=1.47778213]\n",
      "Training Epoch [179/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.33it/s, curr_train_loss=0.92443132, val_loss=0.00000000]\n",
      "Validation Epoch [179/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.77it/s, val_loss=1.46808469]\n",
      "Training Epoch [180/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.21it/s, curr_train_loss=0.95707697, val_loss=0.00000000]\n",
      "Validation Epoch [180/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.55it/s, val_loss=1.48142552]\n",
      "Training Epoch [181/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.37it/s, curr_train_loss=0.84666413, val_loss=0.00000000]\n",
      "Validation Epoch [181/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=1.45828795]\n",
      "Training Epoch [182/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=0.74283254, val_loss=0.00000000]\n",
      "Validation Epoch [182/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.49675059]\n",
      "Training Epoch [183/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.81it/s, curr_train_loss=0.53983313, val_loss=0.00000000]\n",
      "Validation Epoch [183/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s, val_loss=1.45560598]\n",
      "Training Epoch [184/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.71it/s, curr_train_loss=0.90078473, val_loss=0.00000000]\n",
      "Validation Epoch [184/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.00it/s, val_loss=1.45849776]\n",
      "Training Epoch [185/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.16it/s, curr_train_loss=0.75317788, val_loss=0.00000000]\n",
      "Validation Epoch [185/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.45it/s, val_loss=1.46889532]\n",
      "Training Epoch [186/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.24it/s, curr_train_loss=0.89839327, val_loss=0.00000000]\n",
      "Validation Epoch [186/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.83it/s, val_loss=1.39848042]\n",
      "Training Epoch [187/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, curr_train_loss=0.87645704, val_loss=0.00000000]\n",
      "Validation Epoch [187/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s, val_loss=1.27471411]\n",
      "Training Epoch [188/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.03it/s, curr_train_loss=1.04745626, val_loss=0.00000000]\n",
      "Validation Epoch [188/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.68it/s, val_loss=1.25864303]\n",
      "Training Epoch [189/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.46it/s, curr_train_loss=0.95107758, val_loss=0.00000000]\n",
      "Validation Epoch [189/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.60it/s, val_loss=1.46723354]\n",
      "Training Epoch [190/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.30it/s, curr_train_loss=0.92527664, val_loss=0.00000000]\n",
      "Validation Epoch [190/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.64it/s, val_loss=1.30274737]\n",
      "Training Epoch [191/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.23it/s, curr_train_loss=1.09102094, val_loss=0.00000000]\n",
      "Validation Epoch [191/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.53it/s, val_loss=1.53144181]\n",
      "Training Epoch [192/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.27it/s, curr_train_loss=0.93503076, val_loss=0.00000000]\n",
      "Validation Epoch [192/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.84it/s, val_loss=1.18033206]\n",
      "Training Epoch [193/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.18it/s, curr_train_loss=0.68728846, val_loss=0.00000000]\n",
      "Validation Epoch [193/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.40591872]\n",
      "Training Epoch [194/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.68it/s, curr_train_loss=0.83099884, val_loss=0.00000000]\n",
      "Validation Epoch [194/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.23it/s, val_loss=1.23297238]\n",
      "Training Epoch [195/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=0.80296737, val_loss=0.00000000]\n",
      "Validation Epoch [195/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.98it/s, val_loss=1.49226058]\n",
      "Training Epoch [196/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, curr_train_loss=0.92597795, val_loss=0.00000000]\n",
      "Validation Epoch [196/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=1.45703948]\n",
      "Training Epoch [197/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=1.00858128, val_loss=0.00000000]\n",
      "Validation Epoch [197/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.28290927]\n",
      "Training Epoch [198/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.68it/s, curr_train_loss=0.95083255, val_loss=0.00000000]\n",
      "Validation Epoch [198/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.82it/s, val_loss=1.26839769]\n",
      "Training Epoch [199/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.36it/s, curr_train_loss=0.92738116, val_loss=0.00000000]\n",
      "Validation Epoch [199/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.04it/s, val_loss=1.52842319]\n",
      "Training Epoch [200/200]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.42it/s, curr_train_loss=0.88026458, val_loss=0.00000000]\n",
      "Validation Epoch [200/200]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.77it/s, val_loss=1.34518051]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training!\n",
      "How did we do? Let's check the accuracy of the defaut classifier on the training and validation sets:\n",
      "Training Acc: 92.0%\n",
      "Validation Acc: 61.0%\n"
     ]
    }
   ],
   "source": [
    "from exercise_code.models import Classifier\n",
    "from exercise_code.models import Encoder\n",
    "\n",
    "# Create the encoder and the classifier.\n",
    "encoder = Encoder(hparams).to(device)\n",
    "classifier = Classifier(hparams, encoder).to(device)\n",
    "\n",
    "# Create a tensorboard logger.\n",
    "# NOTE: In order to see the logs, run the following command in the terminal: tensorboard --logdir=./\n",
    "# Also, in order to reset the logs, delete the logs folder MANUALLY.\n",
    "\n",
    "path = os.path.join('logs', 'cls_logs')\n",
    "num_of_runs = len(os.listdir(path)) if os.path.exists(path) else 0\n",
    "path = os.path.join(path, f'run_{num_of_runs + 1}')\n",
    "\n",
    "tb_logger = SummaryWriter(path)\n",
    "\n",
    "# Train the classifier.\n",
    "labled_train_loader = torch.utils.data.DataLoader(train_100_dataset, batch_size=hparams['batch_size'], shuffle=True)\n",
    "labled_val_loader = torch.utils.data.DataLoader(val_100_dataset, batch_size=hparams['batch_size'], shuffle=False)\n",
    "\n",
    "epochs = hparams.get('epochs', 10)\n",
    "loss_func = nn.CrossEntropyLoss() # The loss function we use for classification.\n",
    "train_classifier(classifier, labled_train_loader, labled_val_loader, loss_func, tb_logger, epochs=epochs, name=\"Default\")\n",
    "\n",
    "print(\"Finished training!\")\n",
    "print(\"How did we do? Let's check the accuracy of the defaut classifier on the training and validation sets:\")\n",
    "print(f\"Training Acc: {classifier.getAcc(labled_train_loader)[1] * 100}%\")\n",
    "print(f\"Validation Acc: {classifier.getAcc(labled_val_loader)[1] * 100}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "i16vmHZXMNkm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. Autoencoder\n",
    "\n",
    "With only a limited number of labeled images, it's challenging to achieve high performance. We have no money left to pay the student to create more labels, and labeling the data ourselves is out of question. A commonly used approach would be to apply data augmentation to maximize the potential of our limited labeled data, but here we provide another way to solve this problem: **transfer learning**.\n",
    "\n",
    "For each input, the autoencoder tries to reproduce the same image as an output. The difficulty behind this task is that the autoencoder has to go through a low dimensional bottleneck, which is called the **latent space**.\n",
    "In other words, the autoencoder learns to represent all the input information in a low dimensional latent space - it learns to compress the input distribution. To train the autoencoder, we use the mean squared error loss, which calculates the discrepancy between the input pixels and the output pixels. The best part is that this loss function doesn't require any labels!\n",
    "\n",
    "By pretraining the autoencoder in this way on the large amount of unlabeled data, we can capture valuable latent representations of the input images. Then, we transfer the weights of the encoder to our classifier, enabling it to benefit from the knowledge learned during the unsupervised pretraining phase. \n",
    "\n",
    "![autoencoder](img/autoencoder.png)\n",
    "\n",
    "After this, our encoder has learned to extract meaningful information from the inputs. We can then transfer its weights\n",
    "to a classifier architecture and finetune it with our labeled data, i.e., instead of initializing our encoder randomly we are re-using the weights of our trained encoder from our autoencoder network. \n",
    "\n",
    "![autoencoder_pretrained](img/pretrained.png)\n",
    "\n",
    "## 3.1 Decoder\n",
    "\n",
    "Before we can train our autoencoder, you have to initialize the your `decoder` architecture. The simplest way is to mirror your encoder architecture which ensure that the `latent space` output of our `encoder` is correctly transformed to our input shape.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <h3>Task: Implement</h3>\n",
    "    <p>Implement the <code>Decoder</code> and <code>Autoencoder</code> class initialization in <code>exercise_code/models.py</code>.</p>\n",
    "    <p>Implemet <code>training_step</code> and <code>validation_step</code> of the autoencoder, following the pipeline we've shown you in train_classifier().</p>\n",
    "    <p>Note the differences between the classificaiton task, and now the regression task!</p>\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "## 3.2 Autoencoder Training\n",
    "\n",
    "Now, we can train the full autoencoder consisting of both en- and decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xqqdoLDgMNkm"
   },
   "outputs": [],
   "source": [
    "from exercise_code.models import Autoencoder, Encoder, Decoder\n",
    "\n",
    "########################################################################\n",
    "# TODO: Define your hyperparameters here!                              #\n",
    "# Hint: use a large batch_size                                         #\n",
    "########################################################################\n",
    "\n",
    "hparams = {    \n",
    "    \"device\" : device,\n",
    "    \"num_workers\" : 8,\n",
    "    \"epochs\" : 300,\n",
    "    \"batch_size\" : 2048,\n",
    "    \n",
    "    \"num_classes\" : 10, # There are 10 digits\n",
    "    \"input_size\" : 28 * 28, # Number of pixels in images\n",
    "    \n",
    "    \"learning_rate\" : 2e-3, # Optimizer\n",
    "    \"weight_decay\" : 1e-5, # ADAM\n",
    "    \n",
    "    \"dropout_p\" : 0.5, # Dropout probability for the classifier, reduces overfitting\n",
    "    \"latent_dim\" : 20, # Encoder output dim, Decode input dim, classifier input dim. If this it too high, overfitting will occur\n",
    "    \"decoder_hidden\" : 512, # Decoder Hidden\n",
    "    \"encoder_hidden\" : 512, # Encoder Hidden\n",
    "    # \"classifier_hidden\" : 2048 # Classifier Hidden\n",
    "}\n",
    "\n",
    "\n",
    "########################################################################\n",
    "#                           END OF YOUR CODE                           #\n",
    "########################################################################\n",
    "encoder_pretrained = Encoder(hparams).to(device)\n",
    "decoder = Decoder(hparams).to(device)\n",
    "autoencoder = Autoencoder(hparams, encoder_pretrained, decoder).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "uRuIIm8YMNkn"
   },
   "source": [
    "Some tests to check whether we'll accept your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "SoAaC-NqMNkn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Paramters: Your model has \u001b[92m1.078\u001b[0m mio. params.\n",
      "Model accepted!\n"
     ]
    }
   ],
   "source": [
    "from exercise_code.Util import printModelInfo, load_model\n",
    "_ = printModelInfo(autoencoder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "plQwnphtqggl"
   },
   "source": [
    "After implementing the relevant functions - read the following code, and then run it.\n",
    "Keep in mind that an epoch here will take much longer since\n",
    "we are iterating through 5,8600 images instead of just 100.\n",
    "\n",
    "For speed, colab is indeed recommended. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_uuzXMq6zjbb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [0/300]: 100%|█████████████████████████████████████████████| 29/29 [00:15<00:00,  1.87it/s, train_loss=0.44261360, val_loss=0.00000000]\n",
      "Validation Epoch [0/300]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.72it/s, val_loss=0.08841546]\n",
      "Training Epoch [1/300]: 100%|█████████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.08104732, val_loss=0.08841546]\n",
      "Validation Epoch [1/300]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.20it/s, val_loss=0.07712215]\n",
      "Training Epoch [2/300]: 100%|█████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.07175236, val_loss=0.07712215]\n",
      "Validation Epoch [2/300]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.49it/s, val_loss=0.06511107]\n",
      "Training Epoch [3/300]: 100%|█████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.06584603, val_loss=0.06511107]\n",
      "Validation Epoch [3/300]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.61it/s, val_loss=0.06177102]\n",
      "Training Epoch [4/300]: 100%|█████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.06341660, val_loss=0.06177102]\n",
      "Validation Epoch [4/300]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.43it/s, val_loss=0.06101518]\n",
      "Training Epoch [5/300]: 100%|█████████████████████████████████████████████| 29/29 [00:15<00:00,  1.88it/s, train_loss=0.06237045, val_loss=0.06101518]\n",
      "Validation Epoch [5/300]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.50it/s, val_loss=0.05979795]\n",
      "Training Epoch [6/300]: 100%|█████████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.06170241, val_loss=0.05979795]\n",
      "Validation Epoch [6/300]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.18it/s, val_loss=0.05974617]\n",
      "Training Epoch [7/300]: 100%|█████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.06115982, val_loss=0.05974617]\n",
      "Validation Epoch [7/300]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.56it/s, val_loss=0.05935710]\n",
      "Training Epoch [8/300]: 100%|█████████████████████████████████████████████| 29/29 [00:15<00:00,  1.89it/s, train_loss=0.06089488, val_loss=0.05935710]\n",
      "Validation Epoch [8/300]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.40it/s, val_loss=0.05922895]\n",
      "Training Epoch [9/300]: 100%|█████████████████████████████████████████████| 29/29 [00:15<00:00,  1.87it/s, train_loss=0.06044111, val_loss=0.05922895]\n",
      "Validation Epoch [9/300]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.20it/s, val_loss=0.05865547]\n",
      "Training Epoch [10/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.87it/s, train_loss=0.06009395, val_loss=0.05865547]\n",
      "Validation Epoch [10/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.24it/s, val_loss=0.05873756]\n",
      "Training Epoch [11/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.87it/s, train_loss=0.05978791, val_loss=0.05873756]\n",
      "Validation Epoch [11/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.51it/s, val_loss=0.05844190]\n",
      "Training Epoch [12/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.88it/s, train_loss=0.05946406, val_loss=0.05844190]\n",
      "Validation Epoch [12/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.43it/s, val_loss=0.05873068]\n",
      "Training Epoch [13/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.05917735, val_loss=0.05873068]\n",
      "Validation Epoch [13/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.12it/s, val_loss=0.05829345]\n",
      "Training Epoch [14/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.05892363, val_loss=0.05829345]\n",
      "Validation Epoch [14/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.32it/s, val_loss=0.05810227]\n",
      "Training Epoch [15/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.05861268, val_loss=0.05810227]\n",
      "Validation Epoch [15/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.69it/s, val_loss=0.05840192]\n",
      "Training Epoch [16/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.05844648, val_loss=0.05840192]\n",
      "Validation Epoch [16/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.18it/s, val_loss=0.05758840]\n",
      "Training Epoch [17/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.05817917, val_loss=0.05758840]\n",
      "Validation Epoch [17/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.52it/s, val_loss=0.05777849]\n",
      "Training Epoch [18/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.05790427, val_loss=0.05777849]\n",
      "Validation Epoch [18/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.49it/s, val_loss=0.05771145]\n",
      "Training Epoch [19/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.87it/s, train_loss=0.05769691, val_loss=0.05771145]\n",
      "Validation Epoch [19/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.41it/s, val_loss=0.05724261]\n",
      "Training Epoch [20/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.05753274, val_loss=0.05724261]\n",
      "Validation Epoch [20/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.36it/s, val_loss=0.05750586]\n",
      "Training Epoch [21/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.87it/s, train_loss=0.05710549, val_loss=0.05750586]\n",
      "Validation Epoch [21/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.57it/s, val_loss=0.05758360]\n",
      "Training Epoch [22/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.05692889, val_loss=0.05758360]\n",
      "Validation Epoch [22/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.63it/s, val_loss=0.05792621]\n",
      "Training Epoch [23/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.05649632, val_loss=0.05792621]\n",
      "Validation Epoch [23/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.35it/s, val_loss=0.05640869]\n",
      "Training Epoch [24/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.87it/s, train_loss=0.05639754, val_loss=0.05640869]\n",
      "Validation Epoch [24/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.45it/s, val_loss=0.05744211]\n",
      "Training Epoch [25/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.87it/s, train_loss=0.05618315, val_loss=0.05744211]\n",
      "Validation Epoch [25/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.15it/s, val_loss=0.05617367]\n",
      "Training Epoch [26/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.05588851, val_loss=0.05617367]\n",
      "Validation Epoch [26/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.34it/s, val_loss=0.05638206]\n",
      "Training Epoch [27/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.87it/s, train_loss=0.05562996, val_loss=0.05638206]\n",
      "Validation Epoch [27/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.64it/s, val_loss=0.05620361]\n",
      "Training Epoch [28/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.05539644, val_loss=0.05620361]\n",
      "Validation Epoch [28/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.56it/s, val_loss=0.05637943]\n",
      "Training Epoch [29/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.05505592, val_loss=0.05637943]\n",
      "Validation Epoch [29/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.47it/s, val_loss=0.05540707]\n",
      "Training Epoch [30/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.05479488, val_loss=0.05540707]\n",
      "Validation Epoch [30/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.50it/s, val_loss=0.05519652]\n",
      "Training Epoch [31/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.05447478, val_loss=0.05519652]\n",
      "Validation Epoch [31/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.42it/s, val_loss=0.05482036]\n",
      "Training Epoch [32/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.05432447, val_loss=0.05482036]\n",
      "Validation Epoch [32/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.70it/s, val_loss=0.05463561]\n",
      "Training Epoch [33/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.89it/s, train_loss=0.05409545, val_loss=0.05463561]\n",
      "Validation Epoch [33/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.64it/s, val_loss=0.05481268]\n",
      "Training Epoch [34/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.87it/s, train_loss=0.05396335, val_loss=0.05481268]\n",
      "Validation Epoch [34/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.44it/s, val_loss=0.05347556]\n",
      "Training Epoch [35/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.05375137, val_loss=0.05347556]\n",
      "Validation Epoch [35/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.61it/s, val_loss=0.05443304]\n",
      "Training Epoch [36/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.87it/s, train_loss=0.05365958, val_loss=0.05443304]\n",
      "Validation Epoch [36/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.46it/s, val_loss=0.05392044]\n",
      "Training Epoch [37/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.89it/s, train_loss=0.05342979, val_loss=0.05392044]\n",
      "Validation Epoch [37/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.63it/s, val_loss=0.05405670]\n",
      "Training Epoch [38/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.05315006, val_loss=0.05405670]\n",
      "Validation Epoch [38/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.57it/s, val_loss=0.05343368]\n",
      "Training Epoch [39/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.87it/s, train_loss=0.05289388, val_loss=0.05343368]\n",
      "Validation Epoch [39/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.41it/s, val_loss=0.05249699]\n",
      "Training Epoch [40/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.05255837, val_loss=0.05249699]\n",
      "Validation Epoch [40/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.38it/s, val_loss=0.05150852]\n",
      "Training Epoch [41/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.05224399, val_loss=0.05150852]\n",
      "Validation Epoch [41/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.38it/s, val_loss=0.05219589]\n",
      "Training Epoch [42/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.05188841, val_loss=0.05219589]\n",
      "Validation Epoch [42/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.69it/s, val_loss=0.05182633]\n",
      "Training Epoch [43/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.05164657, val_loss=0.05182633]\n",
      "Validation Epoch [43/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.41it/s, val_loss=0.05066456]\n",
      "Training Epoch [44/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.05123228, val_loss=0.05066456]\n",
      "Validation Epoch [44/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.42it/s, val_loss=0.05071186]\n",
      "Training Epoch [45/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.05068978, val_loss=0.05071186]\n",
      "Validation Epoch [45/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.54it/s, val_loss=0.04969577]\n",
      "Training Epoch [46/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.87it/s, train_loss=0.05026575, val_loss=0.04969577]\n",
      "Validation Epoch [46/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.57it/s, val_loss=0.05012659]\n",
      "Training Epoch [47/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.04999444, val_loss=0.05012659]\n",
      "Validation Epoch [47/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.42it/s, val_loss=0.04913933]\n",
      "Training Epoch [48/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.88it/s, train_loss=0.04960844, val_loss=0.04913933]\n",
      "Validation Epoch [48/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.69it/s, val_loss=0.04899812]\n",
      "Training Epoch [49/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.04925336, val_loss=0.04899812]\n",
      "Validation Epoch [49/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.47it/s, val_loss=0.04845016]\n",
      "Training Epoch [50/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.04873912, val_loss=0.04845016]\n",
      "Validation Epoch [50/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.58it/s, val_loss=0.04834346]\n",
      "Training Epoch [51/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.04826486, val_loss=0.04834346]\n",
      "Validation Epoch [51/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.70it/s, val_loss=0.04747079]\n",
      "Training Epoch [52/300]: 100%|████████████████████████████████████████████| 29/29 [00:16<00:00,  1.79it/s, train_loss=0.04776417, val_loss=0.04747079]\n",
      "Validation Epoch [52/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.35it/s, val_loss=0.04591943]\n",
      "Training Epoch [53/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.04720832, val_loss=0.04591943]\n",
      "Validation Epoch [53/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.31it/s, val_loss=0.04555170]\n",
      "Training Epoch [54/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.04701153, val_loss=0.04555170]\n",
      "Validation Epoch [54/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.67it/s, val_loss=0.04538145]\n",
      "Training Epoch [55/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.04656200, val_loss=0.04538145]\n",
      "Validation Epoch [55/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.59it/s, val_loss=0.04436140]\n",
      "Training Epoch [56/300]: 100%|████████████████████████████████████████████| 29/29 [00:16<00:00,  1.76it/s, train_loss=0.04616582, val_loss=0.04436140]\n",
      "Validation Epoch [56/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.39it/s, val_loss=0.04447229]\n",
      "Training Epoch [57/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.04580532, val_loss=0.04447229]\n",
      "Validation Epoch [57/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.36it/s, val_loss=0.04431623]\n",
      "Training Epoch [58/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.87it/s, train_loss=0.04552930, val_loss=0.04431623]\n",
      "Validation Epoch [58/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.94it/s, val_loss=0.04344514]\n",
      "Training Epoch [59/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.88it/s, train_loss=0.04513767, val_loss=0.04344514]\n",
      "Validation Epoch [59/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.46it/s, val_loss=0.04304045]\n",
      "Training Epoch [60/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.04495330, val_loss=0.04304045]\n",
      "Validation Epoch [60/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.38it/s, val_loss=0.04367961]\n",
      "Training Epoch [61/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.04460700, val_loss=0.04367961]\n",
      "Validation Epoch [61/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.45it/s, val_loss=0.04264705]\n",
      "Training Epoch [62/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.87it/s, train_loss=0.04441730, val_loss=0.04264705]\n",
      "Validation Epoch [62/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.43it/s, val_loss=0.04268729]\n",
      "Training Epoch [63/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.04417083, val_loss=0.04268729]\n",
      "Validation Epoch [63/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.12it/s, val_loss=0.04195135]\n",
      "Training Epoch [64/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.04403324, val_loss=0.04195135]\n",
      "Validation Epoch [64/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.32it/s, val_loss=0.04138857]\n",
      "Training Epoch [65/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.04373268, val_loss=0.04138857]\n",
      "Validation Epoch [65/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.60it/s, val_loss=0.04154400]\n",
      "Training Epoch [66/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.04352115, val_loss=0.04154400]\n",
      "Validation Epoch [66/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.42it/s, val_loss=0.04131180]\n",
      "Training Epoch [67/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.04344063, val_loss=0.04131180]\n",
      "Validation Epoch [67/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.07it/s, val_loss=0.04099727]\n",
      "Training Epoch [68/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.04321085, val_loss=0.04099727]\n",
      "Validation Epoch [68/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.49it/s, val_loss=0.04102568]\n",
      "Training Epoch [69/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.04299473, val_loss=0.04102568]\n",
      "Validation Epoch [69/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.51it/s, val_loss=0.04065171]\n",
      "Training Epoch [70/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.04277671, val_loss=0.04065171]\n",
      "Validation Epoch [70/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.33it/s, val_loss=0.04068303]\n",
      "Training Epoch [71/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.04264716, val_loss=0.04068303]\n",
      "Validation Epoch [71/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.54it/s, val_loss=0.03979073]\n",
      "Training Epoch [72/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.87it/s, train_loss=0.04249208, val_loss=0.03979073]\n",
      "Validation Epoch [72/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.47it/s, val_loss=0.03944207]\n",
      "Training Epoch [73/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.04220325, val_loss=0.03944207]\n",
      "Validation Epoch [73/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.44it/s, val_loss=0.03955816]\n",
      "Training Epoch [74/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.04208005, val_loss=0.03955816]\n",
      "Validation Epoch [74/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.35it/s, val_loss=0.03895247]\n",
      "Training Epoch [75/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.04194680, val_loss=0.03895247]\n",
      "Validation Epoch [75/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.34it/s, val_loss=0.03859790]\n",
      "Training Epoch [76/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.87it/s, train_loss=0.04183832, val_loss=0.03859790]\n",
      "Validation Epoch [76/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.42it/s, val_loss=0.03892546]\n",
      "Training Epoch [77/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.87it/s, train_loss=0.04164055, val_loss=0.03892546]\n",
      "Validation Epoch [77/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.41it/s, val_loss=0.03823125]\n",
      "Training Epoch [78/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.04135434, val_loss=0.03823125]\n",
      "Validation Epoch [78/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.66it/s, val_loss=0.03856723]\n",
      "Training Epoch [79/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.04133693, val_loss=0.03856723]\n",
      "Validation Epoch [79/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.47it/s, val_loss=0.03783006]\n",
      "Training Epoch [80/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.04115851, val_loss=0.03783006]\n",
      "Validation Epoch [80/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.59it/s, val_loss=0.03798572]\n",
      "Training Epoch [81/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.04097476, val_loss=0.03798572]\n",
      "Validation Epoch [81/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.47it/s, val_loss=0.03785145]\n",
      "Training Epoch [82/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.04076796, val_loss=0.03785145]\n",
      "Validation Epoch [82/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.09it/s, val_loss=0.03749638]\n",
      "Training Epoch [83/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.04062127, val_loss=0.03749638]\n",
      "Validation Epoch [83/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.38it/s, val_loss=0.03731951]\n",
      "Training Epoch [84/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.04048174, val_loss=0.03731951]\n",
      "Validation Epoch [84/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.40it/s, val_loss=0.03701418]\n",
      "Training Epoch [85/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.04026110, val_loss=0.03701418]\n",
      "Validation Epoch [85/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.66it/s, val_loss=0.03668696]\n",
      "Training Epoch [86/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.04010646, val_loss=0.03668696]\n",
      "Validation Epoch [86/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.53it/s, val_loss=0.03714304]\n",
      "Training Epoch [87/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.03989750, val_loss=0.03714304]\n",
      "Validation Epoch [87/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.29it/s, val_loss=0.03615649]\n",
      "Training Epoch [88/300]: 100%|████████████████████████████████████████████| 29/29 [00:16<00:00,  1.77it/s, train_loss=0.03979164, val_loss=0.03615649]\n",
      "Validation Epoch [88/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.29it/s, val_loss=0.03645384]\n",
      "Training Epoch [89/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.03960959, val_loss=0.03645384]\n",
      "Validation Epoch [89/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.23it/s, val_loss=0.03572170]\n",
      "Training Epoch [90/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.03951158, val_loss=0.03572170]\n",
      "Validation Epoch [90/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.31it/s, val_loss=0.03543073]\n",
      "Training Epoch [91/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03933517, val_loss=0.03543073]\n",
      "Validation Epoch [91/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.36it/s, val_loss=0.03606898]\n",
      "Training Epoch [92/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.03912693, val_loss=0.03606898]\n",
      "Validation Epoch [92/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.54it/s, val_loss=0.03569612]\n",
      "Training Epoch [93/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.03899397, val_loss=0.03569612]\n",
      "Validation Epoch [93/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.30it/s, val_loss=0.03510622]\n",
      "Training Epoch [94/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.03881316, val_loss=0.03510622]\n",
      "Validation Epoch [94/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.79it/s, val_loss=0.03506867]\n",
      "Training Epoch [95/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.87it/s, train_loss=0.03880008, val_loss=0.03506867]\n",
      "Validation Epoch [95/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.94it/s, val_loss=0.03423912]\n",
      "Training Epoch [96/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.03857744, val_loss=0.03423912]\n",
      "Validation Epoch [96/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.45it/s, val_loss=0.03464545]\n",
      "Training Epoch [97/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.03847534, val_loss=0.03464545]\n",
      "Validation Epoch [97/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.48it/s, val_loss=0.03479120]\n",
      "Training Epoch [98/300]: 100%|████████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.03835661, val_loss=0.03479120]\n",
      "Validation Epoch [98/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.54it/s, val_loss=0.03464574]\n",
      "Training Epoch [99/300]: 100%|████████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.03828849, val_loss=0.03464574]\n",
      "Validation Epoch [99/300]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.22it/s, val_loss=0.03410803]\n",
      "Training Epoch [100/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.03813459, val_loss=0.03410803]\n",
      "Validation Epoch [100/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.63it/s, val_loss=0.03387184]\n",
      "Training Epoch [101/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.79it/s, train_loss=0.03798426, val_loss=0.03387184]\n",
      "Validation Epoch [101/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.66it/s, val_loss=0.03410818]\n",
      "Training Epoch [102/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.79it/s, train_loss=0.03785790, val_loss=0.03410818]\n",
      "Validation Epoch [102/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.35it/s, val_loss=0.03417541]\n",
      "Training Epoch [103/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.74it/s, train_loss=0.03787838, val_loss=0.03417541]\n",
      "Validation Epoch [103/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.53it/s, val_loss=0.03371309]\n",
      "Training Epoch [104/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.75it/s, train_loss=0.03773934, val_loss=0.03371309]\n",
      "Validation Epoch [104/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.98it/s, val_loss=0.03310088]\n",
      "Training Epoch [105/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.76it/s, train_loss=0.03759338, val_loss=0.03310088]\n",
      "Validation Epoch [105/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.37it/s, val_loss=0.03318772]\n",
      "Training Epoch [106/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.76it/s, train_loss=0.03747965, val_loss=0.03318772]\n",
      "Validation Epoch [106/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.19it/s, val_loss=0.03336701]\n",
      "Training Epoch [107/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03739472, val_loss=0.03336701]\n",
      "Validation Epoch [107/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.10it/s, val_loss=0.03295922]\n",
      "Training Epoch [108/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.03726256, val_loss=0.03295922]\n",
      "Validation Epoch [108/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.32it/s, val_loss=0.03267860]\n",
      "Training Epoch [109/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.03709616, val_loss=0.03267860]\n",
      "Validation Epoch [109/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.27it/s, val_loss=0.03292481]\n",
      "Training Epoch [110/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03707269, val_loss=0.03292481]\n",
      "Validation Epoch [110/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.19it/s, val_loss=0.03278372]\n",
      "Training Epoch [111/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.79it/s, train_loss=0.03694491, val_loss=0.03278372]\n",
      "Validation Epoch [111/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.36it/s, val_loss=0.03276245]\n",
      "Training Epoch [112/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.79it/s, train_loss=0.03685956, val_loss=0.03276245]\n",
      "Validation Epoch [112/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.20it/s, val_loss=0.03263974]\n",
      "Training Epoch [113/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.03678724, val_loss=0.03263974]\n",
      "Validation Epoch [113/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.91it/s, val_loss=0.03205529]\n",
      "Training Epoch [114/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.79it/s, train_loss=0.03661888, val_loss=0.03205529]\n",
      "Validation Epoch [114/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.33it/s, val_loss=0.03169313]\n",
      "Training Epoch [115/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.77it/s, train_loss=0.03660892, val_loss=0.03169313]\n",
      "Validation Epoch [115/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.70it/s, val_loss=0.03224559]\n",
      "Training Epoch [116/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.81it/s, train_loss=0.03651058, val_loss=0.03224559]\n",
      "Validation Epoch [116/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.30it/s, val_loss=0.03185398]\n",
      "Training Epoch [117/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.76it/s, train_loss=0.03633867, val_loss=0.03185398]\n",
      "Validation Epoch [117/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.12it/s, val_loss=0.03187988]\n",
      "Training Epoch [118/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.03629836, val_loss=0.03187988]\n",
      "Validation Epoch [118/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.62it/s, val_loss=0.03201408]\n",
      "Training Epoch [119/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.03630455, val_loss=0.03201408]\n",
      "Validation Epoch [119/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.88it/s, val_loss=0.03197635]\n",
      "Training Epoch [120/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.03609877, val_loss=0.03197635]\n",
      "Validation Epoch [120/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.60it/s, val_loss=0.03160550]\n",
      "Training Epoch [121/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.03605170, val_loss=0.03160550]\n",
      "Validation Epoch [121/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.33it/s, val_loss=0.03119087]\n",
      "Training Epoch [122/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.03593040, val_loss=0.03119087]\n",
      "Validation Epoch [122/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.04it/s, val_loss=0.03110256]\n",
      "Training Epoch [123/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.76it/s, train_loss=0.03583132, val_loss=0.03110256]\n",
      "Validation Epoch [123/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.43it/s, val_loss=0.03133648]\n",
      "Training Epoch [124/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.03581101, val_loss=0.03133648]\n",
      "Validation Epoch [124/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.52it/s, val_loss=0.03175958]\n",
      "Training Epoch [125/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.03577313, val_loss=0.03175958]\n",
      "Validation Epoch [125/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.75it/s, val_loss=0.03093206]\n",
      "Training Epoch [126/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.79it/s, train_loss=0.03568295, val_loss=0.03093206]\n",
      "Validation Epoch [126/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.96it/s, val_loss=0.03065270]\n",
      "Training Epoch [127/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.03563529, val_loss=0.03065270]\n",
      "Validation Epoch [127/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.33it/s, val_loss=0.03101380]\n",
      "Training Epoch [128/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.79it/s, train_loss=0.03554400, val_loss=0.03101380]\n",
      "Validation Epoch [128/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.03it/s, val_loss=0.03099199]\n",
      "Training Epoch [129/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.03545925, val_loss=0.03099199]\n",
      "Validation Epoch [129/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.28it/s, val_loss=0.03075254]\n",
      "Training Epoch [130/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.03540756, val_loss=0.03075254]\n",
      "Validation Epoch [130/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.41it/s, val_loss=0.03110772]\n",
      "Training Epoch [131/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.03534619, val_loss=0.03110772]\n",
      "Validation Epoch [131/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.18it/s, val_loss=0.03060443]\n",
      "Training Epoch [132/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.03533803, val_loss=0.03060443]\n",
      "Validation Epoch [132/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.36it/s, val_loss=0.03054897]\n",
      "Training Epoch [133/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03524667, val_loss=0.03054897]\n",
      "Validation Epoch [133/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.39it/s, val_loss=0.03059009]\n",
      "Training Epoch [134/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.03511835, val_loss=0.03059009]\n",
      "Validation Epoch [134/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.06it/s, val_loss=0.02979471]\n",
      "Training Epoch [135/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03510721, val_loss=0.02979471]\n",
      "Validation Epoch [135/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.38it/s, val_loss=0.03054102]\n",
      "Training Epoch [136/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03500144, val_loss=0.03054102]\n",
      "Validation Epoch [136/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.14it/s, val_loss=0.03044067]\n",
      "Training Epoch [137/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.03498266, val_loss=0.03044067]\n",
      "Validation Epoch [137/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.72it/s, val_loss=0.02949310]\n",
      "Training Epoch [138/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03489142, val_loss=0.02949310]\n",
      "Validation Epoch [138/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.08it/s, val_loss=0.02996293]\n",
      "Training Epoch [139/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.81it/s, train_loss=0.03481532, val_loss=0.02996293]\n",
      "Validation Epoch [139/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.28it/s, val_loss=0.02996741]\n",
      "Training Epoch [140/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.03482090, val_loss=0.02996741]\n",
      "Validation Epoch [140/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.14it/s, val_loss=0.03039128]\n",
      "Training Epoch [141/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03465205, val_loss=0.03039128]\n",
      "Validation Epoch [141/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.28it/s, val_loss=0.03007605]\n",
      "Training Epoch [142/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.77it/s, train_loss=0.03467077, val_loss=0.03007605]\n",
      "Validation Epoch [142/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.35it/s, val_loss=0.03004776]\n",
      "Training Epoch [143/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.03451339, val_loss=0.03004776]\n",
      "Validation Epoch [143/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.14it/s, val_loss=0.02990810]\n",
      "Training Epoch [144/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.03453406, val_loss=0.02990810]\n",
      "Validation Epoch [144/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.06it/s, val_loss=0.02977802]\n",
      "Training Epoch [145/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.03453123, val_loss=0.02977802]\n",
      "Validation Epoch [145/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.27it/s, val_loss=0.02943174]\n",
      "Training Epoch [146/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03441550, val_loss=0.02943174]\n",
      "Validation Epoch [146/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.37it/s, val_loss=0.02928048]\n",
      "Training Epoch [147/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.03430119, val_loss=0.02928048]\n",
      "Validation Epoch [147/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.39it/s, val_loss=0.02942573]\n",
      "Training Epoch [148/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.77it/s, train_loss=0.03430205, val_loss=0.02942573]\n",
      "Validation Epoch [148/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.18it/s, val_loss=0.02908359]\n",
      "Training Epoch [149/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.03414267, val_loss=0.02908359]\n",
      "Validation Epoch [149/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.09it/s, val_loss=0.02966077]\n",
      "Training Epoch [150/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.03424658, val_loss=0.02966077]\n",
      "Validation Epoch [150/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.47it/s, val_loss=0.02978639]\n",
      "Training Epoch [151/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.03412194, val_loss=0.02978639]\n",
      "Validation Epoch [151/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.40it/s, val_loss=0.02922892]\n",
      "Training Epoch [152/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.03404934, val_loss=0.02922892]\n",
      "Validation Epoch [152/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.30it/s, val_loss=0.02939683]\n",
      "Training Epoch [153/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.79it/s, train_loss=0.03399586, val_loss=0.02939683]\n",
      "Validation Epoch [153/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.20it/s, val_loss=0.02874164]\n",
      "Training Epoch [154/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.03397043, val_loss=0.02874164]\n",
      "Validation Epoch [154/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.27it/s, val_loss=0.02896967]\n",
      "Training Epoch [155/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.03389510, val_loss=0.02896967]\n",
      "Validation Epoch [155/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.37it/s, val_loss=0.02911560]\n",
      "Training Epoch [156/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.03377831, val_loss=0.02911560]\n",
      "Validation Epoch [156/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.27it/s, val_loss=0.02881730]\n",
      "Training Epoch [157/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.03376633, val_loss=0.02881730]\n",
      "Validation Epoch [157/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.21it/s, val_loss=0.02921049]\n",
      "Training Epoch [158/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.03369335, val_loss=0.02921049]\n",
      "Validation Epoch [158/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.49it/s, val_loss=0.02937154]\n",
      "Training Epoch [159/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03371072, val_loss=0.02937154]\n",
      "Validation Epoch [159/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.37it/s, val_loss=0.02860824]\n",
      "Training Epoch [160/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03363654, val_loss=0.02860824]\n",
      "Validation Epoch [160/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.33it/s, val_loss=0.02876519]\n",
      "Training Epoch [161/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.03356150, val_loss=0.02876519]\n",
      "Validation Epoch [161/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.40it/s, val_loss=0.02900865]\n",
      "Training Epoch [162/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.03353060, val_loss=0.02900865]\n",
      "Validation Epoch [162/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.88it/s, val_loss=0.02855456]\n",
      "Training Epoch [163/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.03341188, val_loss=0.02855456]\n",
      "Validation Epoch [163/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.09it/s, val_loss=0.02842402]\n",
      "Training Epoch [164/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03350369, val_loss=0.02842402]\n",
      "Validation Epoch [164/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.91it/s, val_loss=0.02898681]\n",
      "Training Epoch [165/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.03332759, val_loss=0.02898681]\n",
      "Validation Epoch [165/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.15it/s, val_loss=0.02819097]\n",
      "Training Epoch [166/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03336595, val_loss=0.02819097]\n",
      "Validation Epoch [166/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.14it/s, val_loss=0.02870655]\n",
      "Training Epoch [167/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.79it/s, train_loss=0.03326123, val_loss=0.02870655]\n",
      "Validation Epoch [167/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.38it/s, val_loss=0.02850414]\n",
      "Training Epoch [168/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03321817, val_loss=0.02850414]\n",
      "Validation Epoch [168/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.26it/s, val_loss=0.02828181]\n",
      "Training Epoch [169/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03321388, val_loss=0.02828181]\n",
      "Validation Epoch [169/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.32it/s, val_loss=0.02823711]\n",
      "Training Epoch [170/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.78it/s, train_loss=0.03312829, val_loss=0.02823711]\n",
      "Validation Epoch [170/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.67it/s, val_loss=0.02874513]\n",
      "Training Epoch [171/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.03310790, val_loss=0.02874513]\n",
      "Validation Epoch [171/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.32it/s, val_loss=0.02851831]\n",
      "Training Epoch [172/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.03296005, val_loss=0.02851831]\n",
      "Validation Epoch [172/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.30it/s, val_loss=0.02783976]\n",
      "Training Epoch [173/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.03289503, val_loss=0.02783976]\n",
      "Validation Epoch [173/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.58it/s, val_loss=0.02802897]\n",
      "Training Epoch [174/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.03292539, val_loss=0.02802897]\n",
      "Validation Epoch [174/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.51it/s, val_loss=0.02800709]\n",
      "Training Epoch [175/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.87it/s, train_loss=0.03289165, val_loss=0.02800709]\n",
      "Validation Epoch [175/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.22it/s, val_loss=0.02780435]\n",
      "Training Epoch [176/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.03287801, val_loss=0.02780435]\n",
      "Validation Epoch [176/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.34it/s, val_loss=0.02781503]\n",
      "Training Epoch [177/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.87it/s, train_loss=0.03278275, val_loss=0.02781503]\n",
      "Validation Epoch [177/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.51it/s, val_loss=0.02838140]\n",
      "Training Epoch [178/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.03278415, val_loss=0.02838140]\n",
      "Validation Epoch [178/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.52it/s, val_loss=0.02830131]\n",
      "Training Epoch [179/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.03267427, val_loss=0.02830131]\n",
      "Validation Epoch [179/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.39it/s, val_loss=0.02783137]\n",
      "Training Epoch [180/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.03262533, val_loss=0.02783137]\n",
      "Validation Epoch [180/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.34it/s, val_loss=0.02796340]\n",
      "Training Epoch [181/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.03250839, val_loss=0.02796340]\n",
      "Validation Epoch [181/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.57it/s, val_loss=0.02759112]\n",
      "Training Epoch [182/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.03248419, val_loss=0.02759112]\n",
      "Validation Epoch [182/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.61it/s, val_loss=0.02799538]\n",
      "Training Epoch [183/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.03245729, val_loss=0.02799538]\n",
      "Validation Epoch [183/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.43it/s, val_loss=0.02781019]\n",
      "Training Epoch [184/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.87it/s, train_loss=0.03237422, val_loss=0.02781019]\n",
      "Validation Epoch [184/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.51it/s, val_loss=0.02753538]\n",
      "Training Epoch [185/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.85it/s, train_loss=0.03239745, val_loss=0.02753538]\n",
      "Validation Epoch [185/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.15it/s, val_loss=0.02782799]\n",
      "Training Epoch [186/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.03233262, val_loss=0.02782799]\n",
      "Validation Epoch [186/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.39it/s, val_loss=0.02772042]\n",
      "Training Epoch [187/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.03233939, val_loss=0.02772042]\n",
      "Validation Epoch [187/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.41it/s, val_loss=0.02752740]\n",
      "Training Epoch [188/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.86it/s, train_loss=0.03229554, val_loss=0.02752740]\n",
      "Validation Epoch [188/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.34it/s, val_loss=0.02753191]\n",
      "Training Epoch [189/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.88it/s, train_loss=0.03234354, val_loss=0.02753191]\n",
      "Validation Epoch [189/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.20it/s, val_loss=0.02784229]\n",
      "Training Epoch [190/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.03219833, val_loss=0.02784229]\n",
      "Validation Epoch [190/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.56it/s, val_loss=0.02778270]\n",
      "Training Epoch [191/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.79it/s, train_loss=0.03225141, val_loss=0.02778270]\n",
      "Validation Epoch [191/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.28it/s, val_loss=0.02761579]\n",
      "Training Epoch [192/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.03217620, val_loss=0.02761579]\n",
      "Validation Epoch [192/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.34it/s, val_loss=0.02720553]\n",
      "Training Epoch [193/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03214795, val_loss=0.02720553]\n",
      "Validation Epoch [193/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.22it/s, val_loss=0.02774634]\n",
      "Training Epoch [194/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.03210502, val_loss=0.02774634]\n",
      "Validation Epoch [194/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.52it/s, val_loss=0.02752289]\n",
      "Training Epoch [195/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.03198986, val_loss=0.02752289]\n",
      "Validation Epoch [195/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.50it/s, val_loss=0.02695022]\n",
      "Training Epoch [196/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.03203203, val_loss=0.02695022]\n",
      "Validation Epoch [196/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.38it/s, val_loss=0.02711578]\n",
      "Training Epoch [197/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03196541, val_loss=0.02711578]\n",
      "Validation Epoch [197/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.45it/s, val_loss=0.02758631]\n",
      "Training Epoch [198/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03198237, val_loss=0.02758631]\n",
      "Validation Epoch [198/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.33it/s, val_loss=0.02737981]\n",
      "Training Epoch [199/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.03190802, val_loss=0.02737981]\n",
      "Validation Epoch [199/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.51it/s, val_loss=0.02725711]\n",
      "Training Epoch [200/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.03188271, val_loss=0.02725711]\n",
      "Validation Epoch [200/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.38it/s, val_loss=0.02684357]\n",
      "Training Epoch [201/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.03177428, val_loss=0.02684357]\n",
      "Validation Epoch [201/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.04it/s, val_loss=0.02697158]\n",
      "Training Epoch [202/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.03176421, val_loss=0.02697158]\n",
      "Validation Epoch [202/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.22it/s, val_loss=0.02710979]\n",
      "Training Epoch [203/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.81it/s, train_loss=0.03175473, val_loss=0.02710979]\n",
      "Validation Epoch [203/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.40it/s, val_loss=0.02687595]\n",
      "Training Epoch [204/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.03168867, val_loss=0.02687595]\n",
      "Validation Epoch [204/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.42it/s, val_loss=0.02714913]\n",
      "Training Epoch [205/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.03166031, val_loss=0.02714913]\n",
      "Validation Epoch [205/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.37it/s, val_loss=0.02715971]\n",
      "Training Epoch [206/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.77it/s, train_loss=0.03158781, val_loss=0.02715971]\n",
      "Validation Epoch [206/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.38it/s, val_loss=0.02661425]\n",
      "Training Epoch [207/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.03162212, val_loss=0.02661425]\n",
      "Validation Epoch [207/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.40it/s, val_loss=0.02689926]\n",
      "Training Epoch [208/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.03160362, val_loss=0.02689926]\n",
      "Validation Epoch [208/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.59it/s, val_loss=0.02684740]\n",
      "Training Epoch [209/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.03149331, val_loss=0.02684740]\n",
      "Validation Epoch [209/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.32it/s, val_loss=0.02683796]\n",
      "Training Epoch [210/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.03142427, val_loss=0.02683796]\n",
      "Validation Epoch [210/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.36it/s, val_loss=0.02666767]\n",
      "Training Epoch [211/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.03145064, val_loss=0.02666767]\n",
      "Validation Epoch [211/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.35it/s, val_loss=0.02640392]\n",
      "Training Epoch [212/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03143385, val_loss=0.02640392]\n",
      "Validation Epoch [212/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.53it/s, val_loss=0.02688051]\n",
      "Training Epoch [213/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.03141826, val_loss=0.02688051]\n",
      "Validation Epoch [213/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.25it/s, val_loss=0.02663411]\n",
      "Training Epoch [214/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03137932, val_loss=0.02663411]\n",
      "Validation Epoch [214/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.60it/s, val_loss=0.02638872]\n",
      "Training Epoch [215/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.03128376, val_loss=0.02638872]\n",
      "Validation Epoch [215/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.41it/s, val_loss=0.02681091]\n",
      "Training Epoch [216/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03128025, val_loss=0.02681091]\n",
      "Validation Epoch [216/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.18it/s, val_loss=0.02642957]\n",
      "Training Epoch [217/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03122347, val_loss=0.02642957]\n",
      "Validation Epoch [217/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.38it/s, val_loss=0.02668791]\n",
      "Training Epoch [218/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03123316, val_loss=0.02668791]\n",
      "Validation Epoch [218/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.81it/s, val_loss=0.02577540]\n",
      "Training Epoch [219/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.03116701, val_loss=0.02577540]\n",
      "Validation Epoch [219/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.17it/s, val_loss=0.02613490]\n",
      "Training Epoch [220/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03111656, val_loss=0.02613490]\n",
      "Validation Epoch [220/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.29it/s, val_loss=0.02630962]\n",
      "Training Epoch [221/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03107869, val_loss=0.02630962]\n",
      "Validation Epoch [221/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.09it/s, val_loss=0.02629895]\n",
      "Training Epoch [222/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03106492, val_loss=0.02629895]\n",
      "Validation Epoch [222/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.49it/s, val_loss=0.02594611]\n",
      "Training Epoch [223/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03097751, val_loss=0.02594611]\n",
      "Validation Epoch [223/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.16it/s, val_loss=0.02582347]\n",
      "Training Epoch [224/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03097080, val_loss=0.02582347]\n",
      "Validation Epoch [224/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.35it/s, val_loss=0.02586154]\n",
      "Training Epoch [225/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.03098673, val_loss=0.02586154]\n",
      "Validation Epoch [225/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.29it/s, val_loss=0.02606268]\n",
      "Training Epoch [226/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03092580, val_loss=0.02606268]\n",
      "Validation Epoch [226/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.47it/s, val_loss=0.02545551]\n",
      "Training Epoch [227/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.81it/s, train_loss=0.03081929, val_loss=0.02545551]\n",
      "Validation Epoch [227/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.89it/s, val_loss=0.02535633]\n",
      "Training Epoch [228/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.79it/s, train_loss=0.03093979, val_loss=0.02535633]\n",
      "Validation Epoch [228/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.46it/s, val_loss=0.02576831]\n",
      "Training Epoch [229/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.79it/s, train_loss=0.03081652, val_loss=0.02576831]\n",
      "Validation Epoch [229/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.20it/s, val_loss=0.02582575]\n",
      "Training Epoch [230/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.03081909, val_loss=0.02582575]\n",
      "Validation Epoch [230/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.29it/s, val_loss=0.02528910]\n",
      "Training Epoch [231/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.03077264, val_loss=0.02528910]\n",
      "Validation Epoch [231/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.59it/s, val_loss=0.02581312]\n",
      "Training Epoch [232/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.03079529, val_loss=0.02581312]\n",
      "Validation Epoch [232/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.24it/s, val_loss=0.02571870]\n",
      "Training Epoch [233/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.03073797, val_loss=0.02571870]\n",
      "Validation Epoch [233/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.11it/s, val_loss=0.02526420]\n",
      "Training Epoch [234/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.03072232, val_loss=0.02526420]\n",
      "Validation Epoch [234/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.75it/s, val_loss=0.02581094]\n",
      "Training Epoch [235/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.03067736, val_loss=0.02581094]\n",
      "Validation Epoch [235/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.43it/s, val_loss=0.02560455]\n",
      "Training Epoch [236/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03060674, val_loss=0.02560455]\n",
      "Validation Epoch [236/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.41it/s, val_loss=0.02527118]\n",
      "Training Epoch [237/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.03061696, val_loss=0.02527118]\n",
      "Validation Epoch [237/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.19it/s, val_loss=0.02544504]\n",
      "Training Epoch [238/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03057155, val_loss=0.02544504]\n",
      "Validation Epoch [238/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.12it/s, val_loss=0.02532255]\n",
      "Training Epoch [239/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.03064165, val_loss=0.02532255]\n",
      "Validation Epoch [239/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.99it/s, val_loss=0.02557768]\n",
      "Training Epoch [240/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.77it/s, train_loss=0.03052230, val_loss=0.02557768]\n",
      "Validation Epoch [240/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.43it/s, val_loss=0.02520395]\n",
      "Training Epoch [241/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03049860, val_loss=0.02520395]\n",
      "Validation Epoch [241/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.15it/s, val_loss=0.02528653]\n",
      "Training Epoch [242/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03042561, val_loss=0.02528653]\n",
      "Validation Epoch [242/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.14it/s, val_loss=0.02522613]\n",
      "Training Epoch [243/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.03032779, val_loss=0.02522613]\n",
      "Validation Epoch [243/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.55it/s, val_loss=0.02543411]\n",
      "Training Epoch [244/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.03038143, val_loss=0.02543411]\n",
      "Validation Epoch [244/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.36it/s, val_loss=0.02503895]\n",
      "Training Epoch [245/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.03035532, val_loss=0.02503895]\n",
      "Validation Epoch [245/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.09it/s, val_loss=0.02510677]\n",
      "Training Epoch [246/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.03030833, val_loss=0.02510677]\n",
      "Validation Epoch [246/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.06it/s, val_loss=0.02553014]\n",
      "Training Epoch [247/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.03033022, val_loss=0.02553014]\n",
      "Validation Epoch [247/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.31it/s, val_loss=0.02480625]\n",
      "Training Epoch [248/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03025580, val_loss=0.02480625]\n",
      "Validation Epoch [248/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.45it/s, val_loss=0.02508806]\n",
      "Training Epoch [249/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.03029133, val_loss=0.02508806]\n",
      "Validation Epoch [249/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.43it/s, val_loss=0.02526491]\n",
      "Training Epoch [250/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.03028050, val_loss=0.02526491]\n",
      "Validation Epoch [250/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.39it/s, val_loss=0.02508181]\n",
      "Training Epoch [251/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03025478, val_loss=0.02508181]\n",
      "Validation Epoch [251/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.25it/s, val_loss=0.02479806]\n",
      "Training Epoch [252/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.03025199, val_loss=0.02479806]\n",
      "Validation Epoch [252/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.36it/s, val_loss=0.02494996]\n",
      "Training Epoch [253/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03016029, val_loss=0.02494996]\n",
      "Validation Epoch [253/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.15it/s, val_loss=0.02462116]\n",
      "Training Epoch [254/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.03014119, val_loss=0.02462116]\n",
      "Validation Epoch [254/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.30it/s, val_loss=0.02509088]\n",
      "Training Epoch [255/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03016446, val_loss=0.02509088]\n",
      "Validation Epoch [255/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.03it/s, val_loss=0.02485945]\n",
      "Training Epoch [256/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.77it/s, train_loss=0.03012504, val_loss=0.02485945]\n",
      "Validation Epoch [256/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.36it/s, val_loss=0.02463829]\n",
      "Training Epoch [257/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.03008827, val_loss=0.02463829]\n",
      "Validation Epoch [257/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.15it/s, val_loss=0.02472591]\n",
      "Training Epoch [258/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.78it/s, train_loss=0.03005130, val_loss=0.02472591]\n",
      "Validation Epoch [258/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.38it/s, val_loss=0.02486399]\n",
      "Training Epoch [259/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.03005360, val_loss=0.02486399]\n",
      "Validation Epoch [259/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.34it/s, val_loss=0.02454120]\n",
      "Training Epoch [260/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.02999605, val_loss=0.02454120]\n",
      "Validation Epoch [260/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.55it/s, val_loss=0.02494791]\n",
      "Training Epoch [261/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.03003247, val_loss=0.02494791]\n",
      "Validation Epoch [261/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.27it/s, val_loss=0.02476034]\n",
      "Training Epoch [262/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.79it/s, train_loss=0.03001483, val_loss=0.02476034]\n",
      "Validation Epoch [262/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.19it/s, val_loss=0.02491200]\n",
      "Training Epoch [263/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.02991268, val_loss=0.02491200]\n",
      "Validation Epoch [263/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.38it/s, val_loss=0.02444356]\n",
      "Training Epoch [264/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.02990567, val_loss=0.02444356]\n",
      "Validation Epoch [264/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.47it/s, val_loss=0.02481166]\n",
      "Training Epoch [265/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.02990883, val_loss=0.02481166]\n",
      "Validation Epoch [265/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.42it/s, val_loss=0.02476058]\n",
      "Training Epoch [266/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.02993258, val_loss=0.02476058]\n",
      "Validation Epoch [266/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.28it/s, val_loss=0.02465883]\n",
      "Training Epoch [267/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.84it/s, train_loss=0.02989137, val_loss=0.02465883]\n",
      "Validation Epoch [267/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.50it/s, val_loss=0.02463800]\n",
      "Training Epoch [268/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.02987107, val_loss=0.02463800]\n",
      "Validation Epoch [268/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.20it/s, val_loss=0.02432353]\n",
      "Training Epoch [269/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.02985636, val_loss=0.02432353]\n",
      "Validation Epoch [269/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.44it/s, val_loss=0.02455428]\n",
      "Training Epoch [270/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.02980448, val_loss=0.02455428]\n",
      "Validation Epoch [270/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.71it/s, val_loss=0.02458534]\n",
      "Training Epoch [271/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.02986129, val_loss=0.02458534]\n",
      "Validation Epoch [271/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.42it/s, val_loss=0.02450347]\n",
      "Training Epoch [272/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.77it/s, train_loss=0.02983880, val_loss=0.02450347]\n",
      "Validation Epoch [272/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.94it/s, val_loss=0.02454650]\n",
      "Training Epoch [273/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.78it/s, train_loss=0.02977170, val_loss=0.02454650]\n",
      "Validation Epoch [273/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.47it/s, val_loss=0.02478711]\n",
      "Training Epoch [274/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.02973852, val_loss=0.02478711]\n",
      "Validation Epoch [274/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.38it/s, val_loss=0.02412917]\n",
      "Training Epoch [275/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.02974100, val_loss=0.02412917]\n",
      "Validation Epoch [275/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.96it/s, val_loss=0.02423759]\n",
      "Training Epoch [276/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.02974643, val_loss=0.02423759]\n",
      "Validation Epoch [276/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.85it/s, val_loss=0.02394445]\n",
      "Training Epoch [277/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.79it/s, train_loss=0.02968799, val_loss=0.02394445]\n",
      "Validation Epoch [277/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.23it/s, val_loss=0.02479503]\n",
      "Training Epoch [278/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.02973601, val_loss=0.02479503]\n",
      "Validation Epoch [278/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.26it/s, val_loss=0.02417317]\n",
      "Training Epoch [279/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.81it/s, train_loss=0.02965861, val_loss=0.02417317]\n",
      "Validation Epoch [279/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.18it/s, val_loss=0.02435924]\n",
      "Training Epoch [280/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.81it/s, train_loss=0.02967596, val_loss=0.02435924]\n",
      "Validation Epoch [280/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.02it/s, val_loss=0.02432402]\n",
      "Training Epoch [281/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.78it/s, train_loss=0.02965732, val_loss=0.02432402]\n",
      "Validation Epoch [281/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.27it/s, val_loss=0.02443641]\n",
      "Training Epoch [282/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.02964559, val_loss=0.02443641]\n",
      "Validation Epoch [282/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.50it/s, val_loss=0.02439929]\n",
      "Training Epoch [283/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.81it/s, train_loss=0.02961625, val_loss=0.02439929]\n",
      "Validation Epoch [283/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.22it/s, val_loss=0.02437207]\n",
      "Training Epoch [284/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.79it/s, train_loss=0.02956517, val_loss=0.02437207]\n",
      "Validation Epoch [284/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.17it/s, val_loss=0.02427284]\n",
      "Training Epoch [285/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.02954930, val_loss=0.02427284]\n",
      "Validation Epoch [285/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.40it/s, val_loss=0.02428214]\n",
      "Training Epoch [286/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.02953567, val_loss=0.02428214]\n",
      "Validation Epoch [286/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.05it/s, val_loss=0.02426919]\n",
      "Training Epoch [287/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.02953543, val_loss=0.02426919]\n",
      "Validation Epoch [287/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.99it/s, val_loss=0.02418668]\n",
      "Training Epoch [288/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.81it/s, train_loss=0.02952333, val_loss=0.02418668]\n",
      "Validation Epoch [288/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.97it/s, val_loss=0.02416442]\n",
      "Training Epoch [289/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.02955953, val_loss=0.02416442]\n",
      "Validation Epoch [289/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.82it/s, val_loss=0.02451831]\n",
      "Training Epoch [290/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.02937913, val_loss=0.02451831]\n",
      "Validation Epoch [290/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.34it/s, val_loss=0.02413681]\n",
      "Training Epoch [291/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.79it/s, train_loss=0.02938697, val_loss=0.02413681]\n",
      "Validation Epoch [291/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.34it/s, val_loss=0.02442909]\n",
      "Training Epoch [292/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.80it/s, train_loss=0.02945439, val_loss=0.02442909]\n",
      "Validation Epoch [292/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.03it/s, val_loss=0.02417854]\n",
      "Training Epoch [293/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.79it/s, train_loss=0.02943970, val_loss=0.02417854]\n",
      "Validation Epoch [293/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.45it/s, val_loss=0.02383854]\n",
      "Training Epoch [294/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.02934905, val_loss=0.02383854]\n",
      "Validation Epoch [294/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.32it/s, val_loss=0.02398531]\n",
      "Training Epoch [295/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.02937190, val_loss=0.02398531]\n",
      "Validation Epoch [295/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.06it/s, val_loss=0.02432262]\n",
      "Training Epoch [296/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.78it/s, train_loss=0.02931847, val_loss=0.02432262]\n",
      "Validation Epoch [296/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.33it/s, val_loss=0.02397056]\n",
      "Training Epoch [297/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.83it/s, train_loss=0.02936003, val_loss=0.02397056]\n",
      "Validation Epoch [297/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.67it/s, val_loss=0.02359103]\n",
      "Training Epoch [298/300]: 100%|███████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s, train_loss=0.02935008, val_loss=0.02359103]\n",
      "Validation Epoch [298/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.97it/s, val_loss=0.02355678]\n",
      "Training Epoch [299/300]: 100%|███████████████████████████████████████████| 29/29 [00:15<00:00,  1.82it/s, train_loss=0.02935756, val_loss=0.02355678]\n",
      "Validation Epoch [299/300]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.76it/s, val_loss=0.02411959]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_pretrained = Encoder(hparams).to(device)\n",
    "decoder = Decoder(hparams).to(device)\n",
    "autoencoder = Autoencoder(hparams, encoder_pretrained, decoder).to(device)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, loss_func, tb_logger, epochs=10, name='Autoencoder'):\n",
    "    \n",
    "    optimizer = model.optimizer\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=epochs * len(train_loader) / 5, gamma=0.7)\n",
    "    validation_loss = 0\n",
    "    model = model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Train\n",
    "        training_loop = create_tqdm_bar(train_loader, desc=f'Training Epoch [{epoch}/{epochs}]')\n",
    "        training_loss = 0\n",
    "        for train_iteration, batch in training_loop:\n",
    "            \n",
    "            loss = model.training_step(batch, loss_func) # You need to implement this function.\n",
    "            training_loss += loss.item()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Update the progress bar.\n",
    "            training_loop.set_postfix(train_loss = \"{:.8f}\".format(training_loss / (train_iteration + 1)), val_loss = \"{:.8f}\".format(validation_loss))\n",
    "\n",
    "            # Update the tensorboard logger.\n",
    "            tb_logger.add_scalar(f'{name}/train_loss', loss.item(), epoch * len(train_loader) + train_iteration)\n",
    "\n",
    "        # Validation\n",
    "        val_loop = create_tqdm_bar(val_loader, desc=f'Validation Epoch [{epoch}/{epochs}]')\n",
    "        validation_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for val_iteration, batch in val_loop:\n",
    "                loss = model.validation_step(batch, loss_func) # You need to implement this function.\n",
    "                validation_loss += loss.item()\n",
    "\n",
    "                # Update the progress bar.\n",
    "                val_loop.set_postfix(val_loss = \"{:.8f}\".format(validation_loss / (val_iteration + 1)))\n",
    "\n",
    "                # Update the tensorboard logger.\n",
    "                tb_logger.add_scalar(f'{name}/val_loss', validation_loss / (val_iteration + 1), epoch * len(val_loader) + val_iteration)\n",
    "        # This value is for the progress bar of the training loop.\n",
    "        validation_loss /= len(val_loader)\n",
    "\n",
    "# Creat a tensorboard logger.\n",
    "# NOTE: In order to see the logs, run the following command in the terminal: tensorboard --logdir=./\n",
    "# Also, in order to reset the logs, delete the logs folder MANUALLY.\n",
    "\n",
    "path = os.path.join('logs', 'ae_logs')\n",
    "num_of_runs = len(os.listdir(path)) if os.path.exists(path) else 0\n",
    "path = os.path.join(path, f'run_{num_of_runs + 1}')\n",
    "tb_logger = SummaryWriter(path)\n",
    "\n",
    "# Train the classifier.\n",
    "unlabled_train_loader = torch.utils.data.DataLoader(unlabeled_train, batch_size=hparams['batch_size'], shuffle=True)\n",
    "unlabled_val_loader = torch.utils.data.DataLoader(unlabeled_val, batch_size=hparams['batch_size'], shuffle=False)\n",
    "\n",
    "epochs = hparams.get('epochs', 5)\n",
    "loss_func = nn.MSELoss() # The loss function we use for regression (Could also be nn.L1Loss()).\n",
    "train_model(autoencoder, unlabled_train_loader, unlabled_val_loader, loss_func, tb_logger, epochs=epochs, name='Autoencoder')\n",
    "\n",
    "print(\"Finished training!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "vdgiYWy4MNkq"
   },
   "source": [
    "Once trained, let's have a look at the reconstructed validation images (If you have not already looked at them in TensorBoard)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "a991mKcyMNkq"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABjUAAAY1CAYAAABqg1wJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzd15cc15Xn+5OVprwFyqFgCh4gQFAEaEVKoti9JE1rNGt6/sd5mXmYnp61umd1SyIlUpRAgg4k4T1Q3vtKfx/63ttm7d8G8zAqkQF8P4/7cEdGnDg2DrEqU6/X6wEAAAAAAAAAAKDFtT3rGwAAAAAAAAAAAPg+ONQAAAAAAAAAAACpwKEGAAAAAAAAAABIBQ41AAAAAAAAAABAKnCoAQAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKRC7vv+hz09PXt5H2hB9Xq94ZxMJrMHd7L3Njc3o/JGR0cTvhOgdczNzUXlDQ0NJXwnSFqzxuqYeaTVLS8vR+WNjY0lfCfweG38Wa9vnsd+MTs7G5W3f//+hO8EaB2Li4tReQMDA8neCJ5LSc9zzbK6uhqVNzw8nOyN4LmU1n6xsLAQlXfgwIGE7+TF0az9QCv8Tlq/005PTz/1v+FfagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpwKEGAAAAAAAAAABIhdyzvoG0UX9RPum/Jp/0X66Pue+knwn4oWL6RZL9ZS+o+2vmPeDpmjXuxmhr0/9/Qky/iGmTtVqtofjT0P7ToZX7hSfJ3/Ku1QprRrSOmLbiiWlfMWNy0u2V/QV+KNb2T78e+ws8z2LnU/pF60j6e2eMmN/x1lEx12vWXqoV6nuv8C81AAAAAAAAAABAKnCoAQAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKRC7lnfwF5L+q+8t7XZ50Aq7v2Ol+NRz1StVmVOrVZrKB7z+yHEPZP3HtRvxbw7tBbV9pJ+t157jbkHVRZ73979ofUl/f6y2awZLxQKMqe3t1eW9fT0mPH29vaG72F7e1vmbGxsmPHNzU2ZUyqVZJnqm15905ear1l1rsbXXE4vY1U7DiFuHeWVNSrpeotZR6H5YsavmLW9x1unqz7j/U6z1uPsFfB9qfbgtf2k1xaqz8Tsk2PHcMb+F0/MnNDMcTLmt5qVg73RzPFLvfdm7h1jvi0l+T3KEzMHJvke9hL/UgMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpwKEGAAAAAAAAAABIBQ41AAAAAAAAAABAKnCoAQAAAAAAAAAAUiH3rG9gr2WzWVmWy9mPn8/nZU5XV5cZ7+npkTmFQsGMt7XpM6V6vS7Ldnd3zfjGxobM2d7ebigeQgjValWWKbVaTZZ5z4vnk9eOY9qDdz0lpk16v+Ndr9Hf8X4rk8k0/DsvGq+OYtpKs+7By1HzRX9/v8w5cOCALDty5IgZHxoakjnlctmMz83NyZzp6emGczY3N2VZsVg04zHzEpovpv95a6+Ojg4zrtZkXo7HWxOptZeKhxBCpVIx4179xIz9zRrvXjRJ12vM2sIb82LGQ289otqrR+2zYtZ/XttnHfX8SnrMU9eLXdurvJj9RcwegnaM/0i1yZg5K+n1iCfJ68VeK2a+YI2VDs3qFzFziZeT5Doq9ttb2ts4X5kBAAAAAAAAAEAqcKgBAAAAAAAAAABSgUMNAAAAAAAAAACQChxqAAAAAAAAAACAVOBQAwAAAAAAAAAApELuWd/AfxTzF9vVX4wPIYSOjg5Z1tvba8aHhoZkztjYmBk/cuSIzOnr6zPj+Xxe5uzu7sqypaUlMz4zMyNzHjx4YMbn5+dlzubmphn33pFXFiOTySR6vbTy6iHpOk/6eorqt96zqjEgBH3f3vNUKhVZFnMPSq1Wk2VJtnHvWZ/HvhTTVmP7UrVabThHvXdvzlLta3BwUOacOHFClp07d86Mq/kvhBBWV1dlmbK1tWXGd3Z2ZI7X/5Ks72aNaS8iVbfeOKnWZWp9FUIIo6OjZnx8fFzmeG1c3ffKyorMmZ6eNuNzc3MyZ3l52YwXi0WZo9p+CHr8ihnf6Rf/KqZevbJnPRZ5/S9mPeK1yXK53PA95HL29lPFn0b9Fv0iHWLWrl77imnHMeuRQqEgc7q7uxvOUX3Tu7dSqSTLYvZFjV4LP1zMfKHKYvbQMftaT8x9x8wX3l7Km+dUmZej0C/2TpJ1G/NuvfnCu56Xp6h1lLcmUt+RvX7hadb3qL36ff6lBgAAAAAAAAAASAUONQAAAAAAAAAAQCpwqAEAAAAAAAAAAFKBQw0AAAAAAAAAAJAKHGoAAAAAAAAAAIBU4FADAAAAAAAAAACkQm4vL16v12VZJpNpKB5CCNls1ox3dXXJnP7+flk2Pj5uxicnJ2XO0aNHzfjBgwcbvodCoSBzKpWKLFtdXTXjjx49kjmqjtra9LnWkydPzPj29rbMqdVqsky1B++dx7STRq+VdjF15PVNpVwuN3w9rz2oNh5zbyGEUK1WG85Jsk14963GLq+sWf0izWLqyOO1V1XmtTvVJvL5vMwZGhoy42fPnpU5b775piw7dOiQGd/Y2JA58/PzZnxra0vmqPEhpl+GoOempN957HjzvPHqwesX6j21t7fLnP3795vxV155ReacP3/ejJ84cULmeGtD1ZYXFhZkzr1798z49evXZc6tW7fMuOpjIfjrP9XGvbWcV/Yi8epBzcPe3B1T5971VD/L5fRWTfXbjo4OmeONk+oeisWizFFziTdfxMynMe04ZnyP2bviXyW991fXi1l7efsYb9xVfbCvr0/mDA8Pm3FvXlL7a7XvD8GvB/W8rHv+VbP6tFfnamzz1l5KzPjutaGYe/DmObX/6ezslDlqPRnT9p9W1qikv7WkWdLfo1SZN1arNuHlqDKvnST9zUn1Ge9bsboHr/9568mY99dKayJ2OgAAAAAAAAAAIBU41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEgFDjUAAAAAAAAAAEAqcKgBAAAAAAAAAABSQf8J9ATE/EX0mL8M397eLnMGBgZk2fDwsBnfv3+/zBkcHGzo3kIIoVarmfFKpSJzPOoeOjs7ZU5HR4cZ9+67WCya8enp6YZzPPV6veGcGDHtsVV4967KvBzVJkMIoVqtmnHvPaky73dU+/f6RalUkmVKPp9vuCyX00NjW1vjZ8ExdZf0O2/099NOtb2Yd+Hx2qu6B2+OOXHihBl/4403ZM758+dlWblcNuM3b96UObdv3zbj9+/flzmrq6tmfGtrS+Z4/VmNQ96Y8ry25UZ59ZB0v1DjobceOXLkiBl//fXXZc6FCxca/p35+XlZtrm5aca9sX90dLTh31HrU2+sjmnHqr887beSzGkVqk16c7daC3R1dcmc3t5eWab2Hv39/TKnUCiY8UOHDskcdX/e73htfHd314x7bfybb74x41evXpU5i4uLZtwb3739iqq7pNde6v5i1oWtIma88XKSXoeqOldrG+963nvy+vrIyIgZP3PmjMwZGxsz46qthqD31959e2tQVcZa6V/FjANJ11+S1/O+w6g1t/f73hpLfY9Sce963d3dMketb9S+42llMd8snsd9d7PG8aTXk9711PdOFQ9Bry28tZK3HlF5XvtSexIVD0HPgTHfJULQz+Q9q5qbnsUeIr2rMAAAAAAAAAAA8ELhUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpwKEGAAAAAAAAAABIBQ41AAAAAAAAAABAKuT28uL1el2WZTKZhq/X1mafwaj405TLZTO+trYmcx4/ftzw71SrVTNeq9VkTqFQkGXDw8Nm/NChQzLn1KlTDd/D0tKSGd/a2pI5Xt3F1INqJ947V9fz2mMzeW0/5nlzObsb5/N5mZPNZmWZ+i31OyHo9uq1Y3UPXv149dDZ2WnGe3p6ZM729rYZ9+quVCo1dK0QQlheXpZlm5ubDf1OCLoveVql/ceIufeYHK9fqDpX80gIIbS3t5vxo0ePypy3337bjL/11lsyR7X9EEL47LPPzPinn34qc7777jszvrKyInMqlYoZ99qqV6ben/de1dgfs95IM6+OVJl6f0+j5oX+/n6Zo9YqBw4ckDnFYtGMf/PNNzLnq6++kmXqedVaKYQQ+vr6zHhvb6/MUXOJ1ya9cUiJGe+8+TTN84WqW69eu7u7zfjo6KjMmZyclGXHjh0z40eOHJE5ahz3crq6usx4R0dHw78Tgu7PCwsLMufjjz82497aXuV46yhvPaneudfPklxXpLm/eNRzee/WG1eS3Pur9VUIuj+PjIzInIMHD8qyM2fOmPGXX35Z5gwNDZlxb679+uuvG87x9uRqH+GtW9W6LM3rqJhxIOk+HTPne+9dvUOvPajfGR8flzmq7Yeg5yavn6lx3JuX1Peomzdvypzd3d2oshdJTJ+Oacfe2ssbx9U6ZnBwUOaotnz69GmZs2/fPjOu1vwhxK1HdnZ2ZM7Dhw/NuNfGr1+/bsbn5+dlTkzbj9lTPov5gn+pAQAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpkNvLi2cyGVlWr9cbzqlWq2a8WCzKnPX1dVmWy9mPv7m5KXPa2uxzIO8e1PVKpZLMKRQKsuzEiRNmfGBgQOacP3/ejKv3EEIIt27dMuMPHz6UOTs7O7KsVquZ8Uql0nCOd9+K17aaybuPbDZrxvP5vMzp6Ogw4z09PTKnv79flg0ODprx4eFhmTM+Pm7GR0ZGZI4q6+3tlTnt7e2yTNWd159XV1fNuNc31ZiysLAgc27evCnLbt++bcYXFxdljhpv1BiZdjHzhRqrvRw13oSg69wbiw4cOGDG33nnHZnzi1/8wowfPHhQ5nz++eey7I9//GPDOTMzM2bce1Y1n3o5MeM4/pWqP69evTYeQ713b/4ZGhoy4964e/36dTOu2ncIIXzxxReyTPWnl156SeaoOXBubk7mqLk7Zh0Qgh7XvLFf/Vaa+5+qB49qqyHo9qrG8BBC+NGPfiTL1Jp7bGxM5qj1yPz8vMxRfcZbM/b19ckytb/w+oX6LW+v8N1335nx7e1tmROzvonZhyY9RjZTzPqmmfNFzLpMrfu9/cXJkycbiofg9/WJiQkzfujQIZkzOjpqxr3vBcvLy2ZczX8h+PNFkvter520yv46STHP5M1LMdfz+l+5XDbj3v7+zJkzZvztt9+WOWouC0F/L/DaiurP3jesqakpM+7t7588eSLL1D4+5h3F7HFapb/E3Ie3jlLfLru7u2WOakMh6HW6t/Z6/fXXzfjZs2dljlrbe+/W+96pyrz1zezsrBlXc49HjQ0h+N+W1Bor6X6xV+2ff6kBAAAAAAAAAABSgUMNAAAAAAAAAACQChxqAAAAAAAAAACAVOBQAwAAAAAAAAAApAKHGgAAAAAAAAAAIBX0n7BPQK1WazjH+2vp6q+5e39N3rsHldfe3i5z1F9s393dlTk7OztmfHNzU+YUCgVZ1tvba8ZzOf06h4eHzXixWJQ5XV1dDf9OzF+0j8lp5vViqfvw7i+bzZpxrz309PSY8f3798uc8fFxWXbs2DEzfvLkSZkzOTlpxg8cOCBz9u3bZ8ZVuwvBHx9WV1fN+Pz8vMwZHByUZY2anZ2VZWrsCiGEpaUlM76xsSFzvH6bVt67VZLu6957UmVDQ0My5+233zbjf/M3fyNzTp06Zcbv3r0rc/74xz/Ksk8//dSMP3nyROaoZ/XGoZh34b3zVmgPrSCmjrx6UGVtbfr/cfGul8/nzXhnZ6fMUXNWqVSSOTMzM2b88ePHMsdbl6n5R81lIej57M6dOzJHrUG9talX3+o9Jd2XWoWqC++ZYtq4WlcfOnRI5pw+fVqWjY2NmfG5uTmZo8bq7777TuYsLCyYcdUvQ/DXZe+9954Z9+asw4cPm/EzZ87InIMHD5rxxcVFmeP1mWq1asbVmjqEdPcLxaujmOeNmWM8qg92dHTIHDVWnzhxQuacP3/ejI+MjMgc1YZC0P1WzWUh6LWht85Uc6D6jhCCvx9Ico2Qhv4Sc+9Jt3HFu16lUjHj3n13d3eb8XPnzsmc3/zmN2b8jTfekDneWk6ty9bW1mROX1+fGff6puoX3vc6byyM+T6pctKw72jWOkp9H/TakPcdRu2H33zzTZlz6dKlhu9BfSfyvussLy/LMrX3UHNZCCEMDAyY8SNHjsgctc68deuWzIlZE3ltvJX26vxLDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpwKEGAAAAAAAAAABIhdxeXjyTyUSVKdVqtaF4CCGUSiVZVigUzHhHR4fMyeXsKou5h3K5LHN6e3tl2cTEhBk/evSozBkZGTHjDx8+lDmbm5tmfHd3V+bUarWGy7y20NZmn7tVKhWZ0+pinle1O69Mte8QQuju7m64LJ/PyxzVlufm5mTOkydPGrpWCCGsr6/LsqWlpYavp+pucnJS5hw5csSMq3cXgt+fs9msGffGlHq9bsa9tqVyWoVXfzH3rsYb71peW+ns7DTjFy5ckDm//vWvzfilS5dkzsrKihn//e9/L3M++OADWfbo0SMzXiwWZY56F947isnxxnH1nrx+oXjzUsxapJmSvj/1Prx+EVOmxrUQ9FziPat6797ceODAAVn20ksvmfHz58/LHLWWW1hYkDmqzOt/3jOpOvL6mWr/ae4XHlUX3tp+YGDAjKv1tpcTQghbW1tm/KOPPpI5/+t//S8zrsbwEHQ76u/vlzneumz//v1m/I033pA5J06caOhaIYQwNDRkxr11qzc/J7m+8fpFq4vpt0mvDWOu5+0v1Pq5r69P5qj+d+3aNZmztrYmy1R/8sYU1ca3t7dljtoXzc/PyxzvemqN5b0j1YZaZQ8Rs89Jul+o63ljh3c9lefN62ov+tOf/lTmvPnmm2bca8d37tyRZV9//bUZ9+pbfWPwctQ85/XZnZ0dWRbTL2K0+joq5jttTDv29nreXkG1S6+f3bhxw4zfu3dP5ly+fNmMz8zMyBw1x4QQQldXlxl/5513ZM6Pf/xjM97e3i5z1Hop9vu7N96kQbrvHgAAAAAAAAAAvDA41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEgFDjUAAAAAAAAAAEAqcKgBAAAAAAAAAABSIbeXF/f+wrpSr9dlmfpr9+VyuWn3kMvZVabiXtnY2JjMOXfunCz7m7/5GzP+6quvyhz1F+0fPXokc6anp8341taWzFHvKAS/XpPMUe88pi3shZg2XqlUZI4q8/rFzs6OLJubmzPjpVJJ5ty4ccOMb29vy5ylpSUzvrm5KXPW1tZk2cbGhhlvb2+XOSdPnjTj+/fvlzkdHR2yTNnd3ZVlqo68+vb6WVolPT6oOvLqNZvNyrLDhw+b8Z/97Gcy59133zXj3nzxpz/9yYz/8z//s8x58OCBLFPjgNeOVZ+JyfF445p6T8ViUeZUq9WG76HVJT1vqbWAV3feXKLek9fPVL/1+sW+ffvM+PHjx2VOV1eXLHvvvffM+OTkpMz5+OOPzbia/0IIYWZmxox7bT+fz8uymPVNkuuoZlP37t2fauPe+DU8PGzGvXV6oVCQZTdv3jTjf/7zn2XON998Y8a996faeOz7U+3SW5eptZdnYGDAjKt+HkIIKysrskzVkbdWUmVJ7xtjNatPe9dSfSl2DRqTp+am1dVVmaPaipfj9WfVLvv7+2WOqu+pqSmZc/fuXTM+Ozsrc7z9RYwk1+LNnkdi2niSvN+JWZ8ODg7KspdeesmMnzp1SuaodZmar0II4ZNPPpFl6hvSmTNnZI7XZ5TFxUUz7vULb85qVnttVrt7miTvw2vHav3grXe966l3eOvWLZmj2sSVK1dkztdff23GvW9YnoMHD5px79tuzNil6s6rb28ObtZ4vVf9j3+pAQAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpkHtWP1yr1cx4JpNpOKder0fdQ7lcbigeQgj5fN6Md3V1yZyRkREzfurUKZnzq1/9Spb97Gc/M+O9vb0y5/PPP28oHkIIjx49MuPFYlHmeO9ClXk56p3HiG0nSf+e90yVSsWMl0olmbO7u2vGV1ZWnLvT1tbWGs5ZX18348vLyzJnc3PTjKvnCUHXj5e3b98+mXP06FEzPjAwIHOy2awZn5ubkzlPnjyRZUtLS2bc62cx46dX1upUX4qZL7yc7u5uWfbyyy+b8Z/+9KcyZ3h42Ix/8803Mud3v/udGb927ZrM8caHvr4+M97f3y9z1Hw2ODjYcI433nlj1Pz8vBn35mdvfHiRtLXp/18lZh6uVquybGtry4x784gqGx8flzlqHdXZ2SlzRkdHZZnqz55bt26Z8Xv37smc7e1tM97e3i5zvD6j3kXS65tmr5eSlMvZW5uOjg6Zo8Z+b23vjTdq/eytE9T+wmvjahz37turBzW+emuYiYkJM+71v4MHD5pxb+21sbEhy1S/SHrd08x+0aw+7dVRTE5MnXtzjBpDp6amGv4dr+0fO3ZMll24cMGMqz1ECPq+b968KXPu3LljxldXV2WOV3dqLIzZq3uaub9ohbkp5h68dZkar702+dJLL5lxr43fvn3bjF+9elXmPH78WJapuenMmTMyZ3Jy0ox7+xi1xpqenpY53h5atdeYsfB5leRewfuuo74fhRDCzMyMGVffTULQY+j169dljvpW5T2rWq+FoMddbw+tvuF6Y7/6jrazsyNzvPlCjVHNGt9/aB/jX2oAAAAAAAAAAIBU4FADAAAAAAAAAACkAocaAAAAAAAAAAAgFTjUAAAAAAAAAAAAqcChBgAAAAAAAAAASAX7z7OnjPdX2b2/pF6pVMx4rVZr+LfUX60PIYSXX37ZjP/qV7+SOe+//74sGxoaMuNff/21zPn7v/97M/7nP/9Z5iwtLckyxXsXqszLqVarDec0+vutRLVXrx3v7u4mlhNCCLmcPSyUy2WZs7m5acZ3dnZkTsyzqvbg5Q0PD8sc1TcPHDggc1ZXV8347du3Zc79+/dl2crKihn36lvJZrOyTNVPmvtFTE4+n5c53ntXbeXYsWMyZ2Njw4x/9tlnMkeVqXYXQgj79u2TZYcOHTLjXr8YGRlp+Hc6OzvNuDcG3Lp1S5Ztb2+b8a2tLZmj5vSY9tMqYu49ZhyIpd7T/Py8zFFjpWpDIeh2fPbs2YZzQgihv7/fjF+7dk3mqPXSkydPZI6qbzXPPo23Pm00J2a91uy+pO6jrU3/P1kxOarPqDElBH9MVuOe994HBwfNeHt7u8zp6uoy4319fTKnp6dHlqn5Mek1qOrrqg5C8Pckal6I3R8qaVgvKep5vX7hlSkxdeStE9S6v1AoyJyBgQEzrtZxIYTwzjvvyLKLFy82fA9Xr141495efXZ21ox741DMO8LTJf2dwWsraj0+OTkpc/bv32/GvX2yGqu9fdGJEydk2cmTJ834e++9J3NGR0fN+JUrV2TOw4cPzbi3H/DeRUyf8eo1rZJez6m1ZqlUkjlra2uyTK2tvXcxPT1txr3vXmo94tWPWnuFoPut15fUPSwsLMgcNV/EfHvzeH0pZn8R8zvfBzMhAAAAAAAAAABIBQ41AAAAAAAAAABAKnCoAQAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKRCbi8vXq/XGy6LyYnV1maf6bS3t8uc0dFRM37x4kWZ8/Of/9yM/+QnP5E5+/fvl2V37twx4//n//wfmfNP//RPZvzWrVsyRykUCrKsVqvJskwm03BONps149VqVeao95p0+4mVdL+oVCoNxUPw60+9J+96pVKpoWuFEPduvXoYGxsz42+//bbMefXVV814LqeHxq+++sqMf/755zLnyZMnsmx3d9eMx/QLr35Uv2gVMf0z5nl7enpkzuHDh2XZmTNnzHhXV5fMuX37thn/5JNPZM79+/fNeEdHh8yZnJyUZWfPnjXj4+PjMmdoaMiM9/X1yZze3l4zvrq6KnOWl5dlmZqHW70dt4KYfhEzd4egx+u5uTmZo9Yd3d3dMmdgYMCM9/f3y5x9+/bJMjVn3bt3T+bMzs6acW9uVOulmDr1eNdTmrnejhWzJlJt2WvjxWLRjK+srMgcNXd7vzU4OChz1tbWzHi5XJY5aq2ixuMQ/D7T2dlpxmPqTvXZEEI4ceKEGVdzZgj+mKLqKGY96T1rmucfNUZ4Y0fS6zJVt15f2t7eNuPefDExMWHG1XoohBDOnz8vy9T+4uuvv5Y5V65cMePXr1+XOWq88epU7Qc8rTK+t4KYulDjgPcuvL3HgQMHzLi3J1FreG+dru5hZGRE5nhj3smTJ834uXPnZM76+roZ99Ze09PTZtxbe3nf8mLG/ph1Rcy6rJlixn6vv8SsXb09oprXvfeu2lfM9yjvd7y9/9GjR824159VO5qampI5ak+i5swQ/Hpo1vpG3cMPnZfSuzoDAAAAAAAAAAAvFA41AAAAAAAAAABAKnCoAQAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKRCLomL1Ov1hnMymYwZr1arP/R2/p22Nn1u09nZacYnJiZkzqVLl8z4r371K5nzk5/8xIwPDw/LnDt37siy3//+92b8D3/4g8y5deuWGS8WizKnu7vbjKt6C8F/f6VSyYx770i1LdV+QgihVqvJslannterV1VWqVQazglB159X54r3bmPuu7+/X5b96Ec/MuNvvfWWzBkZGTHjjx49kjlffPGFGb97967MWVtbk2WqHmLqOyYnDVQ78vp6Nps14319fTLn4MGDsky1lZ2dHZlz7do1M+6N77mcPS0fOnRI5hw9elSWjY+Pm/Guri6Zo+rbG/t7e3vNuLc+8K6n8rzrqfbv9YuY9Uszefee5PN6Y3U+n5dlyu7urixbXl424ysrKzJH9fVCoSBzVF8KQa9HvLmxo6PDjPf09Miczc1NMx7TjkPQ9aDGu9icVhEzp6nn9drk4uKiGZ+bm5M5g4ODsky9X2/MU+3Lo9q41y+8MtUv5ufnZc7o6KgZ9/Y4aj719l/379+XZVtbW2bc2+M8r+slxRvjlZh52CtT46tqdx5vP3DmzBkz/sorr8icw4cPyzI1Z3311Vcy5+rVq2Z8ZmZG5qj9jzcHx8wXMe8vpv2kQZLjgDeneuO7WkN4+xW1hvfWI6odeWsljxrHvTqdmpoy496+aGlpqbEbC/4zqX7h7Sljvke1upj9T8w3Ni/HK1PzQswc441f5XK5oWuF4PezyclJM+6tGdVa88GDBzJHzUseb4xSZd53uVbyfM5QAAAAAAAAAADgucOhBgAAAAAAAAAASAUONQAAAAAAAAAAQCpwqAEAAAAAAAAAAFKBQw0AAAAAAAAAAJAKuSQukslkzLj31+mbpVAoyLLR0VEzfuHCBZnz85//3Iy/8847Mmffvn1m/NatWzLnH//xH2XZRx99ZMZv3rwpc3Z3d814V1eXzOnp6THjXp3GqFarDedUKhVZVqvVzLhqp3slyd9TzxSC7mdeHXllMdSzer+j7jufz8ucs2fPyrL333/fjJ8/f17mbG5umvFPPvlE5nz22WdmfGpqSuao/tdMrTxOhxDXX7x7b29vN+Pd3d0yZ2BgQJapcW9nZ0fmbG9vm/He3l6Zc/z4cTN+8uRJmaPmshBCaGuz/9+Fcrksc9SYnMvpJYOqH28MUPUTQgjFYtGMe/et2kOrtHFPs+YL1R483r1ls1kz7r0n1We83+ns7DTj3vphZWVFlsWsO4aHh8342NiYzFHzgmrfIcS1Vy8nZuxXOc1eR8X0aTXmeGP1+vq6GZ+fn5c5XhtXc35fX5/MGR8fb/h31DzX398vczo6OmSZapfT09MyR80/3rykylQfCyGEwcFBWab6ujcWqnqNWW83W5L90HummP2FN7aquvXqXK0tDh06JHMuXrxoxk+fPi1zvDr9y1/+YsY/+OADmXPt2jUzrvYdIfhrLMV7f6pevZyYNQL+hdeGvDrf2toy4w8ePJA56t3GjO9LS0syZ2JiQpadOnXKjM/MzMicy5cvm/HPP/9c5iwuLprx2LVus/YKzVwvJb2eixk7YnjvMGadHnOtUqlkxtX+JoQQjhw5IsvUdyfveuob7o0bN2SO2kN77zVmjvEkuVf4of2FmQsAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpwKEGAAAAAAAAAABIBQ41AAAAAAAAAABAKnCoAQAAAAAAAAAAUiH3rG/gP2pra/ycJZfTjzEwMCDLJicnzfhrr70mc958800zvm/fPplz//59M/5//+//lTkfffSRLJuZmTHj+Xxe5qj76+3tlTmq7rx3tLm5KcuUUqnUcE61Wm04p9nq9boZz2QyMkeVqWvF/k5MP/Ooe6jVag1fS/XLEEJ4//33ZZnqt+3t7TLnypUrZvzTTz+VObdu3TLja2trMserB/Westlswzkx7SQNYu69Wf3CG3fHx8fN+IULF2TO7u6uGR8bG5M53jyndHZ2yrL9+/eb8aGhIZmjxvGHDx/KHK9sdXW1od8JQfczr/8lPRbGUu3Vuz/VlmPaeGwdqfWXty7r7+834xMTEzJHtb3l5WWZs7CwIMsKhYIZ98bdAwcOmPGRkRGZo9qxt4aJWd947zzJnDTMI6otb21tyZypqamGrhWC/95V+/fal2rjMX3Te7fr6+uyTK1jlpaWZI6a544dOyZzVP309PTIHG+/ouazcrksc9Kwj2iGpPckXr2qPK9fHDx40Iz/5Cc/kTk//elPzbgaw0MI4c9//rMs+/DDD834N998I3PU2O/Vt6oHL6dSqciymHWwGm9i1iJpENPGFW+s9uaf6elpM76xsSFz1F7Uaw/qHrz9wG9+8xtZptrE3bt3Zc6f/vQnM37jxg2Zs729bca7urpkTswY5eW0+r7b64Mx95Fkv4gVM34pXr9QZd4a74033pBlau3jraM+//xzM+7tk9V+WO1vQvDH8STXRM9ir9Aau3kAAAAAAAAAAICn4FADAAAAAAAAAACkAocaAAAAAAAAAAAgFTjUAAAAAAAAAAAAqcChBgAAAAAAAAAASIXcXl7c+8vnqszLUX+xvbu7W+aMjo7KspMnT5rxV155ReYcOXLEjKu/QB9CCDdv3jTj169flzkbGxuyrK+vz4zv379f5qg6UtcKIYRCoWDGNzc3Zc7i4qIsU+9ve3tb5qj2UC6XZU6j12q2mPvIZDINX8/L8cqSvAf1zkMIYXx83Iz/9V//tcx59913ZdnAwIAZ//bbb2XOH/7wBzPu9c21tTUzXqvVZE42m5Vlql69umv0Wq0kpr3G9Bn1PiqViszxxqKdnR0z3tnZKXPOnTtnxnt7e2WOGvu9sdqbA9U43t7e3vD1vHnp9u3bZvzq1asy5969e7JM/Va1WpU5SkxfahVe21d9Jmbt5fHqL5/Pm3GvX6h12djYmMxR/fnJkycyZ3V1VZYNDg6ace+++/v7zfjQ0JDM6enpMePeWOPNJTHzRcyY2+q8dqzGeK+OvLai7O7uyjI1Xqv+4vHGPHUP3p4kZv3szTFq3e/VT0dHR8O/45V1dXWZca+fqfYf0y+avb941n3a+52Y+dbbv168eNGMv//++zLnpZdeMuPeHvW3v/2tLPvTn/5kxufn52VOLmd/YonZD3iSbntJ9osXjTd3e2Py8vKyGffmJfVbaq8Sgp5LLl26JHNOnToly1Qbv3btmsz5/PPPzbiqgxD0fBHbJmO+Qba6Vrj3pL9Hqbkk5nuBVz+qfZ0/f17mvP3227JM7fH/8pe/yJwvvvjCjKtvTiHoucRbZya9P3zWa5F/K707fQAAAAAAAAAA8ELhUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpwKEGAAAAAAAAAABIBQ41AAAAAAAAAABAKuT28uKZTEaW1ev1hnOy2awZ7+zslDmDg4Oy7MCBA2Z8bGxM5qjf2tjYkDmlUsmMj46Oypz+/n5Z1tHRYca7u7tlTm9vryxTNjc3zfj09LTM2draarhse3u7sRvDv6P6jNeXPLVareGcfD5vxvfv3y9z3n33XTP+/vvvy5yDBw/Ksjt37pjx3/72tzLnypUrZnxhYUHmVKtVM67GpxBCyOWSHWpj3rkac5sttl1avGcql8tm3Burp6amZNnDhw/N+LFjx2TO4cOHzfjExITMaWuz/1+D9vZ2mePVqerP6+vrMufx48dm/KuvvpI5H374oRn/+uuvZc7MzIws293dlWWKqjsVD6H1+4V3fzH3HpPj1V9XV5cZHxoakjlq7eWtU4rFohlfXFyUOaurq7JM9SdvHaVyCoWCzFHv1ZsvvPr2yhq9hxeNWouHEEKlUmk4x1u7qnnGW9urd6vmshD0OK7WKSH47SGmHtRewRvDVZ9Ra8kQ4vpm0vvQmPVxq4h5XlXmjUPe2NbT02PGJycnZc7bb79txl999VWZo+7vk08+kTl//OMfZZna93r1oNqyNwerfpvmdtdMMXNdkjmxezA17qp4CHpe2NnZkTkjIyNm/NKlSzLn9OnTskyN/V9++aXMUfsLb86K2UN7dafKYtbHMe1nL/YdSd9Hs/ZGMetd71m9tYoyPj5uxt955x2Zc+bMGVk2Nzdnxj/66COZc/v2bTPurf+87wJK0vvGJL9B/tA2x7/UAAAAAAAAAAAAqcChBgAAAAAAAAAASAUONQAAAAAAAAAAQCpwqAEAAAAAAAAAAFKBQw0AAAAAAAAAAJAKuSQu8kP/Wvn31dZmn8Hkcvox8vm8LFP3vbm5KXOWl5fNeK1WkzmHDh0y495frfeup/6ivKqfEEIolUpmfG1tTeaoZ93e3pY5xWJRlpXLZTPutR9VD179vGhUe/DqVeWEoNtRNpuVOQMDA2b8/PnzMudnP/uZGT9x4oTMmZ2dlWUffPCBGf/oo49kztTUlBmvVCoyR40pXv9LWsyYG9NOWl3M2LGxsSFz7ty5I8v+8pe/mPGuri6Zc+HCBTN+7NgxmePNC8r6+rosW1hYMOP37t2TOepZL1++LHOuX79uxpeWlmSOmpc83nyvpKGNq3v0xmrVxr2xKGbu9K6nxkM1J4QQQn9/f8O/s7OzY8ar1arM8fpmX1+fGe/o6JA5SY6h3rN6c22S9xCzRkhDX1K8eV21I29NG1O2u7src2LGftWfvXHDo8Zkb6xWZd6zqr7p3XfsMymqLae5XzRrHPDm4UKhIMuGh4fN+NmzZ2XOuXPnzLiaR0II4datW2b8ww8/lDm3b9+WZWp86O7uljmqXtVeOATdn2PbV8z3gph+1ir9ImYdpcSMRbHjV8y6TM1n3jxy8uRJM37x4kWZ09nZKcu++uorM37t2jWZo9Zy3rih2qvXl2L6mSfpby2tTt27V3cx/d1bw8e8J/Xevf2A+lb16quvyhxvDP3yyy8bioegv8d6c23MO/LWwc1aE8WMn98H/1IDAAAAAAAAAACkAocaAAAAAAAAAAAgFTjUAAAAAAAAAAAAqcChBgAAAAAAAAAASAUONQAAAAAAAAAAQCpwqAEAAAAAAAAAAFIhl8RFMpmMGa/X6zKnrc0+T6lWqw3/fqlUkmXr6+uybGZmxoxfu3ZN5uzs7Jjx7u5umVMul814e3u7zPHqYXt724x7zzo3N2fGFxcXZc709LQZX15eljnePWxtbZlxVach6Hfr1Y/X7lqBd3+qL8VeT8lms7JM9c3e3l6Zc/LkSTP+2muvyZzjx4+b8Y2NDZnzySefyLKPPvrIjD948EDmqHZUKBRkjnpHtVpN5nhl6noxbcHT6v3Ck+R8USwWZZka80II4fLly2Z8YWFB5nz55Zdm/Pz58zKnq6vLjFcqFZnjjeOPHz8243fu3JE5169fN+NqzgxBj+Mx64AQ9BgVM3Z5WqVfxKyjYsaimN/xqDrv7OyUOfl8vuF7UGPyyMiIzPHmrOHhYTOu1msh6Llpc3NT5qg1TMw7elqZourVu1ar9IsYqk1644OaS7z9hTcmqzLvemof4a1Hcjl7G6f6WAhx79Z7VtWWvb6k6sHL8e5BPVMrrLdbnfdMMfNwT0+PLDt48KAZP3HihMwZHBw0497aS+0Vrl69KnO8cdzrT4oaU7yxX4mdE2LWRGnuFzH3nuSayMuJuZ7XVtTY762JXn75ZTOu+mUIfj/76quvzLi3l1Jjh/dNTNWDtwf05ouYNUJMO2mVfhFDPW/MOipmzPPyYuas8fFxmXPu3DkzrvYJIYTw6NEjWfbZZ5+ZcbUfDyHue5Sqh6S/R3nzfZLj5A/97sW/1AAAAAAAAAAAAKnAoQYAAAAAAAAAAEgFDjUAAAAAAAAAAEAqcKgBAAAAAAAAAABSgUMNAAAAAAAAAACQChxqAAAAAAAAAACAVMglcZF6vW7GM5lMw9dqa9PnLNVq1YyXSiWZs7i4KMuuX79uxre3t2XOrVu3zHh3d7fMqVQqZrxYLMoc7x6Wl5fN+NbWlsxZXV0145ubmzJH3V+5XG44JwT9nrwcVXe1Wk3mxLS7ZvLuL8m+5OV4/ayzs9OMj4+Py5wTJ06Y8WPHjskc9azfffedzPnss89k2b1798y4Nz4UCgVZpqi2p54nBP9dqLLY6z2PVF1ks1mZo+YLNaaEEMLOzo4sm5qaMuPz8/My58svvzTjf/d3fydz1DN59727uyvL1Fzi5XhjvKLGFG+siS1TVN9MQ3/x+nujvOdNevxSvOuptqz6bAghdHV1NRQPIYS+vj5Zpn5rZmZG5qj135MnT2SOWpc1s76TzGkVMesob0zJ5eztUOzYodqXt95VfVOtyUIIoaOjw4x784XXz9Qc6K2V1G95+xhVr2qv4t2bV+at/2LGwudRzFyr+ksI/n54aGjIjHtj9fr6uhmfnZ2VOZ9++qkZf/jwoczx+oVal3lrJXU973dUv4jdz8XsL1pd0nvomHWjGvNivmF5vHtQa59Dhw7JnMOHD5txrx0/ePBAlqnvaN5YrerIm7NUTkxfelqZ4n13SquYvhTDu5b3DmP6WW9vrxmfmJiQOer7lpp7Qgjh7t27skz1C2/fHTNWq/pp5veoGHu1J+dfagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpwKEGAAAAAAAAAABIhVwSF2nWX0tXvL8mv7S0JMt2dnbM+JMnT2ROR0eHGc9mszJH/XV6FQ/BfyZVVq1WZU6tVpNljWpr02dhMffg3VvMfat2p9ppK4npS+p9eO8pn8/LsoGBATM+NjYmc0ZHR814LqeHmMePH5vxb7/9Vubcv39flm1vb8uyZvDq23t/aW6vzRJTF6rteWOUV6beU7lcljlbW1sN56gxz2tD3jip5iavTlXdeW1caWY7ftH6jGoTSa+9vH6h1iOLi4syR439PT09Mke92/7+fpkzOzsry5aXl834vXv3ZI6am7zf8fp6jGatq59HMWOet4bxqLHSe3+lUsmMe/1P7WNi9iQh6Pvz+plae83MzMgctZdSY0MI/n5uc3PTjMfO9y8Sr02qduS1L6+fqbXKwsKCzFFj6NzcnMy5evWqGV9fX2/43kLQz9sK+26Puoc0r5Vi5kAvJ2bfrXK8d+61FXU9b/7p7Ow04319fTJH3Z+37rl27Zosm5qaMuPFYlHmqHqN6S+x/YJ11L+IqQdv7IhZ93jUuNve3i5z1FpleHhY5qhn8tYjN27ckGVq/+OtvZIch2LH97TPF/xLDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpwKEGAAAAAAAAAABIhdxeXjyTySR6vXq9bsar1arM8cqKxaIZX11dlTnZbLahewshhFqtZsZLpZLMqVQqskz9lrq3EEIoFAoN58RQzxqCbg9e3cW0oaTbXTOpuvCeSeW0tekzy/b2dlnW399vxvv6+mROPp834ysrKzJnbm7OjD948EDmrK2tybKYfqHq1atvVa9e20fzxbQHb76IoX7LuwfVvrxx0hMzpqi2HDO+e2LG/jSP780SM1/E1qtaqywuLsqccrnccM61a9fMuDeXee1rc3PTjC8sLMgcdX9bW1syR/V12vHeSXIsauZ7Um3Fm5fUfas+9jQx6xvVL1SfDUE/66NHj2TOzMyMLFP92dtnqbqLnWvTKma+8NqD1/bm5+fNuPee1P2pPUQIITx+/NiMq31/CP6eSfXBmLbi/U6z1lH4YWLGjpgy7/2p7zoeNYZOTU3JnNu3b8sytV7yvmEp3rMm3Y7pF/+iWeONN+ap70chhJDL2Z+pe3p6ZM7Y2JgZ975hqTX80tKSzPHmH9X+vT6r1kQx84U3P8fMWWmZY/iXGgAAAAAAAAAAIBU41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEgFDjUAAAAAAAAAAEAqcKgBAAAAAAAAAABSwf6z8i1K/YV176+ye381Pob6i/Yxf03ek8s1/mqy2WzDOTF/0T7pZ1W/g3+VdJ17baVWq5nxYrEoc9bW1sz41taWzFlaWjLjq6urDd9bCCG0t7eb8VKpJHNU2/PaZMy7oI3vjaTrNZ/PyzL13r17iJl/1PWq1arM8dqk6jPevanrxTxP7PxMn9kbMfO6N1+oPK+9Li8vm/GNjQ2Z8+jRIzPutSGvTPULb74ol8tmPKatenOZJ+a3kl4/PI+S3l+oPO96zVpbxMxZ29vbMmdmZsaMr6ysyBzV/r0xQK0zQwhhd3e3od8JgX7xfag68urV2yssLi6acW/dr67ntYednR1ZpiS9vklyHeVJegx40fpFkuNu0utdb0+ixKyjvPF9ampKlsX0M/WsMWu5Vvge9aL1F4+qP28P4ZWp9t/T0yNzurq6zLi3J1Hfo7w5Ru1jQtBtolAoyBy1v2hm+0r7vpt/qQEAAAAAAAAAAFKBQw0AAAAAAAAAAJAKHGoAAAAAAAAAAIBU4FADAAAAAAAAAACkAocaAAAAAAAAAAAgFTjUAAAAAAAAAAAAqZB71jfwH2UyGVlWr9fNeFtb3NmM+i3veuoeVNwry+V09XvX8+ooyZxardZwDppPtZVqtSpztre3ZdnS0pIZL5VKMmd1ddWMe+1ua2urod8PwX+mbDZrxr1+pu7P638xkr4eni5mzEv6d2Leuxp3vd+JKfPuLWZOTXp+RnPFtq+YNq5yKpWKzFFjf9L37a17kuwXsXXKXNJcse8pZhxPUuzvqGcql8syR63ZvPVazBjg3YOqb/rL08XUUcy7CCGE3d1dM+61V9UmvHtQ1/P2A56YOlLzRSu0yVa4hzSLmdc9qq14Y6jaQ09PT8uc+fl5M676pfc7IejvAjFrpaS/bSW5NsW/iqnzpNdROzs7Mke18WKxKHPy+bwZ99r++vq6LNvY2DDj3vpGYT/w/fG1AQAAAAAAAAAApAKHGgAAAAAAAAAAIBU41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEgFDjUAAAAAAAAAAEAq5J71DTQik8kkej31V+Or1Wqiv6N4zxNTpp7HE5OT9HvA3qhUKrLMa+M7OztmfGFhQeY8evTIjGezWZlTq9Uaij+tLKYtq+t514r5HaRDs8bQmOvF/k6zxmvmhedXs9YJXk5Mv2jl9Q3zyPOtra3x/2dMtYmYfuGtlTzqt4rFoswpl8sN/06z+jN+mJh9csweOqaNx2hmG6K94t/y5gTVVrx9/MbGhhnf2tpq+Hdix92YOSsGfSkdYt67927V2sLrF6r9z8zMNHwP3r0l/T0q5lrN6n9pwb/UAAAAAAAAAAAAqcChBgAAAAAAAAAASAUONQAAAAAAAAAAQCpwqAEAAAAAAAAAAFKBQw0AAAAAAAAAAJAKHGoAAAAAAAAAAIBUyNTr9fqzvgkAAAAAAAAAAICn4V9qAAAAAAAAAACAVOBQAwAAAAAAAAAApAKHGgAAAAAAAAAAIBU41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEgFDjUAAAAAAAAAAEAqcKgBAAAAAAAAAABSgUMNAAAAAAAAAACQChxqAAAAAAAAAACAVOBQAwAAAAAAAAAApAKHGgAAAAAAAAAAIBU41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEgFDjUAAAAAAAAAAEAq5L7vf9jX17eX9wE8U+vr61F5+/fvT/hOkFb1el2WZTKZJt5JchYXF6PyJiYmEr4TJC3p9updL8nfaQVTU1NRecwXeJ7FzhcHDx5M+E5eHM/buPs8rqOePHkSlTc0NJTwnQCtY3l5OSqvUCgkfCdA6yiVSlF57C/wPPs++wv+pQYAAAAAAAAAAEgFDjUAAAAAAAAAAEAqcKgBAAAAAAAAAABSgUMNAAAAAAAAAACQChxqAAAAAAAAAACAVMg96xtoRZlMRpbV6/WGcxq91vNK1dGLVg/PoyT7Rczv7MVvNepZ/z5eXEmPoTH9mfb/Ykpy7ZP02svrF81q40n3TdZRzdXMNUcrtMmY6zVrDAD+rdixv1laYaxuhXtAusXMF0nPI+oeaMf4vpq5fo/Ji+lLtP9/j3+pAQAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVcs/6Bp4l9RflY/6avJejyry/aB/zWzH3HXMPXo5XFnN/2Bveu0i6TTR6D9612tr0OWxMf07yvmnf6dAK7ylmnIwdd2u1WkO/44npf0i/VpjXmzXuqv4SQvPmOTRf0uv+JHltUt2DN1Zns1lZptpl0mNAtVpN7FqepO+bfts6vH7RLDFrr9jrxWiF9S72RsyaKOl9tyqL2a/E9KWYuRHPtyTblyemn8V8j/L6H/49agoAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpwKEGAAAAAAAAAABIBQ41AAAAAAAAAABAKnCoAQAAAAAAAAAAUiH3rG+gFWUymYZz2toaPx+qVqsN54QQQr1eN+O1Wk3mZLPZhn9H1UNM/aC1eO8wyffr9QtV5v1+zPVUf/FUKhVZpvqZ1/9i7gE/jKpzr321wnuKmUtirue115ixPyYnpr5b4R09j7x6jXnv3vVUmbcmUjlef/Gup8Z4r1/E9E1VP96azPudJPsmmi+mX8Tw3nk+n5dlhULBjHttUvWZUqkkc2L2MR51vZg6pb/snSTrNum1QMz1YtZRsXOtkvSaEenQrPkil9OfClWZl6N+y1uvlctlMx47n8b0TTRfzHiY1m80ak+Q9P7Lk+Se/Fmso5gJAQAAAAAAAABAKnCoAQAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKRC7lnfwF7z/vq6+ovt6i/QhxBCW5t9DuTlqLJqtSpzKpVKw2Xes8bcd8xfrveeSd2Deg9emZeDp1PvwhPTvjo6OmROLmcPPyoeQvLtVfWlUqkkc1RZTJ/1xPSLmDpIM6+OVF00c+xQ9+D1v5hxslaryTKV193dLXMGBwcbzlG2trZk2fr6uiyL6WfMF0/XrLHDa+OqvcaM/d59x6zLYvpmsViUOepZY+bgEHS/SLqNP499ppnPFDMWqTKvreTzeTPe09Mjc/r6+mSZyvPW9moc98Zq1S+8ucwT258sMesKfD9J9sGYvbonZo0Vu49X1DN5c2OM53F8x7+IWRN1dXXJnKGhIVnmzSXK5uamGff2A+Vy2YzH7H1itcKe8nkUsybyxIy76t16fam9vV2WqW9far0Wgh7jvTau9gNejupLIei6S0sb519qAAAAAAAAAACAVOBQAwAAAAAAAAAApAKHGgAAAAAAAAAAIBU41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEgFDjUAAAAAAAAAAEAq5J71DfxHmUzmmf+Wdw/ZbNaM53K6KtX1KpWKc3daknVUr9cT/Z22Nn1OVqvVGr4Hxbu3mOs1U9J1HnOtmHvw3m2hUDDjHR0dMqe9vd2Md3Z2yhyvrKury4zn83mZs7OzY8Y3NjZkzvLyshlfX1+XOV59q37haeY42cpi2njs+BAzXzQrx2tDqm+Ojo7KnKNHj5rxkZERmbO1tWXGHz16JHPK5bIsK5VKZtx7fzHvVuU8r30s5rm89qXWRJ6YdZQa34eGhmTO4OCgLOvp6THjfX19MkfNgV79qHa8uLgoc1ZWVmSZmme8OatarTYU97TK+ipmDRPT9pMebzzq/tRaKYQQBgYGzPiRI0dkzqFDh2SZ6merq6sy58GDB2a8WCzKHFXmtcmYOTDmnT+vY7+S9PM2q/5ifsdrX944rvK8HFXm7aVUWey+MWYd/KK1/yQlve+O2St4azK1Jx8fH5c5J06ckGXDw8Nm3Bv71Z7A2w+o/UXs/PyirfuTlOQ+62llMe9DrZd6e3tljtrbHj9+XOZMTk42fD3vG9b29rYZX1pakjlq7fXw4UOZMz8/L8tUP1P7mBD0PBfzbeuH4l9qAAAAAAAAAACAVOBQAwAAAAAAAAAApAKHGgAAAAAAAAAAIBU41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEiF3LO+gf+oXq/Lsra2xs9gMplMw9fL5/Myp1AomPFsNitzKpWKGfeetVgsyrLd3V0zHvOX5nM53QRUmZfjvSPveRXv/TWaE/P7e8F7piTv0btWTL/w3q0q89pKZ2enGe/t7ZU5g4ODDZf19/fLnFKpZMYfP34sc7a3t834+vq6zPH6ZrP6hfqdmGs1W0wdJV2vMfWk3nvSv+P1ze7ubjN++PBhmfPyyy+bca//PXjwwIwvLCzIHE8rjIXPI1UX1WpV5nh1FLPuaG9vN+NqTgghhAMHDpjxQ4cOyRyvbN++fQ3FPV1dXbJMreVWVlZkzp07d2SZ6mcqHoKem9T8F0II5XJZlrWCJOfAvbgH1Z+8HLWPGBgYkDmnT5824xcvXpQ5k5OTskztV+7evStz1BjvzUsx40bMOJ50TqPXSoNW2Bt596DKVFsNQfc/r016e3/VB705K6Z9qTHZ+ybglal+FvOtJen9/YvG+06k2krMvtv7HbUfPnbsmMy5dOmSLFPrstnZWZmj1iPT09MyR4ldmzbrO9HzOC/EjNVJf9v12rjap164cEHm/PjHPzbjb7/9tsw5cuSILFPzgrfP2tzcNOMzMzMy56uvvjLj3rc3b92v5tSY/cCzWEfxLzUAAAAAAAAAAEAqcKgBAAAAAAAAAABSgUMNAAAAAAAAAACQChxqAAAAAAAAAACAVOBQAwAAAAAAAAAApAKHGgAAAAAAAAAAIBVyz/oG/qNMJiPL2trsM5hsNitz8vm8LGtvbzfjPT09Mqejo6Oha4UQQrlcNuO7u7syxysrlUqyTFldXTXjlUql4d+p1Woyx3t/9Xq9KTmtIubeVZm6VqyYfqbiHq9vKt69edcbHBw040ePHpU5ql6LxaLMefDggRmvVqsyx5NkW47pS62imW28WTmqz+RyeupVOWoeCcFve319fWb85MmTMufcuXNm3HtH09PTZtyby7x+pp7Ju4cXbY6JoeZvr15jxrbOzk5Ztm/fPjN+5MgRmXPmzBkzfvr0aZkzMTEhy4aHh814b2+vzFFrIq8/K9466vjx47LsypUrZtwbH9R9e+u/Zq1FnqZZv6d+J+nf99672keMj4/LnFdeecWMv/baazJn//79smxubs6Mq/E9BN3+Y8ZQr75j1s6emDVtq6+jYrTC/sKbY9Q45Y1fahz35oTJyUlZNjIyYsbVviME/Uzefc/MzJjxu3fvyhyvb25vb5vx57Edt7qkv2+p63nfvdR+4NChQzJHzTEh6HWU175ixt0kv0uEENf+VX0nPc+lmXoub90TM+d7+4vDhw+b8Z///Ocy5xe/+IUZP3HihMzxxvHZ2Vkzvrm5KXPU92W1XwohhLGxMTOu+nkIfp+J2R+qnGfxPYp/qQEAAAAAAAAAAFKBQw0AAAAAAAAAAJAKHGoAAAAAAAAAAIBU4FADAAAAAAAAAACkAocaAAAAAAAAAAAgFTjUAAAAAAAAAAAAqZDby4tnMpmGy9ra9DlLoVAw4+3t7TKnp6dHlg0MDJjxkZERmTM4ONjQtUIIobu724yr53kaVXdra2syZ2FhwYzPzMzInFu3bpnx7e1tmVMul2VZrVaTZUq9Xm8oHoLf7pop5j6852o0x+tL2WxWluVy9rCg4t71qtVqw7/j3bdH9bPDhw/LnEqlYsZv3rwpc3Z3d814sVh07k7L5/NmPKa/eFR7jGlze8HrL6oumtnXY+asmBzVZ7z2pdpQCCGMjY2Z8TNnzsicyclJMz41NSVzVlZWzPjS0pLM2dnZkWWqXbbK+N4KkhwjvGupcTKEEDo6Osz48PCwzDl37pwZ//GPfyxzXnvtNTN+6NAhmeOty9Sc5a1vNjY2Gs7p6uoy4zFrU8/c3FzDZVtbWw3/Tqv0P+8+Yua0mOfy+oy39lE6OzvNuLeGefnll8241y+8uUSNyaVSSeao8cGr05g1o0fNqUm311ZZLykx66gY3hrG2yvErEPVHHPw4EGZ88Ybb5jxV199VeaotVII+juDV9+qHrz3cO3aNTPu9b/V1VVZFrMvaZUxvlli9tBK0nUXcw9eTm9vrxn35pjjx483fD3VjkPQe2gVDyFuPxAz/8SsK7yxK83zRbPu3dtfqLas1koh6P2rWiuFoNu4N7Z++OGHsuzLL780495eXe2LvL6p3pE3X3hlav2VljbOv9QAAAAAAAAAAACpwKEGAAAAAAAAAABIBQ41AAAAAAAAAABAKnCoAQAAAAAAAAAAUoFDDQAAAAAAAAAAkAq5JC6SyWQaintl2WxW5hQKBTPe1dUlcwYGBmTZ6OioGT906JDMOXLkiBkfHx+XOfv37zfj/f39Miefz8syVXflclnmbG5umvHPP/9c5nR2dprxu3fvypy1tTVZpu6vUqnInGq1asZrtZrMqdfrZtxrj83k3bsS05fa2vSZpdfPvDxFtdfu7m6Zo9q/l+P19d7eXjM+MjIic1T78upA9aXd3V2Zo/rS035LUW1ItX1Pq/QL795b4R6TrFtvrC4Wi2a8VCrJHDXHhBDChQsXGoqHoPvmF198IXPu3btnxufn52XOzs6OLFNjlDd2qfqOeXetwrv3mOeKmVM7Ojpk2djYmBl/4403ZM57771nxt99912Zc/jwYTPurZXUWB1CCDMzM2Z8aWlJ5iwvL5vx9fV1maPq7vjx4zJneHhYlk1OTprxiYmJhu/B0+p9KaZfeHNtzJzq9Rm1rvXaq+pLp06dkjkHDhxo6PdDCGFubk6WLSwsmHGvL8VQ7yLmHYUQtw9VWqWNx0h6DRizV8/l9KcFdT1vjXzw4EEz/stf/lLm/PrXvzbj3jjp7V+np6fNuLeWU/25p6dH5qh+5u2LYnj9TLWhF21/4d17zHzhlan3kfQ8Nzg4aMbVuiIE/d0rhBC2trYaiocQwurqqhnf3t6WOWrd6r0jrx68MUpR7/x5/R6V5L0n/bzeGHrs2DEz7n3b3djYMOO//e1vZc5//+//XZbduHHDjJ89e1bmqHnOqzu1zvP6n9fP1HwWM3bFrNd+KP6lBgAAAAAAAAAASAUONQAAAAAAAAAAQCpwqAEAAAAAAAAAAFKBQw0AAAAAAAAAAJAKHGoAAAAAAAAAAIBU4FADAAAAAAAAAACkQm4vL57JZGRZW5t9nqLiraJerzcUDyGEtbU1M769vS1zstmsLOvu7jbjJ06ckDkdHR1mvFQqyZzHjx+b8ZWVFZlTqVRk2dbWlhn36q5Wq5lxr23FvKNmaoV79+5BlXl9U7Wv/fv3y5zBwcGGfyeX00OWuoeBgQGZs7GxYcaXl5dljmr/Xl/q7OyUZTH1rdqD6i/e7zSbuveYNhnTL2LGmxD0+/CuV61WzXi5XJY5qh11dXXJnHPnzsmyn/70p2Z8cnJS5jx48MCMX716VebcunXLjHvzhTfPxfSLJNtJq4jptzHPq8bPEEIYHh6WZa+++qoZ/6u/+iuZ87Of/cyMj4+Pyxy1Xrpx44bMuXv3riy7d++eGV9YWJA5al7Y3d2VOb29vWZ8dXVV5rz11luyrKenx4yPjY3JHLVmbNaY+0M863krZr0Wgp5LvH6m2v/Bgwdljrq/xcVFmeOtb4rFohn3nlXNWd5+QM2N3hzsUXneHNPqe4UYzeovMWNHCHoNv2/fPpnz9ttvm/H/9J/+k8w5c+aMGZ+ZmZE5X3/9tSxT6xvvvkdHR824Go9D0Osb1S9D8NeTql/EtPFnPRb/EM2a65q5B1O/5e031Rxz+PBhmaPWMCGEMD8/b8a9+Uetfbw2nuS+0bteq3+DTFps/TWa4/WLmD7jraPUWtgbdx8+fGjGL1++LHPUnBCCbkcTExMy5+jRo2bcW8NMTU2Z8bm5OZnjfXtWc4k3FrbSeunF6r0AAAAAAAAAACC1ONQAAAAAAAAAAACpwKEGAAAAAAAAAABIBQ41AAAAAAAAAABAKnCoAQAAAAAAAAAAUiG3lxeP+WvptVpN5qi/yr67uytz1tfXZZlSrVZl2cbGhhl/8uSJzFH35z1rW5s+bzp69KgZHxgYkDmjo6OJ3YN3b9lstuGyTCYjc7yyRiV5rTTw3q3XxtV7yufzMmdwcNCMDw0NyZxczh5+KpWKzPF0dnaa8UKhIHPU+LC0tCRzdnZ2zHhsf1Zl3jtKkjdO7wXVD2P6p5cTM8d4VF7S81xHR4cZn5yclDl//dd/Lctef/11WaZcuXLFjP/pT3+SOVNTU2bce9auri5ZFtMemt2Wm8F7JlVHXo6q8/3798ucV199VZb99Kc/NeNvvfWWzNm3b58ZV20ohBCuXr1qxq9duyZzbt68KcseP35sxjc3N2WOmpu8NWh3d3dD1wpBr/FCCOH48eNm3Fv/qTnQ65tp7kvefKuodY/3nrw5WtWtWqeEoPugN06q3/HebXt7uyxTv+Vdb3t724x7falYLDb8OzF7j2a18VZZRzXrPrzfUXv1EPQ+Ynx8XOacP3/ejKt5JIQQbt++bcb//Oc/yxyvTO0J3nzzTZmj1nJe3S0vL5vx+fl5mbO1tSXLVPtPej/8rNvjDxFz7zFre+/7iLpezH64t7dXlk1MTJjxAwcOyByvHubm5sy4117VdzRv3FBjv3dv3nyR5DuPaeOt0i9ixoGYOdrLiWnj3veomG9Laq3itaFjx47JsiNHjpjxX/7ylzJH7fG9Pc63335rxtX+JgS99goh7v0lPRb+EPxLDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpwKEGAAAAAAAAAABIhVwSF6nX6w3n1Go1M57JZGROuVxuKB5CCDs7O7Jsc3PTjG9vb8uc5eVlM97Wps+H1PUqlYrMGRwclGUDAwNmXD1PCCF0dnaa8cXFRZmzurpqxr069Z6pWq02FA9Bty2vnagy1ebSTj2v1yZj+mxvb68sGx4eNuPd3d0yR/ULrx3ncnrIUu+3VCrJnI2NDTO+u7src1TdeffmUe3fa68x7y8mp5li7s8bB2LGDu8eYu5P9cFsNitzxsbGzPjbb78tc37+85/Lsp6eHjP+2WefyZx/+Id/MOPffPONzFF9xhsDvHpQmtWOW6W/xLTXfD4vc9T6YXJyUua88sorsuzSpUtmXM0JIYTw6NEjM/7xxx/LnK+++sqM37t3T+bMz8/LMrW+8d67ehfFYlHmLC0tmfEDBw7IHG8NqsaUQqEgc9TcFDPHtEq/8MSM/UrsOkrVrXe9mDWEWturcT+EEPr7+2WZeiavrWxtbZlxbx2l9m2x83PMXBvzjpSYttUqYurc23d71D7Cmy/UGuLu3bsy5+uvvzbj3rrHm0tUPxsaGpI5ah+v+ksIIdy/f9+MT01NyZyY+cLrF2luyzFivkcl+W3Cuwdv3FX9wutLR44cMeP79u2TOV57VeublZUVmaPGjqTbZMz8HHu9tIrZ8zZz362+j3jzj/qGtLa2JnPUvPTGG2/InDNnzsiyw4cPm/GTJ0/KHPU99vLlyzJHzXPet12vvlUfjH1/jeb80LmHf6kBAAAAAAAAAABSgUMNAAAAAAAAAACQChxqAAAAAAAAAACAVOBQAwAAAAAAAAAApAKHGgAAAAAAAAAAIBVye3nxmL+IXqvVGi6rVqtR91AsFs14uVyWOZubmw3dWwghlEolM14oFGTOkSNHZNmxY8fM+ODgoMxZWVkx4/fv35c5c3NzZnxra0vmqDoNQdeD9/5UvWYyGZmjxOS0irY2ff6Y9HPlcvaw0NPTI3M6OjrM+M7OjsxZXl4241776u7ubvgevPYVcw/ZbLah+NN4Y4cSM7amWczzqn7hXcvrS0nWudeOjx8/bsZ//etfy5yTJ0/KsgcPHpjxv/u7v5M5H330kRmP6Zvt7e0yxxvXYqh3lOb5wmt3qv7UWBhCCKOjo2b81KlTMuell16SZfv27TPj8/PzMucvf/mLGf/4449lzs2bN8346uqqzFlfX5dllUrFjOfzeZmj6ntjY0PmqPcXM+6HoOcz9TzePcSOha1OPVfMOiqm/4Wg35O3JlJt2Rt3VV8/dOiQzFlbW5Nl09PTZtxr49vb22bc20vFjNXeu1D9yXtHae4XzVoDqt/xxhuPqj9vnf7w4UMzfv36dZlz69YtM/7kyROZ492D6k/nzp2TOV1dXWb86tWrMkc9kzfPeXOJ2pd47TimL6VZzFiU9P5CtT2vTaq9en9/v8xR67XOzk6Zs7S0JMsWFhbM+OLiosxRvLVXzHgXsybyJPk9Ks2SXkd59afeoTce3rt3z4yfOHFC5pw+fdqM/+QnP5E5Xt9U4663L1L77j/+8Y8y5/Hjx2bca/tq3PB47zxmXlA5P3Rd83zOUAAAAAAAAAAA4LnDoQYAAAAAAAAAAEgFDjUAAAAAAAAAAEAqcKgBAAAAAAAAAABSgUMNAAAAAAAAAACQChxqAAAAAAAAAACAVMjt5cUzmUyi16tWqw3FQwihUqk0fL16vS5zdnZ2Gv6dWq1mxo8cOSJzTp8+LcvOnTtnxvv6+mTO7du3zfiDBw9kztzcnBnf3NyUOcViUZap+vbqTolpW957baaYe/dyYq7X1qbPMwuFghnv6emROdls1oxvbW3JHFXm3dvg4KAsGx0dNeOdnZ0yR1HPE0II7e3tDV/Pe0dJtkvvWuoekh6nY7VC/4ypP4/qS8PDwzLnRz/6kRk/e/aszNne3pZlV65cMeMffPCBzFlYWDDj6nlCCKGjo8OMe30ppr7VfOrlJP1em8m7PzVWdnV1yZyJiQkz7q059u3bJ8vW19fN+LVr12TOn//8ZzP+9ddfy5zl5WUz7q05vLJczl7+eutJtf7z5jm1LvPmU+/9qfXSxsaGzFH3HTPmtsI4/TRJ3qPX/7yxSLUjb/2s2riXo+TzeVnmjcmlUsmMe3Wq+lLM2OrVaUxezPVi5os09AvFu3dVf9446bUvNWctLS3JnG+++caMq3HNu97u7q7M8fYKan6cnJyUOaurq2b8iy++kDk3b940494c4+2Z1LuIWVe8aLx+ocq8uvP6TMz1ent7zbi3vxgYGGj43tQaL4QQVlZWzHi5XJY5qk3GtDvvvmO8aGN/0pL+vqWotVIIIdy9e9eM379/X+ao77Hj4+Myx2t7ql9431zVnmlmZkbmqH4Wszb1eH1TlcWMdz8UMxcAAAAAAAAAAEgFDjUAAAAAAAAAAEAqcKgBAAAAAAAAAABSgUMNAAAAAAAAAACQChxqAAAAAAAAAACAVOBQAwAAAAAAAAAApELuWf1wJpMx4/V6vSm/45XVajWZo8q8nOHhYTP+xhtvyJyf//znsmxyctKMr6+vy5xHjx6Z8YWFBZlTrVbNuPeOvHool8sNX0/x3mvSbcjj/ZZ3j0nmqHvIZrMyJ5fTXb+vr8+MDwwMyJze3l4z3t7eLnNUWX9/v8w5d+6cLDt8+LAZHxoakjmFQsGMe3WXz+dlmeJdT70/1f9C0P2sra3xc+pm9hdPTJ/27j3p51LXi+lLFy5ckDnvv/++Ge/p6ZE5165dk2W///3vzfi9e/dkjmpHXV1dMserByVmvPOodxTTtpK+t6dR9+H1aTWueG1FjZMq7v1OCCHcvn3bjF++fFnmXL161Yx765Hd3V0z7r0n775VvXprmO3tbTNeqVRkjpo3vfpW40YIIezs7JjxpaWlhnM8Xj00U0z/jJkH1fPGziOqTah1cAghFItFM+69v62tLTO+vLwscxYXF2WZ6mdqrRRCCB0dHWbcWyt5fUZJet2f5vkiSTF7Oi/H63+lUsmMe21yc3PTjKv+4v2OR+3VQwjhpZdeMuPevui7774z41988YXMmZqaMuNefXt9U82B3vj+PLZxT5Lfo2L3JKqss7NT5oyMjJjx0dFRmaPWhmptE0IIa2trsszLU1R9N7N9Jbk/bJXvUZ4k11FJP6+3TlDrJbVOCUGvhWdnZ2XO/Py8Gfee1Zt/NjY2zPjq6qrMidnPqevFrPlDiFv3x3yP2qs5hn+pAQAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVcklcRP21cu+vmKsy9RfRQ9B/Sd37nVxOP6Iq6+jokDmFQsGMj4yMyJzz58+b8f/23/6bzHnnnXdk2e7urhn/+uuvZY4qW1xclDnFYlGWKd77U2VeTkw78cqS5rW9Z30971rt7e2yTLX/rq4umTM8PNxwTrVaNeN9fX0y5/Tp07Ls0KFDZlz12RD0mOJRObVaTeZ478LLa4ak23CrixlvQtDzhddejx49asbffPNNmXPixAkzvry8LHM+/PBDWfbBBx+Y8c3NTZnT3d1txvP5vMyJ4dV3zDgesxZJ8vd/iJh7V++jt7dX5kxMTJjx/v5+mbO9vS3L7t+/b8bv3Lkjc2ZnZxv+nZix2nuHpVKpoXgIes4aGhqSOa+88ooZP3XqlMzx1qCq7qanp2XO1taWGX/Wc8/3keT8pN6f9zteHXnXy2azZtxrx+Vy2YxvbGzInLW1NVmmzM3NyTL1W95eqqenx4yreSSEECqVihn3+p8npp0kuXdttiTntJi5LmY8DkHvK729qGp7Xv9TVFsNwd9fvPrqq2ZcteMQQrh8+bIZ//zzz2XO+vq6Gff6X+y7UJLsS3uxjkp63ZjkPcTuL9RabnBwUObs37/fjHvrP3V/3hyzuroqy9Q+wusXqh7UnBmCnodjx2pVD0mP/a2yxkpy3orpY7H9Qn2/8faiqs69tcWTJ0/M+N27d2WOWleHoOcZb21/7NgxM760tCRz1Hyxs7Mjc7y+GfOdXfHaftJz1v9/3T25KgAAAAAAAAAAQMI41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEgFDjUAAAAAAAAAAEAqcKgBAAAAAAAAAABSgUMNAAAAAAAAAACQCrm9vHi9Xm84J5PJyLJsNttwTqFQkGWdnZ1mfGBgQOYcPnzYjL/55psy57333jPjP/7xj2VOuVyWZd9++60Z/+6772TO/Py8GS+VSjKnUqmY8Wq1KnO8MvWe1HsNIa4NvWja2ho/m/TqtVarmXHv3SodHR2yTN2315+LxaIsU/et4iGEsLu7m9jveLwc9S5i2r6Xo+o1DX1M3aPXVrwyxRuLurq6zPjo6KjMuXTpUkPxEELI5exp+erVqzLnww8/lGVq7FfPE4Kuh6Tn9JjreeNdTDuJydkLSdaFWtuEEEJvb68Zb29vlznb29uybHFx0YxPT0/LnOXlZTPuzTH5fN6Me+8pZqz22tfg4KAZP3funMx55513zPj58+dlzsbGhixT48CNGzcavl5M/bRKv4i5j5gcr468tqL6U09Pj8zp6+sz415/3tnZMeNen11aWpJlau8RM6Z467+trS0zHrPODEG/26Tnn2Zca69+L2YNqNq4t1by6ly1r83NzYbvwaNyjhw5InPeeustWab2/l999ZXM+eijj8z4w4cPZY5q/956Lek5MEYz23+z9jlJjx1qbR+CHkOHhoZkzvDwsBlX84jH2/N636NUHXl9VtWDdw+N/v5eUH2p2WuiGKq9eu8pyeeK+bYbgv6GOzIyInMmJibMuLf2evDggRm/c+eOzFHfj0LQe4KXX35Z5qg5xttL3b1714x7a7yYfhbzzdDL2av5gn+pAQAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVct/3P/T+cn3MXzH3rtdoTi6nH6Ozs1OWDQwMmPEjR47InNdee82M/9Vf/ZXMeeONN8y4V2+XL1+WZb/73e/M+JUrV2TO8vKyGS+VSjKnUqmYcfWX7p8m5p3HtK1Wl3R/UdfzfqdcLsuyzc1NMz4/Py9zCoWCGd/a2pI5qh1599bWps9hV1ZWGrq3EEJYX19v6N68e6hWqzIn6Xas2kNMH2sVMXUUk5PNZmVZR0eHLBsaGjLjp06dkjkXLlww4yMjIzJnenrajH/88ccy5/r167JMtQmvXyhev0hyTg+heeuKVp9jvGdS78NbE6k23tvbK3M2NjZkmVoneGP/9va2GY9pD96c4JW1t7eb8b6+Pplz5swZM/7WW2/JHLVmVL8fQghff/21LPvmm2/M+NTUlMzx3oXSKnNJkn066THF62dqnvHaV09Pjxn32sru7q4Z99b2KicEPabk83mZo8aUrq4umaPWax7vXXh9PeZ6SqvPFzFi6iGmvkPQ7cur15j7U/1MrclC0Hv1EPQ898knn8icq1evmvFisShzVF/3+p+3plX7kuexHYegnyvptaYSs/YKQY/9+/btkzlqT6KuFYLut179eHtb1Za9+SdmDFDfBbx788piqDry7jvJtcgPEXPvSf6ON19441d/f78ZP3r0qMxR33C9Nn7nzh0z/uWXX8oc75nGxsbMuDc+jI6OmvHh4WGZ433jVtRc5vGeNckx94fuO/iXGgAAAAAAAAAAIBU41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEgFDjUAAAAAAAAAAEAqcKgBAAAAAAAAAABSgUMNAAAAAAAAAACQCrnv+x/W6/W9vI//XyaTaTgnl9OPUSgUZFlPT48ZHxsbkznHjx8340NDQzJndnbWjF++fFnm/Pa3v5VlX331lRlfWlqSOZVKxYzXajWZUyqVGrrW07S12Wdo3j3EtAelWW34aZJ8phD0c1WrVZmzu7sry1ZWVsx4NpuVOeVy2YyrPhaCbkde/YyOjsoy1f698WF5ebmhewsh+Xakrtcq7fV547Xjzs5OWaba3okTJ2TOxMSEGd/Y2JA5n3/+uRn/4osvZM7m5qYsa29vN+NeP1NtL+mxyxPzW0nmNLv/qfvw5kd1jzHjV0dHh8zZv3+/LFNtfGRkROaoOcabl9T6obe3V+Z46z91f6dPn5Y5b775phl/6aWXZI6aA7/99luZ86c//UmWqbzFxUWZEzPXtrpWmIe9+lNtz5tjVB9UbT8Evc7z7s3r68rq6qosi1nbq3r1ntV7Ji8v5novEq8eVFnse0qSt7ZX67L33ntP5oyPj8uyq1evmvGPPvpI5kxPT5tx777V+JDP52WO189ipLlfNGs9p9q/1y+8967GZG++6OrqauhaIej9j7f2Wl9fl2VqXvD2JFtbW2Z8Z2dH5qg1jPdeY9550nPM87iPj6nz2PWI+h576NAhmTMwMGDGvW+kt27dMuP379+XOX19fbJMrcu8b2Kqr3vfLFS/LRaLMsfbH6rf8uYY1S+atYf/d/fyg7IBAAAAAAAAAACahEMNAAAAAAAAAACQChxqAAAAAAAAAACAVOBQAwAAAAAAAAAApAKHGgAAAAAAAAAAIBVyz/oGGqH+Krv3l+ELhYIs6+3tNeP9/f0yp1wum/GHDx/KnBs3bpjx3/3udzLnq6++kmVra2tmvL29XebkcvarrtfrMqdSqZjxarUqc2J494CnU/VXq9VkjvcOVZn3norFohnv6emROap9ef2vVCrJso2NDTOu+mwIISwsLDT8O5lMxoy3tSV7Rqx+J+nrNbv/Nev3Yt5TR0eHLBsaGjLj+/fvlzmqLz148EDmfPbZZ2bcm2O8/uzNj41eL+bdefXtlSXZXtM8x3j3rt7T5uamzJmbmzPj3pg3MTEhy958800zrsbjEEI4cOCAGZ+enpY5XV1dZtzrf/v27ZNlk5OTZvzEiRMy5/Dhw2ZczX8hhPDNN9+Y8Y8++kjmXLlyRZbNzMw0fA/NmrP2QpJ917uWKov9fVW33ryufstbw6gc1V9C8Oc5dT1vjtne3jbju7u7MkeJma88Sa+jnvXvNFvSz5Vkf1ZrshBCuHTpkhm/cOGCzPHmzT//+c9mXI3vIeg9Tmdnp8zJ5/Nm3Ks3b68XM67FvPM07y+SbOOx11Lv0Bt31byws7Mjc5aWlhrO8fYrjx8/NuOLi4syR33D8p41pl69tqDm5zSsiZpFtcmYd+HVq7dWUWP8wMCAzFHj7uzsrMyZn583414bGhsbk2XHjx8342rvE0IIKysrDcVDCGF9fd2Me/uBVthD79V6id4LAAAAAAAAAABSgUMNAAAAAAAAAACQChxqAAAAAAAAAACAVOBQAwAAAAAAAAAApAKHGgAAAAAAAAAAIBU41AAAAAAAAAAAAKmQe1Y/nMlkEsvJZrMyp1AoNFxWLpdlzr1798z4d999J3M+/fRTM/7NN9/InLW1NVmWz+fNeFtb42dU9Xo90RyvTL0/ry2o68XeQyvw7i/JdxhbD7VazYzv7u42fK3t7W1Zpp61u7tb5lSrVVm2tLRkxldWVmTOwsKCGS+VSjJHjTeq3kKI6xdJU/fQrN/fi9+LqVevj3V0dDRcVqlUZM6TJ0/MuJpHQgjh2rVrZnx1dVXmeG1P3V/S7z3p6yU9NzWa0+x+EUONh4uLizLn+vXrZvzUqVMy55133pFlr7zyihkfGRmROQ8fPjTj09PTMqerq8uMDwwMyJze3l5Z1tPTY8a99eTc3JwZ/+KLL2TOn/70JzPurf+8elB93bvvmHVFq1D9MOl1nrqeN7Z6ZapvemuL9fV1M+6tYVT7b29vlznefW9tbZlxtb4KQa+jYtaMXltNen8RI+n1dqtL+rm8tqeosfrEiRMy5+LFi2bcmy9u3rwpyy5fvmzGVdsPQe/VvXWmav/eOtPbF8V8N1Fi9zitIGYciBlvvDryxn417i4vL8sctb9Qa6UQ9D5C/X4IIdy5c0eWqTWRt/f32qsS0768d55ke0jDXiFGzNpLjStqLAzBb69q7PfW9uob0uDgoMw5e/asGf/Rj34kc9544w1Z9t5775nxoaEhmaO+Iz948EDmqP7sjUMxewVvXZbkd8sf2pfSu9MBAAAAAAAAAAAvFA41AAAAAAAAAABAKnCoAQAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKRCbi8vnslkZFmtVjPj2Wy2Kb8TQgjFYtGMLywsyJypqamGc+7evWvGd3Z2ZE6hUGi4rK1Nn1FVKhUzXq/XZY6qOy/Hexcqz3tHjV4r7WKeS+V47cF7Tyovl9PDRbVaNeOq3YWg27G6VgghrK+vy7IHDx6Y8bm5OZmzuLhoxr37VpJukzH9LLZvppXXxhWvHrz3rsbr2dlZmTMzM2PG1ZzgXc8bJ716UG3Cayvqekm3r2a18ee1X6g24Y2TV69eNeODg4Myx6ujS5cumfEjR47InNHRUTPuvSfVN70+u7m5KctUP/P65pUrV8z4V199JXPu3LljxldWVmSOx5uHn0dJzqtJ93VvTC6VSmZ8e3tb5szPz5vxx48fyxzVHlZXV2WOt8Z6+PChGb9//77MUesotccKIe5dtMIc0+i1WknMc3ltJeZ3VFlHR4fM2bdvnxk/ffq0zDl48KAZX1pakjlffPGFLLt165YZV/08BL2O8upUlXk5XttLso2nWbP2Z96cUC6XZdnGxoYZ9/av6t1ubW3JnKGhITPu3ff09LQsU/sir02q73zePTRrfG3WfJEG6nljvtPm83lZ5o39vb29ZnxsbEzmqLH/7NmzMkd9j+rv75c5hw8flmWdnZ1mXH2nCiGETz/91IyruSeEEHZ3d824t0/wytS7Tbr/7VV/5l9qAAAAAAAAAACAVOBQAwAAAAAAAAAApAKHGgAAAAAAAAAAIBU41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEgF/SfQE1Cv12WZ+svnXo5Sq9Vk2c7OjixbXl424+vr6zJHla2trcmcjY0NM+79BXrvL8OrslKpJHOq1WrDv6O0temzMO/9xbzbmJxWF1PnXo73PpSYvun1M1Wm2p1nd3dXls3OzsqySqVixldXV2WO6rfqWiHouottqyov6XaS5O80W8x8ofqF1ybVWB1CCFNTU2bca6+qHc3Pz8uczc1NMx7zbkPQ9RDTXmPmpWa2rzS38Rjqeb21wPT0tBn/4IMPZM7c3Jwse/jwoRk/ePCgzBkaGjLjPT09MkeN4wsLCzLn/v37suzWrVtm/MGDBzJHPevKyorMUWvQpOf0bDYry9Lc/pPcK3hixsmYevX2JKote+9W7Um6uroSvQevn6k5y1szqvqOnefYX8SLGYu8NbK3xlLXa29vlzn79u0z4wMDAzJH9Qs1/4UQwueffy7LVPv3nlW1L6/uVP3EzAkh6D4Ys5bD03ljitdW1JrN27+qdqTG4xBC6O7uNuPe9yhvX7S9vS3LlJg2HvNdgvH96ZL+5prP5xu+njceFotFM+7tu9U+4tixYzKnt7fXjHtjodc3r127ZsYvX74scz799FMz7u2/1Pvz5tOYfpaWOYF/qQEAAAAAAAAAAFKBQw0AAAAAAAAAAJAKHGoAAAAAAAAAAIBU4FADAAAAAAAAAACkAocaAAAAAAAAAAAgFTjUAAAAAAAAAAAAqZB7Vj9cr9cbiocQQrVaNePlcjnqHiqVihkvFosyZ2dnx4zv7u7KHPVMmUxG5mSzWVmm6qFWq8kcVdbWps+11D1478grQ7yYOvfal3c91S+89qXapIp711tdXZU509PTskzlbW1tyZz19XUz7o0B6r5j+4X3npLUrN9pFarOvfnCa3sbGxtmPGYMVX3MK/N+xytTvPYQ01ZUTjPb3YvWxtXzeuPN9va2GX/8+LHMWVxclGVXr14144ODgzKnr6/PjHd0dMiczc1NM67G8BD8/ry0tGTGkx77Vd+M7X8vWhtXkq6HpNfpSqlUkmVra2tm3GuTc3NzZty7N2/+Ub/l3be3NlRixq6Y62FvxKw5QgihUCiY8c7OTpnT1dVlxr19940bN8y4t4e4c+eOLFPrP6/tJ7kua2a/YB//dDHzRcw46e1f1Zis5pEQQsjlGv/s5+3jvXlBUXOTVz+qXr0+luS89LxKenyIaQ8rKyuy7ObNm2bcG/vVfuXIkSMyR80/at8RQghTU1OyTM0lDx48kDlPnjwx4+q7cwi6L8XOz2lv//xLDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpkHvWN/Af1Wo1WVav182499faveuVSiUzXi6XG87x5HJ2NXv37f3levVMMX/tPibH4z2Ten/YG159x7x373qqz3g51WrVjO/u7sqchYUFWaaeybvezs6OGff6eUw79voF4sWMN977864XM/bHtBXVjpNuQzHXa4V23Ar30Cpi1kSKt+7xytbX1834o0ePZE6SaxU1j4QQN//EjCne86j1n8e7HuuovREz7mazWVkWM/8Ui0Uz7vW/ra0tMx47Tqq8mL1Z0vUTO3cjnqpX7916ZYVCoaF4CCFUKhUzPjc3J3MWFxfN+OzsrMzxrqfmC+9ZlZj5j/bdWmLeR9LzupovWmGNEDP2x9QPc0I6ePtnbw2/vb1txp88eSJzPvvsMzPutS/VXr17U/OSV+ZdT63zvHas9hetMAY8C/xLDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpwKEGAAAAAAAAAABIhdyzvoFG1Ot1M16pVGROtVqVZZlMpqHf8XJyOV2V2Wy2oWs9raytzT6L8p5V5Xi8ekgyBz+M11aSzFHtOIQQCoWCGffag7peuVyWOevr67KsVquZcW98UDlJt+OYMQVPF/OeYutbjaGx43ijOaqthpD8WJ1km4ztS/SLeM2ch2Pek7dWUdQzxaxtQojrZ0n2Z9p383l1rtpX7HuKyYtpy0m3o5h6iLlv1c/oF+nnvUP13jc3N2XO9PS0Gff2A6odezkbGxuyTN13Pp+XOUrSa0b23enXrHFPjdWtsGakHadfzPrB2w/EfNfZ3d2VZUqzxt1mfVuKWes+D/iXGgAAAAAAAAAAIBU41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEgFDjUAAAAAAAAAAEAqcKgBAAAAAAAAAABSIfesbyAJtVot0et5fzU+RrVaTfR6Mfen/tq9ij+tDOkW8269dpfLJTeUlMvlqDJ1f81qx0mPG3i6VqjzZo2h3rWSrgf1W97vJD2mIB2aNb6qdVTS679mYX3VWmLWD60wfiW97om5Xsx8EaMV6hs/jFrDVyoVmbOzs2PG29r0/5cZMy94e/Uk23jS6yi8mFQ78toXYyj2UrP2okmPk80adxnf9xb/UgMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpwKEGAAAAAAAAAABIBQ41AAAAAAAAAABAKnCoAQAAAAAAAAAAUiFTr9frz/omAAAAAAAAAAAAnoZ/qQEAAAAAAAAAAFKBQw0AAAAAAAAAAJAKHGoAAAAAAAAAAIBU4FADAAAAAAAAAACkAocaAAAAAAAAAAAgFTjUAAAAAAAAAAAAqcChBgAAAAAAAAAASAUONQAAAAAAAAAAQCpwqAEAAAAAAAAAAFKBQw0AAAAAAAAAAJAKHGoAAAAAAAAAAIBU4FADAAAAAAAAAACkAocaAAAAAAAAAAAgFTjUAAAAAAAAAAAAqZD7vv/h2NjYXt4H8EzNzs5G5Q0ODiZ8J8+Xer0uyzKZTCrvwbtekr/TClZWVqLy+vv7E74ToHWsra1F5Q0MDCR7I0ALWV1djcobHh5O9kaAFrKwsBCVNzIykvCdAK1jfn4+Ko9+gecZ/WJvtML3KI+6v1a4t1bwffoF/1IDAAAAAAAAAACkAocaAAAAAAAAAAAgFTjUAAAAAAAAAAAAqcChBgAAAAAAAAAASAUONQAAAAAAAAAAQCrknvUNtCLvL80366/T12q1hnOSvoekf0fVHZ5fSbfJpNtQktdrVv9Da4mZL2Kvl+TvAM+Kaq9tbcn+fzb0CzzvWnm+SHpujPktxoDnVzPbV7P2/sAPlfSc0Kx9DLCXWv17FH44/qUGAAAAAAAAAABIBQ41AAAAAAAAAABAKnCoAQAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTIPesbeJYymUzDOW1t9jlQzLVi1Wo1M16tVmWOum9PzDPV6/WGc9B8rfCe1D0k3ZdinjXptu9dL8l30cxxCP+iFfpS0u2rWW2yWf0Ce0e9p5jxUK1tvOvFjnkqz7vvmPVf0u2YfvHi8d6512eUpPcDMfcQg/midcSud5t1D0m3yZg5S+XE9L+Y38GLKel+0aw9ecxeoRX23fhXSX9vSXLd791b0u0hyf1FzHwR+zwx+znlWcxL/EsNAAAAAAAAAACQChxqAAAAAAAAAACAVOBQAwAAAAAAAAAApAKHGgAAAAAAAAAAIBU41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEiF3LO+gSRkMplE87zrqbJsNitz2trss6NyuezcnVav1xuKx0r6enjxxPQlr93F9PWYdlyr1Rq+B9XPnyZ2/EJzJfmevGupdhQ7Hqu2nHQ/S3I+DSFunmPOar4k+0W1Wm34d2Lbg+oX3jiu7iGXa3wp7dWbN/+oOqLtp0PS70m1V69NevsV1b4qlYrMUc8Us47y7g2tI3bcj1knq/blzReqLGbN4fFy1LN69x2z/oupU/Yd6RCzvmnmt6CYdqTG+Jjfie3Pqox+8XQx7ym2TSb93hv9nWbuN5v1TSxG0vW9V/iXGgAAAAAAAAAAIBU41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEgFDjUAAAAAAAAAAEAqcKgBAAAAAAAAAABSIfesb6ARMX/l3ctRZdlsVuYUCgUz3t7eLnNqtZoZb2vTZ0o7OzuyTOXlcvp1qmdN+q/Wq2f1xLzXpO+71XnPm3S/SDLHa+Mx1/PaV7lcbjhH9dve3l6Z093d3fDveP25WCyacfU83m+9aP0iRky7CyGuzlX79/qFmn+8+65UKrJM3Z933+oeOjo6ZI7qS7H3rdp/tVpt+Hox89LzSr332H4Rs7ZQ79B7TyrH+518Pi/L1Dg+NDQkcwYHB824t/5TfalUKsmctbW1hsu2t7dljqpX+sXeialbNS+othqCbpMTExMyp7OzU5bNzs6a8YcPH8qclZUVM+6NKV7fVJJeB8f8zovGW6so3l5UvXdvDFU5PT09MidmLeCNybu7u2bcW9ur63lre3Xf3nvwninm/WFveOOKKvPebcwco/qm+rb1NKpvxrQ7b20fs4/x9hcx98e88C9ivqt6Od43V1XmzRdqn+p914l5t177UmXefKHW8N58EdMvkv6WF3MPSe9D/z/MdgAAAAAAAAAAIBU41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEgFDjUAAAAAAAAAAEAqcKgBAAAAAAAAAABSgUMNAAAAAAAAAACQCrlnfQNJyGQyUWWFQsGM9/T0yJy+vj4z3tXVJXM2NzcbiocQQq1Wk2XZbNaMd3Z2yhylUqnIsp2dHTNeLpcb/p0QQqjX6w3neO/vRZJ0PcT0mVyu8eEi5p0nzbtv1Z+PHz8uc4aGhsz49va2zJmZmZFlCwsLZrxarcocb3xQ1Lt4XvtYW5t9Zu89r9deY66n2l4+n5c56npee/DGca9dKqpf7Nu3T+YMDg6aca9Ot7a2ZNn6+roZV/OS91sx/eV5pdYPqn2H4Le9GOp9eL+j3m1HR4fMGR0dlWVHjhwx46dOnZI5AwMDZry/v1/mqL6+vLwscx4/fizL7t27Z8afPHkic9QY4K3l6DP/InYNo/JU/wshhPb2djPe29src1Q7vnjxoszxrnfjxg0z7rXXpaUlMx6zj/HqJ3buxr9Q9RezhvH2m954OD4+bsYPHjwocyYmJsz4yZMnZY66P2/ttbu7K8vUfn1+fl7mPHjwoKF4CCFMT0+bca//efet+qDXX1R78Prz87qPaJRXR16ZWvt49arGSrUWD0Gv4dW+NgS9HwhBf/vy+plaj6yursqclZUVM+71C2/vUywWzTj94uli5gv1vTUEf74YGxsz48eOHZM5ak308ssvyxyvvSre/nVjY8OMq+89Ieh54eHDhzJHzT/q90Pw77tUKplx7xtDzL57r/oF/1IDAAAAAAAAAACkAocaAAAAAAAAAAAgFTjUAAAAAAAAAAAAqcChBgAAAAAAAAAASAUONQAAAAAAAAAAQCrYf6a+Ram/pO79FfWOjg5Z1t/fb8YPHTokc/bv32/GOzs7Zc7s7KwZX1hYkDnd3d2yTD1TT0+PzCmXy2Z8eXm54RwVD8F/F21tjZ+h1ev1hn9H5aRZzDN5dZTNZmWZek8x70/12RCSf7fVatWMFwoFmTMxMWHGX375ZZmzb98+Mz43Nydzdnd3ZZnXB5Pk1Wtaec8UM1/EyOX0NNrV1WXGe3t7G/6d9fV1Wba5uSnLVL/wxgB1f+Pj4zLnwIEDZrxUKsmcmD5TLBZlTszY5Y1RrSDpsV9dr1KpRF1P1Z93PbWG8N7T0NCQGT969KjMee2112TZK6+8YsaPHTsmc1Q9eOs11c+8dnzr1i1Z1tfXZ8a9fjY1NWXGvXeUZjFjvGrHXv/zfkeVeW1ctRVvDaP2MYcPH5Y5ah8Tgt6XeM+q+rM3x8S8o+dxbd9Mqs69NYza23pt6NSpU7Ls/PnzZvzcuXMyZ3Jy0oyrtXgIfp9RvPFQlXnj+MzMjBm/fv26zLly5YoZ/+abb2TO9PS0LNvZ2THj3rPGrIli9nOtzqsHVRaz5w1B15Ma30PQY/ylS5dkzokTJ8z4wYMHZY63X1H9zKuH1dVVM67WKSGEcPPmTTN+48YNmeNdT+2LvHWUkuY27klyvhgeHpY5p0+flmWvvvqqGX/77bdljtoTeN9p1f56bW1N5mxvb8sy1Y7GxsZkjtpfe3ucx48fm/EHDx7IHG++WFpaMuPes3rfhBv1Q9d4/EsNAAAAAAAAAACQChxqAAAAAAAAAACAVOBQAwAAAAAAAAAApAKHGgAAAAAAAAAAIBU41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEiF3LP64UwmY8ZrtVrDOdlsVuZ0dnbKsvHxcTP+0ksvyZyBgQEzvrW1JXPm5+fNeKVSkTn5fF6WqfseHh6WOdvb2w3FQwihXC6bce8dee/Cy2uUagshhFCv1xP7nb2Q9P2pumhr02eWXpl6hzF17uU0eq2nlanf6u3tlTnHjh0z46+88orMUdfz7u3OnTuyTNV3TDtJc7+IkeSY8jSqz7S3t8scNSZ7Y7Uad6vVqszZ3NyUZcVi0Yx7c8zg4KAZP3LkiMw5fPiwGV9ZWZE5a2trskzVt9eOVXuIGYeeVzHjgJdTKpXMuNde1bsdHR2VOT/60Y/M+Pvvvy9z3n77bVl29OjRhu4tBN2Wd3d3ZU6hUDDjExMTMkf1vxD0fDE3Nydz1BrUu2/VZ9I8j3jzRdJzScweR/UlFfd+p7+/X+aMjY3Jsq6uLjOu5pEQdF/35saYdaZHtUuvPzd6raeVtbqYPbRqDyMjIzLHG9vU2keNkyHo9c2TJ09kjtrbqvXV0/T19Zlxby03NDRkxs+cOSNz1tfXzfjs7KzMWVhYkGWq7mK+tbxo+4uYccCrV2/NrdqKWveEEMLPfvYzM/7Xf/3XMketsbz1mvd9S5V511P7CK9f7N+/34x789Ly8rIsU/3Ma+Pq3XpzTJr7haqLXE5/OlbfXNV3yxBCOHv2rCw7f/68GT9w4IDMUevajz/+WObcvn3bjK+ursocb33T09Njxr25tru724yrth+Cnpc6OjpkjjcHbmxsmPGdnR2Zo8T0ix+6V+dfagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpwKEGAAAAAAAAAABIBQ41AAAAAAAAAABAKuSe1Q/X63UznslkZI4qy+X0YwwMDMiyEydOmPGzZ8/KHHXfn332mcx58OCBGV9bW5M5fX19siyfz5vxI0eOyJzNzU0z/ujRI5lTLpfNeLValTnZbLbhskqlInO89pBW3jOp9pX078SWKeq+vfbQ1mafqXp14JWp+96/f7/MUX39woULMmd7e9uMf/vttzJnZ2dHlnn9qVFJtp9WEvNcMe3Yexfqer29vTJHzTEHDhyQOQsLC2Z8aWlJ5qi+5CkUCrKsv7/fjKvnCSGEgwcPmvFbt27JHO+9qnnBmy9qtVrDv9Pqkp4v1PW8tq/WAiGEUCwWzbhap4Sg2/9PfvITmfOf//N/bjhnfHxclqn1l1qvhRDC/fv3zbjXN/ft22fGjx8/LnOGh4dlmeqDqv+FEML169fN+MbGhsxJsyT3F0lTY1QIIZRKJTOu1hwh6Gft6uqSOYODg7JM5cWMu97eTJXFrv9i5sCY32l1MW3cqztV5s0Xq6urskyNr964u76+bsZnZ2dljirz5jJvzpqYmDDjb7zxhsx59dVXzXhPT4/MGRoaMuMdHR0yJ+adt8JY2CqS7O9eG/K+R50/f96M/+Y3v5E5v/zlL834yMiIzHny5IkZv3Hjhsy5efOmLJufnzfjqh2HEMLFixfN+LFjx2SOWjN685w318bsFVSZ9zut3pe8+1Njvzevq/fhjXne2KbqVq1pQwjh6tWrZvwPf/iDzFHX8/bJ3jpKfcPt7u6WOWNjY2b83LlzMkfNS943J2+ujVlHqZxn0S/4lxoAAAAAAAAAACAVONQAAAAAAAAAAACpwKEGAAAAAAAAAABIBQ41AAAAAAAAAABAKnCoAQAAAAAAAAAAUkH/CfsE1Ov1RK+XzWbNeFdXl8w5ePCgLDt9+rQZP3DggMx5+PChGZ+ZmZE5qqxUKsmcQqEgy9rb2834xMSEzCkWi2b8m2++kTnq/VWrVZnj/bX7trbGz9CSbkOtIOaZkq4H7z2p38pkMjJH9c1cTg8xqsy7t3K5LMu6u7vN+NmzZ2XOpUuXzPihQ4dkzvXr18340tKSzFlbW5Nl3jigeO9CafW+5N1fTJtU7chrX97YptrXiRMnZM7FixfNuDdnbWxsmPFKpSJzvGdSfbOnp0fmHDt2zIyfP39e5qhnunXrlsxRzxpCCFtbW2bcGwO8emhUTB/bCzH9wqPqyKtXr0ytRyYnJ2XOz372MzP+t3/7tzLnzTffNOMDAwMy58mTJ7Lsk08+MePXrl2TOWr9t729LXPGxsbMuFennZ2dsqy/v9+MDw0NyRy1nvTWZN5Y2OpUv/CeV/X32HlT5cX0Z2/sV+sHNV+FEEJfX58sy+fzZtxrD6pevfWfykm63XnjeMy6otFr7ZUk79GbN3d3d824t9712uv9+/fN+ObmpsxZWVkx46urqzJHrR+8e/P6jOpn6jtCCLoveeO76hfefXtzSZL7uSTXV80W0z+9OlLvqaOjQ+aotUAIei/69ttvy5z9+/eb8a+//lrm/O///b/N+JUrV2TOgwcPZJla+3j77tHRUTN+6tQpmaPmEm//7K3LvP6ktMqeoFmSfF5vjFpfX5dlqu3Nzs7KnMuXL5tx73vnzs6OGffmBG99o/a23rddVd9eX+rt7TXjap8Qgr8OjlkjtBL+pQYAAAAAAAAAAEgFDjUAAAAAAAAAAEAqcKgBAAAAAAAAAABSgUMNAAAAAAAAAACQChxqAAAAAAAAAACAVOBQAwAAAAAAAAAApEJuLy+eyWRkWb1ebzgnn8+b8Z6eHpkzPj4uy44dO2bGe3t7Zc7y8rIZn5mZkTmbm5tmPJvNypxcTr+affv2mXH1PN49dHR0NHwPlUpF5nhqtZoZj2kn6loe73eaqa1NnyWq543hXcurP3V/3vVUW/HasXof1WpV5nh9RrX/1157Tea88sorZry9vV3m3L9/34zfvn1b5qhxI4QQisWiGY9pC0m2n2bz+qdqr147VnVRLpdljppjQtBzycWLF2WOal9TU1MyZ3V11YxvbGzIHG9MVm15bGxM5qj7PnXqlMyZnZ014wsLCzJnaWlJlm1tbZlx71lbZYxPkjdfqPbvjQMx83d3d7csO3TokBn/xS9+IXP+63/9r2b89ddflznqmS5fvixzPv7444bLnjx5InPW19fNeKlUkjlHjhwx46reQgjhzJkzskzNqd66tbOz04w/j/3F4/WLmLqImW+9OUutfbz2pXIKhYLMUe0hBD0Hxoy73npN8eo06fVNkmusZvcldR/efKF4bVK1vcXFRZnjlan7VuvgEPSazesX6n14a7zBwUFZdvz4cTOuxnfvemptE0II09PTZnx+fl7meGvamL3y87jvTvp7lCrzxt3h4WFZNjk5aca9sfrq1atm/H/+z/8pc/7+7//ejD969EjmqO9HIejnPXr0qMxR/cLbd6sxRfWXEELY3t6WZWrejHnnXr9olfafJO951Tju7V9j3qE3x6j22tfXJ3NUWex3NJXnzVkxa3uV4/VZr1+o9+fNMTHf8mLWKd8H/1IDAAAAAAAAAACkAocaAAAAAAAAAAAgFTjUAAAAAAAAAAAAqcChBgAAAAAAAAAASAUONQAAAAAAAAAAQCrYfzb9GfL+Ino2mzXj3d3dMmdkZESW7d+///vf2P9rbW3NjKu/GB9CCPl83ox79z06OirLTp8+bcYPHDggc6amphq+h56eHjNeqVRkTi6nm1Qmk2n4evV6vaG49ztpFvNMtVot6nqqbpPOqVarDcVDCGF4eFiWvfXWW2b83XfflTmqn33++ecy5y9/+YsZv3XrlsxZX1+XZYo3Fr5oVDvy2rgqU/NICCHs27dPlp0/f96Mv/766zJHzT/fffedzHny5IkZV3NPCH6fGRgYMONnz56VOeqZhoaGZM63335rxh8+fChzlpeXZVmpVDLjXr/w5gWl1eeLpOe69vZ2M14oFGTOsWPHZNnbb79txv/2b/9W5rz66qtmvFwuy5xPPvnEjP/hD3+QOWqsDiGE+/fvm/Hd3V2Zo/qZt/5T60xv3RPzXr0xQJXF9Jc0SHLu9OaYGDHv1msrapz0+rNXpp7Xqwe1x/HaV8z6z6Pq1buHmHVro9dqtpj78NpXzPvwctT9eXtH1V77+/tljtq/ejknTpyQZZcuXTLjZ86ckTlqHLpz547MUesotYcPwZ9/1D0kve5p9XWUJ2bsUDkdHR0yx2t7al02PT0tcy5fvmzGP/30U5kzNzdnxr21l1cPan9x8eJFmaP2Ut493Lx504w/fvxY5uzs7Mgy9f68tYOaA2Pafhr6ixrHvflia2vLjC8tLckcbz2yvb3d0L2FoNtkX1+fzFHvVj1PCP5eQV1vcHBQ5qhvu9636tXVVTPu9Qtv3+31wSTFjLnfB1/NAAAAAAAAAABAKnCoAQAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVcnt58Xq9LssymUxiv5PP52VZe3u7LCsUCmbcu7f+/n4zPjo6KnM6OjrM+MDAgMw5e/asLDt06JAZ7+npkTnqvvft2ydz1PV2d3dljqdarUblWZJsP83m9QtV1grP29amz0BVWalUkjm1Ws2Md3V1yZxLly7JsnfffdeMnzp1SuY8efLEjP/jP/6jzPnoo4/M+NTUlMzx6k6NUTHtJGbM9XJanVev6nnVuB9CCAcPHpRlqu2dPn1a5qysrJjxhw8fypzFxUUz7o0B3tiv5os333xT5hw7dsyMb25uypzvvvvOjD9+/Fjm7OzsyDI8neq7uZxe2nV2dprxsbExmfP666/Lsl/84hdm/KWXXpI5qh2psTWEED744AMz/uWXX8qcmZkZWba1tWXGvfFQtVe1xgshhP3795vxAwcOyJze3l5Ztry8bMa9vqnWbN6aLGaOaRVJrqOSXnt514uZo9U79HK8ebOvr8+Mq3EjhBDW19dlWZK8Z1LrSa++09CWG9WsOord36v1rjfmjYyMmHFvzjpy5IgZV+uhEEI4evSoLFN5qr+EoOcftVYKIYS7d++a8Y2NDZmj3msIIWSzWTPerO8zaRDTL2LqyJtvFxYWzPjq6qrM+fbbb8342tqazFF7BW9O8NY3ap3385//XOaofdann34qcz7//HMz7u27vfr2vhs2Kg3zSJLjeLlcbvj3vXbsfaeN+U6k5gvvd1Q9bG9vyxxv/6r2YBMTEzLn5MmTZtxrx7dv3zbjt27dkjnqG0MI+t16c4xqJzHrih869/AvNQAAAAAAAAAAQCpwqAEAAAAAAAAAAFKBQw0AAAAAAAAAAJAKHGoAAAAAAAAAAIBU4FADAAAAAAAAAACkgv3n2RMS85fPPeqvr3t/Gb5YLDb8O4ODg7LswoULZtx7VnUP3u8cPnxYlh07dsyM53L6dVYqlYZzOjo6Gs6Jea8e9c69+m51MXXk5ai68Ooom802fA+qDYWg35Onu7vbjF+8eFHm/OY3v5Flb775phn3xod/+qd/MuP//M//LHPu379vxkulkszp7OyUZTFUe4jpF63Sl2L6hdeO1XMNDAzInKNHj8qykydPmnFvHF9YWDDj3n2rezh06JDM6e3tlWWvvPKKGf/JT34ic/r6+sz4jRs3ZM69e/fM+Pb2tszx5hJV5o01qq97bbxV2n+Mtjb7/0tpb2+XOcPDw2ZcrW1CCOHdd9+VZS+99JIZ98bDy5cvm/Hf/va3MufTTz814/Pz8zKnXC7LMvXed3Z2ZI4ao7wx5cSJE2ZcjSchhFAoFGTZ4uKiGZ+enpY5m5ubZtzrS0nOMc2m7l31F0/s2BGzJlK8Nczq6qoZ9/Y+SY+7ql5j9oCx+8Y0tMtW5dVrzLrMa19qrTI+Pi5zTp06ZcbPnz8vc86dO2fG1Xgcgr+WU5aXl2WZWv95Od56SYkZo7yxMGb8VL+T5DjYSmL6xcbGhixT+0pvDTM7O2vGvf2FWqt4aw5vf/HLX/7SjL/11lsyZ2VlxYx/8MEHMufLL78042ptE4K/71ZjlDfXKs/r/kL1Xa/tqxxvTlhbW5Nlql16Y1FXV5cZV980Qwghn8+bcW9O8J5J9bOJiQmZo+7v0aNHMufq1atm/MGDBzLH2+OoelX1E0LyfeaH4F9qAAAAAAAAAACAVOBQAwAAAAAAAAAApAKHGgAAAAAAAAAAIBU41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEgFDjUAAAAAAAAAAEAq5J7VD2cyGTNer9dlTq1WM+Pb29syZ3l5WZYtLi6a8YMHD8qc1157zYxPTk7KnHK5bMb7+vpkTkdHhyzr6elpKB5CCENDQ2Z8//79Miefz8syRb3XEEJoa7PP0NR79XjtxLuHVuDdn/dcSYr5nWq1KstUGy8UCjLnwIEDZvzHP/6xzHn99ddl2cDAgBn//e9/L3P+4R/+wYx/++23MkeNN96zZrNZWaZ4/UK1IS9H9b9WEdNvvZzOzk4z7o153tg/MjJixr33rsb4ixcvypyjR4+a8ZhnDSGE06dPm/EzZ87InK2tLTP+8OFDmaPmWm8e8eYsNaaUSiWZo8a1mL6UBqpPd3d3yxy1VlFrmxBCOHv2bMP3cPXqVZnzu9/9zox/8sknMmd6etqMx6w5QgihUqmYcW9uVP1M9dkQQvjRj35kxtX8F4Ju+yGE8PjxYzOu6ieEEDY2Nsy4N6fHrNGfR7HrNTXnx+xxYuZuL8cbD1Xb88Zx9UxeO46pnxhJX+9F6xcxz5vL6U8LXV1dZlztUUMIYWJiwoyfOHFC5pw8ebKha4Xg93U1hhaLRZmj1oZqLRlCCEeOHDHju7u7Dd9bCMm21zTvL2J4daSe1xvzlpaWZNndu3fNuPfeFxYWGr4HZXBwUJadP39elr3zzjtmvL29XeZ89NFHZvzjjz+WOfPz82bca3fenKXyvDUR/kXMfsobJ3d2dmTZ+vq6GffauNojejmjo6NmfHh4WOYcPnxYlo2Pj5tx73uB2l8/evRI5szNzZlxtb8JwZ+f1bv1+oUaJ2P2Fz/U8zcLAQAAAAAAAACA5xKHGgAAAAAAAAAAIBU41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEgFDjUAAAAAAAAAAEAqcKgBAAAAAAAAAABSIfesb+A/qtVqsqxUKpnxtbU1mTM1NSXL7ty5Y8ZHR0dlztjYmBnft2+fzKlWq2Z8Y2ND5qyvr8uyzc1NM37s2DGZMzg4aMb7+vpkTjabNeOVSkXmxPDeeb1eN+OZTCbRe9gLMfeuytS1QtD119amzyy9Olfv18spFApm/NSpUzLnv/yX/2LGf/WrX8kcr29+9913Zvyf/umfZM4333xjxre2tmROe3u7Gc/n8zJH9aUQ/HerqHfhta1W6UtJ9guvjav30d3dLXNyOT0lqvHam3+6urrM+Pnz52VOuVw2416b9OpOzQuqHYcQwv37983448ePZY66P69fqHEjBD1velqljSfJa+PqHQ4NDcmc06dPm/GXX35Z5vT29sqyu3fvmvEPP/xQ5vzlL38x40+ePJE5av3X0dEhc7w5S/Gud/DgQTN+4cIFmaPq21t7PXjwQJapdavXN3d3d814GvpFzJooJkeVeTle33zWvPnCG1sHBgbMeGdnp8xRc5Y3n6p3lHSbjFkTPa/UOjRmnPTq1Vvvqv3F9va2zFFrr7m5OZmjxnG1tglBj5Mh6DbuUfWg5oQQdP14/dl7pmKxKMuUmD1lmvuSassx3ya8+vb2Cqp9eW3S6zNKf3+/Gfe+H73zzjuyTOXNzs7KnMuXL5vx27dvyxy1/lN7rBD8vYd6tzFrhDTsu2Oo/u59A1TP5a05vLFV9Rn1HTQE/f3Uq3P1bXd4eFjmeN+jenp6Grq3EEJYWVkx494YoL5nqHVcCHHfWrz310rzReuuyAEAAAAAAAAAAP4NDjUAAAAAAAAAAEAqcKgBAAAAAAAAAABSgUMNAAAAAAAAAACQChxqAAAAAAAAAACAVMh93//Q+2vpSf4Vc/VX1EMIoVKpmHHvr8nfuXNHlqm/5j49PS1zDh06ZMY7Ojoa/p35+fmGc0II4cSJE2a8t7dX5gwMDJjxnp4emZPL2c3DuzevTLUTr/2o9uC1R6+smdR9eM8bk6PKVH/xfieEENra7LPO7u5umXP48GEz/qtf/Urm/PrXvzbjJ0+elDl3796VZf/jf/wPM/4P//APMmdqasqMe/WTzWYbzvHGNa9MUb8V0/aTHL+/j2fdL4rFosyZnZ2VZV988YUZn5mZkTmqz3jvvFwum/HV1VWZMzY2Jsvy+bwZX1lZkTnqWVU8hBAWFxfNuHqeEPwxSpXF9BdPTNvaC+o+1DwcQgjt7e1mfGRkROa89NJLZtxrQ2tra7Ls888/N+OffPKJzLl9+7YZ397eljlqjRUzBoQQQqFQMOOTk5My58c//rEZf++992SOut7W1pbMuXXrliz77rvvzPjc3JzMUX0pZp7bC83aX3hi1qfeejdmnaDWXt497O7umnFvX+SNoaqfeeNQzBpUXU/VQayY9hOzjtqLfUfS/aJZfcl775ubm2bc23erNYSX09fXZ8a9cVf1pRBC6OrqMuPDw8My58KFC2b8+PHjMke9I+9ZFxYWZNnOzo4ZT8NeIY28OUG1/RB024tZ33jfddR65K233pI5at0Tgp4v1LowhBCuXbtmxr3+19nZacbVOi4Efw0Ts79o1lzSKtTzxsxLXt2VSiVZpt6Tt05Q7121oRBC6O/vb+haIfjfcNV47X0vUPss777Vvs27b2+MUu8i6flir/oF/1IDAAAAAAAAAACkAocaAAAAAAAAAAAgFTjUAAAAAAAAAAAAqcChBgAAAID/h707e5LruvJ7v7JyqnkeUZhHggQIiiApSuq21JI6usNhR/jR4X+ybUd0ux0hyeqm1JRIcQQBYh5qnufKyjnvg3yvHbr7t8DcPCjkAb6fx7W5ztl5zh7PJqIAAAAAIBU41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEiF3Hf9D1utVqI3zmQybcW9Ouzu7sqcg4MDWbayshKMP3r0SOaMjIwE48ViUeao31Qul2VONpuVZVtbW8H4pUuXZE5fX18wHvNevZxardb29bx3/rppNpvBeNLvKZfTXb+/vz8YP3nypMz52c9+Foz/h//wH2TOW2+9FYyvrq7KnP/6X/+rLPvtb38bjC8tLcmcer0ejHvPp6ur/bNgdR+Pd5+kx+NO4I0Dqkz1FzM9Fm1sbMicO3fuyLLl5eVgXPUXM7N8Ph+Me+1BzQveHPP3f//3sky1lcePH8uc3/zmN8H4F198IXPU81bPwMysUqnIsmq1Gox77zxGmvtSoVAIxqempmTOqVOngvGenh6Z8+zZM1n2zTffBOP379+XOWrN5tVB/daYuczM7PTp08H4X/3VX8mcn/70p8H4lStXZE6j0QjGvb70P//n/5RlX3/9dTCu1oVmei7xxtyYeS7Wce0vkhYzZ3nPVa37VRvyqPHzeddTfXBoaEjmqN8as+7xnmnSY3+M45wvYu4V0/Zj9t3eu/Deu7qe1ybVOsFby6n6HR4eyhyv3mr9NTs7K3NGR0eDcW++mJmZCcanp6dljjdvqvEmzesej/pdMWN1TF/ynmvMeOitb9R3HbW2MTO7fv16W3Ezs+HhYVm2uLgYjD948EDm7O3tBeNeO46ZT70xRb0L7/29it+qYn5TzNrQe64x83pvb68sU/sf7xuWup7a95v584/69ux9r1Z7nImJCZkzNjYWjHvvyJsDVd+Meecvo7/wLzUAAAAAAAAAAEAqcKgBAAAAAAAAAABSgUMNAAAAAAAAAACQChxqAAAAAAAAAACAVOBQAwAAAAAAAAAApELuZd241WoF495fS4/5S+pHR0dtl21vb8sc9dfpe3p62s7x/pp8d3e3LJuYmAjGt7a2ZE65XA7Gs9mszOnr6wvGczndbKrVqixrNBqyTFHPyGsLMW0rzdTvUu3OTL9bM7MTJ04E4z/4wQ9kzk9/+tNg/MKFCzJnd3c3GP/v//2/yxyv7N69e8G41yaLxWIw7vVN1b7q9XrbOWZx7fJVbcuKen7ec61UKsG4Nw4dHBzIsoWFhWA85l14baXZbAbjb731lswZGxtr+3q3bt2SOZ9++mkwvri4KHMGBwfbur+ZWa1Wk2XqGXnvPGa+ULz7HKeYuqt3YabXD8PDwzLH6zOHh4dt56j5Z2RkROb09/cH49PT0zLn8uXLsuz9998Pxn/84x/LnNOnTwfjm5ubMuerr74Kxn/1q1/JnI8//liWra6uBuNeP1P9wlv/dYok+27Mtby1QNL7FZXj1UGNk2r+M/Pbilrfe+tJleONoTFzuifJd94pY3+MmPkxJid27Ih5TypH7WvN9LrfW+N53wtUP/PqXSqV2s5R3xJi+p+Zfn/eGlSJeUdpEFP3mLWmV6b6U8y3oFOnTsmc2dnZYLy3t1fmqL2Pmd53Ly8vyxy1lpucnJQ56vuWt7/35sDX7TvRy+aNUd4zV99oxsfHZY5q496+aH9/Pxifn5+XOUtLS7JMzTNqv2Smf9PAwIDMGR0dDca9Mc37/ufNM0qSfeb7ziP8Sw0AAAAAAAAAAJAKHGoAAAAAAAAAAIBU4FADAAAAAAAAAACkAocaAAAAAAAAAAAgFTjUAAAAAAAAAAAAqcChBgAAAAAAAAAASIXcy7pxJpNpK25mls1mg/F8Pi9zms2mLKtUKsF4rVZrO6der8uc/v7+YLxQKMiccrksyw4PD4Px3d1dmXNwcCDLlFwu3DyKxaLM8erdaDSCce8ddXW1f+7mtaFO4NWv1WoF495zUNfr7u6WOcPDw7Ls/Pnzwfg777wjc86cOROMb29vy5yPP/44GP+Hf/gHmXP//n1Zpvqt9xzUc/XapLqPenfefczixkJV5t3Hq19aec9IvcNqtSpz1Phupscv77mqHG++UH3z4sWLMufcuXOyTM0XX331lcx58uRJMO7Njeq3ejleWZLtNWbM7ZR5RD1Xr8wbv9S6o6+vT+acOHFClr3xxhvB+M7OTtt1GB0dbbsO169flzmXL1+WZZcuXQrG1XrNzGxubi4Y/9d//VeZ80//9E/B+CeffCJzlpeXZZl6t2q9ZqbXzp3SxmN444P6XTE5npg5OmaPE7NG9uYYb0xRenp6ZJnqzzHju/dbY3RCO+kUqu6q3cXmeFR7jVmne+1YtX9v/VcqlWSZupf3/WFwcDAY98ZqNW/u7+/LHK+vK14/S7oPHqck+2fSe3Wvz6jvKt5efWJiIhj31lHqPt56bXV1VZY9evQoGD86OpI5ao3l7b9UWcw3PrO4dhLzzjt9390Jc503Hqr2PzMzI3NUv/AsLS0F40+fPpU53jpdffvyvpHGfO8cGRkJxr2xpre3V5apvJjvHN7veVFzDP9SAwAAAAAAAAAApAKHGgAAAAAAAAAAIBU41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEgFDjUAAAAAAAAAAEAq6D85n4BMJpNoTsxfZff+wroqq1arMkfdq16vyxz1l+G9+6gcM7NSqRSMHx4etp3jPZ9isdhW/HnUu+3qav9szXvnMe3uRfDqqKi6e78pn88H4319fTJnYmJClp08eTIYn5qakjl7e3vB+L1792TO//gf/yMY//rrr2WOasdmZr29vcF4LqeHOdVvY96d1469siTHyZh6x+Qct5jfq8picsz0WOmNoWqM99rDzMxMMH716lWZ09/fL8vm5uaC8YcPH8qco6OjYFyNNZ5arSbLvHlOPdek54tOoeroPaNKpRKMr66uypz5+flg/Pz58zLnzJkzsuznP/952znd3d3B+MjIiMw5d+5cMK7mKzOznp4eWba7uxuMf/bZZzLnn//5n4PxX//61zLn1q1bwfjOzo7M8eYEtf7y5rk0S7Lves81yfXa88raFTMveWsltV4z0/sI1We9Mu8ZxIzjMZLeh3a6mLoXCgVZpsYVrz14Y1HMOKXW6QcHBzJHzY3eXl19YzAzGxsbC8bfeOMNmXPp0qVg3HsGKysrwfja2prM8fq6tz5tVxrWUUmKGXe99VpMv1D7WjOzgYGBYNzbD6jxQbU7M7PHjx/LMtUuvTFF/SavHau9hzfexbT9mPEzDf0iZg+tnp83TqrreTneXDI4OBiMDw0NyRzVl7x1j2r/S0tLMmd5eVmWbW1tBePenmR2djYYv3btmsw5e/ZsMP7kyROZ4/ULNT96OaptJTn3fFf8Sw0AAAAAAAAAAJAKHGoAAAAAAAAAAIBU4FADAAAAAAAAAACkAocaAAAAAAAAAAAgFTjUAAAAAAAAAAAAqcChBgAAAAAAAAAASIVcEhfJZDKJ5bRarbavlcsl8jP+P97vqdfrwbhX72q12lbczCybzcoypVarybLDw8O2c1Qdurr0WZj3LtQzajabMke9i5g2d9yS7Bce9Z6KxaLMGRwcbLusUqnInDt37gTjn3/+ucz505/+FIzv7e3JnHw+L8sUr42rtue1SdX+vXfn9ZmYMS/JnE7pS149kpwvYu7j3ctrK0pfX58sO336dDA+PT0tc3Z3d2XZ7du3g/GFhQWZo56D1/9i+pL3/lSf8ebGJNtJp/DqXi6Xg/GHDx/KnI8//jgYn5qakjlnz56VZZcvXw7GZ2dnZY7izUuqPWxsbMicx48fy7Ivv/wyGFfzkpnZp59+Gox7fUm9I68veW1c5XlzjOK1rU6fLzqB9/wajUbb11P7i5g55uDgQJatr6/LMrX+8tpkT09PMO61FfV8Ytqkd69Xtb3G/N6YMaK3tzcYHx4eljlemRrjvfFQreG9dqz2vF5fGhgYkGXnzp0Lxj/44AOZc/78+WB8f39f5jx58iQYX15eljmlUkmWxfSz143qMzHjrpcTU+b1WbXHV+OxmX7vXps8OjqSZeqbj/f9Qc1zMeNTzDxrlux88ar2pZh+odqD922wu7tblg0NDQXj3lit2n/M905vrz4+Pi7LJicng/GLFy/KnP/yX/5LMP7DH/5Q5qi9/927d9vOMdN93etnx/UN67vgX2oAAAAAAAAAAIBU4FADAAAAAAAAAACkAocaAAAAAAAAAAAgFTjUAAAAAAAAAAAAqcChBgAAAAAAAAAASAUONQAAAAAAAAAAQCrkkrhIq9VK4jIv5D5dXfrcJp/PB+OZTKbt63n3Uer1uiwrFouyTNW7XC7LnK2trWB8b29P5jSbzWA8m83KnFxON6lqtRqMe8/7daPauPfM1fPznmuj0ZBlpVIpGJ+bm5M5S0tLwfjXX38tc9bX12WZ4vUz1Z9UOzZLdkyJbcfqel69Fe/3dHo/8+oe855UjvccYu7jXU+N1cPDwzJnamoqGPf67NOnT2XZvXv3gnFv7Fe/yauDyoltkzFz6nGtRTpFrVYLxtV4bGb2m9/8Jhj3nt0777wjy8bGxoJxr63s7+8H4948t7KyEow/ePBA5ty6dUuW3blzJxhfW1uTOZVKRZYpPT09wXhs24/pZ0mPa50gZhxP+jfFPHNvXld9xqu3ut7Ozo7M8dZyMeuyvr6+YNwbAxQvJ+n1TUxf6hRJ1jFmf9Hb2ytzpqenZdn58+eD8dnZWZmj7qXmPzP9m9SazEy3YzO9Zuvv75c5h4eHwfjt27dlzt27d4Px1dVVmePt/VV/SvNe4bh483DM+B6zF43ZX3R3d8sc9W3J++Y0MjIiy7z2r2xvbwfjXjs+OjoKxtV3JbO4552GsT9Gkmsib75Qfcb7NuiNyaotDwwMyBy1hz558qTMuXTpUjDurUe8eo+OjgbjFy9elDlvv/12MK6+yZnpuUTtb8z8/eHBwUEw7n2vTtL3nXv4lxoAAAAAAAAAACAVONQAAAAAAAAAAACpwKEGAAAAAAAAAABIBQ41AAAAAAAAAABAKnCoAQAAAAAAAAAAUkH/OfoXrNVqBePeXz5XZepaz7teNpuVZTHXUxqNRtv3LxaLsiyXC7+2/f19mbOwsBCMr6+vy5xqtRqM1+t1meO9i66u8Blas9mUOfgz77mq53d0dCRzvPf+4MGDYPzZs2cyZ21tLRhfXFyUOaodef3Ca3uK6n8e1VbN9BjgjQ0x78/jXa/dnJgx7bjF1DFmvPHaSswzV+P44OBg2zlbW1syZ25uTpbNz88H4+VyWeYk2SZi+pIndr5/FalnUSqVZM79+/eD8d3dXZnzxRdfyLLTp08H414/Ozg4CMa9ej99+jQYX1pakjkbGxuyrFarBeNqfWVm1t3dHYzHjP2x7TjJcfx16y8xYuf1GDFrATWOq3HfzKynp0eWqX3Ezs6OzFFrTdXHzOJ+a9LtNen31wm836TWz2qvZ2ZWqVSCcTWGm/njuFoPDA0NyZxz584F49PT0zJHjdXeesSr9+bmZjCu9tZmet788ssvZc7Dhw+DcW/9p96R2avZxpOW9BytxOw9Yt6f18aVfD4vy/r6+mSZGvu99aRal6k+ZmZ2eHgYjHtjl/e9QL2LV3VNFPP9VPHaccx3Ve96amzz9q+qDmoeMdNzycTEhMzx5ixvH6E8evQoGP/Tn/4kcz7++OO2c1ZXV2WZeq5p+U7Lv9QAAAAAAAAAAACpwKEGAAAAAAAAAABIBQ41AAAAAAAAAABAKnCoAQAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTIvewK/KVWqxVVlmROJpORZYVCIRhvNpsyR5V59+nq0udN+/v7wfjTp09lzsbGRltxM7OVlZVg/OjoSObUajVZlvS7eJ147aterwfjh4eHMqdarcqy1dXVYNx7f+q9l8tlmaOu593Hew4x10uyfcXWW9XhuOqdBkmO/bFzTKPRaLsO+Xw+GO/u7pY5BwcHwfjDhw9lztbWlixbWFgIxr2+maTYtvq6tfEY6hl5441aP3jz+tzcnCxTayKPqp+3flDt1fut2WxWluVy4eWv93uSHFOSXut6XsW+lPR+IOY9eWLmdTVfeG18b28vGP/iiy9kzp07d2RZqVQKxr31ZKVSCca936r2ON5vxfej3oe3H1DrHu/detdT88+zZ89kzrlz54LxEydOyJxisRiMe+sebz+s5sClpSWZMz8/3/Z91PpP9TGzuP0F/g/1jLxnp9p/7PNW71CNx2ZmOzs7wbha85vpvYLXvlSbNDPb3d1t6z5m+tuS1y/U+lR9/zCLm0uSXnt1upj26j0j9T68OcFbWywuLrZ9PdUm19fXZc7s7GwwPjw8LHO8Z6f6pleHu3fvBuOPHj2SOep7nXoGZn5fT/t3Wv6lBgAAAAAAAAAASAUONQAAAAAAAAAAQCpwqAEAAAAAAAAAAFKBQw0AAAAAAAAAAJAKHGoAAAAAAAAAAIBUyL3sCrRD/YV176+1Z7NZWRbzV94bjUYwXq/X287x7l+r1WTZyspK23Xo6ekJxvf392WOKiuXyzKn2WzKMkW9V3w36plXq1WZE9NeVdy7ntfGu7rCZ6ox/dLL89qXKvNy1H1i663QL76fmHfrzReKaseew8NDWba4uBiMq3HfzGxnZ0eWLS8vB+Mx43gu1/6SIWYMwPcTM355c4J3PTXPxIy7XlvJ5/PBuDcvxTwH73ox94kZh2LvhXgxzzUmx5tjYtbPaq+wtrYmc7w2ruoQ08aT/q14MbxxV80L3prD21eqdcxXX30lc4rFYjAe0/+8ec4rU/NcTDv2nnfM/iKmb+L7iZnXY9ZRXj979OhRMK7W/F4dvP1ApVJpu8zLOTo6arsOqp8xj3QWNU553zS9+ULtlVdXV2XOt99+K8sUtbf1+qy3jlK/18tRz85r4zH9witLer9y3PiiAAAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpkHvZFUhCV1fc2Uwmk2krbmbWarXarkM2m20r7t3HzGxvby8Yr1arMkfVr1aryZx6vR6MNxoNmdNsNmWZ91wRT7UVrw1570nlee8vl2t/KFFtMrbeMWLGAKSbN1Z77Uu18Zj5Qo3hZmblclmWKZVKRZaVSqVg3Otn6rd6cxZ9Kd1i2vFxXk+JmXu8OiRZN+963jiUdB0QL7Ydx4yHqk14bUVdL6ZuZv4YH3M9hTbeOWLeRew6Xe0rvTZ0dHTUdh1ixvfYPpNkTsy16Eudw3sX3rcTtYbf2dmROYeHh8G4N4arvunV2/tOpK7njQGqzHs+MZLuz3g+9cyT/m7otcmYNVHMt6WYHK/dJdkmX9e2z7/UAAAAAAAAAAAAqcChBgAAAAAAAAAASAUONQAAAAAAAAAAQCpwqAEAAAAAAAAAAFKBQw0AAAAAAAAAAJAKuZddgSR4f+U9aeqvxudy+lFms9lg3Kt3V5c+b2o0GsF4qVSSOareMc/Oy1H3wfFL+j15OUm2L4/XL2LqEPMcYn4T/SIdvPYVQ7WVw8NDmeOVtXsfr8ybsxTacfolPfYrSY/9zWYzGO+ENpn0OgqdI/Y9Hdf7ZT2CNFHt9bj2ojH7mE6X1nq/btQaxiur1+syp1wuB+Mx7cGrW9JUv026HdMvOkfMHtXTCe+2E+pwXH0pLfiXGgAAAAAAAAAAIBU41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEgFDjUAAAAAAAAAAEAqcKgBAAAAAAAAAABSgUMNAAAAAAAAAACQCplWq9V62ZUAAAAAAAAAAAB4Hv6lBgAAAAAAAAAASAUONQAAAAAAAAAAQCpwqAEAAAAAAAAAAFKBQw0AAAAAAAAAAJAKHGoAAAAAAAAAAIBU4FADAAAAAAAAAACkAocaAAAAAAAAAAAgFTjUAAAAAAAAAAAAqcChBgAAAAAAAAAASAUONQAAAAAAAAAAQCpwqAEAAAAAAAAAAFKBQw0AAAAAAAAAAJAKHGoAAAAAAAAAAIBU4FADAAAAAAAAAACkQu67/oezs7Mvsh5oQyaTaStuZtZqtRK7f5LX6hSLi4tReSMjIwnXBJ3A60vKq9gvtre3o/KGhoYSrgleRcc1ZyVtd3c3Km9wcDDhmqSTeu8x77wT2hDzxZ/t7e1F5fX19SVcE3S6JMeATnd4eBiVNz09nXBNkLSYsT/Gq9gvVlZWovLYX+BVFru/GB0dTbgmQOfY2tp67n/Dv9QAAAAAAAAAAACpwKEGAAAAAAAAAABIBQ41AAAAAAAAAABAKnCoAQAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTIvewKvEyZTKbtnFarFYx3denzIXUf7/7e9bwypdlsBuPq93g5Kv483r3QOZLsF0nfP61t6GU/U6Rf0v3Cy4lprzFi6kC/6CzHtY46LsfVvl7FeQ7/R5L9IunxOGbcPa45IRZ9Bv+3mPaa9L5btUmvrcbkxNSh0/vz6ybJ9e5xzhfHVQeFcR/f1XF+h0ly3GWv8N29/B0kAAAAAAAAAADAd8ChBgAAAAAAAAAASAUONQAAAAAAAAAAQCpwqAEAAAAAAAAAAFKBQw0AAAAAAAAAAJAKuZddgSQk/ZfhvZyurvA5UKFQkDk9PT3B+MDAgMwZGxuTZb29vcF4vV6XOeVyORjf3t6WOTs7O8H40dGRzPHqoCT9/vD9xDxz9Q69ayX9bmPqoPpz0nWjHeP78tpQ0mNos9ls+z5eWQz6zPE6znlYjbsqbmaWzWbbzon5Td5vVf3CW/eoHKRD0uNa0vdSOaq/mJnl8/m2y7zrqTo0Gg2ZU61Wg/FarSZzvOvFYI55MWLWKjE53tify4U/bxSLRZnT398vy/r6+oLxmPni4OBA5qiySqXS9n3Mjnf8gi/J8T2W6jPenKD6knc9b6xWZTE5x7kvwvFT7ylmLxrzPSrpNhSzhvHmOSW2X6R9vuBfagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpwKEGAAAAAAAAAABIBQ41AAAAAAAAAABAKuRedgX+UiaTaTun1WpFXU+VdXXps55sNhuMDw4OypzJyclgfHZ2VuacOXNGlk1NTQXj9Xpd5szNzQXjDx8+lDnNZrPt+3jvQl3Py0E6qHfr9SVVFtufVd9UdYul6hczdiVdB6RDzLyUtJh+EdPujrNf4M+8Z67eYey4G0ON1d3d3TJHlRUKhbbv4/HWN6VSKRgvl8syJ+l1VAzmiz+L6Rex14uhrue143w+H4x7/aJYLMqynp6etuJm+tl5/eLw8DAYV33MzKxSqciyRqPRVt3w/ST9XL29gqLavplZb29vMD42NiZzTpw4IcvGx8fbrsPu7m4wvri4KHNWVlaCcW+95s0l7LvTQbV/b+xX4/jAwIDMGRoaCsaHh4dljne9XC78GbFWq8kc1S82NjZkzt7eXjDuzRfValWWxfQL+ky82GcX851IvVu1Rnje9WJy1L28Oqi+7o0BMXscb92qnl3MWvdl7P35lxoAAAAAAAAAACAVONQAAAAAAAAAAACpwKEGAAAAAAAAAABIBQ41AAAAAAAAAABAKnCoAQAAAAAAAAAAUiH3sivwl2L+Ar33F9a9MnWvri591lMoFILx/v5+mTMzMxOMX7t2TeZcunRJlql7LS4uypylpaVgXP2lezOzRqMRjGezWZnjPbuYd3sc10qDmHbs5Xhinq1677mcHmJUWcxv9XhtPOY+qn5ejleHJH9T0vXG96P6hTdOxvRbr32p6/X09Mic7u7uYNyrd71eD8ar1arM8cpi2rjyurXxpNdRMffyxv6+vr5gfGpqSuZMTEwE4+Pj4zLHq4Oq9/7+vsxZXV0NxtfX12XO4eFhMF4ul2WO6ktmcfOZ6revW19Kuu7e9WLWZTF7ErUe9/YkIyMjskz1wYGBAZlTq9WC8e3tbZmztbUVjO/t7cmcg4MDWab6mdeXWBM9XyfvL9Q6xcxsdHQ0GD937pzM8fbdk5OTwbg3X6h+EbOH9saApPfdtP8/i23jivfeY74tqbXPhQsXZI5q/+fPn5c56huWmd5HqLZvZvbs2bNg/NGjRzLn8ePHbV3LzGxlZUWWHR0dBePenkT1i5g12esm6fki5ruv1//UfdR30OeVKV4dYr6JqevFfmNIsi2/jHmEf6kBAAAAAAAAAABSgUMNAAAAAAAAAACQChxqAAAAAAAAAACAVOBQAwAAAAAAAAAApAKHGgAAAAAAAAAAIBU41AAAAAAAAAAAAKmQe9kV+EuZTKbtMi+n0WjIslar9d0r9r91dYXPgQYGBmTOuXPngvE333xT5szMzMiy1dXVYPzJkycy5+7du8H4s2fPZM7+/n4wXi6XZY73vGPe3+sm5lnEPNeY+6i2b2aWzWbbint18O7jUXm5nB7mVJlX71qtFoyXSiWZU61WZVmz2QzGvfGJPvN8MeO7R7Uv713EtMmY+3iKxWIwPjY2JnMGBwfbvs/e3l4wvrm5KXPq9XrbZTHv9VXtL+p3xYwdXo43r6v22tfXJ3NOnz4djN+8eVPmnD17NhgfHx+XOV772t3dDcbX1tZkjvpN+Xxe5qjrec/Uq3eS41pMO0lzX4pZE3nPSK0FvDxvfaPaUW9vr8yZnJwMxtW+w8zswoULsmxiYqKtupmZbW1tBePr6+syp6enJxj3no/XZ9S7UOur55Xhz2LW4957innmqu15bVK148uXL8ucq1evyjK1J9jZ2ZE529vbbcXN9D7CmxO8Z6rGIW9cU2VpHvs9Se6hvRxv3d/d3R2Mj46Oyhy1jlJrJTM9L5w4cULmjIyMyDK1v/DGANVvvfuo/jw8PNx23czMnj59GozH9DPvnSe9D+10MftXryxmTdTf3x+MT01NtZ3j7WO8+Uf1da9Nqj20921J5Xjzksrx7uV9w1J95rj2Mf83/qUGAAAAAAAAAABIBQ41AAAAAAAAAABAKnCoAQAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFQI/3n2DqX+Wnqz2ZQ5jUZDlqm/zJ7NZmWOKjt9+rTMefPNN4Pxs2fPypzDw0NZ9u233wbjH3/8cds529vbMkfJZDKyLObZeTldXe2fu6l20im85xdDtX/vPt5zjamfyunp6ZE5uVx4+PHq5pUVCoW269Dd3R2Me2PK3t5eMF6tVmVOpVKRZaq9xrRj793FtJNOl3Rfj+kXMe3Vy8nn823d/3nXGx8fD8YvXbokc0ZHR4PxUqkkcx4/fhyM7+zsyBzv/an26uUkOXalgXoW3m9S6x5vzPOoMfTMmTMy58MPPwzGf/nLX8qc6enpYNwbdxcXF2WZWmOpecTMbGRkJBgvl8syR439Xo73m9T78/qFWmN57aTT11FJU8/V20N4Zer5eesR1b6uXLkic9T+4vr16zLn3Llzsky1f28cf/bsWTDujSm1Wi0YV+/BzO8XqszrZ69bG48Rsz713nvM/KPGqYGBAZmj2vjbb78tc9QcY2b25MmTYHxubk7mqLLV1VWZo+aLpNtqzPN+VcU8W5UTu7dWc3TM/sLbb6o1kbdWOjo6kmVqHPfqPTMz01bcTPdntV8y8/crm5ubwbj3W2PXyK8arx2rMu899fX1yTK1fz158qTMuXDhQjDuraPU9SYmJmTO4OCgLFPrKO9758LCQjDuzRdPnz4NxtV+3Myfs9Q4sLGxIXNUP4tZH39f/EsNAAAAAAAAAACQChxqAAAAAAAAAACAVOBQAwAAAAAAAAAApAKHGgAAAAAAAAAAIBU41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEiF3MuuwF9qtVptlzWbTZnTaDRkWb1eD8ZzOf1YRkZGgvFr167JnLfeeisY7+3tlTm3bt2SZf/2b/8WjH/55ZcyZ21tLRj3nl0+nw/Gu7u7ZY737LLZbDCeyWRkjuLleG2oE3j1U78rJsfjvXd1Pe8+6t0ODw/LnGKx2PZ9vPalrjc4OChzhoaGgvHDw0OZc3R0FIx7Y41Xpt6F9xxi3lFM2+oUqo4xbd8T08Zjcrx2rK4XM1abmU1MTATjb775pswZGxsLxufn52XOwsKCLEtS0vNFp0iyf8aMN177KhQKsmxycjIYf/fdd2XO3/7t3wbj7733nszZ3d0Nxj///HOZ89VXX8my1dXVYLxarcoc1c/U3GOm14yx84Uq8+qt3q0an8yOb8w9TjHPtVarRd1LtQnVX8z0XuFnP/uZzHnnnXeC8bNnz8ocz8rKSjC+vb0tcw4ODoJx79mpvuStGb33p5TLZVmm6t3Vpf9/vzSsl5SYuqsc711491FjkdqPm+m+NDMzI3NUv3jjjTdkztbWliy7e/duMH7nzh2Zs7S0FIyXSiWZo56P1ya9cTxmvE6ynaRhvoj5thSzB/Oeqxor1X7TzGxzczMY9/qmGg/X19dljjf2q72y1yavXLkSjP/1X/+1zPnwww+D8TNnzsicZ8+eybKY7w8xe/U0zxcx1N52YGBA5nhrIrWOUW3ITI/9ly9fbrsO3ndab9+t2oRac5iZTU9PB+NeX1Jl/f39Msfbr6hxyKu3GlNextjPv9QAAAAAAAAAAACpwKEGAAAAAAAAAABIBQ41AAAAAAAAAABAKnCoAQAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTIvawbN5vNYDyTycgcVebltFqttuvQ19cnc956661g/ObNmzLn9OnTwfijR49kzp/+9CdZ9vXXXwfjm5ubMqfRaATj+Xxe5nhlMWLen+K9V1UWc58XIaYesW1cUW3f47WH/v7+YHxsbEzmTE5OBuPValXmlEolWZbNZoPx8fFxmTM9PR2M7+zsyJz5+flg3Kt3rVaTZblccsNwTFvolH5xXGLmGK+sq0v/vwExY57qm1776u3tlWWzs7PB+JUrV2ROT09PML62tiZzKpVKW3Ezv72qfhEz9qdZTFuJGd+9djwwMCDL3njjjWD83/27fydzPvjgg2Dca+O/+93vgvFf//rXMufevXuyTLXL7u5umTM0NBSMDw4Oyhz17Lz3qtZrXtne3l7bOTHtJA2Oq194c/fExEQwfuPGDZnzi1/8Ihj/q7/6K5lz4sSJYPzw8FDm3L9/X5Z98803wbi3X9nd3Q3Gveet1pNqHWem14xeXrlcljlqXeaNQ2leLyU5P3r9whu/6vV62zlqT37hwgWZ8+GHHwbjql+amX366aey7JNPPgnGHz9+LHNUH/TauPdcY6jrvW7rqE7gjYeq/R8dHcmcra2tYFyNx2Z6bPP2vN5cosZXb92v5s13331X5qg9jrdeKxaLskyJWSOkeR0VM5956x41r3vvydtfDA8Pt52j+tLCwoLMefLkSTDufXPy+sXBwUEw7rUVVeZ9exsdHQ3GvefjraOWlpaCce/9JflN8/vOPfxLDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpoP+E/UvS1aXPWWL+KrqXo/6i/KlTp2TOD3/4w2D82rVrMqdWqwXjf/rTn2TOH//4R1mm/jp9o9GQOYVCIRjPZrMyR/11+mazKXPq9bosU/eKqYMnJudFUPWIaccxv8m7T0yZakNmZhcuXAjG3377bZkzMDAQjKv2bWb25MkTWabapbqPmdm5c+eC8bW1NZlz+/btYFz1czO/X+Ry4WE46Xfe6ZLuF0k/i5jrqfnMG6ur1Wow7o27IyMjskzNTVeuXJE5m5ubbcXNzDY2NoLxcrksc7xn6q0F2r2e9+w6vc94dffKFPV7i8WizJmdnZVlN2/eDMbVWslMj8m/+tWvZM4//MM/BONffvmlzKlUKrJMjbu9vb0yRz1vrw0NDw8H40NDQzLHGx/UXOLNMYeHh8G4V+9OWUcpXt2T7Bfeumd8fFyW3bhxIxj/+7//e5nz85//vO37zM/PB+NqnWLm95k7d+4E497Yr9qe9+z6+/uD8bGxMZnjlfX09ATjqu2bme3u7gbjXl/q9Pki6XVUTF/yqPp5872af959912Zo/YkCwsLMsfbk3/99dfB+NbWlszp7u4OxtXcYxa3hvGo63nv/FXcd8esAZN+Rl7fVGOOt4aJWSOr+3jX8vbQ6vuNt4ZR7X9wcFDmjI6OBuM7Ozsyx9uTq/qleez3HFf/jOl/XlvZ398Pxp89eyZz1DckdS0zs/X19WDcW/eo9YOZWalUCsbVusdM7wkuX74sc37wgx8E4xMTEzJHffs287/HKuqdx3zP/759jH+pAQAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpkHuRF89kMrKsqyu585RmsxlVNjg4GIxfvXpV5rz//vvB+MDAgMz57W9/G4z/+te/ljm3b9+WZUdHR8G497yVbDYry2LeUavVarsspt7efY5TTN29HPW7vN+rrue1fU+xWAzGT58+LXN+8pOfBONvvPGGzFleXg7G7969K3PW19dlWS4XHs66u7tlzuzsbDBerVZlTqPRCMYrlUrbOR71e8zM6vV6MN4p/SJGknOCWVzf9PqMup73zNV79+5Tq9WCcTVfmZm9+eabsuyDDz4IxqempmTO/fv3g/GHDx/KnI2NjWDc6xfeO1dlXk6nt/+k54sY6vl5a5hTp07JsnfffbftHNWO/vmf/1nmfPLJJ8H43t6ezOnv75dlqg8eHh7KnJj+rJ73yMiIzPHeRblcDsZLpZLMUWOKulYaeONAzNpHzbdDQ0My59KlS7LsZz/7WTD+i1/8QubMzMwE448ePZI5H330UTD++eefy5zHjx/LspWVlWD84OBA5qhxt1AoyJy+vr62c06cOCHLxsfHg3Gv3uq3xowBnT73xFLzjzcvxezJVXswM7t8+XIwfv36dZmj+vOtW7dkzmeffSbLVFtJep8cM8d4Zfl8PhiPWUfFjKtJr19iJT1fxHzPiHmH3vpZ5XjfdVT78p6PakNmerxW3xHMzKanp4Pxc+fOyRy1XlpcXJQ5u7u7skytl9Te2izunXdK+0+y7jHfsNQa1Mx/T6qNe+9dvVtvr6DKdnZ2ZI73m9T809PTI3PU+sa7j+qb3hzjfd9SewKvX6gxxfvu9aLWS/xLDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpEP7z7Mcgk8m0FTczazabbcXN9F+gNzObnp4Oxq9fvy5zzp49G4xvbGzInN/97nfB+BdffCFzDg8PZVlvb28w3tPTI3P6+vqC8WKxKHOUSqUiy6rVatvXS/qde9dLWqvV6oh6hHh184yMjATjN27ckDk3b94Mxr02+emnnwbj9+7dkzlzc3OybHZ2NhgfHByUOWNjY8H40tKSzOnqav8s2GsL2Wy27Rylk9vji+D9JvUsYscOlZd0HVSfOX/+vMz5m7/5G1l27dq1YNybsz777LNg3Oubu7u7wbg3B6u2b6afa+y41gmSrnvMM1Jz/vj4uMx58803Zdnly5eD8UajIXO++uqrYFy1OzOz7e3tYLy7u1vmeGXqGXn1Vv12f39f5qj2n8/nZY6al8zMpqamgvGjoyOZUyqVgnFvLdcp/S+mHirHm7sHBgaC8UuXLsmcn//857LsF7/4RTB+6tQpmfP06dNg/KOPPpI5//Iv/9LWtczM9vb2ZJkax721vXqu5XJZ5qjrDQ8Py5xCoSDLVL9Qbd/M7O7du7Isrbz1SMwaUL1bbw3jlSlDQ0Oy7MKFC8H4zMyMzFHrGzX3mJktLCzIMvWbvD2Omn9i9hDeeBdTlnSO+k3HPV+o+yXdL9R96vV629fy8ry2onK8tYWqd8xayavD6OiozFHfEry5Vq3L5ufnZY7Xnw8ODoLx42qvad6Pe89IjZO1Wk3meOtntR7x6qDWHTFzlvreaub3M5WnvsWa6T2+t2ZU1/Oe6fr6uixT+yxvLaf65svYq/MvNQAAAAAAAAAAQCpwqAEAAAAAAAAAAFKBQw0AAAAAAAAAAJAKHGoAAAAAAAAAAIBU4FADAAAAAAAAAACkAocaAAAAAAAAAAAgFXIv68atVisYz2Qyiebk83lZdvr06WD8ypUrMke5deuWLPvyyy+D8d3dXZkzOjoqy6anp4Px2dlZmTMxMRGM9/f3y5xqtRqM7+zsyJyVlRVZtr29HYwfHBzInEqlIsuUmHbyIqh6xOTE1N3LKRaLsuzMmTPB+AcffCBzTpw4EYx/++23Mkf1mfv378scrz2cPXs2GB8cHJQ5w8PDwbjXL2Lea1fX8ZwfH3cb72Qx78mjnq33zLPZbDDe3d0tc06ePBmM//jHP5Y5P/nJT2RZLhee5tW8ZGb2u9/9Lhifm5uTOUqhUGg7xyzu/TWbzbZz1PtLuv0cJ69NqvcxNDQkcyYnJ2VZX19fML68vCxz7ty5E4xvbGzInIGBgbbiZmY9PT2yrF6vB+O1Wk3mqL6k+rmZWblcbuv+Zn69VZm3nlTPdW9vT+Z0SvuPqYdq/95+YGxsLBi/evWqzHnvvfdk2aVLl4Lx9fV1mfOrX/0qGP/Hf/xHmfP06dNgXK3fn1emxlBvHI+ZGxVv7eWNQ1NTU8G418ZVX/LaXKf3i5g9dMz61MvxnpHKU/3PzOzUqVPBuBqPzfQ+4tGjRzLHG/vV/Ojt1dXew6u36pteOy6VSrJMvYuk23in9IsYSe67vefgzfmKt7ZQZd59vOvFUHsZb9788MMPg3E1hpuZPXv2LBj//PPPZY6aG810n/HeX5L7607pL0mPA2p899qkN34p3hg6MjISjHtrC7WP8eY5b++hytR9zPS3XRU303PW4uKizPH6hdorHB0dyZxGoxGMJ7kf/674lxoAAAAAAAAAACAVONQAAAAAAAAAAACpwKEGAAAAAAAAAABIBQ41AAAAAAAAAABAKnCoAQAAAAAAAAAAUkH/+fgOpP6SuvfX0gcHB2XZqVOngvHx8XGZs7e3F4zfv39f5mxubgbjY2NjMufcuXOy7Nq1a8H4hQsXZM7IyEgw7j27w8PDYHxnZ0fmPHr0SJbdu3cvGF9eXpY59Xo9GG80GjLndaPeYS6nu7fXL1TbO3PmjMzp6gqfjy4uLsqcra2tYDyfz8ucqakpWXbjxo1g/OLFizKnUCgE46VSSeaoNuk9b6+9tlqttuKxVDtJ+j6xjuv3elQ79sq8HNWWh4eHZc7Vq1eD8X//7/+9zDl//rwsu3XrVjD+j//4j23nqLZvZtbX1xeMe/3Co9qD916TzDluSfZPr00Wi8VgXL0/M7Pu7m5ZdnBwEIyvr6/LnLW1tWBcjcdmus94c5lX76Ojo2C8XC7LHNWfvX5Rq9WCcW9OUO/ITP8mb0xROV47UevtTukvHvW7vPYwMzMTjL/xxhsy58qVK+1VzMzu3Lkjy373u98F4998843M2d/fD8Z7enpkjrfGGhgYCMa9cVyVVavVtnPUezAzm56elmWq/cc8h5h+kWbe/BgzL3ll2Ww2GFd7VDOzoaGhYHx3d1fmPHv2rO0cbwxV3wu8fZGqt5oTzPT+Ws2ZZv4eWs1znpg9ieoznTJfJF0Pdb3Y8UFdz1snqHYU85483hiq2v/f/d3fyZybN28G42otaWb28ccfB+NffPGFzPH6jLdmU9RYGLPXTIOYPqPav9eOvT6j1mze99PTp08H49430hMnTgTjaj1k5u891H7Ke6aqTapvsWZm8/Pzwbj63mpm9vTpU1m2vb0djHtrOfWbYsaa7ztO8y81AAAAAAAAAABAKnCoAQAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVci/y4q1Wq+2cZrMpyzKZTFtxM7Ph4WFZNjs7G4z39fXJnK2trWB8bW1N5nR3dwfjP/jBD2TOe++9J8veeuutYHxoaEjmlMvlYHxnZ0fmjI2NtRU3M8vldJPa399vK25mdnBwEIzXajWZo8S0xzRQ7b+rS59Zev1iZmYmGJ+YmJA5vb29wfjIyIjMefvtt4Nx1b7NzE6cOCHLrl27FoxfuXJF5gwMDATjXjvO5/Nt5yRNtWWvjXvjZKdTvyvmN3n9wivLZrPBeKFQkDn9/f3B+KlTp2SOmheuXr0qc9Q4aWb2ySefBON//OMfZc7e3l4w7rVx9Xy8d+TN90nmpGHsj6ljTPtX7bVYLMqcarUqy1ZXV4Px5eVlmXN4eBiMq7HVTPdNtb56XplqR94zrdfrwXipVGr7Po1GQ+Z4Y4qas9Qc7F0vpv2kYR5RbaWnp0fmnDx5Mhi/ePGizFHvwsxsc3MzGP/yyy9lzq1bt4Jx1cfMdJ/x6ubtcVQ78uZGxZsvRkdHg3H1HszMJicnZZnq6964GjOXKMc9x6h+eFz1UGPh88rUe1LtwUz3W2//urS0JMuUS5cuyTI1Dpw/f17mqHHXq/f6+now7s2N3vqvUqkE40m2/bRLch70ruWVxayfY/b+KsdbK509e1aW/c3f/E0w/vOf/1zmqDnmo48+kjn/8i//Eow/evRI5qh1pifm2b2q++4keXOCt/dQe2hvnXD9+vVgXH1zMjM7c+ZMMD4+Pi5zvDWWWt97e4WNjY1g/N69ezJHzXNev/C+Vx8dHQXj3nyh+oy3x3lR/YJ/qQEAAAAAAAAAAFKBQw0AAAAAAAAAAJAKHGoAAAAAAAAAAIBU4FADAAAAAAAAAACkAocaAAAAAAAAAAAgFTjUAAAAAAAAAAAAqZB7WTfu6gqfpzQaDZnTarWC8WKxKHNGRkZk2ejoaDDe3d0tc/b29oLx3t5emXPjxo1g/PLlyzLn0qVLsqyvry8YX19flzlPnjwJxvf392XOzMxMMH727Nm2c8z0u/CedzabbStu5rehTpfJZNrOaTabwXg+n5c53jNXZV4/Gx8fD8Z/9KMfyZzz588H47mcHpbUuGFmVigUgvHh4WGZo/qt91tV/by6xbxXrx2rd+5R42caqOfn/Sb1Prz35I0r6r17fUn1i7ffflvm/PjHPw7GvTb5xRdfyLJ/+Zd/CcYXFxdljnoOXh1Ujtf2vXeRZBuP6X+dwmvjMX1aPQvvGdVqNVm2vb0djG9ubsqco6OjYNybs1SZl+P1Z9WWvXan1n8qbqbHDW+e6+npkWVqvPGeg3q3Xv+r1+ttXauTqPfujdWTk5PBuBrDzfw5Wq25b9++LXPUmOz1P/Wb1HrIy3lenlKtVoNxr02q/cCZM2dkztjYmCw7PDwMxg8ODmSOeq5ev+gUMXNdkutQNT48r0y1L9X/zPSet1KpyBzljTfekGXe94KpqalgvL+/X+Yk2b68OWZgYECWqfk5Zn3ltZ9O2V/E9Isk+7s35sXsbb01jMpR/cVMj6HeNye1JzEz++EPfxiMq/5iZvbw4cNg/Msvv5Q5jx8/Dsa9b1hJ7w9jxs9O6ReK95uS3NN57ThmreKNeYODg23XQa1hvH2MV6beuzfuqmfnfV9W4025XJY5pVJJlsXMWeq3ejlqXfF99xedv3IDAAAAAAAAAAAwDjUAAAAAAAAAAEBKcKgBAAAAAAAAAABSgUMNAAAAAAAAAACQChxqAAAAAAAAAACAVMglcZHv+9fK/2/eX4aPUSgUZFk2mw3G6/V629c7f/68zDl9+nQwPjk5KXO8Z/r48eNg/NatWzLn0aNHwXh3d7fMGRkZCcbz+bzMKRaLbZe1Wi2Zk2TbSvJa3+Wa3u9qV9LP6OjoSJYtLCwE4177Urz2MDU1FYzv7e3JnN3dXVmm+nOpVJI5vb29bV3LU6vVosrUmNfVpc+cY3JeRV7bV2XeM8rl9JSoxv7BwUGZc/LkyWD8ypUrMkfNC/Pz8zLnV7/6lSz76KOPgvHDw0OZ09PTE4x7/SKm7cW8P28sTLL9Jzl+vyiqjjF193LK5bIs29nZCca9dZTqM15fUnXw3nm1WpVlakz25p+NjY1g3JtjVH/2fmtfX58sU7+3UqnIHPVbj2vt9SJ4712VeesR9T685+CtR9bX14Nxb+2l3oc37qp5KWb9YKb7mTc3qj3B6OiozLl27VowfurUKZmj5iUzs5WVlWB8dXVV5qh+G7MPPe7+EnM/leP9XtUmvbHVK1NtxdtXqrbsjZOXLl0Kxk+cONH2fcz0Mzo4OJA5ag70vkuoccgbu5Jel8XolPkiph7qGcWMu94Y5X1v6e/vb+s+3r28Nn7mzJlg/ObNmzLn3XfflWUDAwPB+LNnz2TOH/7wh2Dc+8awtbUVjHtrGG/OUmK+6XTKOirJOcEsrl+oZx6T49VB7TvMzO7cuROMq2+nZnp89eYy772rb0sTExMy5+rVq8G493zUmKLub+a/85hvS+o5NBqNqDp8H6/XFzAAAAAAAAAAAJBaHGoAAAAAAAAAAIBU4FADAAAAAAAAAACkAocaAAAAAAAAAAAgFTjUAAAAAAAAAAAAqcChBgAAAAAAAAAASIVcEhdptVrBeCaTaTtHxc3Mms1mW3Ezs2q1KsuOjo6C8VqtJnOGh4eD8XPnzsmcSqXS9n02NjZk2ZMnT4LxpaUlmaPuNT09LXOmpqaC8Z6eHpmzvLwsy3Z3d4Nx9R7MzOr1ejDuvXOvDSUt6Xt5faZd5XJZlq2ursqyL774Ihj3nvnjx4+D8f7+fpmjrre1tSVzvLLR0dFgfGBgQObk8/lg/ODgQObs7+8H495Y4/X1QqEgy9oV0x6TbHNp19Wlz/l7e3uDcdXuzPS8cObMGZmj5ovPPvtM5nz00UeyTPWZvr4+maP6hRqPzeLakTemKN47Utfz6hZThxchpu+qnEajIXNKpVIwruZnM7Pt7W1ZNjMzE4wPDg7KnImJiWB8b29P5uzs7ATj3jwXszb0rqfavxobzMxOnToVjF+8eFHmDA0NybLNzc1gXD0fM/3OvTZ3nOuoGN67jenTh4eHwbjX9r21cC4X3l6ptm9mdvbs2bbq5t3Hq1t3d7csU+sRbx01Pj4ejHv7ops3bwbjp0+fljneu/jmm2+C8QcPHsgc1Wc6ZX/hUfXw5kc1D8bMj94cE1MHL0e1ZW//qtYwKysrMkeNrWZx+1e1//HmRvVc1brQzN9fKGlo40ny2rgqKxaLMkfN0SMjIzLHa6/q25J3vbGxsWDcG3dV2ZUrV2SO117Vt6qHDx/KHPW9wJvn1BpLzX9m/n5F9RlvXFPX65Q9dEy/9cbdbDYbjHv9Qq0tvPt4ZWqdvr6+LnPUd0ivfXltRfHanuoz165dkzlqfPC+Mai50XtHam400887po177fFF9Rn+pQYAAAAAAAAAAEgFDjUAAAAAAAAAAEAqcKgBAAAAAAAAAABSgUMNAAAAAAAAAACQChxqAAAAAAAAAACAVNB/uj0B3l8+V7q69DlLo9EIxr2/Wr+/vy/L1tfXg/Hd3V2Zo/4K/ZkzZ2SOut7m5qbM8Z6d+mv3Xh36+vqC8dOnT8ucmZmZYPzg4EDmLCwsyLLV1dVgvFQqyRz1bmPaVhrE/C6Vo/qLmdnOzo4sq9VqbefcunUrGC8WizJH9fVKpSJzvLai2v9bb70lc1R/LpfLMkc979g2qfKazabMyWQybcWPm1ePJNt4zO/1cvL5vCzr7e0NxicmJmTOiRMngvFCoSBz5ufng/FPPvlE5jx69EiWKV4d1DPKZrMy57j6hff+OqX9J8l7fmqM8MYONYZ6ayWvTM3RIyMjMkf1i8PDQ5kTs/7zxnF1vVxOL4tVvaenp2XO9evXg3Fv7eWtg7e2ttqKm5kdHR0F41476RQx44Baw3hri+3t7WDcW/d4bXxsbCwYf++992TO4OBgMO7tSdR6vLu7W+ao/YCZ2dDQUDA+NTUlc06ePBmMj4+Pyxz17Lx3dOfOHVl2+/btYFzNp2Zme3t7wXin7C+SXCu9iOsp3rii+qa3r1TjuLeGUe3Y68/enkmNN976T5V5Y9fc3Fww7n0vUO3YTP8m770mub847r4Ucz+1ru3v75c5k5OTwfipU6dkzuzsrCxT46u3tlB18MZq9V3Hmy+8+efBgwfBuLcnUf15eHhY5qg1kdf2ve8Fqg7emlHxxo1OmUti+rRaC3v9QpV56+qYNbz3blWb8PYx3t5W8dbp1Wo1GFfzn1cH7x2pHK9uMXvopL/nvyj8Sw0AAAAAAAAAAJAKHGoAAAAAAAAAAIBU4FADAAAAAAAAAACkAocaAAAAAAAAAAAgFTjUAAAAAAAAAAAAqcChBgAAAAAAAAAASIXcy67AX8pkMrKsqyt8BtNsNmXO9va2LHv06FEw/uTJE5kzPj4ejM/MzMicYrEYjHd3d7ed492rWq3KnHw+H4xns1mZs7e3F4w/fvxY5ty6dUuWLS0tBeMHBwcyp9FoBONeO2m1WrLsOKk6xtQv6Zx6vS7Ltra2gnHvPa2srATjuZweYgqFQjDu1btSqciynp6eYNwbA3Z2doLxUqkkc9Sz8/pS0u9PjYVevzhOXt2Pq1+oscN7Tx41Jg8NDckc1cZVHzPT4+s333wjc7z2qsZ+j3qu3vNOMsfTKeN70mL6rsrx1kSqrWxsbMichYUFWXbixIlgfHBwUOaosqmpKZlTq9WCcTXum/nzhSrzxofJyclgXD0DM7MzZ84E416/fPr0qSx79uxZML66uipzyuWyLOt0MfOFKtvf35c5an3qrXcHBgZk2fT0dDD+wQcfyJx33nknGPfGd7Xu7+3tlTneuqy/vz8Y7+vrkzmqLXtrRjWmePPcJ598Istu374djK+trckcb8/UCZJez8XMnWqtGbuOUm1C9T8zs7m5uWD83LlzMkftr0dGRmSON28q3vyjeGPK3bt3g/HFxUWZE7NfiWkLad53e3VX45caC830t6DTp0/LnIsXL8qykydPBuPemmh4eDgYV33WTO+LYvqfmdmdO3eCcfVNwEy3FfV7zOK+YXnznKLWmWa6DXl1UM+7U/qLVw/1zL21gBpfvfWIN36tr68H4968rr75eOtg9Vu9dbr3HCYmJoLx8+fPyxz17Lx6q+ezu7src2LmOdWOzTqnLZvxLzUAAAAAAAAAAEBKcKgBAAAAAAAAAABSgUMNAAAAAAAAAACQChxqAAAAAAAAAACAVOBQAwAAAAAAAAAApELuZVegHdlsNhj3/pL7zs6OLLtz504w7v1Fe/UX4N955x2ZMz4+Hoz39PTInKmpKVk2PDwcjO/t7cmczc3NYPzJkycy59GjR8H4w4cPZY5Xtra2FoxXq1WZo95tq9WSOZlMpu2cF+G47qd+b2yOeualUknmqLJCoSBzisViW/c3M6vX67JM9U0vR/WZw8NDmaPGIfV7zPzfpN5FV5c+c455550iyX4Rcy3VTsz896Tu5dVhf38/GPfGvG+++SYYX15eljneb1LtyPutqsy7j3oOXluNKYt552mYLxTvGamxyBs7VNvb2tqSOXNzc7JMrUe6u7tlzsTERDB+4sSJtu/jje9eG1fy+bwsU+syby2nnrf3TL/99ltZ9uDBg2B8e3tb5qhnlOZ+4VHv3Vsjq/Vub29vVB3Ue7969arMOXPmTDA+NDQkc3K59rdxXp+p1WrB+MHBgcx5+vRpMO61YzXPqbiZbvtmZhsbG8G4N9cmOWeloV8oMeOA1+68+UftFR4/fixzPv/882B8enpa5ly4cCEY9/pSf3+/LFN9xusX9+7dC8Y/+eQTmaO+S6j2bWZWLpdlmdfXlZg23ul7Eq/uqr16ezrVVtT3HjOzU6dOyTLVXkdGRmTO0dFRMO61h/n5+WBcjeFmem40M3v27Fkw7u2hFbWe9XjtzhuHYnLUvWL62HFLcn7y1shqna7W/GZ6zWGm5xlvPIz5bqj2K169z507J8tu3rwZjF+7dk3mqO9lXv9T33C9/Zw3PsR852j3WmYvbr7gX2oAAAAAAAAAAIBU4FADAAAAAAAAAACkAocaAAAAAAAAAAAgFTjUAAAAAAAAAAAAqcChBgAAAAAAAAAASAUONQAAAAAAAAAAQCrkXtaNu7rC5ynNZlPmZDKZtuJmZrVaTZYtLi4G46VSSebMz88H499++63MOX/+fDA+NjYmc3I5/WqOjo6C8bW1NZnz4MGDYFz9HjOzpaWlYHxnZ0fmeM+uXq8H461WS+Z471bxrnecYuoeQ/UZ1cfMzPL5vCxT9fb6knq3jUZD5qiyarUqc7x69/T0tH29zc3NYHx/f1/mKIVCQZZ5z07x2k/MWNgp/SKG+l3efKF+b0ybNNPtaG9vT+aoOaZcLsucx48fB+Nem/TerXpG3rNTZZ3QhpKuQyf8JrO4+UKN8THX8tqXt05QY7K3hrlw4UIwPjs7K3MmJyeDcTXum5kVi0VZluTaYmtrS+Y8fPgwGL9z547MuXXrlixT67xKpSJzYtr4q9gv1NrZzGx5ebnt+3hjv1o/LywsyBzV/i9evChz1PPx5rKDgwNZptry6uqqzLl9+3Ywfu/ePZkzNzcXjK+vr8scr96Ktw72ypRO6RfHRf3ebDYrc7xxV62j1FrJzOxf//Vfg3Hv/b399tvBuDfHeHOW6utef/7DH/4QjKv9uJkeN7yxS+2/zOL2CjFUOzmuffD3uZ8aK711umrH3rgbs6fzxrxnz54F49567enTp8G4Go/N/Dau9tDe+NDd3R2Me89HvQvvHXl9Ru3Jvb70Kq6jvPqpZ+E9c2V0dFSWed9CT5w4EYyPjIzIHLWW8/Y409PTwfipU6dkzqVLl2SZWrP19/fLnCdPngTj3n5A9Wdv3IjZ+8c47rHfjH+pAQAAAAAAAAAAUoJDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpkHtZN242m23ntFqttuJmZl1d+tymXq8H46urqzJnbW0tGP/0009lTl9fXzDe29srcwqFgixT1O8xMzs6OgrGy+Vy29drNBoyJ5vNyrIY3rvtBJlMRpapusfkeFSO1/a9OuTz+WDce7eqrXh1yOXCw4/Xjru7u9u+3s7OjsxR49DGxobMUbzno56pmd+f2tXp/SVpSfclr+2psXJ7e1vm1Gq1YPzw8FDmbG5utl23mOfgzcExOaoO3hgQ41Vt40n+LjUWelRbNTPb3d2VZU+fPg3Gvd9TKpWCca9fTE1NBeP9/f0yxxt3VXv1+pla/y0uLsqcR48eBeNPnjyROVtbW7JMjUMxfTMNkuwX3nNQbW9ubk7meP1iaWkpGL99+7bMGRwcDMaHhoZkjlo/VCoVmeOt+/f29oLxg4MDmaPmLO/5qD2J1/+8cU2tv7z286rOJUqSv9eb1739q6qD1ybv3r0bjHvr9D/+8Y/B+NjYmMzx2peas1R/MTNbXl4OxlXbNzOrVqvBeOz677h0Qh3M4vbdau2zv78vc1ZWVoLxhw8fyhxvj7i+vh6Mq/ZgptdeKm5mtrCwEIyrMdzMb+OqfsViUeZ4ZYqa57x+4c2Bqsx73qoOaZhHYuqo+oUaC830fth7F2rdY2Z28eLFYPyDDz6QOWqt4r1bVQdvf+G1Y/V7vb752WefBePffvutzFHP2+sXHjVOeu0nJudF4V9qAAAAAAAAAACAVOBQAwAAAAAAAAAApAKHGgAAAAAAAAAAIBU41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEiF3MuuQDti/sJ6s9mUZV1d7Z/p1Gq1YHx/f1/mbG5uJnZ/M7NsNhuM5/N5maPu5dVBPW91fzP/eavrpZnX9pLM8aj34b0Lrw4x70nVwWtfqg4xbdLM7OjoKBhfWlqSOTs7O23FzfRz9eoWU5Z0O3ndqHbkPddqtSrL1Bi/srIicwqFQtv32d3dDcYbjYbM8fq64j0HVea1Y/W8X8Vxv9N5c3TM+1DrHjM9Vsa0cW+sHh8fD8Z7enpkjrcmUr/J62eqft76T/1WFffqZpb8/PM68fqFGvPUusLMrFwuyzLVL7w2WSwWg3Hv/dXr9WDca0Ne31TX86g+E7POjNnHeNeL3We9TmLWmjFrATP9fr12p/rg/Py8zFlfXw/G1ZrseWLG3ST3OMfZjl/F+cJr42qsjNkHemuBhw8fyrK+vr5gvFQqyRz1bcmr9+HhYTBeqVRkjlem2qWay8zMcrnwp8eY+dnjjSmqLPZ7YlrF7If39vZkzvLycjDurdNVezDT6/6ZmRmZc+nSpbbrcHBwEIx7fcnbr6i+fv/+fZnz6NGjYNz7xqDWoN4+Jum9fyd9q2K1BwAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpkHvZFfhLrVar7bJMJiNzvDJ1vWw2K3NyufAjKxaLMqfZbAbjjUaj7RyPqpuZ/k3e81bPLuaZPi8P8VRb8d6F1/YU73pe21Pq9XowXqvVZI7XL3Z2doLxxcVFmaP67fb2tsw5ODgIxtXvMfPr7T1X+GLGIu95V6tVWba5uRmM7+7uypxCoRCMe/VWfdNrXzFtiPE4/WLeYVdX+P9lyefzUfdRba9cLsuclZWVYHxra0vmqDlG/Z7nlSne+k/1QW/cUP05dv0X85teN+oZJb2u9sbkUqkUjMeso2LeecxvNYvbF3ljh8L+Ih1UO4rddyfZxj3qese5jlJ18O6TdF+P6WevG/U+KpWKzFF7RDXum5ktLy+3XQdvHaXu5eXEzAtem4wZ+1Uf9O6j5h/v93h9Hc8X0ybX19eDca8vqW83ZmYLCwvB+OnTp2XOyZMng/GBgQGZo/bxq6urbdfNzGx+fj4YV8/HTD8H73mrvUfsNyc1L6TlOxW7IwAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpkHvZFfhL6i+ve2XeX2XP5fRPVH8dPqYOnmw2+1LvY3Z8f7k+pt5eznHVO826usJnk6p9m8X1C0+j0Wj7Wion5j5mZnt7e8H448ePZU53d3cwfnBwIHOOjo6C8VqtJnO8dhzTZ+gXL0bMGOq18XK53HYdVHuI6Zfe9ZLOUWirL07Ms1Xv1nvnhUIh0TqoOcsbQ+v1eltxs7hxV9XNy0m6jyVdh9etD6rfm+S4ZmZWLBZlmVqreO/Cm38U9Zu8fhHTVrw1Y5L3ib0e4sWORUrM/iKmfcWIXUcp3vNR94p5prF7CPrM88WMRWp89a7lvfeY+UJdT+1rn3c9JaYNxfQL7z4xz9sT8z3xdROz561UKsH45uamzFHfbszMnjx5Eox7exLV/r02qX6r+j1m/hpL7f29nJi56bjWumnBv9QAAAAAAAAAAACpwKEGAAAAAAAAAABIBQ41AAAAAAAAAABAKnCoAQAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTIvewKJKGrS5/NtFotWZbJZNqKe2XefZRcTj9+rw5KTB1ieHWLqcNx1ft14/ULT0zbU7x3m81mg/HYfnF0dBSM12q1tuvg5TQajbbiZrTxlyFmfPeo/hQzX8TwrtVsNtu+XszciHSImaNj11Ex/SJGTL2TvI/Z8fUL+t/xi5kvku4XMesENfartc3z6pCkmN+T9PPB95N0Wzmu+UJJ+j7e9dRv9dqx6s/MCZ1FvUNvHxizR4xpX97YH3OfpMfkmDVbzB7Hw1wSz3t2qszL8fpFpVIJxmPaUNLfJ5O+Xid/900L/qUGAAAAAAAAAABIBQ41AAAAAAAAAABAKnCoAQAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTIvewKJOE4//p7kvfyruWVZTKZxK6nruU5zueN49fV1f5Zp2pHMdfyeNer1+ttxc1o//juYt57s9lsOydmfI8R0/aRDsfZVo6rHan7ePePeQ5Jz1lK0vVmXjp+Sbf9JK+XdPtKeq10XPMcOsvLni+S1gnrMtZynSO2PXTyuJf0eiTJ69H20yHpfhGzt05azPrGo35TzFrude0X/EsNAAAAAAAAAACQChxqAAAAAAAAAACAVOBQAwAAAAAAAAAApAKHGgAAAAAAAAAAIBU41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEiFTKvVar3sSgAAAAAAAAAAADwP/1IDAAAAAAAAAACkAocaAAAAAAAAAAAgFTjUAAAAAAAAAAAAqcChBgAAAAAAAAAASAUONQAAAAAAAAAAQCpwqAEAAAAAAAAAAFKBQw0AAAAAAAAAAJAKHGoAAAAAAAAAAIBU4FADAAAAAAAAAACkAocaAAAAAAAAAAAgFTjUAAAAAAAAAAAAqcChBgAAAAAAAAAASAUONQAAAAAAAAAAQCpwqAEAAAAAAAAAAFIh913/w0Kh8CLrAbxU1Wo1Km9qairhmiBpmUzmWO7TarWO5T7HaXV1NSpvYmIi4ZoAnWN9fT0qb2BgIOGaAJ1jf38/Km9mZibhmgCdY3l5OSpvdnY24Zqg06n9ire/8PY4nbwvWVxcjMqbnp5OuCZA51hZWYnKo1/gVfZd+gX/UgMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpwKEGAAAAAAAAAABIBQ41AAAAAAAAAABAKuRedgXQvlarldi1MplMYtcCXqaYtqxyvGsl2f9exPXw+km6DcX0i6TRL9Ihpk0c1xqGNgT8/8X0C/YKSEKS80XM2O/lNJvN9ir2nOslKfY+Ko+5MR1i2nhXl/7/lY+rPXjXU2VejvebYuoAfF+NRkOWJbmHpu1/d/xLDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpkHvZFXjRvL8AH/NX6JOsg3d/r0xdL+nfGpPj1QGvH689NJvNtq/X1aXPYbPZbDBeKBRkTk9PT1vXMjNrNBrBeLValTlembqe93zoZ8cvyWcec62YOSFWLhdeGnj9T0l6DKDtp4P3nlSZ1x5UWew66rjWf+o+Sa//0FmOa76IGUNj2l7Sc1bSexL6xfHqhHdxXOseM70niKlDzNqe9p0OseuKmLW1aq/enleVefVWe1Qzs3q93lY8Nifp72gx60l0jpg1kdeOY8ZXr8+qMu8+MTkx+4uYvVla+gX/UgMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpwKEGAAAAAAAAAABIBQ41AAAAAAAAAABAKnCoAQAAAAAAAAAAUiH3sivwomUymURzVFlMTqvVSrQOzWaz7ZyY+3i836TKvBzEi32uMW1F3ctrk6rMyykUCrKsp6cnGJ+cnJQ5ExMTwXixWJQ55XI5GN/Y2JA5Ozs7sqxUKgXjtVpN5qhnRF96vqT7Rcy9vDp0dYX/X4OYsdVMt5VcTk//qp95/U89n3q9LnOq1aosazQawbg3PtD+XwzVJs3i5osYMfeJaSsx464n5jlks9lE70O/iJf0s4sZq5Me85Le48S0V6RDzPjlzRcx1PW8uqn1TT6flzneul9dz/utqm96ayK17oldR6n5jL368fPW3Kqsu7tb5gwODgbjal9rZjYwMCDLFLXnNTM7ODgIxr09797eXtv3Uf1CxZ8n6fUp/izp9UjMWHRc41fM9y2vDt74oMR8X056flZeRh/jX2oAAAAAAAAAAIBU4FADAAAAAAAAAACkAocaAAAAAAAAAAAgFTjUAAAAAAAAAAAAqcChBgAAAAAAAAAASIX2/9T6K0T9ZXbvL7arMu+v1mez2cTuY2bWbDaDce8v2qsy7z6tVisYbzQaMqder8syleddT1F1w//hvdukxbwP9d69a6m+ZGY2OTkZjF++fFnmTE9PB+Pes9ve3g7GvXbs/SbVn1X8eddLMifN1O+N7RdJPr98Pi/LVP1ixkkzs97e3mB8eHhY5gwMDATj3jynxv5yuSxzDg4OZFmlUgnGq9WqzFF95nVr+x61FvDG1p6eHlmm2tfQ0JDMGRwcDMbVGG6m255Xb6/t7e7uBuObm5syZ2VlJRjf39+XOaq9en3JW8sl2ZbpF/9HzLyQ9LyuymLW1bHvNmZ8UDnePKfKYtu+91zb9br1i9i9aEyOaq9ejmp7XvsqFArBuDeXeWXFYjEY7+vrkzkx9VZ2dnZk2d7eXttlpVJJ5iS5V39VqXHKm9e9tqLWSydOnJA5b7zxRjD+7rvvyhy1tvfGvKWlJVn27NmzYHx+fl7mPH78OBhfX1+XOYeHh8G4N1/E7KG95xCT87pJ8ruqmR5DY765xuR4Y7U3Hqp1v9rXmpltbW21dS2Pt17zfpPKi1n/vQydUxMAAAAAAAAAAAAHhxoAAAAAAAAAACAVONQAAAAAAAAAAACpwKEGAAAAAAAAAABIBQ41AAAAAAAAAABAKnCoAQAAAAAAAAAAUiH3sivwMmUymbbiZmbZbDYYLxaLMqdQKATj+Xxe5uRy+tWo6/X29sqcZrMZjNfrdZlTKpWC8cPDQ5nTarVkmbqXl4M/89qk4j1X1R68e3l1UGWNRkPmVKvVYNzrS1NTU7Ls+vXrwfi1a9dkTnd3dzC+s7Mjc/b29mRZjK6u8Nmyintl3nt93fqZekbec4h5RjF9s1artV0HNe6bmQ0ODsqyM2fOBOMXL15s+3reb11fXw/Gl5eXZc7a2pos29raarsOquxVbfsxY7UaXwcGBmTO5OSkLDt37lwwfvbsWZlz8uTJtnN6enqCcbUmM/PXKisrK8H448ePZc6tW7eC8Xv37skc1S+8McAb+xVv7Fde1X6hxIzVMTlmcfO6eofe2F+pVNqrmPnrMlWHmPt4bVI9h9jnrcS0cS8n6fodp5j5IqYde/tKdS/vemqM9/bJar7w5jlv76GuNzExIXNGR0eDcW8+VX1GzVdmZvPz87Jsbm4uGFf7LzPd/l+3/UXMtyDVTszMhoeHZdmFCxeC8Zs3b8qc999/Pxi/ceOGzFFj/8LCgswpl8uyTO2H9/f3ZY7qF956Tc0/seso1ZZfxXactJh+4X3vVN9hzPRedGxsrO0cte8w0/Xz6uaNh+ob0ubmpsx5+PBhMO7toVU/8/qsNz+r3+T9VvXOY75hfV/8Sw0AAAAAAAAAAJAKHGoAAAAAAAAAAIBU4FADAAAAAAAAAACkAocaAAAAAAAAAAAgFTjUAAAAAAAAAAAAqZB7WTdutVrBeCaTSfQ+3vVUmfdX2XO58CPL5/Myp1gsBuPd3d0yp7+/X5ZNTEwE49PT0zKnVqsF4zs7OzJnYWEhGG80Gm3fx0w/V+96x9VOOp16Dp5msxl1L/WevH5Rr9eD8Uql0naO147fe+89Wfbzn/88GD99+rTMWVtbaytuZra9vR2M7+/vy5zDw0NZpt6T985VWUw7SbOkn5E3rqg8b/xSbbxarcqcbDYbjA8PD8uc69evy7IPP/yw7Rw1n5XLZZnz6NGjYFz9HjOzg4ODtsu8MUW9v5j3mgZqTC4UCjJncHAwGJ+ZmZE5V65ckWXXrl0Lxi9evChzxsfH26qbmW5H3rv15sCTJ08G4+fOnZM5o6OjbddB9fWtrS2Z49Vb9c2YsfBV7Rcx44BqX9745fUztb4fGBho+3remki1FW+95s0/GxsbwfjTp09lzvLycjC+t7cnc9S82dvbK3O8dxGzJ2B/8WdJr3tinp/XXmOup+pXKpVkjjfmqXFX7e/N9Bxz9epVmaN+69LSUts5ZroPevsVtY9Pso91EvW71Pcer8wbv9S3GzO97rhx44bMOX/+fDB+dHQkc+7cuROMf/XVVzJncXFRlqm5xJtj1LPzxgDVn2O+OXllMftDL0fVOw1zjHpGXr9Q46G3fz1x4oQsU/3i8uXLMkftI4aGhmSOeh/et12vfalvPur7kZn+rWp9ZWb2+PHjYNybL7zvvqrfxvSLmHXF9+0X/EsNAAAAAAAAAACQChxqAAAAAAAAAACAVOBQAwAAAAAAAAAApAKHGgAAAAAAAAAAIBU41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEiF3MuuQDsymUyiOaosm83KnFwu/Mi8nFarJcuUgYEBWXbx4sW24mZmh4eHwfizZ89kzv7+fjBeLpdlTqVSkWWNRiMYbzabMscrU2Ked5qp3+s9O6+9dnWFzzq951qtVoNxrz309/cH4zdu3JA5f/u3fyvLPvjgg2BctX0zs/v37wfji4uLMmd1dTUYV/3FzO8ztVotGK/X6zJH9SWPen8x4+pxi6m7yvHacUyZ18bVO/TuMzY2Foy/8847Muc//sf/KMt+9KMftXUfM90mvd/a3d0djHv9wutnGxsbskx5Fcf+mDVMoVCQOX19fcG41x4mJydlmRrHVRsy02PogwcPZI6az7zf6q2jZmZmgvGpqSmZo9ZYT58+lTlPnjwJxre3t2WO147V2B/T9mPGz04R0y/y+bzM6enpCcaHhoZkjtcvZmdng3Fvna7a3uXLl2WO2pN4z8cbx5eWloLxP/7xjzLnN7/5TTB+7969tuvgrW2S3mepZ5TmfuGJ2Suo/YCKmyW/LlPrZ7Xv8HJUfzHTc5mZWbFYDMa99qpy1Bxspscbb55bX1+XZWqNtbKyInNeNzF7IPU+1Ds3MxscHJRlIyMjwbial8zMtra2gvFbt27JnI8++igYv3v3rszxqPbqzbWlUikY9/pzzF7Ko/qt15+9MS+tkt5fDA8PB+NXrlyROe+9954su3btWjB+4sQJmaPms729PZmj5gWv/3nPQfHWXufOnQvGvXqrb7gPHz6UOXfu3JFlCwsLwbi3X1G8/hLzDes73fOFXBUAAAAAAAAAACBhHGoAAAAAAAAAAIBU4FADAAAAAAAAAACkAocaAAAAAAAAAAAgFTjUAAAAAAAAAAAAqcChBgAAAAAAAAAASIXcy7pxq9UKxru6kj1nUffxeHVQ16vVajKn2WwG4z09PTJndHRUll24cCEYP3/+vMzZ2dkJxjc3N2VOzLvwcgqFQjDuvaN6vR6MNxoNmRPzzjtFTL+IyYm5nnoXZmYHBwfBeCaTkTlvvPFGMP6LX/xC5rz//vuyLJ/PB+MPHjyQOZ9//nkwfvfuXZmztrYWjKtnYOY/OzU+eO1Y5Xi8d9EJvPqpZ+HlxPxeb1zx3qGi+tng4KDMuXnzZjD+n/7Tf5I5Xp/p6+sLxldXV2XO0dFRMD4yMiJzpqamgvGhoSGZo/qsJ6adeH0ppm0dp6T7hWqTXtvf29uTZc+ePQvG79+/L3N2d3eD8a2tLZmzv78fjPf29sqcM2fOyDI1l7z55psyp7+/Pxj3+rNa53nvyBtrstmsLFNi3nmn855fLhfe2nR3d8uc4eHhYHxmZkbmvPXWW7LsBz/4QTD+zjvvyJyxsbFg3Fuvqd/qja0qx8ysXC4H45OTkzJHrUe8djw/Px+Me781Zr5Pej9wXPc5TjHzRez8qNpKtVqVOZVKpa1rmen6efvuYrEoy1R/UvtaM93+1e8x0+O71y+8cU2t/7x5U+1lYvbdaVhHxeSoMi8nZv7xnrkaQ7/++muZo8rUmszMX98cHh7KMkWtJ9W+wyxun+w9O3W9mL316zb2e+Pk9PR0MK6+95iZ/ehHP5Jlb7/9djCu9gNmeu8R871TrfnNzAYGBmSZ4rVJNVZ7/W9iYiIYP3XqlMzxvi9/9tlnwfjjx49ljvq+HPPN5PviX2oAAAAAAAAAAIBU4FADAAAAAAAAAACkAocaAAAAAAAAAAAgFTjUAAAAAAAAAAAAqcChBgAAAAAAAAAASIXci7x4q9WSZZlMJrHredfy6tBsNoNx76/TK7VaTZYVi8VgvLe3V+acPXtWlr3xxhvB+PT0tMw5PDwMxvf29mTO/v5+MF6tVmWO97xVWVeXPluLaSedLuYZHedzVderVCoyR/WZkydPypxf/OIXwfgvf/lLmTM6OirLPv3002D8N7/5jcz55JNPgvG1tTWZo55DvV6XOV6Zehfe+2v3WmmgxuNYXp9Jsg65XPvT6MTEhCx79913g/GbN2/KnGw2K8t+//vfB+O3b9+WOQMDA8H4hx9+KHPy+Xww7j1Tb0xR84w3P6t7pblfxKyjvPXI0dFRMO6tBebm5mTZ48ePg3G1fjAz29jYaLsO6t2Oj4/LnL6+PllWLpeD8Zg1oze+q/t46yivXxQKhWDcGwOU2LXzcVLzoFd3VeaN1T09PcG4N1Z765vZ2dlg3HuuT58+DcZXV1dljuozQ0NDMsfrM8PDw8G4mhPMzC5cuBCMP3r0SOYcHBwE42p8MvPnkuNqr53SL5SY+h3nb1JjmzfmqTJvLaD23d4YoNq+V6bGDTM9D3tzo/ou4M2Nqi+Z6f7k9aWYMbfTJd0vVNtT87OZ2eDgoCxTe9vu7m6Zo9Zlm5ubMkfVb2ZmRub09/fLMvUcvHFc9QtvHRWzH/bWwcc1TnZKn4mph3rmXhtX4+TFixdlztWrV2WZWtd6+9ePP/44GN/e3pY56rd647s3l6i27K2j1NjvreXGxsaCcW+Nd+PGDVmm+ow3x6gyrz+/KPxLDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpwKEGAAAAAAAAAABIhdyLvHhXV7JnJup6zWZT5jQajbbv412vXq8H461WS+b09fUF4ydOnJA5V69elWXnz58Pxr16b25uBuMLCwsyZ3t7Oxg/PDyUObVaTZapd+E9OyWTybRdFnOfF8GrewzVL2Lvo9q4924HBweD8R/+8Icy5+/+7u+C8bNnz8qcJ0+eyLL/9b/+VzD+hz/8QebMzc0F495vVf0stn3lcuFhOKaNp5n3m9Sz9cY8db2YHDOzfD4fjFer1bavNzk5KXMuXrwYjPf09MicO3fuyLJ//ud/Dsbn5+dlzocffhiMq2dgZlapVILxra0tmbO7u9v29bw5XbUT772q8bNT5osYXhsvl8vBeOx7UmOluo+ZfrdqLDQzm5mZCcbPnDkjc95++21Zdvny5WC8u7tb5uzs7ATjS0tLMketo0qlksyJGaNi2njM+vi45x7VD739RcwzymazbeccHR3JsqdPnwbjn3/+ucxR4/jq6qrMOTg4CManpqZkjtdn1PzjzVnFYjEY7+/vlzm9vb3BuBobzPwxOcnxOnaN0Am8fpHkHszjPT/Vz1TcTLcv710MDQ0F416/OH36tCxT7d+rQ8zcqPbqi4uLMsebf/b29oJxtc/zeG0rZo1+nGL6rdcv1O/y1g+jo6OyTLVLNU6a6f7s5Vy5ciUY9+rtrctUW1ZrJTPd1739hZprvfnCm59V30x6TxmzJzlOMd8ZvLFazfne905vXLl161Yw/t/+23+TOX/84x+DcW/M89q4UigUZJn6TWouM9P9dmxsTOaoOevNN9+UOd449MYbbwTj3hyzvr4ejHvz3IvCv9QAAAAAAAAAAACpwKEGAAAAAAAAAABIBQ41AAAAAAAAAABAKnCoAQAAAAAAAAAAUoFDDQAAAAAAAAAAkArt/7n3Ea1ZgQAA0/BJREFUl6jZbAbjtVot6nqZTKbt6zUajWC8u7tb5kxPTwfj165dkzlvv/22LJuamgrG7927J3Pu378fjD979kzm7OzsBOP1el3mtFotWaben5ejytS10k61yZgc7xl5z7xarQbj2WxW5pw7dy4Y/+u//muZ8+abbwbjpVJJ5nz66aey7LPPPgvGV1dXZY5qy14bV7znncvpobarK7mzZa8O6j5eW+gUqo3HjB0xOWb62VYqFZnT09MTjE9MTMickZGRYHxvb0/m3Lp1S5YtLS0F42NjYzLnxo0bbefcvXs3GF9cXJQ5ao4x0+NQzNgf0y86RUx7VesUM72+OTg4aK9i/5t6fr29vTLnxIkTwfjJkydljmqTV65ckTlqjjHT66itrS2Zc3h4GIx7fVM979h2p9656i+xOn2+8Pq0KvPmdfWe1Ds3M5ubm5NlT58+DcYfPnwoc9QY6u1JCoVCMO61Se/Z9fX1BeNee/WekeKtiRSv7cWsndX1Yq7VKWKekfdu8/l8MF4sFtu+j5lZuVwOxr39hfpNan1lZjY+Ph6Mnz59WuaoOcFM7/G9eqs27o1Dqi9589Lm5qYsU+OAN1+8ivvrpOct9W69Njk6OirL1Lrf+7Y0ODgYjJ89e1bmqOvF9mf1XL21vSpbX19vO8e7jzcH7u7uthU3i/su0ClzScy3NJXjjXlqbT87Oytztre3Zdlvf/vbtuJm+rumtydR78l7f16fUc/Iu56aa711phr7vbb6/vvvyzL1vfrixYsyR3179ualmO8z30Vn7+YBAAAAAAAAAAD+Nw41AAAAAAAAAABAKnCoAQAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKRC7kVevNVqtZ2TyWQSvV7S+vr6gvGZmRmZc/PmzWD8Rz/6kcy5dOmSLKvX68H4o0ePZM6dO3eC8ZWVFZlTKpWC8Ww2K3M86v01m82o66VVJ/SLWq0my9T7GBkZkTk//OEPg/Gf/OQnMmdwcDAY/+qrr2TOvXv3ZJl6Rl7frFarwfjR0ZHM2d3dDcbL5bLMOa6xq6ur/XNqr211CvX8vLqrduzleGWqrajx2Ez3mZMnT8qcYrEYjG9sbMgcNVabmZ09ezYY/8EPfiBz3n777WDcG6sfPHgQjD9+/Fjm7O/vy7KYeSGmn8W0rU6h6u49h0ajEYyr9m1mls/nZVlvb28wfurUKZlz5cqVtuJmZjdu3AjGL1++LHPGxsZkmWpfXl8aHR1tuw5qvsjl9PJ7e3tbllUqlWDc6y+qPXjzRSest83i6qGehTdWq+fqvQtvnbC1tRWMLy0tyZyDg4NgvLu7W+aoPYmX463h1fjgta+BgYFg3FszFgoFWaZ470+1Za+NqzG+U9p+DK/u6vd6Y5Ea371367U91Y5U/zMz6+npCcb7+/tlzuTkZDA+Pj4uc1Rf8njPTvUL9XvMdBs/PDyUOd6zU/uSmPXVq7pXjxkHkszx8rxnrvpZzLir+rl3H+96HvUcvLXXwsJCMO599/Lm2sXFxWDce95qv+K9807vM17dY9aNQ0NDwbg3Tq6vr8uyL7/8Mhh/8uSJzFHU2sZM18+rt7eOUs/I22ep73Le97rl5eVgXO1VzMzOnTsny9ReZnZ2Vuaodx7zfeb74l9qAAAAAAAAAACAVOBQAwAAAAAAAAAApAKHGgAAAAAAAAAAIBU41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEgF/WfdU8T7C+temfrL9cViUeaMjIwE4xcuXJA5H374YTD+k5/8ROYMDw/Lss8++ywY/7d/+zeZ8+DBg2C8VCrJnK6u8JmXipuZ1et1WRbz1+5brVYw7r1XldMpkq67ul7suygUCsH42bNnZc77778fjHv9olwuB+Pz8/Myx+ub169fl2VKo9EIxldWVmTOkydPgvG1tTWZs7e3J8vUu1Djk1my7eRVpX6v1/a9Z6TGvb6+PpkzPT0djI+OjrZdh2q1KnNmZ2dl2dtvvx2MX7t2Teb09vYG4998843MuX37djC+ubkpc2q1mixTz8F7R2rM8+asNIvp02rsiO0Xqq0MDAzInKGhoWC8u7tb5hwcHATjS0tLMscbk4+OjoJxr0329/cH497co56rN5c9fPhQlq2vrwfjaj716hAz3nX6+spM19Gru3p+3vjlUWvrSqUic3p6eoJx1cfMdDvy+lJMmaqbmV5HeTm5XLLbT/VuvbH/ddtfqGfutYfJyclg/NSpUzJnbGxMlsXsV9R8oepmZjY1NRWMDw4OyhyPGh+8dbrqt/l8XuZsbW0F49584c3d6rl668mY+SKmL3UKVUevr6vn6s3Dh4eHskzNM967nZubC8a9/asaq705xutnqv17/UztV8bHx2WO+i7hta+Y+cd73qrPeGNXmtdR6tl684X6dun9Xm+drvqFt05X790bQ2N+q3c9tc5T/c9MzwteG9/Z2QnGFxcXZc7GxoYsu3LlSjDuzenqnXtrL9XPvm+/eDV3+gAAAAAAAAAA4JXDoQYAAAAAAAAAAEgFDjUAAAAAAAAAAEAqcKgBAAAAAAAAAABSgUMNAAAAAAAAAACQChxqAAAAAAAAAACAVMi97Aq0I5PJBOO5nP4Z2WxWlvX29gbjIyMjMufs2bPB+AcffCBzbt68GYyPjo7KnOXlZVn22WefBePffPONzNne3g7G6/W6zPGeq9JsNmVZq9Vq+3ox91HtJM28Z6eehfduPWNjY8H49evXZc4PfvCDYNzrS/fv3w/G9/f3ZY53vdnZ2WDc62ddXeFz3YWFBZkzPDwcjH/99dcyp1KpyLJSqSTL4PP6hSrzclR7MNPtaGpqSuaoeeHatWsyZ2JiIhj36n3y5ElZNjMzE4wPDQ3JnKdPnwbjX331lcx58OBBML6zsyNzvN+kxnFvfFdzVqPRaPs+xy3JenjXUs/cm1O9uUSNbd57f/z4cTC+tbUlc9R8EVtv1dfV/GdmduLEiWDc60vvvvtuMJ7P52WO117Vb/KencqJGT/TQNXde65qHi6Xy1F1qNVqwbi3J4kZA7z2r3h1UGVqv2Rm1tPTE4yfOXNG5jx69CgYX1lZkTneOsqbu9sVMy8dd39R9fCeQ6FQCMbVmtbM7NSpU8H422+/LXO8967aildvVT9v7aX2CsViUeZ4fV3tS7z+p8pi7uONXTFl3lijcrz7KJ0yj3jtK6aOak71xihvjp6bmwvGvf2w+uajrmWm5yVvfFfrHjM9X/T398uc+fn5YNwbh9S44a29vG9Yqv0fHBzIHLWm9fbwMfPzi6DauNcv1DPy1q5qfPX6xfr6uixTY6U3jqvfFNPPY9YCHu/Zqb4U8y3P23957VXVb2BgQOZ4ff248S81AAAAAAAAAABAKnCoAQAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVci/rxplMpq24mVk2mw3G8/m8zOnp6ZFlw8PDwfiZM2dkzjvvvBOM//SnP5U5ly5dCsY3NjZkzu9//3tZ9oc//CEYX15eljn1ej0YV8/UzCyXCzePVqslc2J47zwmJ+n6HSf1u5rNpsxR79bLKRaLsmxycjIYv3r1qsyZmZkJxvf29mTO06dPg/G1tTWZUy6XZVm1Wg3GvbYyNTUVjF+4cEHmqPa1ubkpc1ZWVmTZ0dFRW/cx078ppu3H9L/vQ9XRq0dMv2g0Gu1VzMwGBwdl2alTp4LxH//4xzLnl7/8ZTD+3nvvyZz+/v5g3Gv7tVpNlg0MDATjlUpF5qi5aWlpqe0c1S/N/Hfe1RX+fy68d67alrpW2h3X7/L60vb2djDutS81xnu/R7UVNX6a+W2vu7s7GFdzgpmeF65cuSJz1HrSm2PUMzUz29/fD8a936py0rBWipmf1O9SayUz3ca9NumtnxXvemrNHdPPvd96eHgoy3Z2dtrOUXspry+psqGhIZnj9XUlZl2Rhn6heG2lr68vGFdrfjM9tnlrmLNnz8oy1c+8NYwaq3t7e2WO6kulUknmeG1cXS9mDPDmU7W+8eZT79mpcSCmDmkWs5/yxlD1zL33pMZWM/39xttDz8/PB+OLi4syR/1WtU94HtVWvPWIyvH68/nz54Px69evyxz1XcJM9+fV1VWZs7CwEIx7Y4BqQ8e9707yO5t6dmb63R4cHMgcr8+ofqvmBK8Onpg1o7ceifn+EDM3qt/q1dt7f2qN4NUhZm70rvd9vJo7fQAAAAAAAAAA8MrhUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpwKEGAAAAAAAAAABIBf0n0F+wTCYTjHd16XOWYrEYjA8MDMicsbExWXbq1Klg/OrVqzLn/fffD8bPnz8vc9Rfef/yyy9lzm9+8xtZ9sUXXwTjm5ubMifmeascFTczy+V0k2o2m21fr91rmZm1Wq22r9cpVN1jfq/3HLq7u2XZ1NRUMD40NCRztra2gvHHjx/LnFu3bgXjd+7cafs+Zvr3jo6OyhzVn69fvy5zTp48GYyPjIzInHw+L8uUNLdjT0x/T1KhUJBl3jt88803g/H33ntP5ly7dq3t++zv7wfjz549kzmVSkWWqf6s5iUzs5WVlWB8cXFR5qi+WS6XZY73LpSk289xtseYeyWd483Rijf/lEqlYPzg4EDmqHWHtx7JZrPBeLValTle21PPYWNjQ+aoNZZ6Bma6jc/MzMic06dPyzLVB725UT0HbwzoFEnOg/V6XZapPqPa3fPErJ/Vb/X6hWrH3nPz2qtq42trazJH7bMGBwdlzvT0dNs5u7u7skzNgd7zjtmTeGNh0rx6xLTXnp6eYHxyclLmXLp0KRi/cuWKzJmYmJBlq6urbcXN9JjsvQs17no53r5oeHg4GO/t7ZU56l7Ly8sy5+nTp8H44eGhzPHGtZi5VrUtb0x52ev6/1eS3xNi9t3emmNnZ0eWqfHVm6NVG/fG0EajEYyr72tm/nyhfq+3HlG/1Xt2anw4e/aszPHGKNVO+vv7ZY4aW2PG6RchZm0Rw+sXaj3u7Qe8Nq6+O3nvyWtH7fLqdnR0JMti1haqD3r7e8XbW3vjQ19fXzC+vb0tc9Q7j5kvvm875V9qAAAAAAAAAACAVOBQAwAAAAAAAAAApAKHGgAAAAAAAAAAIBU41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEgFDjUAAAAAAAAAAEAq5F52Bf5SNpuVZcViMRgfHByUObOzs7LsjTfeCMavX78uc65cuRKM5/N5mfPw4cNg/E9/+pPMefDggSyr1WrBeHd3t8xpNpvBeLValTldXeEzr0wmI3M8Kk/dx8ys0WgkWodO0Gq12i7zctQz8nhtRfWnXE4PFxsbG8G4avtmZnfv3g3Gvba/tLQky8rlcjB+/vx5mXPt2rVgvKenR+aoMcrrS/V6XZYp3jtX0twvPDFjhyrz3u3IyIgsm56eDsZHR0dlztHRUTD++eefyxzVLx4/fixzJiYmZNmHH34YjBcKBZmztbUVjK+srMic7e3tYDxmfDLT7V/NZV5Op/DqF9N3VY43Vqv37q1hvPGrUqkE42qdYhY3z6k6eHXznqlqR7u7uzJH/VZvPr106VIwfvr0aZnjjSlqjOrt7ZU5qj14z67T+1IMb+yI4bUvb25S1NrC688qx+t/XhtX43V/f7/MUW3Zm2tVnxkYGJA5ag9opttyTDtOQ9uPWROpsd8bb8bHx4Nx7916a+HV1dVg/P79+zJnbW0tGPfWMKq9Dg0NyRyvP+/v7wfjXl8qlUrB+NzcnMyZn58PxtUey0zvfcz0b4oZu9Kwv0hy3+T9XjVOqnduptfIZrqfDQ8Pyxz1fcsbJw8PD4Nxrw3FrLm9db/aF+3s7MgcNZ953/9mZmZkmRqjvHee5BzzIiRdD3U9r60sLi4G496429fXJ8vUvnt9fV3mqPnCW+/G7C+8eS5m36ueq9p3mOn1kvpWbWb21ltvyTI1dqh520zPTTHfOr8v/qUGAAAAAAAAAABIBQ41AAAAAAAAAABAKnCoAQAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTIfdf/MJPJyLIk/4q5d59cLlzdnp4emTMxMSHLTp48GYyfOnVK5vT29gbjm5ubMufu3bttxc3Mtre3ZVmj0QjGu7r0GVU+n5dlStJ/nb7ZbAbjXr3bvZZZ8vU+Tqru3m9SZV5f8tqD6mfeMz86OgrGDw8PZc7BwUEwXi6XZU61WpVlhUIhGD9z5ozMeeONN4LxgYEBmaP67dbWlszx6h3TXtW79d75qyhmvlBjuJnZ4OCgLCsWi8G4asdmZl9//XUw/s0338icr776KhivVCoy56c//aksy2azwXi9Xpc5a2trwfj6+rrMUfWLGd/N9HgTM/bH1qETJDk+mOl23N/fL3O851er1YJxr72qHK9NqnlBtW+zuHWr175UvT3d3d3BuDfHeGOKWu+q8c5MP6OY55OG9VXMmijJtVcs1fbUmt/M72eKtx5R9yqVSjJH9Vtvnan6hbef866nxiivz6ahLSsx7VW1r5gx1Huu+/v7skytLbw2OTIyEoyPjo7KnKGhoWDcGye9/cr8/Hww7q37d3Z22s5RY7/X/7x3nuRe4bi+A70IxzVWe+04Zgz11gmq/av+Yqa/Ve3t7ckcr96qz3j7+MnJyWB8dnZW5vzwhz8Mxq9fvy5zxsfHZdnDhw+DcW8MUHOtt2ZMM9UmvfF9eXk5GFffW830txszs9OnTwfjamw10+/J27+qfuuNG966TPH6hSrzxt3Lly8H4zdu3JA5ly5dkmWqLc/Nzckc9VxfRr9I704fAAAAAAAAAAC8VjjUAAAAAAAAAAAAqcChBgAAAAAAAAAASAUONQAAAAAAAAAAQCpwqAEAAAAAAAAAAFKBQw0AAAAAAAAAAJAKue/6H7ZarRdZj++k2WwG417dVI6ZWaPRCMZrtZrMWV5eDsbn5+dlzhdffBGMP378WOYcHh7KMlU/r95Jvj/vmcbcJ+Z6ndAeO0XMs6jX67KsVCoF40dHRzKnqyt8Pjo0NCRzTp06JcuUkydPyrITJ04E4z/72c9kztWrV4Px9fV1mfPtt98G44uLizKnXC7LstetLWcymWDcew4qR8XNzHK58PRWKBRkTrFYlGVqnFpZWZE5W1tbwfjXX38tcxYWFoLx06dPyxyvL42Ojgbj3vwzNzcXjKvfY6afj3oPZv44FDPfx7STTqF+l1f3mJx8Ph+MDwwMyJzBwUFZ1t3dHYx787qaY/b392XO9vZ2MO7NS177Uus/77eOjY0F42oeMTO7dOlSMN7f3y9zvGdXrVbbij/veq+imP4eMw9798lms8G4Nx6qnBiqfT/vPuo5ePX2yhRVP6+tqnWmmX4XSe9XOl3MnOrtN9Va+OnTp23V6/+lxilvPFRjsre/UO1haWlJ5ty5c0eWqfX97u6uzFHrfq9vqndUqVRkjrf3V+0hpp28bmLmEe+57u3tybKdnZ227zU1NRWMq72wmdnBwUFbcTO/3mpP4D0HNf+o9ZWZ2S9/+ctg/MaNGzLH65vqW563n/P28WnlzYGqzGsP6luo1ybPnTsny9Q3n6T3jhsbG7JM8dZRap7z6qD2Zt6z+7u/+7tg/Oc//7nMmZ6elmWff/55MH7v3j2Z47WH48a/1AAAAAAAAAAAAKnAoQYAAAAAAAAAAEgFDjUAAAAAAAAAAEAqcKgBAAAAAAAAAABSgUMNAAAAAAAAAACQCrmXXYG/5P1F+0qlEowfHBzInNXVVVn24MGDYLzRaMicZrMZjK+trcmcL7/8MhhfWFiQOUdHR7JMPSNVNzOzVqsVjHu/NZPJtHUtL8fj1VuVeTmdzntGqizp57q/vy/LVlZW2oqbmU1PTwfjp06dkjkjIyPBuNf2C4WCLJucnAzGJyYmZM729nYw/sknn8icW7duBeNbW1syp1aryTLVn7q69JlzTHuIyXkRvPFDiekXqsx7rt54qPqMdz3Vvrx57uTJk8H4+++/L3OuXbsmy1T9nj59KnMeP34cjJdKJZmTy4WXE9lsVubEjP0x79y7j/f+Ol3M/KjanvccxsfHZdnU1FQwPjw8LHPUGOCto/b29oJxr02Wy2VZpp5Rd3e3zDl//nwwfv369bZzDg8PZc7i4qIsU8/Iew5qXIsZi9PguNauMZJe/6k1UbFYbDvHzKy/vz8Y7+3tlTlq7Pf6n2r/3txYrVZlmWrj3rNTY0BMO3kRfcm7Zsz91Bjhre3v3LkTjHvr3Xw+L8vUOkq1ITOzzc3NYFy1VTOzZ8+eBeO3b9+WOWrdY6bnH6/efX19wbj3fNT1vD2E1y9ivhcoaZ4vYsb3mD2Y94y88VD1p/X1dZmj1l7evlu1Sa/e3tpC9Quvfc3Ozgbj3jpT/SavX3z22Wey7E9/+lMw7q291PvzfutxzhdJU3Oq1x7UuOvtBwYGBmSZ+rZ07tw5maP6bU9Pj8xRc4z3fdkrU+sbr62cOXMmGL9586bM+c//+T8H496eZH5+XpZ99NFHwfj9+/dljnoOL+M7bXp38wAAAAAAAAAA4LXCoQYAAAAAAAAAAEgFDjUAAAAAAAAAAEAqcKgBAAAAAAAAAABSgUMNAAAAAAAAAACQChxqAAAAAAAAAACAVMi9rBu3Wq1gvNFoyJxqtRqMb29vR9Vhf38/GH/69KnMUfXb3d2VOYuLi23nNJtNWdbVFT6L8nJiqHeUyWQSvY9X76R/U6eLebe5XLgb1+t1mXN0dCTLlpeXg/Hbt2/LnN7e3mD8xo0bMmd2djYYz2azMkc9HzOzSqUSjD948EDmfP7558H4Z599JnMePnwYjB8eHsocj/q93m/1yl5FasyJGR+8fnFwcCDLdnZ2gnGvvebz+WD84sWLMufEiRPB+M2bN2XO4OCgLHvy5Ekw/vXXX8uc1dXVYNxrd8ViUZYpMfOcN//E5HQ6NQ+b6d+l1kpmepz0xi9vvujp6QnGz5w5I3NGR0eDca89lMvlYLxWq8kc73rq2Xn9eWZmJhjv7u6WOWqd582nX331lSxT60nv/al1q9e2vLJO4NUvZhxQbcXL8eqgrhfzXGPmGK9NFgoFWdbX19d2HVQb98YhtW/zxpqYZ5d0O+6UfqHapVe/UqkUjM/NzckcNb4ODw/LHG+doPbdXr339vbaznn8+HEwvr6+LnPU3GhmNjAwEIwPDQ3JHNVnvO8cirdujVkHH9f3gjSI2V+oNu49B7WGMdPj4cLCgsxRfVCtr7wcrz+rOcZM/15vvlBzjPe8Hz16FIzfuXNH5vzrv/6rLLt161YwvrW1JXO8Pqh0er9Ien+h9o7emtabL65fvx6Mnzx5UuZcvXo1GJ+enpY5av0cuy9S86a3LlN7/DfffFPmnDp1Khj3xo1/+qd/kmUff/xxML6ysiJz1G99GW3/9foyBgAAAAAAAAAAUotDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpkHtZN261Wm3nVKvVtq9Vq9Vk2d7eXjBeKBRkTr1eD8YrlYrMOTo6CsYbjYbMyWazskz9Xu85NJvNtuJmZplMpq14LK8OMe3kVRTTHjzeM9/a2grGb9++LXMODw+D8cXFRZkzNTUVjOfzeZlTLpdlmar30tKSzHn06FEwvrm5KXNKpVIwrsYGM7/PJN2fXkVqrOzq0ufyar5Q47GZ/967u7uDca9vDg0NBeOq7ZuZnThxIhj32smDBw9k2aeffhqMf/PNNzJH9WevDuo5eGON9/4Ub7x7FftSzG/ynpF6t17bz+X0UrGnpycYHxgYkDl9fX3B+OzsrMzp7e0Nxr31WszaQj0fM7OdnZ1g/OnTpzLn4cOHwbjX/7z+vLa2Foyrecksbs3Y6bx+oX6Xl5P0WKTanrdOUNfz6qb2Ht5v9eqg7qXWV2a6/Xt7nO3t7WDc20vFvHPvHXV6+4/5vR619vHe7cHBQTDuzQle+1LX8967yvGegcrx+lJ/f78sKxaLbV9PfX/wfqtaR3l9yaPeRczY9apKcg/t9Vlv/7qxsRGMe+1L9UHv/ak1zOjoqMzx9uSqX3jjg+qbak4w02uiO3fuyJy5uTlZtrq6GozHrKPS3F9i9hcx65GVlRWZo/aoZvo77VtvvSVzzp0711bcTO8vvLbvPQe1L/H2K2NjY8G4176++OKLYPzf/u3fZM7vf/97WXbv3r1gfHd3V+aouellrK/4lxoAAAAAAAAAACAVONQAAAAAAAAAAACpwKEGAAAAAAAAAABIBQ41AAAAAAAAAABAKnCoAQAAAAAAAAAAUiH3sivwl2L+WnqtVpNl9XpdllUqlWA8m83KHFU/7z6qzLuP+mvyZmZdXeGzKO/ZNZvNtnMymUzbOTHvLybndaPehZlZLhfuxl778tqr6k+rq6syZ39/Pxh/+PChzCkUCsG491tVnzXTv6larcoc9VtVfzHT7dWrt0fleddLug6dTv1e7z2pcbJcLsucjY2Ntq/nta/R0dFg3GvHR0dHwfjc3JzMWV9fl2UPHjwIxhcXF2WO+k3H2SbV9dR7eFXFzI9ev1Dvdnd3t+0cM7NSqRSMLy8vy5x79+4F45cuXZI5qi8NDAzIHK/tqX62vb0tc1S9l5aWZI7qm97zUfOpmZ6zYtZ/r6qYPhMzrng5qsxb26uymP6s1oXPK1P9Qq3XzHSb9PqfGjfU/c38deur2MaT3hupZ+Q9c/WevH13zDv0rhezf1X7H2++KBaLbV/P+60x70/dx+uz3pii6uDlvIp9KYY3vsfsSWL23QcHBzJH7VeePHkicyYmJoLxoaEhmdPd3S3LVHv15gu19zg8PJQ5an26trYmc7y9nnoXXr943SQ5fnnju/dtSb2nzc1NmTM/Px+MX79+XeacPHkyGJ+enpY53lyi2pHXn+/cuROMq99jpvf36lpm/t5D1S9mjnkZXq+vAwAAAAAAAAAAILU41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEgFDjUAAAAAAAAAAEAqcKgBAAAAAAAAAABSgUMNAAAAAAAAAACQCrmXXYG/lMlkZFmr1QrGm82mzPHKlK4ufdaTy7X/yFSOVzf1W70y79mpMu8+qn7efdA5vHaczWZlmXq/Xns9PDwMxg8ODtq+T6PRkDke9Xu95xDTlr0+E3MfVUY/ez7vXah25LXjWq0my5aWloLxzc1NmTMwMBCMz8/Py5y+vj5Zpqj+Z6br5/XNmGeXNNr/86n2HzNGeer1uiw7OjoKxpeXl2XO3bt3g/Hf//73Mqe3tzcYLxQKMscb+6vVajBeLpdlzt7eXjDu9T81psTOczHrYPxZ0utd75nHjF8x+wv1m7y5zHsOql+otu9dz2vj6nrevOT1TXUv77fG7IteRd57inkWXjtW1/P2JGoc9/pYPp9v+z7eby2VSm3nxOxJYsb3mO8FeL6kv8Mkve/e3d0Nxnd2dmTOvXv3gnGvTXrUb/LWZYqae8zi9iRJfxN73fYkMb836e8Zqo17awG1hlhZWZE5w8PDwfjQ0JDM6enpkWWqvVYqFZmj9kxra2syR/1WtS8z89eGaq+XlnmEf6kBAAAAAAAAAABSgUMNAAAAAAAAAACQChxqAAAAAAAAAACAVOBQAwAAAAAAAAAApAKHGgAAAAAAAAAAIBVyL7sCSchkMrIsl2v/J2az2bZzvL8M32w2g/FGoyFzvN+kyrycGElfz3tGiKfek/e8vX4R855UG+/qav/cNKb/ebx2rH6rl6N+k3oGz5N0P4Mv9j0dHR0F45VKReYcHBwE4zs7OzKnu7s7GPf6UrValWWqfrVaTeZ4c5MSMw7hxYgZU2LXIzFtpVwuB+Pb29syR7X/2PGzXq+3FTfTY4dXBzWfHed6jT74fDHPyHvmMW1F9SVvzorpF95vVXOJ1zdLpVIw7s2NagxQ86xZ3Fjjed36RZJt3FuPFAoFWZbkeOj9HnU9b3z3qLaX9H5F9fWY3+rlse/4fmLWu15biRnHk1xze/3Cu57K88Z+JaZNJr3uoV98PzHfJ725RL1Db/+6tbUVjHtrGPVNzFtzePVW47i3V2/3Wh6v7cd8r04L/qUGAAAAAAAAAABIBQ41AAAAAAAAAABAKnCoAQAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKRC7mVXoB2ZTCbRHFXW1aXPelROq9WSOV6Z0mw2276ed5+YZxdTb3SOmHfu5Xn9QpXFtKGk+1LS/cLrm0neBy9G0u8i5nrValWWNRqNtq/ntcl6vZ7YfTzMF50j6XeR9PVUe/Xuo3K8/uf1C1Xm5cTMjQr9JR1i2qQnpq14bVzNJd59vLFfzRdHR0cyJ5vNtlU37z4qbubXm/50vGLXUblc+LODd70k1/0x/c9M1zumDjE6fU7Hn8W2r5jvOrH3ClFjuFncXiHm21vMGJD0dw58PzHjite+Yr651mq1tuvgrVWUpH/rcUn6G1sn4V9qAAAAAAAAAACAVOBQAwAAAAAAAAAApAKHGgAAAAAAAAAAIBU41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEiF3MuuwIsW81feY/76u5eTyWSC8Waz2XZObB1UWcx9kH4xbbzRaLSdk3T76oR+QZ/B/80bx2NyarVaMB7TZ2ProNq41/aZY/BdxbRl1V5j2qSXl81m26vYc+qAV1fS66iYuUSJafte2XGtvZKe53D8OmHdnzRVh5h+1gm/By9G7PgVs36O2ZPH3CfmN3V16f9nmr6E70q1iZh1VNJri6TbK2uf749/qQEAAAAAAAAAAFKBQw0AAAAAAAAAAJAKHGoAAAAAAAAAAIBU4FADAAAAAAAAAACkAocaAAAAAAAAAAAgFTjUAAAAAAAAAAAAqZBptVqtl10JAAAAAAAAAACA5+FfagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpwKEGAAAAAAAAAABIBQ41AAAAAAAAAABAKnCoAQAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVONQAAAAAAAAAAACpwKEGAAAAAAAAAABIBQ41AAAAAAAAAABAKuS+6384NTX1IuuReq1WS5ZlMpnXpg5ptbq6GpU3MTGRcE2AzrG+vh6Vd/369YRrAnSOW7duReWdOXMm4Zq8Wl6nNcyr+FufPXsWlcf+Aq+y2P1Ff39/wjVBWr2K88XBwUFU3sWLFxOuyasl6bYScz0vp91reV7FfvHw4cOovNOnTydcE3QCrx3H9LO0mpube+5/w7/UAAAAAAAAAAAAqcChBgAAAAAAAAAASAUONQAAAAAAAAAAQCpwqAEAAAAAAAAAAFKBQw0AAAAAAAAAAJAKuZddgddBs9kMxpP+i/bHeT28fpJuXzH3UX3peXlAJ+nq0v8/gdfGgVeBmi+8fqFykpx7nkfNMTFzI/MVXqSk12teTpJtOfZaxzkOoDMkPYYm3caPa1+EV1dMmzzOttJoNIJxby0HfF+v0/eo41p7Pe9eacCoAwAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKQChxoAAAAAAAAAACAVci+7Ai9a0n/JXV2v2WzKHFXm/dX6ri593qTKvN+q7uXlqDKv3selE+rwuvHauBLT/7x3m/R7T7p+MTlJj1HofF5fOq42iddT0u3ruNprWsfJTpiz8GIk/S46YRxXv8n7rdlsNhjP5fQWM+a3NhoNWabm1Jg9Dl4cb2/bbk5M+/Lur9qxmW4rlUql7ZyYduxhzXj8OmHs8NqREvM9KqateO04ZgxQYttxku+PvnT8Yt5fJ+y7O2GsfpXbK/9SAwAAAAAAAAAApAKHGgAAAAAAAAAAIBU41AAAAAAAAAAAAKnAoQYAAAAAAAAAAEgFDjUAAAAAAAAAAEAqcKgBAAAAAAAAAABSIfeyK9COVqv10nOazWZi9/F0denzJq9MUfVTv8fLyWQyMscrSzIH6ZD0u/X6mSrzclT9vJyY/ueJ6WdIhyTnhUajkdi1XoRsNhuM0447S8yYF3M9j1p3eOuRGF7d1Diu2vHzypSYtVfM9WJy6JsvjmpfSa+f1X28duLNJarMa/vFYjEY7+npaTunXq/LnEql0naZd73j2s+9iry26rWVXC782SGfz8uc/v7+tuJmZt3d3W3d38x/74eHh8H4wcFB2zmlUknmqPYas48xS/Z7wes2XyS9d/Qk+WxjvuvESvKbjzcvqXbs/daY9Ro6S0w/i5nXY3K8sTXmejHtVT2f2Dkh7WM//1IDAAAAAAAAAACkAocaAAAAAAAAAAAgFTjUAAAAAAAAAAAAqcChBgAAAAAAAAAASAUONQAAAAAAAAAAQCrkXnYF2qH++rr31+S9v9jeaDSCcfVX6717qWuZ6b9o7/0Fek9MXq1WC8a933pcf+0+5j6x7xzPp56t98yVmLbqtcmYMq/eqsyrt2pfuZweTmOeHdIhpn157TjJ+3j3ihlDvX6h5jkVf14dFG98T/J5p9lxPVevzMuJWY+otpfP52VOf3+/LBsYGAjGe3t7ZY5qy+r3mJlVq9W24mZm5XJZlql7eWvQ1639H5eYtWZMjjeGquvV63WZE9MeisWiLFN9aXBwsO3rVSoVmeOV7e7uBuNJj12vG9W+vDbZ3d0ty9SYPDw8LHMmJyeD8TNnzsgc1fa8eh8dHcmy1dXVYHxlZUXmrK+vB+Ne/1PzQmybTHI//Lrtu73fFNMvvD1ioVAIxr1xV619enp6ZI56h17dvPaq1h3emmhvb6/tHG99E8ObHxXmhedT/SKmL5npdX/MtyWvL6n24LU7rw2pMq+Ne2WK6rdef/bEvD/lZfQX/qUGAAAAAAAAAABIBQ41AAAAAAAAAABAKnCoAQAAAAAAAAAAUoFDDQAAAAAAAAAAkAocagAAAAAAAAAAgFTgUAMAAAAAAAAAAKRC7kVevNVqybJMJtP29VSOd59ms9l2Wa1WkzmNRiMYr1arbd+nu7tb5hQKBVmmdHXpMyr1jLzno3K8d+fVQZUl3U5i6p1mMf0i5npem1RlAwMDMiebzbZXMdP9z8ysXq8H4+VyWebs7e0F415/VuOD97y9fnFcXtX2nyTvHaq2p9qdmR5fvXE3lwtPy8ViUebk83lZFkPVz2vHSfdnvBjHtY7y3q26l9fGZ2ZmgvFr167JnLfeekuWnTx5Mhjv7++XOaqv7+zsyJyFhYVg/P9h7z+bJEmuM4/3VGVmZZbWWrTWPY3BSIADEHK4JJZmXKPtJ9z9AqtIYMEljBhCjdYtp2V1iS6tU2fdF9hr2Ivrz2mkT3R2Rs//9/L4nAhPD5cR01aLi4sy59GjR7JsbW0tGD88PJQ5as3y5i48Xcze1VuH1Tzuze+qDt5crdYYM7Pe3t5gXI0/M7OBgYFgvKenR+aoPdb+/r7M8ah7xeyDvbnrm7ZmqX7kzdWqD5mZjY2NBeMzMzMyZ35+PhifnZ2VOao/eM/v6OhIlqnfq/q+mV5LvD6p5uqDgwOZ463Par7x5ocX8ayQ9Fyt3t94c97IyIgsU31Z9X0zs6mpqWD87NmzMked1b3x7O0T1JjZ3t6WOWp/4+2J1L7Hu4+3L1PjyXtfoHhzihpnaRhjMXVUv9fbc3jvlrq7u4Nx792SGpujo6MyR/Vxrw3K5bIsixkXKysrwXjs3K94zyLp94mt9vzftAEAAAAAAAAAAPwF+KgBAAAAAAAAAABSgY8aAAAAAAAAAAAgFfioAQAAAAAAAAAAUoGPGgAAAAAAAAAAIBX0n0BPgPdX42Oov/Ie+1fZOzvD33S6urpkTr1eD8YnJydlTi6XC8ZHRkZkTn9/vyzLZDLB+NHRkcxZW1trKm5mVq1Wm7q/mW5Ts7j+EPts4T8nr4/39vYG41NTUzJnfn4+GL948aLM6e7ulmWKGn9mZvv7+8H44uKizPn888+D8Xv37skcNc7U/GSm5wAzf8woaiwlPeemWa1WSzRHlXnPXY2zmZkZmTM7OxuMe+Ovp6dHlqk5tFgsypytra1gvFQqyRxVdnBwIHO8Onj3wh+pZ+utm15/bfY+3vW8+/T19QXjly5dkjk/+tGPgvG3335b5pw9e1aWKWodMTM7PDwMxr1+rMbz0NBQU/X6/1L7skqlInPUuumtFzH9JM1ixlIMb73PZps/kqln69V7YmJCll2+fDkYv3LlisxR+xvvTPL48WNZpnh9XO0nvZyYNV2NmTSfVbx5QPVXr68WCgVZpvYq3h5G1WF7e1vmbG5uBuNen/TOF2rNmp6eljmqT3rrhfpNau0x8/tekv3S6yft3v+9uqsyrx8PDg4G42q9NzO7evWqLHv11VebzlF1iDkPeH1f7TnM9Pzq9XH1XuDJkycy56uvvgrGv/zyS5lz9+5dWabm/pgzoLemq7Uk5tzfLryxpNYF9V7JzGxsbEyWqb3K3NyczFHvVr33tOo3eeuc915HnSNUPzYz++1vfxuMX79+Xeaoc7L3jLx3g+r3ensiNafErBdf9x1WekcVAAAAAAAAAAD4RuGjBgAAAAAAAAAASAU+agAAAAAAAAAAgFTgowYAAAAAAAAAAEgFPmoAAAAAAAAAAIBU4KMGAAAAAAAAAABIhezzrkAzOjvD32A6OjqazjEzKxQKwfjExITM6e/vD8Zfe+01mTM+Ph6Mj46ONn0fz9LSkix79913g/H3339f5jx+/LjpOmSzukt5z0k5Pj5u+loqJw3U7/J+by6XC8a7u7tlztjYmCw7e/ZsMP7mm2/KnJdffjkYv3z5ssxRDg8PZVmpVJJlR0dHwfjDhw9lzsjISDBeq9Vkzq1bt4LxarUqc2KeX0wfjxljaeY9J9VGXk6lUmn6egMDAzLn3LlzwfgPfvADmfPSSy8F496YLZfLsmxraysY39zclDnb29tN30etF966tLa2JsvUs2g0GjJH8fYBMddrJW89i1nrVE7S66a3/pw4cSIYf/vtt2XO3//93wfjaoyZme3v78uyTz/9NBi/ffu2zOnq6grGvT2jyvH2eCrHzCyTyTQVN0t2vXhR1xj1u7xxEXP28OYitTZ5+x41J3vrhVpjzMz+7u/+Lhi/dOmSzNnd3Q3GHzx4IHPUfk3FzcwODg5kmVovkj6TpFmrzkZeH1f7ZLVPMTPb29sLxr1xUSwWg3GvDXp7e2XZmTNngvGFhQWZ09fXF4yvrKzIHNVfvTZNmmqjNO+jPGrtVO+IzPT7mwsXLsic119/XZap+dXrk2oP/9vf/lbmqPm1Xq/LHO+5qznUm3fV2qTelZnpPunNG947LNVfvX4cMy6Udll7vHqoMvXOwkzPed4e+dSpU7JMzbtejtpbe2cS9Wy9OWB4eFiWqTz1fs1Mr1mPHj2SOTs7O8G494xa1V9j3mF93T0K/1IDAAAAAAAAAACkAh81AAAAAAAAAABAKvBRAwAAAAAAAAAApAIfNQAAAAAAAAAAQCrwUQMAAAAAAAAAAKQCHzUAAAAAAAAAAEAqZJ93Bf5cR0eHLMtmw9XN5XIyZ2RkRJadOHEiGH/llVdkzunTp4PxU6dOyZzZ2dlgvFAoyJxMJiPL8vl8ML65uSlzuru7g/G1tTWZs7W1FYxXq1WZ49VbldVqNZmj+sPx8bHMaXdeH1di+sPQ0JDMOXPmjCz77ne/G4z/h//wH5q+XrFYlDn3798PxlW/M/Of+8DAQDB+8uRJmbOxsRGMX79+XebcvXs3GC+VSjLHe37e/IU/ihnv9Xo9GPfmm0ajIcvUHHr+/HmZ87d/+7fB+Ntvvy1zJiYmgnFvfv/8889l2b1794Jxb2yOj48H45OTkzKnszP8/0js7e3JHO83qet5z0iJmXPbhVf3mHGhrufdx2tz9Zz6+/tlztmzZ4Pxl156SeZMTU0F46p/m5n9z//5P2XZ//7f/zsY9/qk2jP+6Ec/kjlqb1ipVGSOmrvM9LPw+oIqS/M+yqN+l+qrHi/HK1PjyVt/1Jx8dHQkc9S+59KlSzLnJz/5iSz74Q9/GIx3dXXJHFXvw8PDpnPK5bLM8dpOjaeYPh4zltIgZlyoHG+O8vbCBwcHwbjXx9Vz9+qgctR7BDN/DVTn9enpaZmj6nfjxg2Zo3hrsFdvdfbw+nGS5+522Xt59VBl6mxtpvc3g4ODMsfre+vr68H4O++8I3M++uijYPzWrVsyZ3t7Oxj3fmvMGqjee5mZvfbaa8H466+/LnN6e3uDca9NY9aLmPOFd5+YPUcrxYwLr817enqC8eHhYZmj9vZmZvPz88G4N87UmfP27dsyR+1VvHqfO3dOll27di0Yv3z5ssxR753UHs9M99eYfmym+6u31sasF8/q3W57jzYAAAAAAAAAAID/i48aAAAAAAAAAAAgFfioAQAAAAAAAAAAUoGPGgAAAAAAAAAAIBX4qAEAAAAAAAAAAFJB/wn75ySTyciyfD4fjHt/nf7ixYuy7M033wzGX3/9dZkzNzcXjHt/aX59fT0YPzo6kjnqL8Obmc3OzgbjIyMjMufMmTPB+MzMjMy5detWMH54eChzPOqv2nu/VeV4vOu1kqqH95ti6t7ZGf422dPTI3O8vjI1NdV0HT799NNg/IMPPpA57733XjDujYuxsTFZ9tJLLwXjly9fbvp63n26urqCce+5xjzzdunH7SBmHlBzsnetbFYviWre9daL73//+8H4+Pi4zLl+/Xow/qtf/Urm/Pa3v5Vlq6urwfi5c+dkzve+971g3JsbhoaGgvFCoSBzkpbk/Nkukl4D1fVi20Fdr6+vT+acPHkyGJ+YmJA5KysrwfjPf/5zmfNf/st/kWUfffRRMN7f3y9zpqeng/HBwUGZ093dHYzXajWZc3BwIMuKxWLT14tZY9p9/YkZFzHX88aFV6bWn2q1KnPU3qe3t1fmvPrqq8H4f/pP/0nm/PSnP5Vlam9448YNmaP2eZ999pnMUeN5d3dX5uzv78sy1XZeeyfdh1qpVWejmH5cLpdlWZL19vYWMfsO9Y7BTM/xk5OTMqdSqQTj6gxhptunXq/LHO+9SZJ9POmz67OQ5B7Q+73qeXh9//Hjx7Lsww8/DMZ/97vfNZ2zubkpc1Tf8/q+R7WdtzaqucPrx+q9097enszx9lFqbHrzmjoftvsZwuz5v4/yztZe+6n9wPLyssy5efNmMH7//n2ZUyqVgvH5+fmmc8z0u1X1HsFMryXe+cJrV8V75t677JjrtVr7j0QAAAAAAAAAAADjowYAAAAAAAAAAEgJPmoAAAAAAAAAAIBU4KMGAAAAAAAAAABIBT5qAAAAAAAAAACAVOCjBgAAAAAAAAAASIXss7x4R0dH02W5XE7m9PX1BeMTExMy59y5c7Ls1VdfDcZPnDghc9bW1oLxTz/9VOb84Q9/CMYPDg5kzsjIiCz73ve+F4y/9dZbMqe3tzcY7+7uljn5fD4YLxaLMsd75sfHx7KsWUleq9W8NorRaDSC8Xq9LnOq1aos29zcDMZ///vfy5wPP/wwGFd938zs7t27wbg3B5w8eVKWFQqFYNybA/r7+4Pxrq4umdPZ2fy3YC9HlXk5qv+rvmCWfL9rpZi6qxzvWmqeNNN979q1azJHzeM3btyQOf/1v/7XYPznP/+5zLl3754sGxgYCMa9dU7lqLiZ2erqajBeqVRkjjdHeX25Wd56keR9noWYfVSr1hjvXt4cOjQ0FIx7c979+/eD8Y8//ljmPH78WJapvc+ZM2dkzne/+91g3Ftj9vb2gvH19XWZs7GxIct2d3eD8XK5LHNqtVownub1ImavmfS+0bueanNvzlPj4pVXXpE5//iP/xiMv/322zLHOzNdv349GP8//+f/yJzf/e53wfji4qLM2d/fD8Zj962qLyc9v6t+l+YziUf9LtW/zfwzorpeNqtfR6h9WU9Pj8xR/cirtzpDmOm93OjoqMzZ3t4OxmPm3diztbpXJpNpug7efdql/6t6xKxn3lxUKpWC8Zi120zv4dV8bKb3EN5YUnt47/l515ubmwvGL1++LHMuXboUjHt7RrWWqPcIZmY7OzuyTO2XvGee5J4o5j3C0yR5To6l5ldvf7q1tSXL1D7hwYMHMkeNGbUXN9Nzv7fGeP1LrYFeH1fvuL0cVRbbv1o1fz6r8wX/UgMAAAAAAAAAAKQCHzUAAAAAAAAAAEAq8FEDAAAAAAAAAACkAh81AAAAAAAAAABAKvBRAwAAAAAAAAAApEL2WV5c/RV1M/2X2b2/iN7d3R2MT05OypwzZ87IMpXn/UX7f/3Xfw3Gf/WrX8mcTz/9NBjPZnXzX7p0SZZ9+9vfDsar1arMUXp6emRZf39/MH5wcCBzGo2GLMtkMsF4vV6XOaoPeX3L60Ot5NWxWV67qrJarSZzdnd3ZdmdO3eCcW9cfPjhh8H4gwcPZI7qR16fPDo6kmW5XC4YV/OGmdn+/n4wXqlUZI56rqp/m5l1dXXJMjUPeP1YjZl26ftJU79LrSNm+nl4z8lbS06dOtV0zsbGRjD++9//Xub85je/Ccbv3r0rczznzp0Lxl9//XWZc+XKlWDcm4cODw+bipv5c38MNTaTvk+7UOMiZu/ltZG3t4gZm0q5XJZle3t7wbhX74mJCVmm9lg//vGPZY4q89YYtf/74osvZM7KyoosU2ug1w5q3Mbs19IsZt/otZF3PVXW29src86fPx+M//SnP5U5P/nJT4Lx+fl5mbO6uirL3nvvvWD8448/ljmPHj0KxtfW1mSOmlO8fhyz3nvPL+aZv4hizhex84Nqc+88XCgUgnFvX6328OpaZv56MTc3F4yrc7KZ2fb2djCez+dlTl9fXzDunYu8s55qb+/5qbnLu0+axZyhi8ViMO7Ned65cnl5WZYpMzMzwfjQ0JDMUecVr0964+Lq1avBuHpPZWZ28eLFYPz+/fsy5969e8H4kydPZI73/NR84+WoceGdu9U4S/L90LO6Zsz6qNrPe2/o7XfVPmFxcVHmqPc63hqj9mXeeuHt+1Wed5byzj+Keu/l9cmY/hqzJ4qpw9ftw/xLDQAAAAAAAAAAkAp81AAAAAAAAAAAAKnARw0AAAAAAAAAAJAKfNQAAAAAAAAAAACpwEcNAAAAAAAAAACQCnzUAAAAAAAAAAAAqZBN4iLHx8fBeEdHR9PXymZ1lXK5XDDe19cncwYHB2WZqt/y8rLM+eKLL4LxGzduyJxqtRqMj4yMyJzJyUlZpn5TPp9v+nonT56UOap+m5ubMqdUKsmyWq0myxT1jGL6VhqosaTiZmaNRiMY957F+vq6LDs8PAzGt7a2ZI4q856TGrdeP+7p6Wn6er29vTLn4OAgGPf6amdn+Ftwd3e3zFFzl5luI++Zx0j6eq0Us8ao5+StMQMDA7JsYmIiGM9kMjJnaWkpGL9z547MURYWFmTZqVOnZNlPf/rTYPztt9+WOSdOnAjGv/zyS5nz5MmTYHx/f1/m1Ot1WRYjzX08Rsy4iFlTveek6nB0dCRzdnZ2gvGNjQ2Zo8bZ2bNnZc7w8LAsO336dDD+ve99T+aovddHH30kc371q18F495Y2tvbk2WK9/zUHsEbL0nu65+FpOuuylTbmfnjQu1jZmdnZc53vvOdpuJmZuPj48H49va2zLl165YsU/t7b90cGhoKxr19lNqDqvPS08T0y6TXn3bQqn1j7DygxsXY2JjMUX3c65OK977g/PnzsmxqaioYLxQKMqe/vz8Yn5+flzlq71Uul2WOt8dS4ymmn6g9tZk/T7aDmDO0NxcVi8Vg3Hs/4rWRaluvr6j3Omq8mOlzhDrfeDlmeh81MzMjc9S7CbUvNNP7SW/8eWNd9QfvmcfMhe1yJol5z6D6q9ePVfupdy1m/txWqVSCcW9vofbpXV1dMkf1Fe+dgPeuSu0tvLZTfTmmDrF7G5WXlvdR/EsNAAAAAAAAAACQCnzUAAAAAAAAAAAAqcBHDQAAAAAAAAAAkAp81AAAAAAAAAAAAKnARw0AAAAAAAAAAJAK2SQu0tHR0VQ8Vmdn+BuMipv5f2m+VqsF495fjR8aGgrGL1y4IHN6e3uD8ZMnT8qcy5cvy7KrV68G4yMjIzJna2urqbqZmfX19QXjhUJB5lQqFVmm2tXrJ+r5Jd23Wun4+LjpnJg2KhaLMmd9fV2WZbPhacG7nvpNXV1dMifm2Xr9dXJyMhjP5/MyZ2dnJxjf29uTOYp3H68d1O/1+ok3rzUrzWPJo9YF7zl5c5t6Hl5fOTg4CMbHxsZkzltvvRWMDwwMyJxvf/vbsuyNN94IxmdmZmTO8vJyMH7nzp2mc7w1IUbM/Bm7R2h3qi2835s09XzV3Gpm9uDBg2B8enpa5szPzwfj3//+92WO1w5TU1PBuDdXf/DBB8H4P/3TP8mcDz/8MBjf3d2VOR61PnvzeMwePc3rgqq71x9Uu1ar1abvY6b70ejoqMxR54tyuSxzPvvss2B8bW1N5nj7v0wmE4yfPn1a5qi91927d2WOOg9sb2/LHHVmM9PzeMx6EZPTLrw+mWRbePfx9liqjy8sLMicEydOBOPqjOrVYXBwUOZ4fVytPz09PTJHlc3Ozsoc9V7AO3+pvZeZ2f7+fjDuzWtqnHnPXM2taRhLau7w5pujo6OmrmWm1xgzs/7+/mDc66+nTp0Kxufm5mSOKvP6/sTEhCxTfWJ1dVXmLC0tNZ3T3d0djKtxaeaf59Sz8PqreuaedhkXSc79Xh9XexXv/t6+TO1HvLHk7eGVJPcPZvo3eXOKaruY96reM0r6DO29M281/qUGAAAAAAAAAABIBT5qAAAAAAAAAACAVOCjBgAAAAAAAAAASAU+agAAAAAAAAAAgFTgowYAAAAAAAAAAEgFPmoAAAAAAAAAAIBUyD7Lix8fHzdd5uVUKpVg/PDwUObs7OzIsoODg2B8eHhY5nzve98Lxq9duyZzhoaGgvHZ2VmZMzIyIssmJyeD8VwuJ3N6e3uD8YWFBZmj6re4uChzSqWSLFPPz3vmipfT2Rn+VtdoNJq+z7PQ0dEhy2LGRa1WC8aLxaLMUc/C47VfvV5vOkfVO5/Pyxw1lszMRkdHg/FMJiNzyuWyLFO6u7uDcdUGZmbZrJ5q1bNV7ePx+tY3jWoLr428Nt/b2wvG19bWmq7DmTNnZM63vvWtYPz06dMy59y5c7Ksp6cnGF9fX5c5n3zySTD++eefyxzVDjFzTayYOb7d14tW8X5vTFuo/ZWZ2aNHj4LxEydOyBzVx8+fPy9z1Fxtpsf6u+++K3P+6Z/+KRj/93//d5mzu7sbjHvrUsx64c1rqo97a1az92817/eqMq/NVZn3e7u6umSZ2quo+dhMn2XUfGym5/GtrS2Z4+2xpqamgnFvbKp28MafOit4a7AaS15e0ufQdt9jxYzPJNdNM7O+vj5ZNjMzE4xfvnxZ5ly9ejUYn5iYkDmqjw8ODsoc7+yvxrPX3mqsT09Pyxy1N1T7TzP/3K3meO98qH5TmtcLT8zvVW3ujSVv7o9Z11Udjo6OZI4qW1lZkTkbGxuybH9/Pxh/8uSJzFleXg7GvX6sxubAwIDM8crUHqtarcoc9Wy9erd7/495H+X1cXXe89Z1by1R7zW9vYWqn1cH1R9i9tVmej/pzQGqj3vvvdR9vN/aDvsbdZ+vO174lxoAAAAAAAAAACAV+KgBAAAAAAAAAABSgY8aAAAAAAAAAAAgFfioAQAAAAAAAAAAUoGPGgAAAAAAAAAAIBX4qAEAAAAAAAAAAFIh+ywv3tHRIcuOj4+D8Wq1KnOKxWIwvrW1JXNWV1dl2cTERDA+NjYmc86ePRuMd3V1yRxVVqlUZM7m5qYsU793aGhI5oyMjATjg4ODMmd0dDQY7+vrkzk7OzuyTD1b1RfMzDo7w9/dGo2GzFHX8/pju1B1jPm9nlqt1nSOehaxOaqsp6dH5gwMDMgyNc7K5bLMKZVKwXg2q6fG3t7eYLxer8sc7xmpZ+FdL2ZcKDH9p13E1N1ro6OjI1m2srISjHtzv5pDx8fHZY5aY2ZmZmSO118fPXoUjH/xxRcy56OPPgrGHzx4IHNU23n92KOeU8wz9+ahmDHzLMSsW+p3eW0U066ZTEaWqfnV28vF9BW1Lnh7GK/t1tbWgvHr16/LHFW2vr4uc9Qz6u7uljneeI4ZT+qZx+zR24VXd9VfvX6s2tyb3/P5vCzr7+9v+npqjbl165bMefz4cTB+eHgoc7yzghqb6veYmV24cCEYv3TpkszZ3t4Oxvf29mSO95vUeSrpftzK80VM3ZMe02rMxPR9M7PZ2dlgXPUhM7NvfetbwfjU1JTMUfXL5XIyx5tb1T5dnSG863ntMzk5GYyr9xVm/juQmLVW/VZv/lQ57XLujnnP4LWR+l3eXtPbE+3v7wfj3v5UzXnePKn6ildvr4+r/uX1STXHFwoFmXPt2rVg3DsXeWutera7u7syR7WrNy7aZR+V5DiMmTti9mtmul8m/Q4r5j7eOFPj2evjao5X7xG863n19tpblcXMhc8D/1IDAAAAAAAAAACkAh81AAAAAAAAAABAKvBRAwAAAAAAAAAApAIfNQAAAAAAAAAAQCrwUQMAAAAAAAAAAKRC9llevNFoyDL119IrlYrMKRaLwfj29rbM+eqrr2RZqVQKxmdnZ2XO8PBwMJ7P52VOtVoNxh8/fixzNjc3ZZn6a/dzc3My56WXXgrGs1ndBUZGRoLx7u5umZPJZGSZ6g/Hx8cyR5Wp/uPlePdpF6qO3lhSbR7TrmZmnZ3hb51em3v9SFH9aGxsTOZMTU3Jsp6enmB8b29P5qiyrq4umTMwMBCMHx0dyZx6vS7L1LP12luVeTleH0qrmN/krTGHh4eybHl5uek6qHupvurlbG1tyRyv7Pr168H4Rx99JHNu3boVjG9sbMgcJWZu8MQ88zT0fTV2Y9atmLnfm6M8aj/S398vc8bHx4Px6elpmdPb2xuMe3slb6yrvuzlqLXWWy+UmPn9aWXN5nj9JOY+rRTTRt7+VO1HVL8z8/v46OhoMK7Gi5k+y3hnhdXV1WDc68fenkjN1ydOnJA56jepcW5mNjEx0dS1zPTe1Kx1c7xXh6TFnHNiruf9plwuF4x7Z15vzKjn682hqk96OaresdR42t/flznqTFCr1WSOqvfg4KDMUWcSMz2nePODemfh1TvJ/UsaxMwD5XK56bKYHPX8zMx2d3eDcW9N8N6xqT7h9RVV5s0bqv97e0b1DstMj9uhoSGZo/aa6l1iqyW9XsS8j1Ji127Vtl7/Uvs8792l4o2/g4MDWabeV3tUH/f2UWru9+odM3d5OTHvXJ/VusC/1AAAAAAAAAAAAKnARw0AAAAAAAAAAJAKfNQAAAAAAAAAAACpwEcNAAAAAAAAAACQCnzUAAAAAAAAAAAAqcBHDQAAAAAAAAAAkArZ512BP1ev12XZ4eFhMP748WOZc3R0JMsWFxeD8aGhIZnT09MTjDcaDZlTKpWC8d3dXZlTLBabrsPFixdlzsTERDDu/daOjo5gPJ/Py5xMJiPLOjvD39C8Z67q4LX38fGxLGt36vd6Yn5vNquHvirznntXV1fT9+nt7Q3G5+fnZc7c3Jwsy+VywbiaN8z02Iypt9cnvXlIaVVfiLlPmsU+p/39/WBc9Qcz3b/K5bLM2dvba+r+ZmZ37tyRZV9++WUwfvv2bZmzvr4ejHv1VmNGzftm/rP4plFjN+l5IKbN1dxqpvv/mTNnZM63vvWtYPzEiRMyZ3NzMxj3+rFX74GBgWB8cnJS5qiypaUlmaPGTCvHheoPadgrxfR/leOt693d3cH4+Pi4zJmampJlas/tUc89Zu8V24dUv/TOCsPDw8G4t/dS42JnZ0fmeOtzrVYLxr3+o36rl5PkPP003vhU94sZ0965zStT1LMwMzs4OAjGNzY2ZM7q6mow7o1n1V/V+dnMHzPVajUYV/s1M91fvb1cpVIJxr3+5a1zau7w2i7JcdFqMeNT/V5vjY7J8caSqnfMOxXVV830eye1vzLTY9bM70eKmvu3t7dlzsjISDDuPVe1LpnpdvDmhyT34q1eL2Ik+Xtj9yMqz3tvmOSeSJ3hzfwxo8rU/G6mx7q3/1Pnr6THrCdmL/Ks3jvxLzUAAAAAAAAAAEAq8FEDAAAAAAAAAACkAh81AAAAAAAAAABAKvBRAwAAAAAAAAAApAIfNQAAAAAAAAAAQCok8ifQvb9wrqi/Qu/9RfRqtdr0/Wu1mizb2toKxjs79bceVW+vDqre3n08fX19wfj4+LjM2d/fD8YHBgZkTldXVzBeKBRkTi6Xk2WK13Zef0irmPHitYO6nnefTCYjy9Tz7e3tlTmqT3Z3d8sc1ffOnDkjcxYWFmRZf39/MK76vpluo56eHpmjxkU2q6dTb6zHPL+YPtSKa7VazFzt5XjPUD13r6+oPumNJbVerKysyJwvv/xSlt24cSMYX19flznlclmWNUs9h69T9k2S5P7Ku17MmmBmNjMzE4xfuXJF5pw9ezYYV33fzOyDDz4Ixh88eCBzTp8+LcteeeWVYHxsbEzmqN967949mbOxsRGMe3vTmH1PzB4hDZLs/9611Nzv7ZHn5uZk2YkTJ4Jxb080PT0djI+MjMgc1ffq9brMGRwclGXXrl0Lxr/3ve/JnNnZ2WD8448/ljlLS0vB+ObmpswplUqyTD1zb15T2uXckfQ8oHh7IlXmtavX93Z3d4PxxcVFmaPGoLcuqX2ZV2/vrPD48eNg/NGjRzLn4OAgGC8WizJnb28vGD88PJQ5Xnsr3jOPGTPtIskx450HVP/yzgPe+qOeYT6flzmqfkdHRzJne3s7GFfj0szfl6lzkXeG2NnZCcZj3ompdw9mZqOjo7JMnX9atVdKw55M1THp9bFV65x3LqpUKsG4N5a8MaPmfm8eV/sbbw5Q7xi8urXq3P08ziT8Sw0AAAAAAAAAAJAKfNQAAAAAAAAAAACpwEcNAAAAAAAAAACQCnzUAAAAAAAAAAAAqcBHDQAAAAAAAAAAkAp81AAAAAAAAAAAAKmQTeIiHR0dwfjx8XHTOR51vWq1KnPq9bosazQaTeeoe3k52Wy4mfv6+mROJpORZQcHB8H44eGhzFH1jnlGXt3UbzUzy+VywbjXdqp+Xv+JyWklrx6qT3q8Z6h0durvmeo5dXd3y5ze3t5gfGhoSOZMTU0F42fOnJE5CwsLsiyfzwfjR0dHMkeV1Wo1maPKvByvj6uymHER0xfSzOvHapx5c1RXV5csU/O118dVmVfvJ0+eBOPXr1+XObdv3276epVKReYoXr1V3/PGhTffJTlfe/WOmXNbqVVj2lvXBwYGZNnJkyebipvpNebWrVsy57333gvG9/b2ZM7w8LAsU9RaZqbXwEKh0PR9vHHh9X01f8X0k5gx1i77KO/3qjEds6575wvvuY+Pjwfj3rhQ68/y8rLMUfO7N+d54+Ls2bPBuNqvmZk9fvw4GFdj1szs448/DsbX19dljvf81O/19lFeG6WVNy7U7/XGtMrx2s7bW6j5emVlReb09PQE42rPbxa3T1f92Mzs3r17wfjS0pLMUecLr71V/UqlkszZ3t6WZcViMRj3npEaMzFrTLucSbw2V2XeeUDtBbzzgNr3mOl28uYv9c5nd3dX5mxtbQXjXv/yqPXRex9VLpeD8cnJSZlz9erVYFytV2b+OzY1ztT7NbO4M1O77JeUpPeNau8Vs8aY6f2uN5ZUjnf2V/VWfdXMH5sqzxsXagx6bafObd5v9fa0ivdbFa9vPat14cXb0QEAAAAAAAAAgBcSHzUAAAAAAAAAAEAq8FEDAAAAAAAAAACkAh81AAAAAAAAAABAKvBRAwAAAAAAAAAApIL+8+gJ8P5iuypL+q+le3+xvVarNZ0T8xfg8/l8MF4oFGSO99fpVb29nEaj0dS1PLlcTpZ5zzyTyTQVN9P18/qCV4d2p+qunp/Hy/Gee6VSCcbL5bLMUeMim9VTzPDwcDA+NjYmc7y+srGxEYwvLy/LHFWmrmVmtre3F4wfHR3JnGKxKMtU2yU9F8bMue0iZkyrHK9PdnV1yTI1X/f09Mgc1V+9vvLgwYNg/NatWzLH6+Nq3HrtoHh9JWZtjL1Xs2Lmz1aL6eMxv0vdx+v7g4ODsmx8fDwY9/Y3a2trwfj169dlzsOHD4PxgYEBmdPX1yfL1O8tlUoyR7V3zLjwxou3zql7eXXo7Ezu/19Kw3qh2lbtbczMdnZ2gvHV1VWZo/qkmdnExEQwfvr0aZkzNTUVjC8sLMgc1V+9/uX1B9XH79y5I3N+/vOfB+O/+MUvZI5qO+8ZedS85v3WJPcVaRZzVvdyvHVJ7YXVmmCmzyu7u7sy59NPPw3Gt7e3Zc79+/dl2ZMnT4Jxr7+qentro9qXefOud/ZXe01vnYt5N5Jmqm29PXJ3d3cwrs61ZnpNMNPvVQ4ODmTO48ePg3FvLCnensPrX6pMvfcy02vgm2++KXP+9m//Nhg/deqUzLl7964sW1xcDMa3trZkTsz7MqVd9lHePJ7ke4bYHFXm9Vc1br3xrMq8+3hlat/hjSW1lnjPIabe3twf88xjziTP6n0U/1IDAAAAAAAAAACkAh81AAAAAAAAAABAKvBRAwAAAAAAAAAApAIfNQAAAAAAAAAAQCrwUQMAAAAAAAAAAKQCHzUAAAAAAAAAAEAqZJ/XjTs6Op7Xrb+WTCYTjGezuinz+Xww3mg0ZE61WpVl6l6qbt69SqWSzKlUKsH48fFx03Uz8+unqH7i1aHdeXXv7Ax/Z0z693r9q1gsBuOqbl5ZoVCQObu7u8H4kydPZI5X76WlpWD8yy+/lDlfffVVU3UzMzs6Omq6bl5ZvV4PxpN+5mkeM6p/eXNozDzplXn9X9nb2wvG1RgzM7tz504wvry8LHPUXG2m2yFmDVZ91cx/FjFU/WKeQ9J1axcx66PqD95c3dPTI8tUnvecVP28/cPCwkIwfu7cOZlz9epVWdbX1xeMe+NsZ2cnGD88PJQ56rd67RMzD3nXS3If1S5795i6e+uwmqtj13U1xx8cHMic06dPB+NnzpyROeVyORhXfdXMbHNzU5YtLi4G49evX5c577//fjD+6NEjmaPWLK/ve31P5cWMi3bp4zG8uqsyb31Ua77qd2b6zGumx4VXb3Wvx48fyxw1J29sbMgcb1zUarVgPOZc67VPLpcLxr210evj6tl6e0Y1r3n9RM3H7TKWvPVClXltpH6Xt1eanp6WZbOzs8G41+ZqrzIyMiJz1tfXg3HvXZC371f9dWhoSOb89V//dTD+yiuvyBy1Nm5tbcmcjz/+WJbdvn07GN/e3pY5ag7wtPu48MScu5u9lll7vJtQ9fPmXe/MpOZ4rw/t7+8H4948FMNrb2+sN3s9r48/q2fOv9QAAAAAAAAAAACpwEcNAAAAAAAAAACQCnzUAAAAAAAAAAAAqcBHDQAAAAAAAAAAkAp81AAAAAAAAAAAAKnARw0AAAAAAAAAAJAK2ed140ajEYx3dHQ0fa3j42NZ5l0vmw3/fC9H1buzU38fqtfrwXi1WpU5Xlkul2u6Dvv7+8F4V1eXzCkWi8F4pVKROTHt4D0/ryytYvpXzLjweO2q+t7h4aHMKZVKwXitVpM5mUymqfub6b5vZra0tBSMLy8vy5yNjY1g3Ovj6jepZxdb5uWo5/cijhezuHk3Rsy42NvbkzlqzGxvb8uc1dXVYFzNx2Z+O8TMHaqPe+M5hpoD8JdRz91rV9UfvLm1UCg0XTY6Oipzent7g/GZmZmm7zM/Py9zpqenZdnKykow/uDBA5mj1hhvbYx5Rt54VnlJz/1J7znanZrfy+WyzNnd3ZVlah6/ceOGzFFjxhsXqn47OzsyR+17zMzW1taCce+3qv2f14di5n7vemrMfNP6sSdmH6X2wl7O0dGRLIt5Tmpsensi1f83NzdljjfWY/bcqsxbL/L5fFNxM/8cr+rgnXHUWd07k7RSzFqX9Dyg+p7X97398/DwcDDuzf1Xr14Nxt944w2Zo5577HuYvr6+puJmes/m9S+1L/vd734nc/793/9dlt2/fz8Y9+YUVb/Yd5DtTv2umHU46TOqJ8l5yqu3eodspsfZ1taWzFFnEvX+1kzP1Soeq13m/qfhX2oAAAAAAAAAAIBU4KMGAAAAAAAAAABIBT5qAAAAAAAAAACAVOCjBgAAAAAAAAAASAU+agAAAAAAAAAAgFTQf7r9GTs+Pm4qbmbW0dGR2H2863l/7V7x/tJ8qVRqOqdWq8my3t7epnM2NzebrsPe3l4wXiwWZU6lUpFl6l7eM/LK8EdJjwulWq3KMvXcVR8yM1tfXw/GG41GcxX7v3Z2dpqKm+l6e3VQbeeNP2+cxcyF+CPvOcXM414fV/Oe6sdmuk/s7u7KHFWW9NoY08e9NlXX83K83xQ7D3yTxMwRmUwmGPfmr8PDQ1m2v78fjHt7gYWFhWD84sWLMqevry8Y9/rX0tKSLPvoo4+C8Y8//ljmrK6uBuPe/K7aO5fLyRxvPMeMi5h+onJi5ppWi6mjek5ee6u9vVe2trYmc1Rf9vq4Gmex+xHVL1X7mJnl8/mmc5TYNT3J81yaxewTvDZXOeVyWeZ4fU/tsbyxlM2GX1XE3Kerq0vmeG2nrhdz5vXmJ9VfvbEUsyZ4c4BX1g6SPvOq9vOe7cHBQTC+srIic9Q8aab3N57p6elg3NtH9fT0BOOFQqHp+5vpMXh0dCRzbt68GYzfunWr6Ry1jzMze/LkiSxT9fP6fpJnkjTso2L2gKrMy/HmNjX3x/DWi5jzq5oDzHTf89Yfdb7w9oxqXYrd/6l2SPr9w7PyzdrtAQAAAAAAAACA1OKjBgAAAAAAAAAASAU+agAAAAAAAAAAgFTgowYAAAAAAAAAAEgFPmoAAAAAAAAAAIBU4KMGAAAAAAAAAABIhezzunFHR0cwfnx8LHMajUZT13ra9RTverlcrunrxfDuk8/ng/F6vS5z1tfXg/GtrS2Zs7m52dS1zMz29/dlWaVSCca9en/TeH0vSd64UM/Dy+nq6grGM5mMzFHjuVQqyRyvfWL6UWdn+LturVaTOareKv60spg5Ck+n2tx7tuVyWZZtb28H496cp3h9XPVj1VefVqbawctp9lpmemwyv389MWuCN6eo/l8sFmXOkydPZNmnn34ajO/u7sqcxcXFYHx6elrmFAqFpu9z9+5dWXb9+vVg/MGDBzJH3ctrb7WX88afd71W7RHaXUw7xORks/qYFLOP8ubDarUajMfMu94ZoqenR5apPG8vF7OHUTnefTxqPH3TxkvSvzdm/fZyYvb9agx640Ktc2qMeTlenvdbVZ+M2Xt5dYvxTVtjYt4TqXcWZvq5e8/p6OhIlq2urgbj4+PjMmd2djYYn5yclDl9fX3BuHqvZOb/JvWeaGdnR+bcunUrGFf7QjO99/KeUcw5/ps2LjxJnj1i9kpeHZJ+pxLzXkf1fTN99vDeuap3CWpu8HK8da5VZ/Ln8W6Lf6kBAAAAAAAAAABSgY8aAAAAAAAAAAAgFfioAQAAAAAAAAAAUoGPGgAAAAAAAAAAIBX4qAEAAAAAAAAAAFIh+7wr8OfUX7qP1dmpv9uoe3l1UH/N3cvx6qBks/rRqOttbW01fZ9qtSrLDg8Pg/Ht7W2Zc3R0JMvq9XowHtPe+JNW9ckY6pmbmVUqlWB8f39f5jQaDVlWKpWC8XK53HQdvHGh6uDVDe3D65O1Wk2WHRwcNH0vNTa9+yQ958VcL8m+7M01jJlnI2ZNVXOhmdnOzo4s293dDcbv3bsnc955551gPJfLyZxMJhOMe+PZm8fVuuCNTXUvVTcz/Szo++ngjaV8Pi/L1PP15mPVv7wcNb8mfZaKWUdi9qCx61/Sv/ebxGtz1a7evOut+Wp+jdkTxfSVmLFkps/k3tyveH01Zr2I6fuMl6eLmau9c0KxWJRla2trwfjt27dlTpLvlrzf6pWpcevtJ2P2PjH9NWZew9ej2jXp/uVRfS+mP3h91TsXKSsrK7JMnVc2NzdljppvvPU5ae30npZ/qQEAAAAAAAAAAFKBjxoAAAAAAAAAACAV+KgBAAAAAAAAAABSgY8aAAAAAAAAAAAgFfioAQAAAAAAAAAAUoGPGgAAAAAAAAAAIBWyz7sCzejo6Ej0esfHx03fR+WouJlZo9FILMfMrFgsBuNra2syZ29vLxgvlUoyp1arNRU3M6tWq7LM+72IFzMuvP4Vc596vR6Me/1ra2srGO/s1N9avT6k+p7XJxX1e55WhyRz8PXE9PFyuZxoHdRc6fWvTCYTjCe9/nm8MajEtDdaT/Wj2P1ITE6lUmn6eqpPeuPCq0PMnBwzNpPcZ+LZUc8j9jmpvuKJyYmRdN+LWZtixgWejZj+ELtPbxX1m7x6e+2g8pJeYxTGRXtJek8U83xj9nIxfTLmt3r3ifmtMWcSPBtJ73eTHhdJ3sd736neq5qZHR0d/eUVewr1ztdM1++beh5nlgAAAAAAAAAAAKnARw0AAAAAAAAAAJAKfNQAAAAAAAAAAACpwEcNAAAAAAAAAACQCnzUAAAAAAAAAAAAqZB93hVoRzF/Nf74+DjRnHq9LstU/SqVisw5ODj4yyv2FDHtg/SL6a9eXymXy03fxyvr6OhoKv606+HF1Mr5S/W9TCbT9LVi+n4s5vhvnqT7UNL3Uv0/tq+26veyxry4ku5D6noxfSi2bq2cB9D+kuyT3vWSFlPvVu2x2n2txdMl3a6q73n3idn7JD2eOzuT+3+jkz6r0/efjaTfdz6LvJCY/uW9V63ValH3albsmvVNxL/UAAAAAAAAAAAAqcBHDQAAAAAAAAAAkAp81AAAAAAAAAAAAKnARw0AAAAAAAAAAJAKfNQAAAAAAAAAAACpwEcNAAAAAAAAAACQCh3Hx8fHz7sSAAAAAAAAAAAAT8O/1AAAAAAAAAAAAKnARw0AAAAAAAAAAJAKfNQAAAAAAAAAAACpwEcNAAAAAAAAAACQCnzUAAAAAAAAAAAAqcBHDQAAAAAAAAAAkAp81AAAAAAAAAAAAKnARw0AAAAAAAAAAJAKfNQAAAAAAAAAAACpwEcNAAAAAAAAAACQCnzUAAAAAAAAAAAAqcBHDQAAAAAAAAAAkAp81AAAAAAAAAAAAKnARw0AAAAAAAAAAJAK2b/0PxweHn6W9QCeq+3t7ai80dHRhGuCVuro6EjsWsfHx1H38fKet83Nzai86enphGuCVmrVuEirlZWVqLypqamEa4J2p8bSizguVldXo/L6+/sTrgnQPvb396PyhoaGkq0IXkhpPV/s7OxE5XHuxoss9tw9OzubcE3QDmLO4+0878daWlp66n/Dv9QAAAAAAAAAAACpwEcNAAAAAAAAAACQCnzUAAAAAAAAAAAAqcBHDQAAAAAAAAAAkAp81AAAAAAAAAAAAKmQfd4VQJj3l+s7OjpaWBPgj7x+5/XXJLVqXMT8Vsbli62dn2/S4y/JPp50u7VqrsFfJub5tmoOTbqvJPlbgb9UZ6f+/89i+lc798nYOaCdfxPSoR3OFzFi6s14wV8qpq8k3cfpx99MST73Vu7fY844nC++Pv6lBgAAAAAAAAAASAU+agAAAAAAAAAAgFTgowYAAAAAAAAAAEgFPmoAAAAAAAAAAIBU4KMGAAAAAAAAAABIhezzrkDaqL807/0FelXm/aX7TCbTXMWewqsf8JdIug/FjIvOTv0dVuV5Odls81Ngo9FoKv60shiM59Z73m3u9WOvTNXb65Mxv1WNv+fdbng+Yp57kv3OrHX7KPo4kqDmca+Pe2VKvV5vusxbL9Q488ZfzG+N2UcxNtMvZt5V/Tjp84VXh5g+njT6/4srZlyoOTR2jUlyXMSIHUuMi3SI6a9K0uMipo97exh1r6R/ayvXn1bjX2oAAAAAAAAAAIBU4KMGAAAAAAAAAABIBT5qAAAAAAAAAACAVOCjBgAAAAAAAAAASAU+agAAAAAAAAAAgFTgowYAAAAAAAAAAEiF7POuQDs6Pj5O9HqZTCYYz+VyMqezU39vqtfrwXitVpM56jfF/Favbh51r46OjqjrfZN4bZR0f1X38p57TI4q836rN2ay2fB0ls/nm76eN5aq1WowXiwWZU6lUpFlajw3Gg2Zo9oo6b7wTeO1X0ybqzJvXKh+rNYRr27evbw+rvpeTE5Mm3pYL1qvVW2edF/xqPEUM57VHB7L+61JzkP4E9WuMeuwVxbTj73+FVNvtYcx8/cqSnd3dzDu7ddUWczZx0z/Ji8nyXMRvp6k591WneM9Se5vYuYAM/ryiyzJcRFzhvDKWtXvYveMvI9qrdj+kOR+KWaf7s37XpkaF7HXU5JeG719o9JOY4Z/qQEAAAAAAAAAAFKBjxoAAAAAAAAAACAV+KgBAAAAAAAAAABSgY8aAAAAAAAAAAAgFfioAQAAAAAAAAAAUiH7vCvQDPUX22P/8rr3F+AV9RftR0dHZc7Y2FgwPjk5KXO8v0D/6NGjYHxxcVHmHB0dBeOZTEbmZLPh7uG1t1dvxPP6amz/b/Z63n1UP+rq6pI5uVwuGC8UCjJncHBQlg0PDwfj/f39Mkf11729PZmzubkpy5q9j5l+tt4zj5kLY+a7bxo1v5vp9vPmUNX/vX6s+n9fX5/M8eqg+t7+/r7M2d3dDcYPDg5kTrVaDca9No0RM9/R958u9jmp/pXk/spMrxcq/rTrKd5cXavVmr6PKkt63+q1t6p3vV6PqsOLSLVf7LiI2UepvufN76reaj5+Wpn6vb29vTJHnX+8Ncu7nlIul2WZWpsODw9lTqlUCsbVePG8qGtMzPwVc66MmUPz+bzMUc9Q3d/Mf4ZqrvT6pCqLOSd77R1b1qwXtY/HiBkXXt9TZTFjyTtDx+xhYvZE3rgoFovBeKVSkTkx67PXdjHrs8K4eHbUvBsz53V3d8sctZb09PTInIGBAVmm9jfe2FTUPsVMjyVv3xOzJ/LOCjHr2bMaM/xLDQAAAAAAAAAAkAp81AAAAAAAAAAAAKnARw0AAAAAAAAAAJAKfNQAAAAAAAAAAACpwEcNAAAAAAAAAACQCnzUAAAAAAAAAAAAqZB93hVoRkdHR9M5x8fHTZdls7pZent7g/HJyUmZc/ny5WD8pZdekjnlclmW/eEPfwjG19fXZc7e3l4w7rVPZ2f4m1fMc3javRR1L+9asfV70cT0fTPdfl67ZjKZYDyfz8uc/v7+YHx6elrmnDhxQpadPHkyGB8aGpI5m5ubwfiDBw9kTqVSCcbVGHuaRqPRVNzzovb9Vv0uNeeZmRUKhWDc618zMzPB+Ouvvy5zhoeHg/GBgQGZU6vVZNnBwUEwvry8LHNu3rwZjN+/f1/m7OzsNF23GDHryDeNN15Umdf3k6bWi5i9V3d3d9P3MTMrlUrBeLFYlDlqTvbqreYNb230np8aT+r3mOnf5K0xjLM/amU7qDHo1UH1B288qzXGTO+/zp49K3OmpqaC8bGxMZmTy+WCcW/8bWxsyDK1nq2srMgctWbt7+/LHLX/S4OYub+rqysYV/Oxmd7bm5mNjo4G416fVHP86dOnZU69Xg/GvbnV28OrfvTw4UOZo87kXv+K2ffH4Az9J0mOC28/4p0VxsfHm4qb6bHkjYuYvZc3J+/u7gbjS0tLMkedI+7duydz1FytxrlZ6/oxY+npvDby5jzVL9W+2sxsZGQkGFfviMzMTp06FYyfOXNG5kxMTMgyNda9+UGd1VXczGx1dTUYv3v3rsy5ffu2LFP7KDX+zMyq1WownvTZ/y/Bv9QAAAAAAAAAAACpwEcNAAAAAAAAAACQCnzUAAAAAAAAAAAAqcBHDQAAAAAAAAAAkAp81AAAAAAAAAAAAKkQ/rPyber4+DgY7+jokDmdnfq7jbpeNqubJZ/PB+P9/f0yZ35+Phh/6aWXZE6lUpFlDx48CMYzmYzMaTQawXhM+6hrPY33nJqtQ0xOzP2fBa8eMb+3Xq83fS2vTNXP619qzPT09MiciYmJYPzChQsy59q1a7Ls9OnTTdfh0aNHwfjh4aHMuX//fjDujYtqtSrLVF5MX8CfqH7sze8x/fXKlSsy55VXXgnG/+Zv/qbpOhwdHcmcg4MDWba/vx+MP378WOaottvZ2ZE5e3t7TV3raVSemu/Mkh0z7bJexEh6rfXK1PPw9hZqDE5OTsocNf76+vpkTqlUkmXb29vBuNd2qt7enDIyMhKMDwwMyByvvdV49sZmrVZrKm4Wt69od0nuJ82e/57WTJ9JpqenZc7Vq1dl2auvvhqMX758Web09vYG47lcTuao9Wx3d1fmeGuWmge8favizRtqL5eGcaHaolAoyBzVrlNTUzLn5MmTTZepc7KZHmfe3B9zTi0Wi7JsdHQ0GPf6l5pDvXm3XC4H497v8fZEqn7so/5E7VXU3GoWNy7OnDkjyy5duhSMnz17VuYMDQ0F48PDwzJH/daYPZ6Z7q9bW1sy5/PPPw/Gu7u7Zc6NGzeCcbWPM/PHjBoXXk67v1tqFa+vxLzP8PYJ6t2qN87Umfw73/mOzFF7otnZWZnjzQ9qjvfe7XrrgqLO/l77eGcztffx1kbv/ZbyrMYS/1IDAAAAAAAAAACkAh81AAAAAAAAAABAKvBRAwAAAAAAAAAApAIfNQAAAAAAAAAAQCrwUQMAAAAAAAAAAKQCHzUAAAAAAAAAAEAqZJ93Bf7c8fFxy67X2Rn+ptNoNGROtVpt+j49PT3B+NjYmMzxrtfd3S3LFPVbc7mczMlkMk1dyyz559fR0dF0jvf82kGr2qher0fVIZsNTwvec1d9pVAoyJy+vr5gfGBgoOkcM92Xvf6gfquKm+l28NrH68cxfTzmWkn3u3YX85y8/jU7OxuMv/766zLnu9/9bjA+PT0tc5aWloLxO3fuyJzd3V1ZNjw8HIyPjo7KnKmpqWDcW3vUfFOr1WROV1eXLEuyv8aMizSPF2/OU78rdu5Q9/L2Fqp/Xbt2TebMzc0F45VKReYsLi7Ksu3t7WA8Zm305o3Jycmm4mZ6n2lmtrKyEowfHR3JHCXJtaedJDl2vbGk9j1mum299UfNod48efr06WD8hz/8ocz52c9+JstefvnlYFydY8z0+rO2tiZzyuWyLFO8OUWtTd4eVD0/77kq7TKWvHqovpfP52WO2j+cOHFC5ly8eFGWjYyMBONevVX/evjwocxRz139HjN/Hh8cHAzGe3t7ZU6MmP2IV6bmlKTPJO2+j4oZF968q/rD/Py8zLlw4YIsO3nyZDDunYfVPuH69etN53hznjf3q3OE935rYWEhGH/w4IHMUWPdO/t470DUucRbnxUvp93fR8WIGdNe//LOlUNDQ8G4Oo+bmZ05cyYYn5mZkTnqN3311VcyZ3NzU5atr68H4+rcYaZ/qzenqDLvfOGd/dVeIGaNeR5zP/9SAwAAAAAAAAAApAIfNQAAAAAAAAAAQCrwUQMAAAAAAAAAAKQCHzUAAAAAAAAAAEAq8FEDAAAAAAAAAACkAh81AAAAAAAAAABAKmSfdwX+XEdHhyw7Pj5u+npejiqr1+syp1KpBOP7+/syp9FoBOO9vb0yp7NTf2/q6+sLxnO5nMzJZDJNxb0yr0295+eVNUu1adL3eRa8+qnf5fUHry2S5NVbjZlisShzYsbS48ePZdnh4WEw3t/fL3MODg6C8VKpJHNUe8f2yWw2PA3H9JOY+a7dx4tZXN1VjjfnFQoFWTY5ORmMz87Oypyurq5g/IMPPpA5//Iv/xKM37x5U+Z4v+m73/1uMH7t2jWZMzAwEIx77V2r1YJxb1zEriWKmidj9g5pkOTv8vY91WpVlqnnNDc3J3NUn3zzzTdljurjX375pczZ3t5uusxbs1Rf9tYYNW+cPHlS5qi1zMxsb29Plikx60W7i5n7Y+YUtT6b+fsyVQe17/Gud+rUKZnz93//98H4P/7jP8ocb+5XfcXbe924cSMYv3PnjszZ2NgIxr3+7bXd7u5uU3Ezvc9Ta5mnXcaS1ydV/1f7FDN9TvX2Sl77ra6uBuOLi4syZ2VlJRgvl8syR83JV69elTnnz5+XZaodvL2XaoeY9dST9LsR1Ye8PYKqd7ucL2LeTXhzv3rf4uV4/VX1cTW3mpktLy83FTfT8656r2RmNjMzI8tefvnlYPzSpUsyJ5/PB+PeOzE133jznSfJ84U3Ltpdq/ZRsc9J8c6Vam//0UcfyRy17/DWpYcPH8oyNZ49J06cCMZ/+tOfyhy1znl7Ja+/qnb1clQ/eR57Iv6lBgAAAAAAAAAASAU+agAAAAAAAAAAgFTgowYAAAAAAAAAAEgFPmoAAAAAAAAAAIBU4KMGAAAAAAAAAABIheyzvLj3l89VWWdn899ZYv/Cuvpr7h0dHTJH/UX5o6MjmVMqlYLxQqEgc3K5nCzr7u4Oxr22y2QyTee06i/Xe+2t6hCT0y4ajUai14tpI4+qnxovZmblcjkYPzw8lDnFYrHpnPX19abr4LV3tVptqm5mun5qbnhaHRTv+cU+2xdNzBrjtV1PT48sGxoaaroOjx8/Dsbfe+89mfPLX/4yGF9ZWZE58/Pzsuy1114Lxnt7e2VOPp8Pxr3fqsaSl+ONC7U2fdP6fkwfj8lRz8/Mf05TU1PB+FtvvSVz/uN//I/B+OTkpMz56KOPgvG7d+/KnEePHsmynZ2dYNxrh2w2vGVWezIzs/Hx8WB8ZmZG5iwvL8sy9Sy89Uet3TF7pXYZf0nXXbVrzJnEzKxWqwXjXr1HR0eD8TfffFPm/N3f/V0wfunSJZnj7aPef//9YPyzzz6TOTdv3gzGV1dXZc7u7m4wrs5LZv6zUGXe9Q4ODoJx9ew8rR4X6n5ePdQ50OuTau7wzrwPHz6UZZubm8H4vXv3ms7xztDnzp0Lxr19z9jYmCzb2NgIxr2+ovpe0nO1dzZTVF/wxPTxVp/HkxyH3r5HPfe9vT2Z442LW7duBePeHkZdb2trS+aovjIyMiJzvHZYWFgIxtV53Cxu36rq4NXNGxeqn3jjImbObff3UTFnhZjrec/Ju496F6PWBDP93L29/ZMnT4Jxby+u1gQzXe/h4WGZMzc3F4z39/fLHNVf9/f3ZY63/1Pvt7y2ixkXzwr/UgMAAAAAAAAAAKQCHzUAAAAAAAAAAEAq8FEDAAAAAAAAAACkAh81AAAAAAAAAABAKvBRAwAAAAAAAAAApAIfNQAAAAAAAAAAQCpkn3cF/tzx8XHTOY1GI9E61Go1WVav14PxUqkkc4rFYjDu/dauri5Z1tfXF4xnMhmZo6jfY2bW0dERjHd2xn0LU9fz2kGVxfSTdhHbfs1ez3u2Xvup51StVmVOpVIJxnt6emSOKuvv75c5Xtnw8HAwrsaLmdnm5mYwvr29LXNUmRrnZn7bJTnOYp5rmnltpMq8edK7nsrznu3BwUEwvry8LHNUP8pm9XKt+r6Z2cTERDA+NDQkc9QauLW1JXOOjo6CcW8t8yQ5x8fsEdplvHj1UL/Lazv1bL31YmBgQJZ961vfCsbffvttmXP58uVg/Pbt2zLnD3/4QzD+6aefypz19XVZpsatWsvM9Frijb+FhYVgfHBwUOY8fPhQlqk5xduDqmceM8bSsPdKcq8Ze75Qed3d3TLn4sWLwfiPfvQjmXP27NlgfGVlRea88847suzXv/51MH7z5k2Zs7a2Foyrvmqm1wvv/JXL5WRZoVAIxr01Xc0B3lzY7mLWLW9cqPnQm1vL5bIs29jYCMa9vYW6nre3n5qaCsanp6dljrfOqT7u1Xt3dzcYPzw8lDkxZ17vmat9q5ejxkzM3N/qfZSqY0w9vLlfjQvVv83Mnjx5IsvUXOmNM9X3vDOJ2vd7fX9sbKzpMu+cpcaFGmNejnfu9taSmD2COssk/Q6ylbxxkeR499rI669qX+v1lZ2dnWDc29ur8ef1L28vp9afmZkZmfPaa68F46dOnZI5qo8/ePBA5njvH2LmlJj9UpJrzP/Pdb9WNgAAAAAAAAAAQIvwUQMAAAAAAAAAAKQCHzUAAAAAAAAAAEAq8FEDAAAAAAAAAACkAh81AAAAAAAAAABAKmSf143VXz6PEfvX0js6Opq+niorFosyZ29vLxj3/mJ8V1eXLMvlcsG4+j0e7y/aq2fkPbtMJiPLYp5T7LNNq5hnqHIajYbM8dpV5ZXL5abr0N3dLXOmp6eD8dOnT8uc8fFxWTYyMhKMe338zp07wfjdu3dlztraWjB+eHgoc7JZPdV6Y6ZZ3nONme/ahapjTD/25t2YMi9H1WF4eFjmXLhwIRgvlUoy58qVK01fz+t3q6urwfjm5qbMOTo6Csa9Z+Stc96YUVR7e3VQ7dAu4yJmTHtzv9Lb2yvLVB8yM3vrrbeC8ZdfflnmqP3SH/7wB5nz/vvvB+MrKysyp1aryTI1nry2W1hYCMa99pmfnw/GDw4OZM7GxoYs297eDsa9+UH9pph+kmbe742ZOzxq/lJ9yMzszTffDMYvXbokc1S9b968KXM+/fRTWfbw4cNgfGdnR+ZUKpVg3OuTal/m5XhrrXpO3nlF5XjzRrvvo2L6uHp+Zvr8qtZ7M/8Zqjx1rjUzGxgYCMbV3GpmdvHixWDcO1945xXV/1X7mOm+4u291LhIun95YynJc2gaxMwD6rznjSXveirPm7/GxsaC8Z6eHpmjxsyJEydkztWrV2XZyZMng3Gvj6uxtLW1JXNUe3tt6s2Fql29ceHdS0nzuIhZ62L2lF67eu+dFDWWvPOmGktTU1MyxzvHz83NBePeOFPneG9devDgQTD++eefN51jFve+Wol5l/51xwv/UgMAAAAAAAAAAKQCHzUAAAAAAAAAAEAq8FEDAAAAAAAAAACkAh81AAAAAAAAAABAKvBRAwAAAAAAAAAApAIfNQAAAAAAAAAAQCpkn+XFOzo6ZNnx8XHTOUomk2k6J+k61Go1WXZ4eBiMF4tFmZPN6kczNTUVjI+MjMicxcXFYFy1gZluh85O/S2s0WjIshiqfl4d0ky1X8xYirmPV1Yul2XO8PBwMH7ixAmZc+3atWD8ypUrMsfr48rt27dl2c2bN4Px+/fvy5ytra1g3JuHvP6qylo1ll5U9Xo9GK9WqzLn6OhIlu3s7DSd09fXF4zPz8/LnP7+/mDcWxNOnz4tyxYWFoJxb83K5/PBeHd3t8xRc5R6Dmb+nKL6vzeWVB2Snj9bKabuMfPN0NCQzDl37pwse/XVV4PxQqEgc379618H47/61a9kzr1794LxUqkkc7w5VOWNj4/LnJdffjkYf+ONN2TOwMBAMH737l2Z8/jxY1mm5qFKpSJzVDvE9P2Y/fE3kRpPFy5ckDmvvPJKMD49PS1z1Dzuza2qT5rptcSb+5eXl4Nxr3+pdcFb5zzqXt46l+S4aBde3dXvjd0TKd4c0dPTE4yPjY3JHHWO8Nal7373u8H4pUuXZM7e3p4sU2cPrw5qzKg53MxsbW0tGFfnDrO4NdDrJ6rMO+O0+5iJGRfe3KHa3Jt3vbktZlyod0Fezvnz54PxM2fOyJzZ2VlZptaS7e1tmaPeF3jr3OrqajDuzV3q3ZuZXn+884p6fml4HxWzb1NjJmbu8NrIu57K8/Yjqh/Nzc3JHHVOHh0dlTmTk5OyTK0XXr1zuVww/vDhQ5nz6aefBuPXr1+XOevr67LMG09JelbrRfuPRAAAAAAAAAAAAOOjBgAAAAAAAAAASAk+agAAAAAAAAAAgFTgowYAAAAAAAAAAEgFPmoAAAAAAAAAAIBUyD7vCvw59ZfuzfRfS+/o6Ii6V6PRaLoO6l7eX4xfXl4Oxnd2dmRONqsfTW9vryxT1G/1qHbw2ifmPh71zFXcLL4/tIOk+3gM9Qy7urpkzuTkZDB+/vx5mXPt2rVg/OrVq07ttPv37wfjt2/fljm3bt0Kxjc3N2VOvV4Pxr328aj2zmQyMqcd+kkrxfwu1a7lclnm7O7uyrL19fVgfHV1VebMzMwE4/39/TJnZGSkqbiZ2ezsrCwbGxsLxr0+rtaYoaEhmdPd3R2Ml0olmeOtm4o3ztS4iFnTvTWm3Xm/N5fLBeMTExMy5/Tp07JM9a+trS2Zc/369WD84cOHMkf1I+85efuR4eHhYPyNN96QOT/72c+C8YsXL8qcJ0+eBOOPHj2SOWrPaGZWLBaDca8dYvpymteSmPVR5Xh9KJ/PyzI1V05PT8ucgYGBpuug9iPeeH755Zdl2YkTJ4LxBw8eyJyenp5g3Jvf9/f3g3Fv35PkPuBpZUnWoZW8sa76ivecYuYO1R/M9Hpx8uRJmaPOBOoMYab78ejoqMzx1k1V7ytXrsics2fPBuPb29syR51X7t27J3PW1tZk2cHBQTBeq9VkTgzVdkm/E4gVsz6q8eLleO9uvPVCnaHPnTsnc1TfU/3OzOzUqVPBuBovZmaFQkGWqXnca7v5+flg3Dv7q/2fNx97+yhVb6+/JrmPavX5Isn7xayBXo43ZtRa4u2j1Lrw6quvypyXXnopGJ+bm2u6bmZmlUolGPfm/sXFxWDce8eg9mUbGxsyR50hPEmfoZ/VuOBfagAAAAAAAAAAgFTgowYAAAAAAAAAAEgFPmoAAAAAAAAAAIBU4KMGAAAAAAAAAABIBT5qAAAAAAAAAACAVOCjBgAAAAAAAAAASIXs865AMzo6OprOOT4+lmWZTKbp69Xr9abiZmbVarXpHE8ulwvG8/m8zFFt12g0ZE5nZ/PfvGKu5z2jmGfe7rzfG5Ojyry288p6enqC8ampKZnzne98Jxj/0Y9+JHOuXLkSjPf398ucpaUlWba4uBiMr66uypxKpSLLlJixFPssms1J81jy6qd+l/d71fNQ87GZ2dbWliy7f/9+MN7b2ytzDg8Pg/HBwUGZMzo6GoyPjIzIHK/t1DozNDQkc15++eVg/Pbt2zJne3s7GFft5tXNTK/PXk7MGhMzH7dSzJj29jaqv46Pj8scr+9ls+Ft5Obmpsw5OjoKxoeHh2WO+k3evOvtiU6ePBmM/+xnP5M5ap1TbWBm9uDBg2D83r17Mmd/f1+WJbnet3vf98TM/V6Omle8HLUXN/PXBWVtbS0Yv3nzpsxR9fPGhbfHUmuTNzbVvKvWBDOz9fX1YLxcLsscr4/HPPM0jwtVR+/cFtNX1H4pZr9mpudKr0+qvYq3j1KWl5dlmbdmHRwcBOPePkqtP/Pz8zJnYmIiGPfG3/Xr12XZyspKML6zsyNzYt5NtPuYiemv3riIOZN4deju7g7Gx8bGZM709HQwPjc3J3PU9Wq1msx58uRJ02VqvJjpdfP8+fMyp1AoNBV/GjUPqL2pWbrXC6Ud3qvG7KO8cTE7OxuMLywsyBz1fquvr0/meGOmWCwG497+Rr2P8t5TqTKvbjHvab19hepD3ruWZ/U+in+pAQAAAAAAAAAAUoGPGgAAAAAAAAAAIBX4qAEAAAAAAAAAAFKBjxoAAAAAAAAAACAV+KgBAAAAAAAAAABSgY8aAAAAAAAAAAAgFbLP68YdHR3B+PHxscxRZepasWWx11Oq1Wowvr6+LnO8dpiZmQnGJycnm6uYmdVqtabLcrmczOnsbP47WUybxjwjr01bKeb3xtQ9k8nIsq6uLlk2OjoajL/22msy52/+5m+C8bfeekvmDA4OBuNfffWVzPnggw9k2YMHD4Lxo6MjmdPT0xOMDw0NyZydnZ1g3Ov7MePCo/pD0vdpF+p3NRoNmaPayJvzvL6yuroajGezehnd3t4OxsfGxmTO9PR003VT9zEz29vbC8YXFhZkzvz8fDD+8ssvyxw1bg8ODmSOV28lZo+QZkmvj2r9LhQKMsdrVzUf1ut1mXPmzJlgvLu7W+aofZS3H1Hzu5nZ7OxsMO6tcwMDA8H4nTt3ZM7t27eDcW//V6lUZJk35zUrpm+1WpL7fq8fq3b1+pdXpp7h2tqazFH7m48//ljmqN/k7fHGx8dl2YkTJ4Lx4eFhmXPu3LlgfGlpSeY8fPgwGC+VSjLH6/tqvvGeecwZMKY/PgsxfVzlxOyjvL2mt8cqFovBuLcXWF5eDsa9M87du3eD8c3NTZmj9kpmep3z9n9qnHn7P3W+99pbrY1m+ll4OYeHh8G4t6a3i5hxodo26b1mzLjw+uvi4mIw7u0fbt26FYxvbGzIHK8Oqt5ef52amgrG1dnHzOzkyZPBuLdeqDHr5Xl9XI2ZF/HcYabntqTXC28OVWPGO1eq9eLDDz+UOWo/4v1Wbw7N5/PBeH9/v8xR5x9v76XeVXltmvQ7btVG3jNXOV93H/VivgEDAAAAAAAAAAAvHD5qAAAAAAAAAACAVOCjBgAAAAAAAAAASAU+agAAAAAAAAAAgFTgowYAAAAAAAAAAEgF/efRn5Pj4+Omy7wcz9f9K+v/r3q9LssODg6C8bW1NZnj/aaRkZFgfHh4WOb09PQE40dHRzJH/aZsVncbr01jnp+6XpLP7llRdYzpr97v7ewMf5vMZDIyZ2BgQJZdunQpGH/zzTdlzre+9a1gvKurS+bcuHEjGP/5z38ucz744ANZptohl8vJHDVmRkdHZU6tVgvGy+Vy03Uzi+vjMf0/yf4Ye6/Y+6mcRqPRdB28Z6GerZnZ+vp6MF4sFmXO1tZWMD47Oytz1Lzr3efx48eyTK0zOzs7MmdhYSEYP3XqlMy5du1aMK7azcxv78PDw2A8DXN/jCTHpzcuVP/a39+XOYuLi7Kst7c3GB8cHJQ509PTwfjU1JTMUePW6w9DQ0Oy7OzZs8G4tzbevXs3GP+3f/s3mfPJJ58E4xsbGzKnVCrJMvVsY/bOHtXez2K98LRqrVP7Wm//4O2xKpVKMP7o0SOZo8aZ1x+UfD4vy06cOCHLVNupce6V9fX1NZ3jrc/evKaerXe9JM8kz0LS+6gYMXsvby+8uroajHv7m5WVlWC8v79f5qj+r/ZkZma7u7uyLGafrtYzdcYyM3vppZeCcW/PuL29LcvU/s/LUfON98xbKekxmORY8t4FeeNC9XEvR60X3pqlPHnyRJZ540Ldy3tPpM4R3juGy5cvB+PqrGJmNj8/L8uWl5eDcW8frJ5tzDm01efumBxV5j3bmH26135qXfD2UerM6Y0L9a7KO6N677fU3H/lyhWZo+Z+70yi1sBCoSBzYvZEMXsRby706vB18C81AAAAAAAAAABAKvBRAwAAAAAAAAAApAIfNQAAAAAAAAAAQCrwUQMAAAAAAAAAAKQCHzUAAAAAAAAAAEAq8FEDAAAAAAAAAACkQvZ53bijoyOxax0fHydah0aj8XWq8/+nUqkE43t7ezLn4OBAlvX29gbj8/PzMmdgYCAY39jYkDkx7erlqDKvL6iy2GeeVp2d+vtjJpMJxru7u2XOzMyMLLt8+XIw/tJLL8mc8fHxYHxxcVHm/PKXvwzGf/GLX8ic9fV1WXbq1KlgfGFhQeaottvd3ZU5h4eHwbjXj2PmFO96SY/NpLXqXt64ULy61Wq1psvK5bLMqVarTddB9ZXNzU2Zs7+/L8tWVlaCcdWPzcy6urqC8Xw+L3PUnDI3Nydztra2ZJlqu6THUruIWR8Vr42Ojo6C8cePH8scb5ypZzgxMSFz1H5E9TuP1ye9vjc1NRWMr66uypzf/va3wfg777wjc+7fvx+Mq/5tpveMXp73zGP61ou4x1LrvZlZLpcLxr19lMox08/Dm/NKpVIw7s3Val3y6u2NGTU/ZLP6uKjWQK+Pq5yYfmz2Yp4VYuoec57ycur1ejDuPSeVY6afu3fmVft+rx+r/urt14rFoixTa6D3W588eRKMe+NCrUuTk5NN55iZDQ8PB+Pe/KDOPzFnnGcx/lo1Ljwx48Kbx1Wf8HLU3t77PWpvoeZ9r25melx47bCzsxOM9/X1yZzZ2dlgfHR0VOZ4e9DBwcFg3DtnqfW5XdaYmHrEvFvy9ulq3o09d6v+6u2R1XtNrx/HnCsLhYIsU+P2xIkTMke1q9c+ag/qPSNvH6zaIS1nBf6lBgAAAAAAAAAASAU+agAAAAAAAAAAgFTgowYAAAAAAAAAAEgFPmoAAAAAAAAAAIBU4KMGAAAAAAAAAABIhfCfqU9Iq/5auncfT71eD8a9uqky9RfjzcwODw+D8Y2NDZlzcHAgy/r6+oLxwcFBmTM0NBSMFwoFmaN+k/dbv2mS7uMxOZlMJhjv7e2VOdPT07Ls1KlTwfjCwkLTdVhaWpI5t27dCsa3t7dljur7ZmZzc3PB+Pz8vMw5OjoKxr3xt7OzE4x746JarcqymPEUMw8lOee2C+83qbGZy+VkTmen/s6fzYaXy66uLpmj7pXP52WOqnepVJI53lqiyrq7u2XOyZMng3FvLI2OjgbjY2NjMqe/v1+W7e3tBeOVSkXmqLaL3SO0g6TXETXnqf2Qmd/3njx5EowPDAzIHNX31DpipsfZpUuXmr6Pmf5NH330kcz513/912D8xo0bMqdcLssyxZvHVVnMXJjmcRFTd2+uVv3Vm6PUmmBmVqvVgnFvLKm+UiwWm87x1rnx8XFZpvZ/w8PDMmdra6upuJneY3nzu7c+v4j7G4/q/0m3Q8w48+YvNS5iztDe+TVmjfHGs1of1T7FTJ9lvLGkfqs3d3nnIm+v2aw0j7GYusf0fS/H22PF7BPUudKbJ1UdYs4+Zno8e2do9SxWV1dljtq3TkxMyBzvHYiaO7zfquYO77m2y5iJ2QOqPYQ336gyb3735lD1vkX1OzM9Lrz3MIq3H/H2crOzs8H4yMiIzFFn5ZWVFZmj+p5Xb6+/KjHvlp7H+YJ/qQEAAAAAAAAAAFKBjxoAAAAAAAAAACAV+KgBAAAAAAAAAABSgY8aAAAAAAAAAAAgFfioAQAAAAAAAAAAUoGPGgAAAAAAAAAAIBWyz/Lix8fHiV6vo6PjuV+vszP8Haher8ucSqUSjO/s7Mic/f19WTY1NRWMDw8Py5yBgYFgvFAoyJxisRiMNxoNmeO1aZLPz+tbSfeT2Hq06j6qzGuHXC4nyzKZTNN1ODo6CsZV3zfTffLSpUsyZ2xsTJZdvXo1GB8aGpI5S0tLwXg2q6dGNQeouJluUzPdrrHjLK1ixnSSc/jTypR8Pi/L1Pzqzbsxa0y1WpVlah7f3d2VOWrcevNGT09PMN7b2ytzvHZQ7Vqr1WSO4vWTmPmzlWLWGC9H9SPVT8z8Nj88PAzGNzc3ZY6aD702V/uet956S+Z4fe/Ro0fB+K9//WuZ8/nnnwfjBwcHMidm7vLm/pj+EFOHVu1tYnn1U3Nod3e3zFF7i4mJCZnT1dUly9S42NjYkDnquXvzu5p3r127JnN+/OMfy7I333wzGPf2cg8fPgzG79+/L3O2t7eDcW+dS3rf36qcWO0wPlUdvL2SN3+psphn6+2rVVnM3t5Mz/He2FS8eUOtc95a5rWdam9vPHtj8JvEG38xZwXvOan+GnNW9/p4TH/wysrlcjDu9SHVdt55QK1z3nOI6cdeTsz1WrmPSnptUmcw753K6OhoMO49J+8Mrfre2tqazFHvo2Lmau/5ee+jzp8/H4x/+9vfljmDg4PB+I0bN2SOeoe1t7cnc7x+rPpQkueOZ4l/qQEAAAAAAAAAAFKBjxoAAAAAAAAAACAV+KgBAAAAAAAAAABSgY8aAAAAAAAAAAAgFfioAQAAAAAAAAAAUiH7vCvw52L+Wnqj0ZBlmUxGlnV2hr/pqLinUqnIslKpFIzv7OzInIODg6bv1d/fL3NUWW9vr8yp1WqyTPHaTj1b75kfHx83XYcXkdfHVX84OjqSOWtra7Ls3r17wfjExITMGR8fD8a98Xf69OlgfHp6WuYMDQ3JstHR0WC8XC7LnJWVlWDcax81nr2+GtOPY8aFdx91vVaPsZg5XtUx5loxOV5ePp+XOT09PcF4V1eXzMnlconlmOl5vFAoyBw1ngcGBmSOup63JtTrdVmmeNdT82QaxkWSvD4e0/+r1aosU8/Qm3dV23p7GLUunDlzpum6mZl9/PHHwfhHH30kc7a2toJxb33OZsPb7Nj1Ism50Kt37DzZKjF93NuPdHd3B+NTU1MyR82TZrptNzc3Zc7+/n5TcTOz+fn5YPwnP/mJzHn77bdlmZrj//3f/13mfPDBB8H4gwcPZI6aH1p5Hog567VS0r9XXS+mHdS8ZubPK+pe3vVi9kTevkzx1iy1Bnptd/78+WD8r/7qr2TOpUuXgnHv93hziipT5xgzvW6meU/kiVlT1XP31hivTPVx7x2N6hPe+It5r+Pt/5S+vj5ZduHChWD8ypUrMkettV7dYt6xeddr93N3q8an1yfVPn1wcFDmzM7OyjK1H/H29urdl/ds1f5vZmZG5rzxxhuy7B/+4R+C8cuXL8uc5eXlYPzLL7+UOXfu3AnGd3d3ZY7XT9Q85OWouTBmXHxd7b2jAwAAAAAAAAAA+L/4qAEAAAAAAAAAAFKBjxoAAAAAAAAAACAV+KgBAAAAAAAAAABSgY8aAAAAAAAAAAAgFfioAQAAAAAAAAAAUiH7vG7c0dHRdM7x8XHTOY1Go+kcT61WC8ar1arMyWQyTecUi0VZViqVmrqPmVk+nw/GC4WCzDk8PAzGvTb1nqsqi8mJ6QutFlN3lVOv12WOKtvZ2ZE59+7dk2Wqfnt7ezJnfn4+GB8cHJQ5lUolGPf6l+qTZrp+S0tLMufTTz8NxhcXF5uug1dv7/mp9vauF9P/0zBmlM7O8Pf3mLGUNO8+ak7OZvXSm8vlgvG+vj6ZMzU1JcvUHP/SSy/JnJMnTwbjPT09Mufg4CAY9+YNbw30xkyS0jwuklwfY9Zh717e/KX6/8jIiMw5e/ZsMD48PCxzHjx4IMvefffdYNxbG1WfVGPWLG5Nj5nXvP1fq+bCVvLaSJWp/btXpvbOZmZzc3OybGxsTJYpqt7eenH69Olg/OLFizLHm8c//PDDYPyf//mfZc7HH38cjHt7ULWme/045jwX0/dj5rs0UL/La1f1nLw28uZDVdbV1SVzVH/17uONGcX7TTMzM8G4N5b++q//Ohh/8803Zc7Q0FAw7q1lt2/flmXLy8vB+NHRkcyJGWfftHGh+p7X77y1ZGBgIBj3ztAqx3sWas/tvXPy2kGN2/7+fpnzxhtvBOOXL1+WOapd7969K3MePnwoy7a2toJx9X7NLN3jIuasoPZE5XJZ5qj+oM6UZv6+/9q1a8H4+fPnZY7aw6+trcmc8fHxYNzbR33nO9+RZd/+9reDcW/e/c1vfhOM/+53v5M5Kysrwbh3tvbWTcVbG2Pezzwr/EsNAAAAAAAAAACQCnzUAAAAAAAAAAAAqcBHDQAAAAAAAAAAkAp81AAAAAAAAAAAAKnARw0AAAAAAAAAAJAKfNQAAAAAAAAAAACpkH1eNz4+Pg7GOzo6Es2Joe7jlXk5nZ3hb0f1el3m7OzsyLInT54E47u7uzJH3ctru2w23D1qtZrM8ah7eW2XZkn+Lu85qWdbKpVkzsrKiizb29sLxpeWlmTO2NhYMD4yMiJzVP/yxoWnWCwG4xsbGzJHlR0dHcmcmHmo0WjIspicNI+lVo2LmPvE5HjPKaYvFwqFYLynp0fmTE1NybKhoaFg/NKlSzJHtcPjx49lzt27d4Px5eVlmXN4eCjL1DqThj6epKT7eMx+KeY+an43MxscHAzG5+fnZc7MzEww7u2Vbt++Lcs+//zzYPzg4EDmqLaLmftj9oxPu5fSqr1zu1C/t1KpyJzt7e1gXO23zcxmZ2dlmeqvk5OTMiefzwfj/f39MketC6urqzLn+vXrsuyf//mfg/Ff//rXMmdxcTEY99ZG1cdj5/eYsamkeY2J+b3efKPawsvxqHWht7dX5gwPDwfjam/j5QwMDMgcr2x8fLzpOiwsLATj3m+9efNmMP7+++/LnC+//FKWra+vB+PeXKikeVx41JjJZDJN5+RyOZmj9vZmek/krTFqLfH6ZHd3dzDu7dfUumSmx0xXV5fMUfXzzktfffVVMP7xxx83nWNmtrm5GYx74yLm/V+7iKm7agv1jsjMbG1tLRg/c+aMzJmenpZlr7/+ejD+k5/8ROaoPZva45npOdkbS948rubd9957T+b84he/CMbVmmCm33t5c1fMvJYW/EsNAAAAAAAAAACQCnzUAAAAAAAAAAAAqcBHDQAAAAAAAAAAkAp81AAAAAAAAAAAAKnARw0AAAAAAAAAAJAK2eddgT93fHwsy9RfZY/9a+1JX09Rv2lvb0/mfPnll7Jse3s7GL9z547MWVxcDMYPDg5kTr1eD8Zj28d7tojX2Rn+Num1d6VSabrs8PBQ5qyurgbj2ayeYlT91O8x8/teLpcLxmu1msxRfVzFPV7dku7737SxpH5vzHrh8XJUWblcljlqjldzuJlZf39/MJ7P52VOT0+PLFN53tz//vvvB+OPHz+WObdu3QrGl5eXZc7R0ZEsazQawXjMM39Rx0tMH1fzqzfnqWdhZpbJZILxrq4umTM0NBSMT05OyhzlwYMHsuz69euyTK1Z3nqh2s57DjE5Hu9ZKEnvadudGu/es1Vz9b1796LqUK1Wg3Gvj6t53NtHqbVE7fnNzD799FNZduPGjWBcjReP2pOZxe1bvb3hizrHNyumHbw5Rc0dXo73nNQ6441Nxdv3jI2NBeOzs7MyxxubAwMDwbi3zn311VfB+NramsxRe6zPPvtM5njXKxaLwbj3/F7EseT9JtUWMet6zPrsXU/tr8zM+vr6gnGvj6txMTg4KHMKhYIsU+3qvS+4fft2MP7o0SOZo8aFOneYmW1sbMiyUqkUjH/TxoX3e9XZdmdnR+ao/bg3T3q6u7uD8YWFBZkzPj4ejHvPb3NzMxj39j2ff/65LFN7rE8++UTmqHHhjaWYeSPJc6NZe40L/qUGAAAAAAAAAABIBT5qAAAAAAAAAACAVOCjBgAAAAAAAAAASAU+agAAAAAAAAAAgFTgowYAAAAAAAAAAEgFPmoAAAAAAAAAAIBUyD7vCjTj+Pi4qfjTdHaGv+k0Go2mr9XV1dV0zv3792XZf/tv/02WZbPhx7a3tydzNjc3g/FyuSxzOjo6gvHY9sbTqTZXca8sk8nIHK+/xjzfarUajFcqlabv493fq3e9Xg/GvXbw2rVZXr29sphnzhh8upg2inlOXh9Xc/KjR49kzuHhYTDe398vc7q7u2VZoVBoKm5mViwWg/H19XWZs729HYyrtccsbn7A08XMHTFrjFfm5eRyuWDc23s9fvw4GN/a2pI5t27dkmU7OztN1yFmz6hyWrle4I+853R0dBSMLy8vy5zd3V1Zpub4gYEBmdPT0xOMe/VWddjY2JA53jyu1iyvDmpflnSfTHpNYI15OvXc1bzm5Zj5Z05FnXk96kzinZMfPnwoy2q1WjBeKpVkjpoDnjx5InPU3su7j6rb08q+SWLmIq8fq/7l3UetMWZ6TvaenxpL3ro0NDQUjOfzeZkTs/6o84CZ2b1794LxmHHhnSHUMzLT7cqa8CfquR8cHMgc9Ty8nKWlJVn2ySefBOMzMzMyZ3x8PBj31ix1TvXqtri4KMvUeUWdO8z02d+rtyrzcmLPemnAv9QAAAAAAAAAAACpwEcNAAAAAAAAAACQCnzUAAAAAAAAAAAAqcBHDQAAAAAAAAAAkAp81AAAAAAAAAAAAKmQfd4VaEbMX2VP+q+8Hx8fN32tRqMRjG9vb8ucw8NDWabuVa/XZU61WpVlivqtKm4W16b4k5j+1dkZ/jbpPadcLtdcxZ5C9XEVN/Prp3jtoK7n1UGVJTk3PIvr4Y+Snm+Sfk5HR0fBeLFYlDkbGxtN1yGTyTSd480BhUIhGPfWkVqtFoyXy2WZ461ZMf2fMfN0qo97fcgrU+uPl6P60crKiszZ3NxsKm5m9vjxY1l2cHAQjHt9SPXXmHUplrpXK+uQVjHP1purS6WSLFP7+2xWH7vUmFFjzEzvYby52puTVf1izlIxOUn3Vfr+16Oek7ev9qg8by9QqVSCcW/uf/DgQTAe+05AjSdvDojpe95Yj7lPkuf4b9pYivm93tzqzcnqrOD18cXFxWDc60OqLHY8q9/rjQt1L6+9WzUu8Ceqjby5Wu2XvHHhnXlv3rwZjMe8E/OoPqnOtWbJv3NVurq6ErvWi45/qQEAAAAAAAAAAFKBjxoAAAAAAAAAACAV+KgBAAAAAAAAAABSgY8aAAAAAAAAAAAgFfioAQAAAAAAAAAAUoGPGgAAAAAAAAAAIBWyz7sCz9rx8XHTOR0dHbIsk8k0naN4datUKoleL0kxvxXPTmdn898mvWeoylTfNzNrNBpNxc10f/X6sVdWr9ebipvFtV2rxhnSwetDqq9446JWqzVdB69Pqvp5a0ypVGr6PkmPZzwbSa/f6nrevLu7uxuMq37nXa9YLMqcg4MDWRbTDmosxaynSWMstZ43j8fsiWL6isqJWROSroPHawe0VjvMHV4dVF/xcqrValPXelpZzF4uZr2IeRZJ77HaoT+0u5g28vZEqh955wFVlvRYiimLWee8caGul/RYwtPFtKvXH7xxEdNXYs6iMZK+Hu9Wvz7+pQYAAAAAAAAAAEgFPmoAAAAAAAAAAIBU4KMGAAAAAAAAAABIBT5qAAAAAAAAAACAVOCjBgAAAAAAAAAASIXs867A86T+cn3MX7RP+q/WNxqNpu/VDvVG68U895jreX2yVbz+GjMukm47tFa7Pz9VP68fZzKZpq71NDHjol6vR90L3zxqXSiXyzKnWq0G4964UPeJnd+z2fD2N2ZPxD7qmynmuSe9H4lZYzz0ZTxLMf01Zj+iruedY7zxp66n9mse77cmOQcgPWLeR7XqTB7Tv7xxkeSaRd9Ph9jnlOR7Wk/MOTnmfZSnHfZ/ace/1AAAAAAAAAAAAKnARw0AAAAAAAAAAJAKfNQAAAAAAAAAAACpwEcNAAAAAAAAAACQCnzUAAAAAAAAAAAAqcBHDQAAAAAAAAAAkAodx8fHx8+7EgAAAAAAAAAAAE/Dv9QAAAAAAAAAAACpwEcNAAAAAAAAAACQCnzUAAAAAAAAAAAAqcBHDQAAAAAAAAAAkAp81AAAAAAAAAAAAKnARw0AAAAAAAAAAJAKfNQAAAAAAAAAAACpwEcNAAAAAAAAAACQCnzUAAAAAAAAAAAAqcBHDQAAAAAAAAAAkAp81AAAAAAAAAAAAKnARw0AAAAAAAAAAJAKfNQAAAAAAAAAAACpwEcNAAAAAAAAAACQCtm/9D8cGhp6htX4Zuro6JBlx8fHTefF5Hi86z3v+yRtZ2cnKi+fzydbEaCNlMvlqLzZ2dmEawK0j6Wlpai88fHxhGsCtI/19fWovEKhkHBNgPZRKpWi8sbGxhKuCdA+NjY2ovI4X/xRku+CYt/DJHm9tL4/Slrs+WJ4eDjhmgDtY3t7+6n/Df9SAwAAAAAAAAAApAIfNQAAAAAAAAAAQCrwUQMAAAAAAAAAAKQCHzUAAAAAAAAAAEAq8FEDAAAAAAAAAACkQvZ5V6AddXR0yLLj4+NEr5ekpO/TqnoDfylv/MX015icmDkAAPBHag5Nes/RqvWCNQHPS0w/bjQaTV8v6bGUNMYm/l8xa0zSfaUdxgXSIcn5q7NT///KSe+9WjW/Mo/j62rl3J9Wad9H8S81AAAAAAAAAABAKvBRAwAAAAAAAAAApAIfNQAAAAAAAAAAQCrwUQMAAAAAAAAAAKQCHzUAAAAAAAAAAEAqZJ93BdqR91feVVnMX4bv7NTflGLLmtWq3+rp6OhoOifpOuDpYto8pn/F9n3Vj7z+lWQ/ok+mXzs8Q1UHrx97ZWrMtGo8x4pZF5AOrVrzY8ZF0tphTsGLK2a9aOe+HzvvM87aR6v2At59Go1GU9eKLfPqEJMTM549SV8Pz8bzfk5J7+3V+DOL+02tykH6JXm2TboPxbyPiqlD7PhL+z6Kf6kBAAAAAAAAAABSgY8aAAAAAAAAAAAgFfioAQAAAAAAAAAAUoGPGgAAAAAAAAAAIBX4qAEAAAAAAAAAAFKBjxoAAAAAAAAAACAVss+7An+uo6NDlh0fH7ewJs3p7NTfhzKZTDCey+VkTldXV9PX86i2q1QqMkeVNRqNpu+DF1vMc1djxhsXXpmaO7z+qsqq1WrTOUnz5kK0XpLPw7uWKvPWGG9cZLPNL/P1ej0Y98aFylFxM/p4O/HmcK/vJXkvrw6qryS950i6T8asF4yL9pH0s4i5Xsx6ETsukhxPMdeKbe+Ye6kcxt/TxfaTJPfpMbz9iHe2VmUxfcWrQ5Jro6eVY/NFlPS8q66XdP9q9v5m/m9SZd6YjdlPJr1u8q7qxRXTV1SfjJ3zkuyvMe9cvTH2Ivd9/qUGAAAAAAAAAABIBT5qAAAAAAAAAACAVOCjBgAAAAAAAAAASAU+agAAAAAAAAAAgFTgowYAAAAAAAAAAEiF7POuwJ9L+q+yJ/kX6L2y7u5umaPKxsbGZM709LQsU3m1Wk3mrKysBOPLy8syZ3t7OxivVCoyx6uDerbeM1dl3jNKug+1u5g2irmeJ2ZcDA4OBuOTk5NN55iZlcvlYHx1dVXmbGxsBOPValXmJN3esXlIXmdn89/5vRxVls/nZU6hUAjGe3p6ZI43zrq6uoJxb67e3d0Nxvf392VOsVgMxmPn6iTn8W/amuBp1Xrhtbm6l1cHNZZi9mueRqMhy+r1elNxM90OmUxG5nhzipenqPoxLr6epM8X2Wz4SBbbV2J464Ki9l5e/1K/KaZ/e2LWGG8OwB/FrheqbWOeU8z85fUvNf7M9D7KG39qLMWsF0mfeZOeN15ESZ/NYvYqMc/J6+Mx94mpgzeW1PW8eTdmDvDGWZJjk33Un6j+1co2SrKPe2M2pr/29vbKnOHh4WC8r69P5qj+6p3V1fneTL/78vaFMWv6s8KqBgAAAAAAAAAAUoGPGgAAAAAAAAAAIBX4qAEAAAAAAAAAAFKBjxoAAAAAAAAAACAV+KgBAAAAAAAAAABSgY8aAAAAAAAAAAAgFbLP68YdHR1N5xwfH7ekDrlcTuYUCoVgfHh4WOaMj48H4+fOnZM53/rWt2TZwsJCMH50dCRz3n///WC8Xq/LnHK5HIw3Gg2ZE1PmPVf1jJLuC2kWM5ZirufdR42Zvr4+mTM7OxuMv/baazJH9X0zs+3t7WD8k08+kTmVSqWpuJkeMzH9+Gl5MdfDH6l29drOm786O8P/D0Amk5E5qv+rNcHMbHR0NBhX48XMX3+6urqC8Z2dHZlz7969YPzx48cyR42LUqkkc1o1jyc9/tJM9ePYNlLX8/YWMfdRY9Ort1dWq9WaipvpdcH7rdlseJudz+dljtpnmunx7LVdtVptKv6066VVbF9J8l7e+UKVeTmqf3nrUgw1zs3Mdnd3m76e+k3q9zyNWmfUOcYsbo7CH3nzQ8w8HnN29Pqk6keDg4MyZ2BgQJb19PQ0XQe1x/LGizrHe+uSR80DSZ+703wmaYe6q37kzYdqL+DtH1SZ1/d7e3ubLvNy1LzrPQc1Lra2tmSOV7a/v9/Ufcz0POStIy/iPsqjfm9sO6g+4c27MXWIqZ+3Zql6e+Ps/PnzwfiJEydkTrFYDMbv3r0rc7z+qt6jpaUf8y81AAAAAAAAAABAKvBRAwAAAAAAAAAApAIfNQAAAAAAAAAAQCrwUQMAAAAAAAAAAKQCHzUAAAAAAAAAAEAqZJ/lxdVff/ck/dfpvTqosmxWN0tfX18wPjY2JnPm5uaC8QsXLsicl19+WZadPn06GF9fX5c5S0tLwfjNmzdlTiaTCcZjnmvSYvrCN433nDo79fdM1bZejhoz3d3dMmd6ejoYv3LliszxylZWVoLx7e1tmbO4uNh0jmofr096z0KNs5g+nvQc2e6839toNJq+XsyY6enpkTmTk5PB+OXLl2XOmTNngvETJ07InKGhIVlWq9WC8c3NTZmjflO9Xpc5BwcHwXipVGq6bma6vb1npPpDmvt4q8TuvVSf8NYL9Txixp+3X/PqoNYmb944OjoKxqvVqszJ5XLBuDdv9Pb2yrKurq5gvFKpyBzVrt5zVWMzDXuvmPGunnvsPiqmv+bz+WBc9SHvempf8bTrqTxv7lf9X/0eM7PBwcFgXJ2xzMzK5bIsU+ef3d1dmaPWJm8OSEP/b1bMPirp9cJrc9Vf1VnYzGxhYaHpnKmpKVmm5l3vrHDjxo1g/IsvvpA5ao3xxl/Mew6Pyok5N6Zh79Wqs1bMnFwoFGROf39/MD48PCxz1LsqdVYxMxsfH5dl6l5qfjeL2/+p88r9+/dlzu3bt2WZeifmnUm89adZaRgXStLjJWYfFXMOjHkn4CkWi7JMjWdvf3P+/Plg/OLFizLnyZMnwfjW1pbMefz4sSxTbRS7/rQa/1IDAAAAAAAAAACkAh81AAAAAAAAAABAKvBRAwAAAAAAAAAApAIfNQAAAAAAAAAAQCrwUQMAAAAAAAAAAKQCHzUAAAAAAAAAAEAqZJ/lxY+PjxPNaTQaTed0dHTIss7O8DedbFY3iyrz7qPqXalUZE69Xpdl6veq+8TmeGWK1w5emaLq7V0rpt/hT9S48Ki+4o2lvr6+YHxyclLmLCwsyDLVJ4aHh2VOT09PMO7VO6Z9vP6ayWSC8aTnzxdxXMT8Jm9uVc/CK1P92MxsbGwsGJ+fn5c5MzMzTd+nWq3KMjU2+/v7ZY4aZ0+ePJE5S0tLwfj+/r7MSXqdixmbMWtMu4uZB5KeO2L2I97zGxwcDManpqaazjHT49mr9+rqajDu7eVi1qXu7m5ZVqvVgvHd3d2mc2LqnYZ1JMm9a+yeVvWvpOeVpMezmpNLpZLMUf3LG39qnZubm5M5e3t7skzt2VTdzPRvjTkXpWFcKDF9xVu7vTZX7dfb2ytz1H7kH/7hH2TOyy+/HIxPT0/LnHw+L8vUb1pfX5c5hUIhGF9bW5M5y8vLwbi3x+vq6pJlSsx7kzTviTwxa11MW3jni1wuF4yrPmRmNjAwEIx7Z2jV/9V8bGY2Pj4uy9S49fqkOnt4+56JiYlg3Nszbm1tyTJv3CpJvo9K83qRtKTfG6o+4a3r6j6x65wat6ofm5ldvHgxGL9w4YLMUby5JmZPFPNuPul3ZX8J/qUGAAAAAAAAAABIBT5qAAAAAAAAAACAVOCjBgAAAAAAAAAASAU+agAAAAAAAAAAgFTgowYAAAAAAAAAAEgFPmoAAAAAAAAAAIBUyD7Li3d0dMiy4+PjxO7T2am/zXj3UWX1el3mlEqlYHxnZ0fmZLPhZn78+LHMWVxclGUDAwNN12FraysY39vbkzm1Wk2WxYh55urZNhoNmaP6XZJ9rtW8sZRkjpluJ+96qkz1fTOzwcHBYHxkZETmDA0NybL9/f1gXI0XM7NcLheMe3OKKvP6V9LXU7xxkeb+n3RbKN5zUn3Z6+Oq7PDwUOasrq4G4/fu3ZM5an43M+vr6wvGz507J3N6enqCcW8sqd8aOw8lOY+nue97khwX3rW8saTKvP1DPp8PxmdnZ2XOK6+8EoxfvnxZ5hQKBVmm9nJq/JmZ9ff3B+PeeFZ1mJqakjmZTEaWra+vB+PValXmHBwcBOOqDdIg6fOFul7s/KV4dVNnD29dUn3FG7NeX1F18M4Kqn5qj2dmdubMmWD89OnTMmdzc1OWqXqrfaGZWaVSCca9uStmX9Euklw7vXbwztBqz+3N/T/4wQ+C8e9///sy5+zZs8H49va2zPHO3Woe8Pr4/Px8MO6dY1R7e31StamZ3pfFnKHTLGa9aNU7LI9XBzX3e/sHNVcfHR3JnOXlZVlWLBaD8e7ubpmjxsXJkydljtpHeWtjzHk4Zn5Pcr/RTpJcL2LegZjFnQPVM/TGhXeOV7x5V60Lat9jptesyclJmXPjxo1g3FvnvD2R2ht67R3zjLxn/nXwLzUAAAAAAAAAAEAq8FEDAAAAAAAAAACkAh81AAAAAAAAAABAKvBRAwAAAAAAAAAApAIfNQAAAAAAAAAAQCo0/+fem+D95XPF+4vo6i/ae9RfZfeuV6vVZE65XA7GDw4OZE42G25m7y/Qq/uY6b9Of3h4KHN2dnaCca/elUolGK/X6zInaTF9qN3F/CavH6vrxfR9j+rHZmb5fD4Y7+/vlzmDg4PB+NDQUNP3MTPr6uoKxr05RfHaTpV59/GuFyPJPtQuY8yrhypLeix5ZWpd8ObqUqkUjO/t7cmc7e3tYHxlZUXmbG1tybJTp04F42fOnJE5atx67aPWCxU3i5uHYiQ9/p6FJMdhzFjynoVXptrWm6vn5uaC8Z/85Ccy52c/+1kwPjMzI3O8MXPr1q1g3FvnYtaYqampYPzkyZMyR+3xzPR48n6ren4x46JdxlLS5wFVFvt7Y8ZZkuucx9vDF4vFYDyXy8kctWdTa4+Z2dWrV4Px2dlZmePNKcvLy03nqLGeyWRkjnc+bAcxc3/M9bxree2n9hbnzp2TOT/84Q+bznn48GEw/m//9m8y5/r167Jsfn4+GP/xj38sc8bHx4Px0dFRmaPWmKSfa8y5qF3OCp6Yc06S48JrV+8+al7x5hs1V3vnAXVe8ertvatS752mp6dljuKNC9UOa2trMmd9fV2WqXdfXnvHvGtpd+0wppMcf2a6L3vrkirz9krenmhhYSEYv3z5ssxR+yX1HsFM73u884A3ntX+1Gu7dur//EsNAAAAAAAAAACQCnzUAAAAAAAAAAAAqcBHDQAAAAAAAAAAkAp81AAAAAAAAAAAAKnARw0AAAAAAAAAAJAKfNQAAAAAAAAAAACpkH2WF+/o6JBlx8fHTcW963V26m8zXh2Uer0uy6rVajDe29src7q7u4PxoaEhmTM+Pi7L1L0qlYrMWV9fD8a3t7dlTqlUkmWK13ZeWbNi+km7iBkXHpXTaDSavpaZWSaTCca9ehcKhWB8cHBQ5vT19TV1fzOzWq0my1T9vDYtl8tNxc10u2azcdNpzFwYk9PuYsaFl+OtC83ex0zP/TF9xRub6nrefNzT0yPL5ubmgvGpqSmZc3R0FIyrdcTMbG1tLRjf39+XOd6YUfOAlxMzB7TLehFTj5g5PuY+3pycy+WC8YmJCZnzox/9KBj/z//5P8ucl156KRhfXFyUOffu3ZNln332WTDu7YkODg6C8enpaZlz8uTJYHx+fl7mqLFkptdANT95OWnmze9qXHh9v1XzQMxclM/nZY4am177eHVQ5xUVNzO7cOFCMP7WW2/JnGvXrgXjXj/2zhBq3fTmyDTvl5Skzxcx+yi1JpiZTU5OBuOqP5iZnTt3LhhX87GZ2T//8z8H4//jf/wPmePN/T/4wQ+CcW9cDAwMBOPefi3mGcXMXTHzpzeW1PWexRhL+qwQk9Pstcz89lPzXrFYlDmqzb05tKurKxj35lav3up9lLdPV+8LvN+6tLQUjN+5c0fmrK6uyjJ1LvH2Skm+t2yXtSdmn5B03WPedcSc/b0+qe7jjSXv/da3v/3tYFydY8z0O+F3331X5qhzzOPHj2WO985CtVHM3vl59HH+pQYAAAAAAAAAAEgFPmoAAAAAAAAAAIBU4KMGAAAAAAAAAABIBT5qAAAAAAAAAACAVOCjBgAAAAAAAAAASAX9p+Cb4P1V9CRzMplMMO79hfWYv77eaDRkmap3d3e3zBkbGwvGFxYWZM78/LwsU/fa3d2VOevr68H43t6ezKlWq8G49+y8sphn8U3T2dn8d0bV5rHtrfLU+DMzKxQKwXg+n5c5tVotGK/X6zLHK1NUPzYzq1QqTeeo9lG/x8xvu2bvY+bPUS8iNS68NlI5Xtt5/UvleXXI5XLB+MDAgMwZHR0NxoeHh2WOWmPMzN54441gfHJyUua89957wfhXX30lc1ZXV4Nxbyz19fXJsmw2ke1J6iXdx1WO6qtmen43M+vp6QnGv/3tb8ucH/7wh8H4hQsXZM7a2low/s4778icX/7yl7Ls/v37wbi3Bk9PTwfjp06dkjlnz55t+j77+/uyTO3zDg4OZI5am7w1S/W7dtnHefVQe6Kkzyreuh6zV1Hj1qtDV1dXMO7Nn169JyYmmoqbmb355pvB+Kuvvipz1Bp48+ZNmbO4uCjL1Bnn6OhI5qj2TvP+qh3Gp7fvn52dDcbPnz8vc1Qf/+KLL2TOb37zm2Dc61+Dg4OyTM39c3NzMifmLBVzVvCo63lzSsxet5X9Lul7JX2GVrw1Qd3Ly1Hrt/ds1bw7NDQkc0ZGRmTZzMxMMK7OMWZ6LO3s7Mic27dvB+N37tyROZubm7KsVCoF4+0wf6ZZzB4r5p1rzL7MyymXy03nXLx4UZapc/fp06dljuqvv//972XOZ599FoxvbW3JnJj1xzuvxIwZlRPTf/5f/EsNAAAAAAAAAACQCnzUAAAAAAAAAAAAqcBHDQAAAAAAAAAAkAp81AAAAAAAAAAAAKnARw0AAAAAAAAAAJAKfNQAAAAAAAAAAACpkE3iIsfHx0lcxszMMplMovep1+uyrNFoBOMdHR0yp7u7OxjP5XIyZ3BwMBifmZmROSMjI7JMqVQqsky1g9fe6nqxz1vlee2teDlJ9sdWS7KNOjvjvlmqOsS0q9cnj46OgvFqtSpzvP6qxmahUJA5MfdRvGek5hqP195J9pM0iPm9qsx7tkmvFwMDA8G4N/fPzc0F4729vTJnfn5elk1NTQXjW1tbMkeV7e7uyhxvrCu1Wk2WqWfhzWsv4tzviemTqiyb1dvBnp4eWXb27Nlg/K/+6q9kzuXLl4PxnZ0dmfP73/8+GH/nnXdkzv3792WZarvp6WmZ88YbbwTjb731lsyZmJgIxr/66iuZ8/jxY1m2uroajB8cHMgcNTa9+e6bRo0Lb77xxplaZ7zrdXV1NRU302PTy1FrjJkezypuZnb16tVgvL+/X+bcvn07GP/ggw9kzvXr12XZ2tpaMK72mWZ6XHj7tST3x19HzP1adb7I5/OybHx8vKm4mdn29nYw/sknn8gcNU9654GFhQVZdurUqWB8dHRU5qizjLeeqnnD27d6zyJmj6Ck4Xyh6tiq8RnbRmrMDA0NyRy17z9x4oTMOXfuXDDurQmzs7OyrK+vT5Ypaq/y8OFDmbO4uBiMb2xsyJxSqSTLkpwLX9RzRzuMmZhzvCorl8syR+0FvHXpzTfflGWXLl0Kxr192W9+85tg/Fe/+pXMefDgQTDuna2999Wx7w1DvP6j7vN1+xz/UgMAAAAAAAAAAKQCHzUAAAAAAAAAAEAq8FEDAAAAAAAAAACkAh81AAAAAAAAAABAKvBRAwAAAAAAAAAApEL2WV7c+4v26i+cezmqzPsr7/V6XZZVq1VZphwdHQXjBwcHMkeVefUul8uyTP3leu+vxvf39wfj3d3dMufw8LDp+8Q8P+96qqyzU3+P8+rQ7lr1e70cNWa8/qrGxfb2tsxRZaVSSeZkMhlZls/ng3HVj830OIvp417dYvq4p9FoBOMv6riIaXOV460Jql29PO/5qefR19cnc+bm5oLx+fl5mTM6OirLisViML65uSlz1JgpFAoyR60x3lrmtZ1qb7X+edd7Efu+WdzvVX3Se7ZDQ0OyTPVLr7+q/r+/vy9zVH/w6vbyyy/LsuHh4WD8ypUrMueNN94IxicnJ2XOkydPgvFHjx7JnAcPHsiyjY2NYFyNc7O4uStmXWp33rhQa4k332Sz+ggVs49SZxJvXZ+eng7GT58+LXNeeeUVWXby5MlgfGxsTOaoel+/fl3mvPvuu8H4p59+KnOWlpZk2d7eXjDujQtV75j9X6vHS5L1iDm3eX1S7cXNzAYGBpq+nloX1LnDzGxmZqapuJk/91+7di0YV/seM7N79+4F4zs7OzJHPT9vHvLaTu1pY84rMf2k1ZLcAyb9e702V/1odnZW5ly8eDEYV33VTPfxU6dOyRzvvKLO614fV3O1905O9WNvDY55Rt4ZUI2zpN97tYsk5wFvjoo5x3sqlUow7u0FVP1ee+01mfP9739flql9lLe3/5d/+Zdg3NtHqd/krRexa4kS00+e1Vmdf6kBAAAAAAAAAABSgY8aAAAAAAAAAAAgFfioAQAAAAAAAAAAUoGPGgAAAAAAAAAAIBX4qAEAAAAAAAAAAFKBjxoAAAAAAAAAACAVss/rxh0dHU3nHB8fB+ONRkPmVKtVWVar1Zq6j5nZ4eFhML61tSVzVlZWgvEnT57InLW1NVk2OjoajPf398uc2dnZYPzBgwcyR9XPa9NcLifLstnmu1tMP8EfxbZdZ2f4W6caL2ZmBwcHwfju7q7M2d/fD8bL5bLMqdfrTZd511N92futXh+PoeYbbx5iXDydaiOvXb3+pfqK179U2dHRkczx1hJleXlZlhWLxWB8Z2dH5gwNDQXjp06dkjl7e3tN161UKskyta57630mkwnG0zyWvLrHUG3U1dUlc/r6+mSZ2o8MDAzInJ6enqbv8/LLLzd1/6dR9bt48aLMGR8fD8a9/drNmzeD8S+++ELmqD2jmR7P3riI2TvHzJ+t5I1bVab2NmZ6XVd91cysu7tblileHVT/P3nypMy5dOlSMP7aa6/JHDWWzPQ+3evjH3/8cTD++9//XuZ89tlnwbh3LvLOHqrMW9NV//dylHZZR2LGhSdmvHt75Jh5JZ/PB+MnTpyQOYVCIRhXc7iZv785ffp0MK7WUzPdv7yzcKvOyV57xzzzdu//Xv3U7/Vy1Dwesz81033cW3/UHkZdy0yfPe7duydzvHlXnXG8M7Ta96sxa2Y2OTkZjHvrhXfOUvuomPkzZh+VBjFjSZV5fd/bE6k8r3+pPumt63Nzc8H4X/3VX8kctfcy02vgu+++K3PUPmp7e1vmqPbxxpL3LGL6uPI8zt38Sw0AAAAAAAAAAJAKfNQAAAAAAAAAAACpwEcNAAAAAAAAAACQCnzUAAAAAAAAAAAAqcBHDQAAAAAAAAAAkAp81AAAAAAAAAAAAKmQfd4V+HPHx8eyrNFoNBV/2vVUWUdHh8xRyuWyLDs8PAzGNzc3Zc76+ros6+3tDcZ7enpkzsTERDA+MDAgcxSvTT2qXWOuF/OM0iDJNurs1N8svfar1WrBeL1elzmVSiUYPzo6kjkHBwfB+O7ubtN1MzMrFArBeC6XkznVajUY935rNhueNmPbO0lpHhdJ112tCzFrzNPyFLUubGxsNJ2zv78vc7wxo8bF5ORk0zknT56UOVtbW8G4Nwd4a6Bq75jn543NJPcB7SJ2jY65Xsz+ZmdnJxj39jBDQ0PBuJqPzfy5f3R0NBgfHx+XOWqcffHFFzLn448/Dsbv3bsnc1T7mOn5wVuzku4P7cAbn2q8e31F9b3BwUGZo/qkmVl3d3cwPjY2JnPU/Prmm2/KnIsXLwbjp06dkjnFYlGW3b17Nxj/6KOPZM4f/vCHYPzLL7+UOU+ePAnGvXUuZu6PyfH6lrdHaHetOoPFtJ+3t1dz8quvvipz1JnEmwM8ql96Y0mtP966lMlkgvGkzxfeeqGekaqbWbr3UapPeHVXbeGNJe966iyqzslmZo8ePQrG1V7c450h1B7PzKyrqysYHxkZkTlnz54Nxr33UWptVOuImdna2posU+O2VetFGsZFknWMHRcqL2a/6/XJH/3oR8H4D37wA5kzOzsryz777LNgXO2VzMyWl5eDca/t8vl8MO7N1THnYU87zf38Sw0AAAAAAAAAAJAKfNQAAAAAAAAAAACpwEcNAAAAAAAAAACQCnzUAAAAAAAAAAAAqcBHDQAAAAAAAAAAkArZJC6S5F849/7yesx9vBz11+GzWd0suVyu6fuo33R0dCRzqtWqLKvX67JMUfWLaW8vp7NTfydLsp94WnWfVvLaXGk0GrIspr96arVaMF6pVGSO6v/7+/syx6t3oVCQZc3y2kC1a9J9P+Y5fNPE9PHYcaH6Vz6flzlqXGxsbMic5eXlYPzu3btN55iZTU1NBeOvvvqqzDl9+nQwPj4+LnNmZmaC8SdPnsicg4MDWebNHUrMmGnlepH0/ibmPqr/F4tFmeP115s3bwbjpVJJ5ty+fTsY7+vrkzmDg4PBeE9Pj8y5cuWKLOvv7w/GV1dXZc7vf//7YPxf/uVfZM6XX34ZjHtt6o0LtTf0nrkqi93LtVLMuFB7+66uLpmj+pE3583OzjZddvbsWZlz+fLlYPzixYsyZ2RkJBj3+tCnn34qy955551g/He/+53MefjwYTC+ubkpc9T84D3vpPdRMeMizWLOdIo3P6h9j5nZ0tJSMK7mSTO9ZvX29jZdB2+vtLu7K8vUPspbs5ShoSFZpuahmDXdk/T8nmTfir1XbI5aL9T7Hq/M6/teW6j97srKisxR86v3bknNu3t7e03nmOl2mJ+flzmqvb0zydjYWDCu1j8zf71X79G8cZHmfVSrqLbw3lt685e6njfOVP86d+6czPnrv/7rYPzChQsy5/DwUJb98pe/DMY/+ugjmbOzsxOMe31I/VaP196qrJXv5r+Ob9ZoAwAAAAAAAAAAqcVHDQAAAAAAAAAAkAp81AAAAAAAAAAAAKnARw0AAAAAAAAAAJAKfNQAAAAAAAAAAACpwEcNAAAAAAAAAACQCtnndePOzua/p3R0dATjXV1dUfdR18tmdbNkMpmm65DP54PxXC4nc3p6emSZ+k2NRkPmHB0dBeOHh4cyR13Pq7dqHzPd3sfHxzLnm0a1UUxOzLVi89Rz98aSUqvVZJk3ntUY9MaSqrc3lmL6q3c9r6xZXt1i+0M7835TzHPy5vHe3t5gfGxsTOYMDQ0F494zf/LkSTB++/ZtmbO6uirLlFKpJMvUHD84OChzVFmhUJA53nqhxnpMP/b6gip7FuMl6Wuq63n9S82v3l6gXC7Lsp2dnWD83r17MkeNpb6+Pplz4sSJYPwnP/mJzPGut7+/H4y/++67MufnP/95MP7ee+/JHDWeY/qkmVm9Xg/Gvb4Vs8aoOrTLfs37vWruUHtxM91X1BxuZjY7OyvLLly4EIxfvnxZ5qg+7j2/u3fvBuOffPKJzPnwww9l2c2bN4PxR48eyZzNzc1gXJ07zPTz89aEmDETO86SzGkXMWcF9TzUPGRmtre3J8vu378fjHtjc2Njo+kctWZ5e6Xd3V1ZdvHixWB8fn5e5oyMjATjMWdob1x4ZyaVF3NWSHostVLMetHd3S1z1LnSm6uLxaIsq1arwbg3h6q9l9rbeHWoVCoyx9v/qeeu9nhm+rd67R0jyX1PrFaeL2IkfYZWOd4c5a0lMXWYnJwMxt944w2Z8+qrrwbj3vn1F7/4hSz71a9+FYx7+yg1zrz1IqZ9vGehxPSTmPf8Xxf/UgMAAAAAAAAAAKQCHzUAAAAAAAAAAEAq8FEDAAAAAAAAAACkAh81AAAAAAAAAABAKvBRAwAAAAAAAAAApEI2iYuov3zu/bV0xcvJZsPV9f4yvPfX19X1VNzMrNFoBOP5fF7mDA4OBuPz8/My5/Tp07Isk8kE47u7uzJndXU1GN/f35c5qu28Nm3VX7uP6Vuqn7aTmDqqtvDayCtTfVz1OzM9Br2xVK1Wg/FKpSJzvOup35T0HKCeUb1elzmqTfEnXt9XzzamXb1+XCgUZNno6GgwPj09LXPGxsaCca/epVIpGD86OpI5Xh/v6ekJxsfHx2XOzMxMU3Uz89dAxZuH1G+KmddatS61C6+N1DwV0yfNzPb29v7yiv1fan6dmpqSOVeuXGkqbmbW398vy959991g/L//9/8uc377298G48vLyzInZs/ozVHN3scsbr/USknXT13Pa9fu7u5gXO3fzcwmJydl2ezsbDDu9cn19fVg/OHDhzLnwYMHwfj7778vc7zrPXnyJBjf2dmROeVyORiPOSt4fcHbI6j+n/S+v93Hkke1hfecYnJqtZos29zcDMa//PJLmfP48eNg3Dv7qzXLO/OqM4mZ3ht65241d6i5xsyst7c3GPfmLq+PqzIvJ+bsn+R7oGch5t2SehZmem/v3cebQ7e2toJxb9+v+rjXj5XY9zqq7bxz0alTp4Jxb61V48zbf3r71pj3HEq79PEYMetjzDrsvR/x1gvF6yuXLl0Kxr/73e/KHPU+9v79+zLnf/2v/yXLPvroo2Dc66/qTBDTJ7329spi3ie20/m6fWoCAAAAAAAAAADg4KMGAAAAAAAAAABIBT5qAAAAAAAAAACAVOCjBgAAAAAAAAAASAU+agAAAAAAAAAAgFTgowYAAAAAAAAAAEiF7LO8+PHxcdM5HR0dsiybDVe3t7dX5vT398uyvr6+YDyXyzVdh0KhIHNeeumlYPz73/++zDl37pwsu337djB+//59mfPw4cNg/PDwUOZ0doa/eak2MPOfX6PRCMa9fqLq4Inpd2nmtXkM9Xy9+6j+7/UVVeY9c+96qn951L28Oqj7eO2TdJ+MeeaqDkn3n2chpv3Uc8pkMjInn8/LsuHh4WB8enpa5kxNTQXjpVJJ5gwNDQXjJ06ckDlevV9//fWm4mZmCwsLwbhae8zMdnZ2gvGjoyOZ4z1X7zkpaty2cmwmzauf+l3e/KWuFzPnxVL7sgsXLsicH//4x8H46dOnZY7a95iZ/eIXvwjGf/vb38qcxcXFYLxer8sctZ+MnXeT7K/tMvfH9PGYucPbP6gcbx7yrler1YLxlZUVmfPVV18F4x9//HHTOaqvmvnrT7lcDsa9Pq6eUUz/8u7jPXM1R3nXw9OpZ+iNC2+9UPsBL2d3dzcYj1mzVP828/uX2t/s7e3JHHWvmDOO914i6XctMeM2yTngWfDaSLV5T0+PzBkZGWk6R71zMtPjaWlpSeaotvXWJdX3vHp715ubmwvGf/jDH8qcixcvBuPeXK3eb3nrXMzZw5uHYt4XpFk7nI26u7uDcXVGNTN77bXXgvHLly/LnEqlEoz/+te/ljneWWFraysY7+rqkjmqzHsOaszE7qOS9Dzm/hdzJAIAAAAAAAAAgBcOHzUAAAAAAAAAAEAq8FEDAAAAAAAAAACkAh81AAAAAAAAAABAKvBRAwAAAAAAAAAApEL2WV7c+8vnMX99XV0vl8vJnP7+flk2OTkZjA8NDTV9veHhYZnzne98Jxh/6aWXZI7nyy+/DMavX78uc5aWloLxarUqczKZTDDequfq8e4Tc700U23htVE2q4e+ar98Pi9zCoVCMK76kFfm3ce7XqlUCsa9dujsDH/X9e4TI+k+qa7HuPgT1Rb1ej3qejH9dWBgIBj31gs1Nk+fPi1zRkdHZdm1a9eC8fPnz8uczc3NYPzu3bsy5+HDh8H4wcGBzPGoscl68f9p7956q6q6BgDPdrdFDooiIEG8MDGa6I3X/nKMd0ZjPECCQQQUOdtiT7Swe9zdfS+88MuXOQbvnu9y0wXPczlmxlprz/NaE9IXy35T1L9a5snsXidOnAhzPvroo2r8iy++CHOifryxsRHmXL58OSz76quvqvF79+6FOZGFhYWJy7I6zdoiKmtpo5ZxMe3x0rKnHI/H1fhoNApzor3w1tZWmLO+vh6W3b59uxrP+uuVK1eq8bt374Y5i4uL1Xi2zrXs/1r6a9QOWVmWk4nyWsbSq7gmZFrn/pbrRf1yOByGOVF7ZPv06LvA3t7exM9WStucEt0r6+PRc2drTPYMkayPt/T/ljWmVdf7ueh6Wf+K9jfRd6UXlUXfnbJ91PLycjWe7bmj62XvEBcuXAjLPvnkk2r8s88+C3Oivvzrr7+GOdeuXavGl5aWwpzd3d2wrGV/4737by1jOltHou9HpZRy9uzZajzqd6WU8umnn1bj2ffgaL/29ddfhzkPHjwIy6J2z35rpGUPk8n6ZNROWfu17BH+LUfnSQAAAAAAABIONQAAAAAAgF5wqAEAAAAAAPSCQw0AAAAAAKAXHGoAAAAAAAC94FADAAAAAADohbkuLjIzM9PFZUoppRweHoZl4/G4Gt/b2wtzsrLoesePHw9z3n777Wr80qVLYc65c+eq8c3NzTDnt99+C8u+/fbbavzWrVthzvPnz6vxrL6jdm1po0yX/aeU/PmOupY6b/m9BwcHYdlgMKjGW9opyzlx4kQ1furUqTAn+63Pnj2rxrM5YHa2fq47NxdPjVHdtbZRVEdZ3UXX63osHRXR78rmm6iORqNRmLO9vR2WbWxsVOOrq6thztraWjX+3nvvhTkXL16sxt9///0w59133w3LojXr8ePHYc73339fjX/zzTdhzr1796rxrE6z/tr1fNNX06qjaC4spZSFhYWJy6J+XEopn3/++UTxUuLx/N1334U5ly9fDst+//33ajybH956661qPKuf6LmzNThbL6J2ytrvVZTVUdSG2Vz09OnTajx7H8jqPCpbXFwMc65fv16Nr6ysTHyfaH+V5ZTSttZGun5XaNlH8Y+o3bO2iMpa+n4p8byXzbuRlj60s7MTlh07diwsi+aBrE8Oh8NqvOt3kuidrZS298Mux9JRGZct68XW1laYE5XNz8+HOefPnw/LLly4UI1/8MEHYc76+no1HvW7Uko5ffp0NX7mzJkwJ/qGleVlY/Pq1avV+A8//BDm3Lx5sxqP3steJBpnWX993fZYLaL6y+av7JtP1P8//vjjMCcaZ9F4KaWUH3/8sRq/ceNGmJONs+j3tuyJWvY9LXu8f+N602aEAgAAAAAAveBQAwAAAAAA6AWHGgAAAAAAQC841AAAAAAAAHrBoQYAAAAAANALDjUAAAAAAIBemOviIoeHhxPnzMzMTJyzv79fjW9tbYU5q6urEz/DeDwOc3Z2dqrxhYWFMOfWrVvV+N27d8Oca9euhWU//fRTNb68vBzmRHXX0nYtOaXE9Z1dr6Wf9FlL3Wb9tUsHBwcTl83Oxuemx44dm/gZ/vrrr7DswYMH1fja2lqYMxqNqvGsHaLflLVD1o9bxgV/y/pXVH9ZvUbzeynx/Hr79u0wJ1qbLl68GOacPHmyGs9+68OHD8OyaGyurKyEOdH6k93n2bNn1XjX87v14h9RXWT1EM1Tc3PxdnB+fj4sO336dDV+6dKlMCfq/9l9rl+/Xo1/+eWXE+eUEo/148ePhznRPi+b+6OybD0dDAZhWddj5lUUrevZ/L6+vj7xfTY2NsKyqM6zeTd6hmzuj/prtr/K+kNUd5moj09rb1pK27h43daLlvaI+kpr20Z9OeuTLfeK5tds3s3GTDT3Z3NK9L6yubkZ5kSyOSBbL7LfG2nZVxwVLfv+6PtI1k5LS0vVeLQfKqWUEydOhGXnz5+vxs+ePRvmDIfDajzrK1FZ1rZR/ZRSyp07d6rx7PvWjRs3qvF79+6FOdFam7Vr1/uo101URy3vF9ne/tSpU2HZuXPnqvEzZ86EObu7u9X4zZs3w5wrV65U448ePQpzsnUpGmct+6tM1BZZ32+5Xl/eIfxPDQAAAAAAoBccagAAAAAAAL3gUAMAAAAAAOgFhxoAAAAAAEAvONQAAAAAAAB6Ye5l3Tj6S+rZX5OP7OzshGV7e3sT562trYU5b775ZjW+tLQU5vzxxx/V+OxsfKYU5ZRSyuPHj6vxrB5Go1E1Hv2l+xeVdanlGaL+8zpqaaes/qLrRX2olFK2t7er8bm5eIpZX1+vxm/fvh3mHBwchGWLi4vV+N27d8OcjY2Najz7rVHdZeM5q++Wvvy6jYvod2V9P2uPSNa/hsNhNX7//v0wZ3V1tRq/c+fOZA9W8t+TrZtR3UVjtpR4XOzu7oY5kaOwxrxuWub3wWAQ5szPz4dl77zzTjV++vTpMCd6vmzfc/369Wr86tWrYU60xpQS/95szYrmh6y+o7GZ3ScbF9G9ulxH+i6q8+x9IJLtBbIxE83Xz58/D3OiNszGX3Sf7Lfu7++HZZGW/tUyD7WK2jy7T0tOn3W5P2y9Vsu+LMrJ9j1R/8/un42z6PeurKyEOdH68/Tp04nv07VX9V0hkv3eaD7M5uonT55U49k7RLSvLqWUDz/8sBqPvjmVUsrCwkI13vLenT1b9n0reu/OcqL+n33DisZ6tgZnojn+VZ37p6WlPbIxE72nZv0r2rMtLy+HOb/88ks1vrm5GeZk60/LOtfynWNa/bgv48L/1AAAAAAAAHrBoQYAAAAAANALDjUAAAAAAIBecKgBAAAAAAD0gkMNAAAAAACgFxxqAAAAAAAAvTD3sm58eHg4cc7BwUGn99nf36/G19bWwpz5+flq/NGjR2HO8ePHw7LI1tZWWDYcDqvx7LcOBoOJn2FmZmbi+7SI7sN/p+v2iMZZNF5KKWV2tn4+muXcunWrGo/6dymlnDx5MixbX1+vxv/8888wJ7rXeDwOc6Lfmum6jbq+Xl9l9RCVZfNNS9vu7OyEZXt7e9X46upqmBP1vdFoFOZkzz03V1/ms5yWupvWPG69+HdkYynrK9GeKJv7V1ZWqvFsH/Xzzz9X40tLS2FO9pui527ZK2X109Jf7bH+HVm9RnN11o+zeo3m8ew9pmXPHa0/2X2y/U30DC3j4ijI6u51Gxct/atlLuq6zqM9TMuzZfeP1oRS4nfyhw8fTvwM2Zr1/Pnzajzb/2XjucWrOC6yvhLVX7a3j9oj+3YT7XtKKeXOnTvVePbO+8Ybb1TjWX+I3nk3NzfDnKhPZteL1tNSpvdu1tKPX8W+f9Rtb2+HZffv36/GNzY2wpxoHo++EZVSyuPHj6vx3d3dMCdal0rpdg/fMi6ynFf5+5H/qQEAAAAAAPSCQw0AAAAAAKAXHGoAAAAAAAC94FADAAAAAADoBYcaAAAAAABAL8R/uv0l6fqvsmd/AT4S/TX5Uko5ODioxre3t8Ocvb29ia5VSimj0SgsG4/H1fhgMJg4p6V+um6jrq/3uonaMKvXrN2jvKgPlVLK/v7+RPHsPltbW2FONjajcbazsxPmZM8XiZ47q+/WtmC6sjk0aqdsXETzeJYTlWU5LeO5pU8ehfWC6cv63rNnz6rxJ0+ehDlPnz6txtfW1sKcR48eVePZ3isbz1FZy1jK1qVJr/WiZ+DFWuacKKelP5QS7++znGictfSV1nk3Ghddrxctfby1Lch1Pd+0zIeZaFxk78nR+Mt+a3a9aD2L3jtKiethZWUlzNnY2Jj42Vr6vjXmHy31F707Zu00HA7DsqhPTGvOy/Z4LetcJhoXLfNG9txMX8v7ZtaGm5ub1Xj2nSiak7Pxt7u7W41nfTJ7v4hM6/2i9XtBS85R2nv5nxoAAAAAAEAvONQAAAAAAAB6waEGAAAAAADQCw41AAAAAACAXnCoAQAAAAAA9IJDDQAAAAAAoBfmXvYD/H8zMzNTu9fh4eHEzxDljMfjMCcqi671IrOzk59FRb8pe4bW5+No6HostfS7zGg0qsaHw2HT9Q4ODqrxbGy21FHLuJjmvMbfWuq8JWcwGEx8vaivvuh6Xcr6cZfrhb5/tETtFM3HpZSyvb0dli0vL1fja2trYU7UJ7K5v2VdWFhYCMtaxlnLuJj0WrwcXbZtKXH/ytq963eFSNf9NSrruo97J5m+ac1T2ftFtF/quh9n69zi4mI1vrKyEubMzdU/sWxtbYU50Tqcvce07OX430R13vUc1fI9qvV6Lab1PYp+y+avvb29sCx7L4lE60X23h3N1dPcw7Tso6Y1ZvoyNv1PDQAAAAAAoBccagAAAAAAAL3gUAMAAAAAAOgFhxoAAAAAAEAvONQAAAAAAAB6of7n3l+io/4X1qPn6/qv02fX6zKnRde/lX7I2n0wGEx8vfF4PFG8VdYnpzVm6IeW+aslp2W8dD23msf5v7J5d3d3d+Kylrm1Za4+duzYxPfJrmdcvJ6m1bYtfbzrsTQ7O/m/Z7OP4t+UrT/RfqnruTp7hp2dnYnimaPwvYAXOwp77q6f4SjsYY7CMzBdWZsfHBw0lU3qqO97jvJ3377wPzUAAAAAAIBecKgBAAAAAAD0gkMNAAAAAACgFxxqAAAAAAAAveBQAwAAAAAA6AWHGgAAAAAAQC/MHB4eHr7shwAAAAAAAHgR/1MDAAAAAADoBYcaAAAAAABALzjUAAAAAAAAesGhBgAAAAAA0AsONQAAAAAAgF5wqAEAAAAAAPSCQw0AAAAAAKAXHGoAAAAAAAC94FADAAAAAADohf8AAM0XhkcToE0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1600x1600 with 64 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reconstructions = autoencoder.getReconstructions(unlabled_val_loader)\n",
    "for i in range(64):\n",
    "    plt.subplot(8,8,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(reconstructions[i], cmap='gray', interpolation='none')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "R2hrP5b1MNkr"
   },
   "source": [
    "# 4. Transfer Learning\n",
    "\n",
    "## 4.1 The pretrained Classifier\n",
    "\n",
    "Now we initialize another classifier but this time with the pretrained encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "OELYQAUmMNkr"
   },
   "outputs": [],
   "source": [
    "from exercise_code.models import Classifier\n",
    "from copy import deepcopy\n",
    "\n",
    "hparams = {}\n",
    "########################################################################\n",
    "# TODO: Define your hyperparameters here!                             #\n",
    "########################################################################\n",
    "\n",
    "hparams = {    \n",
    "    \"device\" : device,\n",
    "    \"num_workers\" : 8,\n",
    "    \"epochs\" : 800,\n",
    "    \"batch_size\" : 2048,\n",
    "    \n",
    "    \"num_classes\" : 10, # There are 10 digits\n",
    "    \"input_size\" : 28 * 28, # Number of pixels in images\n",
    "    \n",
    "    \"learning_rate\" : 2e-3, # Optimizer\n",
    "    \"weight_decay\" : 1e-5, # ADAM\n",
    "    \n",
    "    \"dropout_p\" : 0.5, # Dropout probability for the classifier, reduces overfitting\n",
    "    \"latent_dim\" : 20, # Encoder output dim, Decode input dim, classifier input dim. If this it too high, overfitting will occur\n",
    "    \"decoder_hidden\" : 512, # Decoder Hidden\n",
    "    \"encoder_hidden\" : 512, # Encoder Hidden\n",
    "    \"classifier_hidden\" : 2048 # Classifier Hidden\n",
    "}\n",
    "\n",
    "########################################################################\n",
    "#                           END OF YOUR CODE                           #\n",
    "########################################################################\n",
    "\n",
    "encoder_pretrained_copy = deepcopy(encoder_pretrained)\n",
    "classifier_pretrained = Classifier(hparams, encoder_pretrained_copy).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "R8FUtih6MNks"
   },
   "source": [
    "Let's define another trainer that will utilize the pretrained classifier, allowing us to compare its performance with the classifier trained only on the labeled data. To achieve a reasonable result, you may need to optimize the parameters you defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Mx_euorWMNks"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [1/800]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, curr_train_loss=4.56631613, val_loss=0.00000000]\n",
      "Validation Epoch [1/800]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, val_loss=2.78139019]\n",
      "Training Epoch [2/800]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, curr_train_loss=3.34259152, val_loss=0.00000000]\n",
      "Validation Epoch [2/800]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s, val_loss=2.51529574]\n",
      "Training Epoch [3/800]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  7.60it/s, curr_train_loss=2.95223355, val_loss=0.00000000]\n",
      "Validation Epoch [3/800]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.57it/s, val_loss=2.34771156]\n",
      "Training Epoch [4/800]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=2.73816776, val_loss=0.00000000]\n",
      "Validation Epoch [4/800]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.70it/s, val_loss=2.29025245]\n",
      "Training Epoch [5/800]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, curr_train_loss=2.26428032, val_loss=0.00000000]\n",
      "Validation Epoch [5/800]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.85it/s, val_loss=2.26239753]\n",
      "Training Epoch [6/800]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  6.35it/s, curr_train_loss=2.31855416, val_loss=0.00000000]\n",
      "Validation Epoch [6/800]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, val_loss=2.24311304]\n",
      "Training Epoch [7/800]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  7.07it/s, curr_train_loss=2.19947720, val_loss=0.00000000]\n",
      "Validation Epoch [7/800]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.81it/s, val_loss=2.22761559]\n",
      "Training Epoch [8/800]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  6.84it/s, curr_train_loss=2.21582651, val_loss=0.00000000]\n",
      "Validation Epoch [8/800]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.04it/s, val_loss=2.21463203]\n",
      "Training Epoch [9/800]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  7.04it/s, curr_train_loss=2.18657660, val_loss=0.00000000]\n",
      "Validation Epoch [9/800]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=2.19870901]\n",
      "Training Epoch [10/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.65it/s, curr_train_loss=2.14602804, val_loss=0.00000000]\n",
      "Validation Epoch [10/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.05it/s, val_loss=2.16659427]\n",
      "Training Epoch [11/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.98it/s, curr_train_loss=2.11222219, val_loss=0.00000000]\n",
      "Validation Epoch [11/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.09it/s, val_loss=2.13112783]\n",
      "Training Epoch [12/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.36it/s, curr_train_loss=2.04797983, val_loss=0.00000000]\n",
      "Validation Epoch [12/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, val_loss=2.13156033]\n",
      "Training Epoch [13/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.43it/s, curr_train_loss=2.03619194, val_loss=0.00000000]\n",
      "Validation Epoch [13/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.02it/s, val_loss=2.10199428]\n",
      "Training Epoch [14/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.42it/s, curr_train_loss=2.04547310, val_loss=0.00000000]\n",
      "Validation Epoch [14/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.04it/s, val_loss=2.12485147]\n",
      "Training Epoch [15/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, curr_train_loss=1.98413992, val_loss=0.00000000]\n",
      "Validation Epoch [15/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.05it/s, val_loss=2.07935190]\n",
      "Training Epoch [16/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.82it/s, curr_train_loss=1.90397263, val_loss=0.00000000]\n",
      "Validation Epoch [16/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=2.06318569]\n",
      "Training Epoch [17/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, curr_train_loss=2.16209173, val_loss=0.00000000]\n",
      "Validation Epoch [17/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.95it/s, val_loss=2.08456707]\n",
      "Training Epoch [18/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.35it/s, curr_train_loss=1.95112085, val_loss=0.00000000]\n",
      "Validation Epoch [18/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, val_loss=2.01079082]\n",
      "Training Epoch [19/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.50it/s, curr_train_loss=1.82374012, val_loss=0.00000000]\n",
      "Validation Epoch [19/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.12it/s, val_loss=2.04086494]\n",
      "Training Epoch [20/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.47it/s, curr_train_loss=1.81686819, val_loss=0.00000000]\n",
      "Validation Epoch [20/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.68it/s, val_loss=2.05579472]\n",
      "Training Epoch [21/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.47it/s, curr_train_loss=1.80137098, val_loss=0.00000000]\n",
      "Validation Epoch [21/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=1.98352265]\n",
      "Training Epoch [22/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.63it/s, curr_train_loss=2.00216627, val_loss=0.00000000]\n",
      "Validation Epoch [22/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.74it/s, val_loss=1.95511079]\n",
      "Training Epoch [23/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, curr_train_loss=1.81913924, val_loss=0.00000000]\n",
      "Validation Epoch [23/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.69it/s, val_loss=2.02798724]\n",
      "Training Epoch [24/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.31it/s, curr_train_loss=1.81686902, val_loss=0.00000000]\n",
      "Validation Epoch [24/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.52it/s, val_loss=1.98406184]\n",
      "Training Epoch [25/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.31it/s, curr_train_loss=1.81117582, val_loss=0.00000000]\n",
      "Validation Epoch [25/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.89060175]\n",
      "Training Epoch [26/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.63it/s, curr_train_loss=1.72064793, val_loss=0.00000000]\n",
      "Validation Epoch [26/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.93789470]\n",
      "Training Epoch [27/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.15it/s, curr_train_loss=1.87399673, val_loss=0.00000000]\n",
      "Validation Epoch [27/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=1.93043041]\n",
      "Training Epoch [28/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.55it/s, curr_train_loss=1.78345108, val_loss=0.00000000]\n",
      "Validation Epoch [28/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.54it/s, val_loss=1.81768513]\n",
      "Training Epoch [29/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.49it/s, curr_train_loss=1.75673127, val_loss=0.00000000]\n",
      "Validation Epoch [29/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s, val_loss=1.84309947]\n",
      "Training Epoch [30/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.37it/s, curr_train_loss=1.74629807, val_loss=0.00000000]\n",
      "Validation Epoch [30/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.93it/s, val_loss=1.78362060]\n",
      "Training Epoch [31/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.55it/s, curr_train_loss=1.72937763, val_loss=0.00000000]\n",
      "Validation Epoch [31/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.08it/s, val_loss=1.85907483]\n",
      "Training Epoch [32/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.43it/s, curr_train_loss=1.61035931, val_loss=0.00000000]\n",
      "Validation Epoch [32/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.73it/s, val_loss=1.86856091]\n",
      "Training Epoch [33/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.53it/s, curr_train_loss=1.48854244, val_loss=0.00000000]\n",
      "Validation Epoch [33/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.84it/s, val_loss=1.85630310]\n",
      "Training Epoch [34/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.59it/s, curr_train_loss=1.59701967, val_loss=0.00000000]\n",
      "Validation Epoch [34/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.80414701]\n",
      "Training Epoch [35/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.35it/s, curr_train_loss=1.64599061, val_loss=0.00000000]\n",
      "Validation Epoch [35/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, val_loss=1.87098360]\n",
      "Training Epoch [36/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=1.65353346, val_loss=0.00000000]\n",
      "Validation Epoch [36/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.11it/s, val_loss=1.75308025]\n",
      "Training Epoch [37/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.85it/s, curr_train_loss=1.64812529, val_loss=0.00000000]\n",
      "Validation Epoch [37/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.00it/s, val_loss=1.66329992]\n",
      "Training Epoch [38/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.26it/s, curr_train_loss=1.52861726, val_loss=0.00000000]\n",
      "Validation Epoch [38/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.74it/s, val_loss=1.69054258]\n",
      "Training Epoch [39/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=1.49163198, val_loss=0.00000000]\n",
      "Validation Epoch [39/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s, val_loss=1.66019940]\n",
      "Training Epoch [40/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, curr_train_loss=1.50682330, val_loss=0.00000000]\n",
      "Validation Epoch [40/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.16it/s, val_loss=1.65768290]\n",
      "Training Epoch [41/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.88it/s, curr_train_loss=1.39981604, val_loss=0.00000000]\n",
      "Validation Epoch [41/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.13it/s, val_loss=1.60797071]\n",
      "Training Epoch [42/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.68it/s, curr_train_loss=1.25112557, val_loss=0.00000000]\n",
      "Validation Epoch [42/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.18it/s, val_loss=1.61413622]\n",
      "Training Epoch [43/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.41it/s, curr_train_loss=1.28903472, val_loss=0.00000000]\n",
      "Validation Epoch [43/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.85it/s, val_loss=1.54167175]\n",
      "Training Epoch [44/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, curr_train_loss=1.50713336, val_loss=0.00000000]\n",
      "Validation Epoch [44/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=1.59905088]\n",
      "Training Epoch [45/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, curr_train_loss=1.37261093, val_loss=0.00000000]\n",
      "Validation Epoch [45/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.04it/s, val_loss=1.71307933]\n",
      "Training Epoch [46/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, curr_train_loss=1.51712680, val_loss=0.00000000]\n",
      "Validation Epoch [46/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.04it/s, val_loss=1.67719066]\n",
      "Training Epoch [47/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, curr_train_loss=1.46358716, val_loss=0.00000000]\n",
      "Validation Epoch [47/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.78it/s, val_loss=1.55050373]\n",
      "Training Epoch [48/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.65it/s, curr_train_loss=1.27260125, val_loss=0.00000000]\n",
      "Validation Epoch [48/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.10it/s, val_loss=1.54678333]\n",
      "Training Epoch [49/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=1.28921711, val_loss=0.00000000]\n",
      "Validation Epoch [49/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, val_loss=1.71599913]\n",
      "Training Epoch [50/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, curr_train_loss=1.35529006, val_loss=0.00000000]\n",
      "Validation Epoch [50/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.56890762]\n",
      "Training Epoch [51/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, curr_train_loss=1.38163495, val_loss=0.00000000]\n",
      "Validation Epoch [51/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.70it/s, val_loss=1.58493757]\n",
      "Training Epoch [52/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, curr_train_loss=1.21390319, val_loss=0.00000000]\n",
      "Validation Epoch [52/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.58it/s, val_loss=1.57379532]\n",
      "Training Epoch [53/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.51it/s, curr_train_loss=1.54580152, val_loss=0.00000000]\n",
      "Validation Epoch [53/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.58it/s, val_loss=1.58704221]\n",
      "Training Epoch [54/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=1.17101407, val_loss=0.00000000]\n",
      "Validation Epoch [54/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.95it/s, val_loss=1.49954319]\n",
      "Training Epoch [55/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.55it/s, curr_train_loss=1.15481174, val_loss=0.00000000]\n",
      "Validation Epoch [55/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=1.58897007]\n",
      "Training Epoch [56/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, curr_train_loss=1.32399988, val_loss=0.00000000]\n",
      "Validation Epoch [56/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s, val_loss=1.48359227]\n",
      "Training Epoch [57/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, curr_train_loss=1.25880754, val_loss=0.00000000]\n",
      "Validation Epoch [57/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.04it/s, val_loss=1.45443487]\n",
      "Training Epoch [58/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, curr_train_loss=1.20223272, val_loss=0.00000000]\n",
      "Validation Epoch [58/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.54752946]\n",
      "Training Epoch [59/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, curr_train_loss=1.21384406, val_loss=0.00000000]\n",
      "Validation Epoch [59/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.71it/s, val_loss=1.55365145]\n",
      "Training Epoch [60/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.69it/s, curr_train_loss=1.18446934, val_loss=0.00000000]\n",
      "Validation Epoch [60/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.81it/s, val_loss=1.51166677]\n",
      "Training Epoch [61/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.58it/s, curr_train_loss=1.17446470, val_loss=0.00000000]\n",
      "Validation Epoch [61/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.81it/s, val_loss=1.46236110]\n",
      "Training Epoch [62/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.14it/s, curr_train_loss=1.21761191, val_loss=0.00000000]\n",
      "Validation Epoch [62/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.49it/s, val_loss=1.56444240]\n",
      "Training Epoch [63/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.02it/s, curr_train_loss=1.11573923, val_loss=0.00000000]\n",
      "Validation Epoch [63/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.78it/s, val_loss=1.51010633]\n",
      "Training Epoch [64/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, curr_train_loss=1.33097839, val_loss=0.00000000]\n",
      "Validation Epoch [64/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=1.54377794]\n",
      "Training Epoch [65/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.27it/s, curr_train_loss=1.15085292, val_loss=0.00000000]\n",
      "Validation Epoch [65/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.07it/s, val_loss=1.50413859]\n",
      "Training Epoch [66/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.48it/s, curr_train_loss=1.24488056, val_loss=0.00000000]\n",
      "Validation Epoch [66/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.04it/s, val_loss=1.48855686]\n",
      "Training Epoch [67/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.51it/s, curr_train_loss=1.15463042, val_loss=0.00000000]\n",
      "Validation Epoch [67/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=1.49739218]\n",
      "Training Epoch [68/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.45it/s, curr_train_loss=1.06382596, val_loss=0.00000000]\n",
      "Validation Epoch [68/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.57it/s, val_loss=1.51872253]\n",
      "Training Epoch [69/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.57it/s, curr_train_loss=1.07952988, val_loss=0.00000000]\n",
      "Validation Epoch [69/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.85it/s, val_loss=1.36182296]\n",
      "Training Epoch [70/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=1.01458621, val_loss=0.00000000]\n",
      "Validation Epoch [70/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.64485538]\n",
      "Training Epoch [71/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, curr_train_loss=1.00600374, val_loss=0.00000000]\n",
      "Validation Epoch [71/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.42513871]\n",
      "Training Epoch [72/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, curr_train_loss=1.10954404, val_loss=0.00000000]\n",
      "Validation Epoch [72/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.89it/s, val_loss=1.20217085]\n",
      "Training Epoch [73/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, curr_train_loss=0.97975165, val_loss=0.00000000]\n",
      "Validation Epoch [73/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.83it/s, val_loss=1.31125426]\n",
      "Training Epoch [74/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.24it/s, curr_train_loss=0.98134863, val_loss=0.00000000]\n",
      "Validation Epoch [74/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.69it/s, val_loss=1.28177691]\n",
      "Training Epoch [75/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, curr_train_loss=1.16043186, val_loss=0.00000000]\n",
      "Validation Epoch [75/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.94it/s, val_loss=1.41150045]\n",
      "Training Epoch [76/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=1.20171678, val_loss=0.00000000]\n",
      "Validation Epoch [76/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.55it/s, val_loss=1.42591166]\n",
      "Training Epoch [77/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.54it/s, curr_train_loss=0.93724942, val_loss=0.00000000]\n",
      "Validation Epoch [77/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.50339782]\n",
      "Training Epoch [78/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, curr_train_loss=1.06178844, val_loss=0.00000000]\n",
      "Validation Epoch [78/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.56it/s, val_loss=1.26395702]\n",
      "Training Epoch [79/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.47it/s, curr_train_loss=1.00490212, val_loss=0.00000000]\n",
      "Validation Epoch [79/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.99it/s, val_loss=1.49112284]\n",
      "Training Epoch [80/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.29it/s, curr_train_loss=1.11031485, val_loss=0.00000000]\n",
      "Validation Epoch [80/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.47it/s, val_loss=1.48931181]\n",
      "Training Epoch [81/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.51it/s, curr_train_loss=1.02395022, val_loss=0.00000000]\n",
      "Validation Epoch [81/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=1.30464017]\n",
      "Training Epoch [82/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.49it/s, curr_train_loss=1.22014689, val_loss=0.00000000]\n",
      "Validation Epoch [82/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.93it/s, val_loss=1.37008345]\n",
      "Training Epoch [83/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.42it/s, curr_train_loss=1.08616960, val_loss=0.00000000]\n",
      "Validation Epoch [83/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.30939269]\n",
      "Training Epoch [84/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=0.92114103, val_loss=0.00000000]\n",
      "Validation Epoch [84/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.40it/s, val_loss=1.39106572]\n",
      "Training Epoch [85/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.22it/s, curr_train_loss=1.04797041, val_loss=0.00000000]\n",
      "Validation Epoch [85/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s, val_loss=1.29756665]\n",
      "Training Epoch [86/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, curr_train_loss=0.99688566, val_loss=0.00000000]\n",
      "Validation Epoch [86/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.84it/s, val_loss=1.21407247]\n",
      "Training Epoch [87/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, curr_train_loss=0.93448067, val_loss=0.00000000]\n",
      "Validation Epoch [87/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, val_loss=1.18329680]\n",
      "Training Epoch [88/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, curr_train_loss=0.96059728, val_loss=0.00000000]\n",
      "Validation Epoch [88/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.63it/s, val_loss=1.40668523]\n",
      "Training Epoch [89/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=0.98351979, val_loss=0.00000000]\n",
      "Validation Epoch [89/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=1.27017736]\n",
      "Training Epoch [90/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.09it/s, curr_train_loss=1.08828974, val_loss=0.00000000]\n",
      "Validation Epoch [90/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.66it/s, val_loss=1.23844230]\n",
      "Training Epoch [91/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, curr_train_loss=0.78564692, val_loss=0.00000000]\n",
      "Validation Epoch [91/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.09it/s, val_loss=1.25538087]\n",
      "Training Epoch [92/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.47it/s, curr_train_loss=0.88960016, val_loss=0.00000000]\n",
      "Validation Epoch [92/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.69it/s, val_loss=1.35167408]\n",
      "Training Epoch [93/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.44it/s, curr_train_loss=0.95025063, val_loss=0.00000000]\n",
      "Validation Epoch [93/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.73it/s, val_loss=1.40464187]\n",
      "Training Epoch [94/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.80it/s, curr_train_loss=0.98185509, val_loss=0.00000000]\n",
      "Validation Epoch [94/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=1.23760462]\n",
      "Training Epoch [95/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.55it/s, curr_train_loss=0.78829747, val_loss=0.00000000]\n",
      "Validation Epoch [95/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.38459980]\n",
      "Training Epoch [96/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.85it/s, curr_train_loss=0.93648338, val_loss=0.00000000]\n",
      "Validation Epoch [96/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.27515566]\n",
      "Training Epoch [97/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.60it/s, curr_train_loss=0.89301240, val_loss=0.00000000]\n",
      "Validation Epoch [97/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.76it/s, val_loss=1.16967607]\n",
      "Training Epoch [98/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=0.79092729, val_loss=0.00000000]\n",
      "Validation Epoch [98/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.25it/s, val_loss=1.30282116]\n",
      "Training Epoch [99/800]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.75it/s, curr_train_loss=0.96044713, val_loss=0.00000000]\n",
      "Validation Epoch [99/800]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.86it/s, val_loss=1.18292713]\n",
      "Training Epoch [100/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, curr_train_loss=1.00364304, val_loss=0.00000000]\n",
      "Validation Epoch [100/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.23435521]\n",
      "Training Epoch [101/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, curr_train_loss=1.06621456, val_loss=0.00000000]\n",
      "Validation Epoch [101/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.74it/s, val_loss=1.40806425]\n",
      "Training Epoch [102/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=0.88369071, val_loss=0.00000000]\n",
      "Validation Epoch [102/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.79it/s, val_loss=1.33881330]\n",
      "Training Epoch [103/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, curr_train_loss=0.78841710, val_loss=0.00000000]\n",
      "Validation Epoch [103/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.28160036]\n",
      "Training Epoch [104/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, curr_train_loss=0.90412068, val_loss=0.00000000]\n",
      "Validation Epoch [104/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.84it/s, val_loss=1.39764440]\n",
      "Training Epoch [105/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=0.94309211, val_loss=0.00000000]\n",
      "Validation Epoch [105/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=1.21371853]\n",
      "Training Epoch [106/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, curr_train_loss=1.08558559, val_loss=0.00000000]\n",
      "Validation Epoch [106/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.08it/s, val_loss=1.31480789]\n",
      "Training Epoch [107/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, curr_train_loss=0.82099688, val_loss=0.00000000]\n",
      "Validation Epoch [107/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.03918076]\n",
      "Training Epoch [108/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.50it/s, curr_train_loss=0.92473006, val_loss=0.00000000]\n",
      "Validation Epoch [108/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.28737926]\n",
      "Training Epoch [109/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, curr_train_loss=0.85090715, val_loss=0.00000000]\n",
      "Validation Epoch [109/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.84it/s, val_loss=1.26766813]\n",
      "Training Epoch [110/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s, curr_train_loss=0.90707701, val_loss=0.00000000]\n",
      "Validation Epoch [110/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.04it/s, val_loss=1.05945385]\n",
      "Training Epoch [111/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=0.88644326, val_loss=0.00000000]\n",
      "Validation Epoch [111/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.22830379]\n",
      "Training Epoch [112/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, curr_train_loss=0.76323509, val_loss=0.00000000]\n",
      "Validation Epoch [112/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.16813517]\n",
      "Training Epoch [113/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, curr_train_loss=0.93318057, val_loss=0.00000000]\n",
      "Validation Epoch [113/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, val_loss=1.31792891]\n",
      "Training Epoch [114/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, curr_train_loss=0.77929741, val_loss=0.00000000]\n",
      "Validation Epoch [114/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.01it/s, val_loss=1.32663059]\n",
      "Training Epoch [115/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, curr_train_loss=1.00951898, val_loss=0.00000000]\n",
      "Validation Epoch [115/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.53it/s, val_loss=1.26084650]\n",
      "Training Epoch [116/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.61it/s, curr_train_loss=0.81948274, val_loss=0.00000000]\n",
      "Validation Epoch [116/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.22417080]\n",
      "Training Epoch [117/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, curr_train_loss=0.86430848, val_loss=0.00000000]\n",
      "Validation Epoch [117/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.91it/s, val_loss=1.36490488]\n",
      "Training Epoch [118/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.51it/s, curr_train_loss=0.75606322, val_loss=0.00000000]\n",
      "Validation Epoch [118/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, val_loss=1.31589949]\n",
      "Training Epoch [119/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, curr_train_loss=0.87827510, val_loss=0.00000000]\n",
      "Validation Epoch [119/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.87it/s, val_loss=1.23304105]\n",
      "Training Epoch [120/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.55it/s, curr_train_loss=0.87413079, val_loss=0.00000000]\n",
      "Validation Epoch [120/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.59it/s, val_loss=1.25419247]\n",
      "Training Epoch [121/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.48it/s, curr_train_loss=0.81959891, val_loss=0.00000000]\n",
      "Validation Epoch [121/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.01it/s, val_loss=1.16968966]\n",
      "Training Epoch [122/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.53it/s, curr_train_loss=1.02229047, val_loss=0.00000000]\n",
      "Validation Epoch [122/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.95it/s, val_loss=1.22888982]\n",
      "Training Epoch [123/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, curr_train_loss=0.87480956, val_loss=0.00000000]\n",
      "Validation Epoch [123/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.80it/s, val_loss=1.22750986]\n",
      "Training Epoch [124/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, curr_train_loss=0.76676971, val_loss=0.00000000]\n",
      "Validation Epoch [124/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.24788344]\n",
      "Training Epoch [125/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.57it/s, curr_train_loss=0.62985450, val_loss=0.00000000]\n",
      "Validation Epoch [125/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.02it/s, val_loss=1.31052065]\n",
      "Training Epoch [126/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, curr_train_loss=0.78141004, val_loss=0.00000000]\n",
      "Validation Epoch [126/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.54it/s, val_loss=1.04562879]\n",
      "Training Epoch [127/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, curr_train_loss=0.67782080, val_loss=0.00000000]\n",
      "Validation Epoch [127/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.08it/s, val_loss=1.22494650]\n",
      "Training Epoch [128/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, curr_train_loss=0.74234664, val_loss=0.00000000]\n",
      "Validation Epoch [128/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.74it/s, val_loss=1.07077861]\n",
      "Training Epoch [129/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=0.72926873, val_loss=0.00000000]\n",
      "Validation Epoch [129/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.29783738]\n",
      "Training Epoch [130/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.78it/s, curr_train_loss=0.76777577, val_loss=0.00000000]\n",
      "Validation Epoch [130/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.79it/s, val_loss=1.09728909]\n",
      "Training Epoch [131/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.58it/s, curr_train_loss=0.88464034, val_loss=0.00000000]\n",
      "Validation Epoch [131/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.11773455]\n",
      "Training Epoch [132/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=0.76346099, val_loss=0.00000000]\n",
      "Validation Epoch [132/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.06it/s, val_loss=1.28639555]\n",
      "Training Epoch [133/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=0.79887044, val_loss=0.00000000]\n",
      "Validation Epoch [133/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.98it/s, val_loss=1.07268894]\n",
      "Training Epoch [134/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.78901398, val_loss=0.00000000]\n",
      "Validation Epoch [134/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.61it/s, val_loss=1.23787105]\n",
      "Training Epoch [135/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, curr_train_loss=0.57454389, val_loss=0.00000000]\n",
      "Validation Epoch [135/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.57it/s, val_loss=1.34749460]\n",
      "Training Epoch [136/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.35it/s, curr_train_loss=0.82282943, val_loss=0.00000000]\n",
      "Validation Epoch [136/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.05it/s, val_loss=1.20843804]\n",
      "Training Epoch [137/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, curr_train_loss=0.63922185, val_loss=0.00000000]\n",
      "Validation Epoch [137/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.94it/s, val_loss=1.27625072]\n",
      "Training Epoch [138/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.02it/s, curr_train_loss=0.71856254, val_loss=0.00000000]\n",
      "Validation Epoch [138/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.94it/s, val_loss=1.27074194]\n",
      "Training Epoch [139/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.83it/s, curr_train_loss=0.66717887, val_loss=0.00000000]\n",
      "Validation Epoch [139/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.54it/s, val_loss=1.35197222]\n",
      "Training Epoch [140/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, curr_train_loss=0.84509772, val_loss=0.00000000]\n",
      "Validation Epoch [140/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.11it/s, val_loss=1.36618209]\n",
      "Training Epoch [141/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.85it/s, curr_train_loss=0.65426493, val_loss=0.00000000]\n",
      "Validation Epoch [141/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.36498713]\n",
      "Training Epoch [142/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=0.81709653, val_loss=0.00000000]\n",
      "Validation Epoch [142/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.05it/s, val_loss=1.26576054]\n",
      "Training Epoch [143/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, curr_train_loss=0.75273544, val_loss=0.00000000]\n",
      "Validation Epoch [143/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.78it/s, val_loss=1.22348011]\n",
      "Training Epoch [144/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.37it/s, curr_train_loss=0.84636599, val_loss=0.00000000]\n",
      "Validation Epoch [144/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.62it/s, val_loss=1.33163393]\n",
      "Training Epoch [145/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, curr_train_loss=0.49767223, val_loss=0.00000000]\n",
      "Validation Epoch [145/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.10it/s, val_loss=1.18261528]\n",
      "Training Epoch [146/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=0.63630158, val_loss=0.00000000]\n",
      "Validation Epoch [146/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s, val_loss=1.45672596]\n",
      "Training Epoch [147/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.58it/s, curr_train_loss=0.59974951, val_loss=0.00000000]\n",
      "Validation Epoch [147/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.80it/s, val_loss=1.03997099]\n",
      "Training Epoch [148/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.38it/s, curr_train_loss=0.72612309, val_loss=0.00000000]\n",
      "Validation Epoch [148/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.01it/s, val_loss=1.14678121]\n",
      "Training Epoch [149/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=0.71142697, val_loss=0.00000000]\n",
      "Validation Epoch [149/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, val_loss=1.30747426]\n",
      "Training Epoch [150/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.19it/s, curr_train_loss=0.82712442, val_loss=0.00000000]\n",
      "Validation Epoch [150/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.71it/s, val_loss=1.18122745]\n",
      "Training Epoch [151/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, curr_train_loss=0.62858725, val_loss=0.00000000]\n",
      "Validation Epoch [151/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.40628850]\n",
      "Training Epoch [152/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.30it/s, curr_train_loss=0.68777829, val_loss=0.00000000]\n",
      "Validation Epoch [152/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.05it/s, val_loss=1.36768985]\n",
      "Training Epoch [153/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, curr_train_loss=0.81306100, val_loss=0.00000000]\n",
      "Validation Epoch [153/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=1.29709804]\n",
      "Training Epoch [154/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, curr_train_loss=0.80911618, val_loss=0.00000000]\n",
      "Validation Epoch [154/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.90it/s, val_loss=1.31958354]\n",
      "Training Epoch [155/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=0.85886610, val_loss=0.00000000]\n",
      "Validation Epoch [155/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.18348479]\n",
      "Training Epoch [156/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=0.67618829, val_loss=0.00000000]\n",
      "Validation Epoch [156/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s, val_loss=1.06390238]\n",
      "Training Epoch [157/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, curr_train_loss=0.76055437, val_loss=0.00000000]\n",
      "Validation Epoch [157/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.81it/s, val_loss=1.13216376]\n",
      "Training Epoch [158/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.30it/s, curr_train_loss=0.98600245, val_loss=0.00000000]\n",
      "Validation Epoch [158/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.13934529]\n",
      "Training Epoch [159/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, curr_train_loss=0.70380592, val_loss=0.00000000]\n",
      "Validation Epoch [159/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, val_loss=1.34164488]\n",
      "Training Epoch [160/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=0.61253810, val_loss=0.00000000]\n",
      "Validation Epoch [160/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=1.01837361]\n",
      "Training Epoch [161/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=0.83966619, val_loss=0.00000000]\n",
      "Validation Epoch [161/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.12it/s, val_loss=1.08842123]\n",
      "Training Epoch [162/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.57it/s, curr_train_loss=0.53851110, val_loss=0.00000000]\n",
      "Validation Epoch [162/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.31079054]\n",
      "Training Epoch [163/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.58it/s, curr_train_loss=0.65014619, val_loss=0.00000000]\n",
      "Validation Epoch [163/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.84it/s, val_loss=1.38498890]\n",
      "Training Epoch [164/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.54it/s, curr_train_loss=0.57856119, val_loss=0.00000000]\n",
      "Validation Epoch [164/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.22638166]\n",
      "Training Epoch [165/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.51it/s, curr_train_loss=0.79143274, val_loss=0.00000000]\n",
      "Validation Epoch [165/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.24329388]\n",
      "Training Epoch [166/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.87it/s, curr_train_loss=0.65879750, val_loss=0.00000000]\n",
      "Validation Epoch [166/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=1.10788298]\n",
      "Training Epoch [167/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=0.64811325, val_loss=0.00000000]\n",
      "Validation Epoch [167/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.38148987]\n",
      "Training Epoch [168/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.57it/s, curr_train_loss=0.66354346, val_loss=0.00000000]\n",
      "Validation Epoch [168/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.02it/s, val_loss=1.40681303]\n",
      "Training Epoch [169/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=0.64077652, val_loss=0.00000000]\n",
      "Validation Epoch [169/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=1.55709040]\n",
      "Training Epoch [170/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, curr_train_loss=0.74578470, val_loss=0.00000000]\n",
      "Validation Epoch [170/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.77it/s, val_loss=1.38887346]\n",
      "Training Epoch [171/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.77it/s, curr_train_loss=0.50738668, val_loss=0.00000000]\n",
      "Validation Epoch [171/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.82it/s, val_loss=1.43087876]\n",
      "Training Epoch [172/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.56it/s, curr_train_loss=0.59545392, val_loss=0.00000000]\n",
      "Validation Epoch [172/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=1.36077273]\n",
      "Training Epoch [173/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, curr_train_loss=0.61477625, val_loss=0.00000000]\n",
      "Validation Epoch [173/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.80it/s, val_loss=1.31686711]\n",
      "Training Epoch [174/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, curr_train_loss=0.97622705, val_loss=0.00000000]\n",
      "Validation Epoch [174/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.01it/s, val_loss=1.35485554]\n",
      "Training Epoch [175/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.60it/s, curr_train_loss=0.63802755, val_loss=0.00000000]\n",
      "Validation Epoch [175/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.15748835]\n",
      "Training Epoch [176/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.70it/s, curr_train_loss=0.81330252, val_loss=0.00000000]\n",
      "Validation Epoch [176/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, val_loss=1.38412976]\n",
      "Training Epoch [177/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s, curr_train_loss=0.69655913, val_loss=0.00000000]\n",
      "Validation Epoch [177/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.60it/s, val_loss=1.32393169]\n",
      "Training Epoch [178/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.58it/s, curr_train_loss=0.59004027, val_loss=0.00000000]\n",
      "Validation Epoch [178/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.91it/s, val_loss=1.34052694]\n",
      "Training Epoch [179/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.16it/s, curr_train_loss=0.82222104, val_loss=0.00000000]\n",
      "Validation Epoch [179/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.02it/s, val_loss=1.17131352]\n",
      "Training Epoch [180/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, curr_train_loss=0.66324878, val_loss=0.00000000]\n",
      "Validation Epoch [180/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.71it/s, val_loss=1.13744390]\n",
      "Training Epoch [181/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.42it/s, curr_train_loss=0.62537926, val_loss=0.00000000]\n",
      "Validation Epoch [181/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.85it/s, val_loss=1.26642835]\n",
      "Training Epoch [182/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.19it/s, curr_train_loss=0.68776155, val_loss=0.00000000]\n",
      "Validation Epoch [182/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.05it/s, val_loss=1.22118843]\n",
      "Training Epoch [183/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.66it/s, curr_train_loss=0.60107493, val_loss=0.00000000]\n",
      "Validation Epoch [183/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.90it/s, val_loss=1.61275256]\n",
      "Training Epoch [184/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, curr_train_loss=0.86490798, val_loss=0.00000000]\n",
      "Validation Epoch [184/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=1.33953571]\n",
      "Training Epoch [185/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=0.65149361, val_loss=0.00000000]\n",
      "Validation Epoch [185/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.78it/s, val_loss=1.30296969]\n",
      "Training Epoch [186/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=0.61404622, val_loss=0.00000000]\n",
      "Validation Epoch [186/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.73it/s, val_loss=1.20712280]\n",
      "Training Epoch [187/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=0.48076251, val_loss=0.00000000]\n",
      "Validation Epoch [187/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s, val_loss=1.49642777]\n",
      "Training Epoch [188/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.92it/s, curr_train_loss=0.45980644, val_loss=0.00000000]\n",
      "Validation Epoch [188/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.39044893]\n",
      "Training Epoch [189/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.18it/s, curr_train_loss=0.64870906, val_loss=0.00000000]\n",
      "Validation Epoch [189/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.09it/s, val_loss=1.13552237]\n",
      "Training Epoch [190/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=0.60271055, val_loss=0.00000000]\n",
      "Validation Epoch [190/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.80it/s, val_loss=1.29795277]\n",
      "Training Epoch [191/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.23it/s, curr_train_loss=0.62927169, val_loss=0.00000000]\n",
      "Validation Epoch [191/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.32552218]\n",
      "Training Epoch [192/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, curr_train_loss=0.56769556, val_loss=0.00000000]\n",
      "Validation Epoch [192/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.83it/s, val_loss=1.06172216]\n",
      "Training Epoch [193/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.24it/s, curr_train_loss=0.59272212, val_loss=0.00000000]\n",
      "Validation Epoch [193/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=1.20642257]\n",
      "Training Epoch [194/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.27it/s, curr_train_loss=0.65759492, val_loss=0.00000000]\n",
      "Validation Epoch [194/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.05100977]\n",
      "Training Epoch [195/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.55it/s, curr_train_loss=0.67044741, val_loss=0.00000000]\n",
      "Validation Epoch [195/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, val_loss=1.25160122]\n",
      "Training Epoch [196/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.54it/s, curr_train_loss=0.58265871, val_loss=0.00000000]\n",
      "Validation Epoch [196/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.72it/s, val_loss=1.23318923]\n",
      "Training Epoch [197/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.84it/s, curr_train_loss=0.66782844, val_loss=0.00000000]\n",
      "Validation Epoch [197/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s, val_loss=1.14291370]\n",
      "Training Epoch [198/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.21it/s, curr_train_loss=0.68847007, val_loss=0.00000000]\n",
      "Validation Epoch [198/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.53it/s, val_loss=1.18278170]\n",
      "Training Epoch [199/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.14it/s, curr_train_loss=0.71410775, val_loss=0.00000000]\n",
      "Validation Epoch [199/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=1.10356700]\n",
      "Training Epoch [200/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=0.51627886, val_loss=0.00000000]\n",
      "Validation Epoch [200/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.07952452]\n",
      "Training Epoch [201/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=0.67872846, val_loss=0.00000000]\n",
      "Validation Epoch [201/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.06119311]\n",
      "Training Epoch [202/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.62it/s, curr_train_loss=0.62923443, val_loss=0.00000000]\n",
      "Validation Epoch [202/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.53it/s, val_loss=1.17259312]\n",
      "Training Epoch [203/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, curr_train_loss=0.60855573, val_loss=0.00000000]\n",
      "Validation Epoch [203/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.18it/s, val_loss=1.18882084]\n",
      "Training Epoch [204/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, curr_train_loss=0.49326310, val_loss=0.00000000]\n",
      "Validation Epoch [204/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.76it/s, val_loss=1.02841008]\n",
      "Training Epoch [205/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, curr_train_loss=0.61225802, val_loss=0.00000000]\n",
      "Validation Epoch [205/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.38it/s, val_loss=1.05408001]\n",
      "Training Epoch [206/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.80it/s, curr_train_loss=0.76513422, val_loss=0.00000000]\n",
      "Validation Epoch [206/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, val_loss=1.06701946]\n",
      "Training Epoch [207/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.58it/s, curr_train_loss=0.76502150, val_loss=0.00000000]\n",
      "Validation Epoch [207/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.94it/s, val_loss=1.40344834]\n",
      "Training Epoch [208/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, curr_train_loss=0.64247346, val_loss=0.00000000]\n",
      "Validation Epoch [208/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s, val_loss=1.12515748]\n",
      "Training Epoch [209/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.42it/s, curr_train_loss=0.52545011, val_loss=0.00000000]\n",
      "Validation Epoch [209/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, val_loss=0.99737138]\n",
      "Training Epoch [210/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.24it/s, curr_train_loss=0.56907248, val_loss=0.00000000]\n",
      "Validation Epoch [210/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=0.85468376]\n",
      "Training Epoch [211/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.47it/s, curr_train_loss=0.52143186, val_loss=0.00000000]\n",
      "Validation Epoch [211/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.20it/s, val_loss=1.06496465]\n",
      "Training Epoch [212/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, curr_train_loss=0.61729228, val_loss=0.00000000]\n",
      "Validation Epoch [212/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.61it/s, val_loss=1.24688745]\n",
      "Training Epoch [213/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=0.84144002, val_loss=0.00000000]\n",
      "Validation Epoch [213/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.74it/s, val_loss=1.06338298]\n",
      "Training Epoch [214/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.54it/s, curr_train_loss=0.58978200, val_loss=0.00000000]\n",
      "Validation Epoch [214/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.80it/s, val_loss=1.14110577]\n",
      "Training Epoch [215/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, curr_train_loss=0.65909022, val_loss=0.00000000]\n",
      "Validation Epoch [215/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.71it/s, val_loss=1.12176073]\n",
      "Training Epoch [216/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, curr_train_loss=0.55041885, val_loss=0.00000000]\n",
      "Validation Epoch [216/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.80it/s, val_loss=1.13546276]\n",
      "Training Epoch [217/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.39it/s, curr_train_loss=0.53105766, val_loss=0.00000000]\n",
      "Validation Epoch [217/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.11675680]\n",
      "Training Epoch [218/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=0.44378850, val_loss=0.00000000]\n",
      "Validation Epoch [218/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.10001016]\n",
      "Training Epoch [219/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, curr_train_loss=0.61437416, val_loss=0.00000000]\n",
      "Validation Epoch [219/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.85it/s, val_loss=1.23959804]\n",
      "Training Epoch [220/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.50it/s, curr_train_loss=0.51794571, val_loss=0.00000000]\n",
      "Validation Epoch [220/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.84it/s, val_loss=1.12068903]\n",
      "Training Epoch [221/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=0.49914494, val_loss=0.00000000]\n",
      "Validation Epoch [221/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.76it/s, val_loss=1.27997065]\n",
      "Training Epoch [222/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, curr_train_loss=0.43586314, val_loss=0.00000000]\n",
      "Validation Epoch [222/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.15707958]\n",
      "Training Epoch [223/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, curr_train_loss=0.53552002, val_loss=0.00000000]\n",
      "Validation Epoch [223/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=1.04573143]\n",
      "Training Epoch [224/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, curr_train_loss=0.45042756, val_loss=0.00000000]\n",
      "Validation Epoch [224/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.40662420]\n",
      "Training Epoch [225/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, curr_train_loss=0.66112351, val_loss=0.00000000]\n",
      "Validation Epoch [225/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.75it/s, val_loss=1.21627021]\n",
      "Training Epoch [226/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.44it/s, curr_train_loss=0.56807375, val_loss=0.00000000]\n",
      "Validation Epoch [226/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.15it/s, val_loss=1.25675571]\n",
      "Training Epoch [227/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.12it/s, curr_train_loss=0.69738477, val_loss=0.00000000]\n",
      "Validation Epoch [227/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.71it/s, val_loss=1.40404081]\n",
      "Training Epoch [228/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.64it/s, curr_train_loss=0.51126623, val_loss=0.00000000]\n",
      "Validation Epoch [228/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.71it/s, val_loss=1.36144209]\n",
      "Training Epoch [229/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=0.51060969, val_loss=0.00000000]\n",
      "Validation Epoch [229/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.79it/s, val_loss=1.34207189]\n",
      "Training Epoch [230/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.50it/s, curr_train_loss=0.70963860, val_loss=0.00000000]\n",
      "Validation Epoch [230/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.71it/s, val_loss=1.27860713]\n",
      "Training Epoch [231/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, curr_train_loss=0.53117418, val_loss=0.00000000]\n",
      "Validation Epoch [231/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.80it/s, val_loss=1.23254108]\n",
      "Training Epoch [232/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=0.59010965, val_loss=0.00000000]\n",
      "Validation Epoch [232/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.85it/s, val_loss=1.27161360]\n",
      "Training Epoch [233/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=0.66925567, val_loss=0.00000000]\n",
      "Validation Epoch [233/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.80it/s, val_loss=1.28530991]\n",
      "Training Epoch [234/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, curr_train_loss=0.41019154, val_loss=0.00000000]\n",
      "Validation Epoch [234/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.07448101]\n",
      "Training Epoch [235/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.65it/s, curr_train_loss=0.59356683, val_loss=0.00000000]\n",
      "Validation Epoch [235/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.00it/s, val_loss=1.18903410]\n",
      "Training Epoch [236/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.20it/s, curr_train_loss=0.51483876, val_loss=0.00000000]\n",
      "Validation Epoch [236/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.97it/s, val_loss=1.07548296]\n",
      "Training Epoch [237/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.44it/s, curr_train_loss=0.54700732, val_loss=0.00000000]\n",
      "Validation Epoch [237/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s, val_loss=1.26298332]\n",
      "Training Epoch [238/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, curr_train_loss=0.64594138, val_loss=0.00000000]\n",
      "Validation Epoch [238/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.75it/s, val_loss=0.94298828]\n",
      "Training Epoch [239/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, curr_train_loss=0.46855724, val_loss=0.00000000]\n",
      "Validation Epoch [239/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.96it/s, val_loss=1.36080396]\n",
      "Training Epoch [240/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.00it/s, curr_train_loss=0.62551737, val_loss=0.00000000]\n",
      "Validation Epoch [240/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.51it/s, val_loss=1.12554562]\n",
      "Training Epoch [241/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.44it/s, curr_train_loss=0.38606796, val_loss=0.00000000]\n",
      "Validation Epoch [241/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=1.09497273]\n",
      "Training Epoch [242/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.51it/s, curr_train_loss=0.54686224, val_loss=0.00000000]\n",
      "Validation Epoch [242/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.87it/s, val_loss=1.55810893]\n",
      "Training Epoch [243/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, curr_train_loss=0.48703656, val_loss=0.00000000]\n",
      "Validation Epoch [243/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.93it/s, val_loss=1.29035127]\n",
      "Training Epoch [244/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, curr_train_loss=0.49961185, val_loss=0.00000000]\n",
      "Validation Epoch [244/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, val_loss=1.16001177]\n",
      "Training Epoch [245/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.12it/s, curr_train_loss=0.44883466, val_loss=0.00000000]\n",
      "Validation Epoch [245/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.07it/s, val_loss=1.35083997]\n",
      "Training Epoch [246/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=0.53859103, val_loss=0.00000000]\n",
      "Validation Epoch [246/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.67it/s, val_loss=1.20542955]\n",
      "Training Epoch [247/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, curr_train_loss=0.47490445, val_loss=0.00000000]\n",
      "Validation Epoch [247/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.32686925]\n",
      "Training Epoch [248/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, curr_train_loss=0.55912966, val_loss=0.00000000]\n",
      "Validation Epoch [248/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.85it/s, val_loss=1.22147846]\n",
      "Training Epoch [249/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.08it/s, curr_train_loss=0.59973139, val_loss=0.00000000]\n",
      "Validation Epoch [249/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.80it/s, val_loss=1.33314025]\n",
      "Training Epoch [250/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.50it/s, curr_train_loss=0.48160034, val_loss=0.00000000]\n",
      "Validation Epoch [250/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, val_loss=0.95045471]\n",
      "Training Epoch [251/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.12it/s, curr_train_loss=0.30565202, val_loss=0.00000000]\n",
      "Validation Epoch [251/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.00it/s, val_loss=1.25736988]\n",
      "Training Epoch [252/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.44it/s, curr_train_loss=0.60552114, val_loss=0.00000000]\n",
      "Validation Epoch [252/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.93it/s, val_loss=0.88505960]\n",
      "Training Epoch [253/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.25it/s, curr_train_loss=0.42881942, val_loss=0.00000000]\n",
      "Validation Epoch [253/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, val_loss=1.04247355]\n",
      "Training Epoch [254/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.30it/s, curr_train_loss=0.74831510, val_loss=0.00000000]\n",
      "Validation Epoch [254/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.92it/s, val_loss=1.14305675]\n",
      "Training Epoch [255/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.55it/s, curr_train_loss=0.56854934, val_loss=0.00000000]\n",
      "Validation Epoch [255/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.75it/s, val_loss=1.16023779]\n",
      "Training Epoch [256/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, curr_train_loss=0.53185481, val_loss=0.00000000]\n",
      "Validation Epoch [256/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.15458417]\n",
      "Training Epoch [257/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, curr_train_loss=0.63196850, val_loss=0.00000000]\n",
      "Validation Epoch [257/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, val_loss=1.37242007]\n",
      "Training Epoch [258/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.64it/s, curr_train_loss=0.75001693, val_loss=0.00000000]\n",
      "Validation Epoch [258/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.63it/s, val_loss=1.22749853]\n",
      "Training Epoch [259/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=0.58514041, val_loss=0.00000000]\n",
      "Validation Epoch [259/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=1.20890665]\n",
      "Training Epoch [260/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.31it/s, curr_train_loss=0.54769927, val_loss=0.00000000]\n",
      "Validation Epoch [260/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.66it/s, val_loss=1.33045697]\n",
      "Training Epoch [261/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.95it/s, curr_train_loss=0.72095102, val_loss=0.00000000]\n",
      "Validation Epoch [261/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.88it/s, val_loss=1.48807371]\n",
      "Training Epoch [262/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, curr_train_loss=0.53727978, val_loss=0.00000000]\n",
      "Validation Epoch [262/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.05it/s, val_loss=1.58784485]\n",
      "Training Epoch [263/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.42it/s, curr_train_loss=0.68133271, val_loss=0.00000000]\n",
      "Validation Epoch [263/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.94it/s, val_loss=1.28771317]\n",
      "Training Epoch [264/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=0.40634048, val_loss=0.00000000]\n",
      "Validation Epoch [264/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.32794809]\n",
      "Training Epoch [265/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.47it/s, curr_train_loss=0.50795776, val_loss=0.00000000]\n",
      "Validation Epoch [265/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, val_loss=1.17414677]\n",
      "Training Epoch [266/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, curr_train_loss=0.54612374, val_loss=0.00000000]\n",
      "Validation Epoch [266/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.98it/s, val_loss=1.18427539]\n",
      "Training Epoch [267/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.37it/s, curr_train_loss=0.58442503, val_loss=0.00000000]\n",
      "Validation Epoch [267/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.73it/s, val_loss=1.21562505]\n",
      "Training Epoch [268/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=0.56221712, val_loss=0.00000000]\n",
      "Validation Epoch [268/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, val_loss=1.18411648]\n",
      "Training Epoch [269/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.29it/s, curr_train_loss=0.37519294, val_loss=0.00000000]\n",
      "Validation Epoch [269/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.03it/s, val_loss=1.08241069]\n",
      "Training Epoch [270/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.69it/s, curr_train_loss=0.52265072, val_loss=0.00000000]\n",
      "Validation Epoch [270/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.95it/s, val_loss=1.35592258]\n",
      "Training Epoch [271/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, curr_train_loss=0.62139332, val_loss=0.00000000]\n",
      "Validation Epoch [271/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.78it/s, val_loss=1.12563038]\n",
      "Training Epoch [272/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, curr_train_loss=0.70324928, val_loss=0.00000000]\n",
      "Validation Epoch [272/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.22it/s, val_loss=1.20410168]\n",
      "Training Epoch [273/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.54it/s, curr_train_loss=0.53948885, val_loss=0.00000000]\n",
      "Validation Epoch [273/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.58it/s, val_loss=1.12116492]\n",
      "Training Epoch [274/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.11it/s, curr_train_loss=0.52821904, val_loss=0.00000000]\n",
      "Validation Epoch [274/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.13768816]\n",
      "Training Epoch [275/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=0.88954681, val_loss=0.00000000]\n",
      "Validation Epoch [275/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.73it/s, val_loss=1.21564364]\n",
      "Training Epoch [276/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=0.49834603, val_loss=0.00000000]\n",
      "Validation Epoch [276/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.45141101]\n",
      "Training Epoch [277/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=0.42976192, val_loss=0.00000000]\n",
      "Validation Epoch [277/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=0.97700000]\n",
      "Training Epoch [278/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.52it/s, curr_train_loss=0.53073961, val_loss=0.00000000]\n",
      "Validation Epoch [278/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.20it/s, val_loss=1.49342251]\n",
      "Training Epoch [279/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.61it/s, curr_train_loss=0.40821263, val_loss=0.00000000]\n",
      "Validation Epoch [279/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.51it/s, val_loss=1.23790729]\n",
      "Training Epoch [280/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=0.49846733, val_loss=0.00000000]\n",
      "Validation Epoch [280/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=1.21982563]\n",
      "Training Epoch [281/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.44it/s, curr_train_loss=0.43379071, val_loss=0.00000000]\n",
      "Validation Epoch [281/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s, val_loss=1.38667881]\n",
      "Training Epoch [282/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, curr_train_loss=0.63379657, val_loss=0.00000000]\n",
      "Validation Epoch [282/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.78it/s, val_loss=1.26803541]\n",
      "Training Epoch [283/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, curr_train_loss=0.55909556, val_loss=0.00000000]\n",
      "Validation Epoch [283/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.15it/s, val_loss=1.10364115]\n",
      "Training Epoch [284/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.02it/s, curr_train_loss=0.73391944, val_loss=0.00000000]\n",
      "Validation Epoch [284/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.04570651]\n",
      "Training Epoch [285/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.26it/s, curr_train_loss=0.77127814, val_loss=0.00000000]\n",
      "Validation Epoch [285/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.02it/s, val_loss=1.12723672]\n",
      "Training Epoch [286/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.00it/s, curr_train_loss=0.38464475, val_loss=0.00000000]\n",
      "Validation Epoch [286/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.07it/s, val_loss=1.17571247]\n",
      "Training Epoch [287/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.29it/s, curr_train_loss=0.68319428, val_loss=0.00000000]\n",
      "Validation Epoch [287/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.73it/s, val_loss=1.01567686]\n",
      "Training Epoch [288/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.57it/s, curr_train_loss=0.54060936, val_loss=0.00000000]\n",
      "Validation Epoch [288/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.03555524]\n",
      "Training Epoch [289/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.65it/s, curr_train_loss=0.57140732, val_loss=0.00000000]\n",
      "Validation Epoch [289/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.92it/s, val_loss=1.14570737]\n",
      "Training Epoch [290/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.92it/s, curr_train_loss=0.42957833, val_loss=0.00000000]\n",
      "Validation Epoch [290/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.91it/s, val_loss=1.24995565]\n",
      "Training Epoch [291/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=0.53419256, val_loss=0.00000000]\n",
      "Validation Epoch [291/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.78it/s, val_loss=1.18850970]\n",
      "Training Epoch [292/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=0.52227491, val_loss=0.00000000]\n",
      "Validation Epoch [292/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s, val_loss=1.18139338]\n",
      "Training Epoch [293/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=0.57187837, val_loss=0.00000000]\n",
      "Validation Epoch [293/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.06it/s, val_loss=1.10048163]\n",
      "Training Epoch [294/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.28it/s, curr_train_loss=0.44603556, val_loss=0.00000000]\n",
      "Validation Epoch [294/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.02it/s, val_loss=0.98161989]\n",
      "Training Epoch [295/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.74it/s, curr_train_loss=0.66195071, val_loss=0.00000000]\n",
      "Validation Epoch [295/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.01it/s, val_loss=1.27839971]\n",
      "Training Epoch [296/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, curr_train_loss=0.47160068, val_loss=0.00000000]\n",
      "Validation Epoch [296/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.57it/s, val_loss=1.15853631]\n",
      "Training Epoch [297/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, curr_train_loss=0.57678020, val_loss=0.00000000]\n",
      "Validation Epoch [297/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=0.91420478]\n",
      "Training Epoch [298/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.23it/s, curr_train_loss=0.60508275, val_loss=0.00000000]\n",
      "Validation Epoch [298/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.67it/s, val_loss=1.34156966]\n",
      "Training Epoch [299/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.51it/s, curr_train_loss=0.46652234, val_loss=0.00000000]\n",
      "Validation Epoch [299/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.79it/s, val_loss=1.19639468]\n",
      "Training Epoch [300/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.18it/s, curr_train_loss=0.38812941, val_loss=0.00000000]\n",
      "Validation Epoch [300/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, val_loss=1.25687110]\n",
      "Training Epoch [301/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.40it/s, curr_train_loss=0.56875837, val_loss=0.00000000]\n",
      "Validation Epoch [301/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.85it/s, val_loss=1.15611684]\n",
      "Training Epoch [302/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.33it/s, curr_train_loss=0.46361801, val_loss=0.00000000]\n",
      "Validation Epoch [302/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.09it/s, val_loss=0.91312879]\n",
      "Training Epoch [303/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.59027559, val_loss=0.00000000]\n",
      "Validation Epoch [303/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.11it/s, val_loss=0.78228027]\n",
      "Training Epoch [304/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.07it/s, curr_train_loss=0.44958669, val_loss=0.00000000]\n",
      "Validation Epoch [304/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.30871034]\n",
      "Training Epoch [305/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=0.38837975, val_loss=0.00000000]\n",
      "Validation Epoch [305/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.34081829]\n",
      "Training Epoch [306/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=0.50472808, val_loss=0.00000000]\n",
      "Validation Epoch [306/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.76it/s, val_loss=1.29380953]\n",
      "Training Epoch [307/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=0.50485754, val_loss=0.00000000]\n",
      "Validation Epoch [307/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.01it/s, val_loss=1.23808634]\n",
      "Training Epoch [308/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.32it/s, curr_train_loss=0.40912282, val_loss=0.00000000]\n",
      "Validation Epoch [308/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.73it/s, val_loss=1.13833392]\n",
      "Training Epoch [309/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.54it/s, curr_train_loss=0.55186057, val_loss=0.00000000]\n",
      "Validation Epoch [309/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.24615145]\n",
      "Training Epoch [310/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.19it/s, curr_train_loss=0.54338837, val_loss=0.00000000]\n",
      "Validation Epoch [310/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.26709270]\n",
      "Training Epoch [311/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=0.48599622, val_loss=0.00000000]\n",
      "Validation Epoch [311/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.60it/s, val_loss=1.24767125]\n",
      "Training Epoch [312/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.63it/s, curr_train_loss=0.53277159, val_loss=0.00000000]\n",
      "Validation Epoch [312/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.10it/s, val_loss=1.04351759]\n",
      "Training Epoch [313/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.61920577, val_loss=0.00000000]\n",
      "Validation Epoch [313/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=1.30839372]\n",
      "Training Epoch [314/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=0.52474546, val_loss=0.00000000]\n",
      "Validation Epoch [314/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.54it/s, val_loss=1.30819547]\n",
      "Training Epoch [315/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.51it/s, curr_train_loss=0.54402041, val_loss=0.00000000]\n",
      "Validation Epoch [315/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.09842968]\n",
      "Training Epoch [316/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.03it/s, curr_train_loss=0.48594055, val_loss=0.00000000]\n",
      "Validation Epoch [316/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.15it/s, val_loss=1.12851596]\n",
      "Training Epoch [317/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, curr_train_loss=0.49975950, val_loss=0.00000000]\n",
      "Validation Epoch [317/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.00it/s, val_loss=1.38126481]\n",
      "Training Epoch [318/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.69it/s, curr_train_loss=0.44950727, val_loss=0.00000000]\n",
      "Validation Epoch [318/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.93it/s, val_loss=1.09360349]\n",
      "Training Epoch [319/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.46it/s, curr_train_loss=0.39716133, val_loss=0.00000000]\n",
      "Validation Epoch [319/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.97it/s, val_loss=1.20116496]\n",
      "Training Epoch [320/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, curr_train_loss=0.62578076, val_loss=0.00000000]\n",
      "Validation Epoch [320/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.23582649]\n",
      "Training Epoch [321/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, curr_train_loss=0.28600922, val_loss=0.00000000]\n",
      "Validation Epoch [321/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s, val_loss=1.02227950]\n",
      "Training Epoch [322/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, curr_train_loss=0.46638715, val_loss=0.00000000]\n",
      "Validation Epoch [322/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s, val_loss=1.13544703]\n",
      "Training Epoch [323/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.84it/s, curr_train_loss=0.45039454, val_loss=0.00000000]\n",
      "Validation Epoch [323/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.73it/s, val_loss=1.11078143]\n",
      "Training Epoch [324/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.25it/s, curr_train_loss=0.42979211, val_loss=0.00000000]\n",
      "Validation Epoch [324/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.66it/s, val_loss=1.04687035]\n",
      "Training Epoch [325/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.99it/s, curr_train_loss=0.47379291, val_loss=0.00000000]\n",
      "Validation Epoch [325/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.14it/s, val_loss=1.10478413]\n",
      "Training Epoch [326/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.64it/s, curr_train_loss=0.55117720, val_loss=0.00000000]\n",
      "Validation Epoch [326/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.02it/s, val_loss=1.14045811]\n",
      "Training Epoch [327/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, curr_train_loss=0.65370977, val_loss=0.00000000]\n",
      "Validation Epoch [327/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.16323888]\n",
      "Training Epoch [328/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.13it/s, curr_train_loss=0.60849577, val_loss=0.00000000]\n",
      "Validation Epoch [328/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.76it/s, val_loss=1.25396359]\n",
      "Training Epoch [329/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=0.58209968, val_loss=0.00000000]\n",
      "Validation Epoch [329/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.05it/s, val_loss=1.07690406]\n",
      "Training Epoch [330/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=0.49382153, val_loss=0.00000000]\n",
      "Validation Epoch [330/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.02it/s, val_loss=1.37596464]\n",
      "Training Epoch [331/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.07it/s, curr_train_loss=0.68939000, val_loss=0.00000000]\n",
      "Validation Epoch [331/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.57it/s, val_loss=1.06908178]\n",
      "Training Epoch [332/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=0.47617081, val_loss=0.00000000]\n",
      "Validation Epoch [332/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.98it/s, val_loss=1.21550405]\n",
      "Training Epoch [333/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.16it/s, curr_train_loss=0.47176841, val_loss=0.00000000]\n",
      "Validation Epoch [333/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.73it/s, val_loss=1.00163257]\n",
      "Training Epoch [334/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.88it/s, curr_train_loss=0.50474548, val_loss=0.00000000]\n",
      "Validation Epoch [334/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.21it/s, val_loss=1.19818759]\n",
      "Training Epoch [335/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.94it/s, curr_train_loss=0.50970978, val_loss=0.00000000]\n",
      "Validation Epoch [335/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.04it/s, val_loss=1.40905094]\n",
      "Training Epoch [336/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.18it/s, curr_train_loss=0.43347156, val_loss=0.00000000]\n",
      "Validation Epoch [336/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.73it/s, val_loss=1.22445154]\n",
      "Training Epoch [337/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=0.45527133, val_loss=0.00000000]\n",
      "Validation Epoch [337/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.91it/s, val_loss=1.27291381]\n",
      "Training Epoch [338/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.37it/s, curr_train_loss=0.52685750, val_loss=0.00000000]\n",
      "Validation Epoch [338/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.98it/s, val_loss=0.98431754]\n",
      "Training Epoch [339/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, curr_train_loss=0.42752972, val_loss=0.00000000]\n",
      "Validation Epoch [339/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.55it/s, val_loss=1.01352596]\n",
      "Training Epoch [340/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.45it/s, curr_train_loss=0.60088420, val_loss=0.00000000]\n",
      "Validation Epoch [340/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.24038064]\n",
      "Training Epoch [341/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.49it/s, curr_train_loss=0.37682065, val_loss=0.00000000]\n",
      "Validation Epoch [341/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.90it/s, val_loss=1.04775977]\n",
      "Training Epoch [342/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, curr_train_loss=0.45258483, val_loss=0.00000000]\n",
      "Validation Epoch [342/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.73it/s, val_loss=1.38318741]\n",
      "Training Epoch [343/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, curr_train_loss=0.67611730, val_loss=0.00000000]\n",
      "Validation Epoch [343/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.07100344]\n",
      "Training Epoch [344/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=0.66818291, val_loss=0.00000000]\n",
      "Validation Epoch [344/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=1.15933216]\n",
      "Training Epoch [345/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, curr_train_loss=0.49032825, val_loss=0.00000000]\n",
      "Validation Epoch [345/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.78it/s, val_loss=1.28444779]\n",
      "Training Epoch [346/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.17it/s, curr_train_loss=0.52885407, val_loss=0.00000000]\n",
      "Validation Epoch [346/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.53it/s, val_loss=1.24937356]\n",
      "Training Epoch [347/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=0.82405603, val_loss=0.00000000]\n",
      "Validation Epoch [347/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=1.23594141]\n",
      "Training Epoch [348/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.56it/s, curr_train_loss=0.35820481, val_loss=0.00000000]\n",
      "Validation Epoch [348/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, val_loss=1.22048676]\n",
      "Training Epoch [349/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.94it/s, curr_train_loss=0.69387525, val_loss=0.00000000]\n",
      "Validation Epoch [349/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.01it/s, val_loss=1.17079937]\n",
      "Training Epoch [350/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=0.40179053, val_loss=0.00000000]\n",
      "Validation Epoch [350/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.19648647]\n",
      "Training Epoch [351/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.57715750, val_loss=0.00000000]\n",
      "Validation Epoch [351/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, val_loss=1.48228729]\n",
      "Training Epoch [352/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.68it/s, curr_train_loss=0.51164794, val_loss=0.00000000]\n",
      "Validation Epoch [352/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.24it/s, val_loss=1.40408766]\n",
      "Training Epoch [353/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.38259056, val_loss=0.00000000]\n",
      "Validation Epoch [353/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.71it/s, val_loss=1.17663336]\n",
      "Training Epoch [354/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.05it/s, curr_train_loss=0.46073833, val_loss=0.00000000]\n",
      "Validation Epoch [354/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, val_loss=1.31220138]\n",
      "Training Epoch [355/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.34it/s, curr_train_loss=0.39935511, val_loss=0.00000000]\n",
      "Validation Epoch [355/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.11it/s, val_loss=1.25586700]\n",
      "Training Epoch [356/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.98it/s, curr_train_loss=0.58802760, val_loss=0.00000000]\n",
      "Validation Epoch [356/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, val_loss=1.31345367]\n",
      "Training Epoch [357/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.53it/s, curr_train_loss=0.48307765, val_loss=0.00000000]\n",
      "Validation Epoch [357/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.08it/s, val_loss=1.22888863]\n",
      "Training Epoch [358/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.38it/s, curr_train_loss=0.43855461, val_loss=0.00000000]\n",
      "Validation Epoch [358/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.93it/s, val_loss=1.21944821]\n",
      "Training Epoch [359/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.31it/s, curr_train_loss=0.40160778, val_loss=0.00000000]\n",
      "Validation Epoch [359/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.78it/s, val_loss=1.18869638]\n",
      "Training Epoch [360/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.54it/s, curr_train_loss=0.53224808, val_loss=0.00000000]\n",
      "Validation Epoch [360/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, val_loss=1.37143338]\n",
      "Training Epoch [361/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.51it/s, curr_train_loss=0.35056469, val_loss=0.00000000]\n",
      "Validation Epoch [361/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.53it/s, val_loss=1.22035122]\n",
      "Training Epoch [362/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, curr_train_loss=0.60300899, val_loss=0.00000000]\n",
      "Validation Epoch [362/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.80it/s, val_loss=1.42737126]\n",
      "Training Epoch [363/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.52it/s, curr_train_loss=0.48974568, val_loss=0.00000000]\n",
      "Validation Epoch [363/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.80it/s, val_loss=1.54086685]\n",
      "Training Epoch [364/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.20it/s, curr_train_loss=0.39710861, val_loss=0.00000000]\n",
      "Validation Epoch [364/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.18it/s, val_loss=1.59457624]\n",
      "Training Epoch [365/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.19it/s, curr_train_loss=0.46464291, val_loss=0.00000000]\n",
      "Validation Epoch [365/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.96it/s, val_loss=1.40248251]\n",
      "Training Epoch [366/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=0.43704310, val_loss=0.00000000]\n",
      "Validation Epoch [366/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=1.10689640]\n",
      "Training Epoch [367/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.39it/s, curr_train_loss=0.51158506, val_loss=0.00000000]\n",
      "Validation Epoch [367/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.82it/s, val_loss=1.32973051]\n",
      "Training Epoch [368/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.65it/s, curr_train_loss=0.46182883, val_loss=0.00000000]\n",
      "Validation Epoch [368/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.05it/s, val_loss=1.04009974]\n",
      "Training Epoch [369/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.55it/s, curr_train_loss=0.46241391, val_loss=0.00000000]\n",
      "Validation Epoch [369/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.90it/s, val_loss=1.28309286]\n",
      "Training Epoch [370/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.50766951, val_loss=0.00000000]\n",
      "Validation Epoch [370/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.68it/s, val_loss=1.41449368]\n",
      "Training Epoch [371/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=0.38504869, val_loss=0.00000000]\n",
      "Validation Epoch [371/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.50it/s, val_loss=0.78421104]\n",
      "Training Epoch [372/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.31it/s, curr_train_loss=0.37836179, val_loss=0.00000000]\n",
      "Validation Epoch [372/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=1.13208151]\n",
      "Training Epoch [373/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, curr_train_loss=0.49793893, val_loss=0.00000000]\n",
      "Validation Epoch [373/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.16322899]\n",
      "Training Epoch [374/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.07it/s, curr_train_loss=0.38385674, val_loss=0.00000000]\n",
      "Validation Epoch [374/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.73it/s, val_loss=1.09772968]\n",
      "Training Epoch [375/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.59it/s, curr_train_loss=0.42323819, val_loss=0.00000000]\n",
      "Validation Epoch [375/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=1.13052392]\n",
      "Training Epoch [376/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.76it/s, curr_train_loss=0.58565062, val_loss=0.00000000]\n",
      "Validation Epoch [376/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=1.36571658]\n",
      "Training Epoch [377/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.33it/s, curr_train_loss=0.56639868, val_loss=0.00000000]\n",
      "Validation Epoch [377/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.89it/s, val_loss=1.08497632]\n",
      "Training Epoch [378/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.10it/s, curr_train_loss=0.56125796, val_loss=0.00000000]\n",
      "Validation Epoch [378/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.80it/s, val_loss=1.25996768]\n",
      "Training Epoch [379/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, curr_train_loss=0.33195758, val_loss=0.00000000]\n",
      "Validation Epoch [379/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.63it/s, val_loss=1.13841033]\n",
      "Training Epoch [380/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.64it/s, curr_train_loss=0.65896678, val_loss=0.00000000]\n",
      "Validation Epoch [380/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.92it/s, val_loss=1.10427356]\n",
      "Training Epoch [381/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.43it/s, curr_train_loss=0.51413703, val_loss=0.00000000]\n",
      "Validation Epoch [381/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.03it/s, val_loss=1.07579792]\n",
      "Training Epoch [382/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.36it/s, curr_train_loss=0.31234789, val_loss=0.00000000]\n",
      "Validation Epoch [382/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.05589616]\n",
      "Training Epoch [383/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.60it/s, curr_train_loss=0.35005328, val_loss=0.00000000]\n",
      "Validation Epoch [383/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, val_loss=0.98760307]\n",
      "Training Epoch [384/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.42it/s, curr_train_loss=0.47201893, val_loss=0.00000000]\n",
      "Validation Epoch [384/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.16it/s, val_loss=1.06113720]\n",
      "Training Epoch [385/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.83it/s, curr_train_loss=0.38288605, val_loss=0.00000000]\n",
      "Validation Epoch [385/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.85it/s, val_loss=1.01003909]\n",
      "Training Epoch [386/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.67it/s, curr_train_loss=0.56184447, val_loss=0.00000000]\n",
      "Validation Epoch [386/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, val_loss=0.77615201]\n",
      "Training Epoch [387/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, curr_train_loss=0.63913465, val_loss=0.00000000]\n",
      "Validation Epoch [387/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.98it/s, val_loss=1.15892589]\n",
      "Training Epoch [388/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.98it/s, curr_train_loss=0.35875401, val_loss=0.00000000]\n",
      "Validation Epoch [388/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.07it/s, val_loss=0.87324464]\n",
      "Training Epoch [389/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.55it/s, curr_train_loss=0.38365650, val_loss=0.00000000]\n",
      "Validation Epoch [389/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, val_loss=1.44334519]\n",
      "Training Epoch [390/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, curr_train_loss=0.56807226, val_loss=0.00000000]\n",
      "Validation Epoch [390/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.22172880]\n",
      "Training Epoch [391/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, curr_train_loss=0.33608434, val_loss=0.00000000]\n",
      "Validation Epoch [391/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.92it/s, val_loss=0.96744734]\n",
      "Training Epoch [392/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.62it/s, curr_train_loss=0.48189363, val_loss=0.00000000]\n",
      "Validation Epoch [392/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.69it/s, val_loss=0.93117762]\n",
      "Training Epoch [393/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.45it/s, curr_train_loss=0.48480684, val_loss=0.00000000]\n",
      "Validation Epoch [393/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.81it/s, val_loss=0.93020731]\n",
      "Training Epoch [394/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.62it/s, curr_train_loss=0.47909918, val_loss=0.00000000]\n",
      "Validation Epoch [394/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.70it/s, val_loss=1.20814586]\n",
      "Training Epoch [395/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=0.37481019, val_loss=0.00000000]\n",
      "Validation Epoch [395/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.07it/s, val_loss=1.25703442]\n",
      "Training Epoch [396/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.18it/s, curr_train_loss=0.61985910, val_loss=0.00000000]\n",
      "Validation Epoch [396/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=1.10323274]\n",
      "Training Epoch [397/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=0.49477455, val_loss=0.00000000]\n",
      "Validation Epoch [397/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.74it/s, val_loss=1.09469783]\n",
      "Training Epoch [398/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=0.46307278, val_loss=0.00000000]\n",
      "Validation Epoch [398/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.85it/s, val_loss=0.91754431]\n",
      "Training Epoch [399/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.40it/s, curr_train_loss=0.42824775, val_loss=0.00000000]\n",
      "Validation Epoch [399/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.84it/s, val_loss=1.08125532]\n",
      "Training Epoch [400/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.09it/s, curr_train_loss=0.47593820, val_loss=0.00000000]\n",
      "Validation Epoch [400/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.75it/s, val_loss=1.14762914]\n",
      "Training Epoch [401/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=0.46118465, val_loss=0.00000000]\n",
      "Validation Epoch [401/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.72it/s, val_loss=0.84338111]\n",
      "Training Epoch [402/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.13it/s, curr_train_loss=0.42940715, val_loss=0.00000000]\n",
      "Validation Epoch [402/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.05it/s, val_loss=1.23726201]\n",
      "Training Epoch [403/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.52it/s, curr_train_loss=0.34717715, val_loss=0.00000000]\n",
      "Validation Epoch [403/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.86it/s, val_loss=0.90425664]\n",
      "Training Epoch [404/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.06it/s, curr_train_loss=0.34347209, val_loss=0.00000000]\n",
      "Validation Epoch [404/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=1.05042601]\n",
      "Training Epoch [405/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, curr_train_loss=0.47452697, val_loss=0.00000000]\n",
      "Validation Epoch [405/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=1.12305236]\n",
      "Training Epoch [406/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.35it/s, curr_train_loss=0.43557110, val_loss=0.00000000]\n",
      "Validation Epoch [406/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.84it/s, val_loss=1.26669550]\n",
      "Training Epoch [407/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.13it/s, curr_train_loss=0.44837812, val_loss=0.00000000]\n",
      "Validation Epoch [407/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=1.04134822]\n",
      "Training Epoch [408/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=0.47669983, val_loss=0.00000000]\n",
      "Validation Epoch [408/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.33201718]\n",
      "Training Epoch [409/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s, curr_train_loss=0.47174564, val_loss=0.00000000]\n",
      "Validation Epoch [409/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.23583484]\n",
      "Training Epoch [410/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, curr_train_loss=0.44040599, val_loss=0.00000000]\n",
      "Validation Epoch [410/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.01it/s, val_loss=1.45750737]\n",
      "Training Epoch [411/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, curr_train_loss=0.42331681, val_loss=0.00000000]\n",
      "Validation Epoch [411/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.85it/s, val_loss=1.39503026]\n",
      "Training Epoch [412/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.78it/s, curr_train_loss=0.33318612, val_loss=0.00000000]\n",
      "Validation Epoch [412/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.59it/s, val_loss=1.35090542]\n",
      "Training Epoch [413/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.46it/s, curr_train_loss=0.38035157, val_loss=0.00000000]\n",
      "Validation Epoch [413/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.78it/s, val_loss=1.22295833]\n",
      "Training Epoch [414/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.52it/s, curr_train_loss=0.40001827, val_loss=0.00000000]\n",
      "Validation Epoch [414/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.75it/s, val_loss=1.43161190]\n",
      "Training Epoch [415/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.97it/s, curr_train_loss=0.45452091, val_loss=0.00000000]\n",
      "Validation Epoch [415/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.79it/s, val_loss=1.22570515]\n",
      "Training Epoch [416/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=0.44992802, val_loss=0.00000000]\n",
      "Validation Epoch [416/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.22564721]\n",
      "Training Epoch [417/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.21it/s, curr_train_loss=0.45743409, val_loss=0.00000000]\n",
      "Validation Epoch [417/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.11it/s, val_loss=1.28718626]\n",
      "Training Epoch [418/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.32it/s, curr_train_loss=0.44297913, val_loss=0.00000000]\n",
      "Validation Epoch [418/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.76it/s, val_loss=1.07775545]\n",
      "Training Epoch [419/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.63it/s, curr_train_loss=0.48291802, val_loss=0.00000000]\n",
      "Validation Epoch [419/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.53it/s, val_loss=1.30192387]\n",
      "Training Epoch [420/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.51it/s, curr_train_loss=0.36651498, val_loss=0.00000000]\n",
      "Validation Epoch [420/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.44it/s, val_loss=0.96487433]\n",
      "Training Epoch [421/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.27it/s, curr_train_loss=0.36489409, val_loss=0.00000000]\n",
      "Validation Epoch [421/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.65it/s, val_loss=0.98176092]\n",
      "Training Epoch [422/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.76it/s, curr_train_loss=0.45212650, val_loss=0.00000000]\n",
      "Validation Epoch [422/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, val_loss=1.21103978]\n",
      "Training Epoch [423/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=0.45158496, val_loss=0.00000000]\n",
      "Validation Epoch [423/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.26013243]\n",
      "Training Epoch [424/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.75it/s, curr_train_loss=0.25531146, val_loss=0.00000000]\n",
      "Validation Epoch [424/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.48it/s, val_loss=1.12203252]\n",
      "Training Epoch [425/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, curr_train_loss=0.50057417, val_loss=0.00000000]\n",
      "Validation Epoch [425/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, val_loss=1.26081038]\n",
      "Training Epoch [426/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.42it/s, curr_train_loss=0.41355094, val_loss=0.00000000]\n",
      "Validation Epoch [426/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=1.32686651]\n",
      "Training Epoch [427/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.18it/s, curr_train_loss=0.39324552, val_loss=0.00000000]\n",
      "Validation Epoch [427/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.10it/s, val_loss=1.23576725]\n",
      "Training Epoch [428/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=0.40724263, val_loss=0.00000000]\n",
      "Validation Epoch [428/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.93it/s, val_loss=1.46962595]\n",
      "Training Epoch [429/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, curr_train_loss=0.41583869, val_loss=0.00000000]\n",
      "Validation Epoch [429/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.50688243]\n",
      "Training Epoch [430/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, curr_train_loss=0.38977581, val_loss=0.00000000]\n",
      "Validation Epoch [430/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.74it/s, val_loss=1.20661402]\n",
      "Training Epoch [431/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.44it/s, curr_train_loss=0.45430487, val_loss=0.00000000]\n",
      "Validation Epoch [431/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.06it/s, val_loss=1.35411167]\n",
      "Training Epoch [432/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.38it/s, curr_train_loss=0.49934185, val_loss=0.00000000]\n",
      "Validation Epoch [432/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.85it/s, val_loss=1.45471585]\n",
      "Training Epoch [433/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  5.83it/s, curr_train_loss=0.39280400, val_loss=0.00000000]\n",
      "Validation Epoch [433/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s, val_loss=1.44679368]\n",
      "Training Epoch [434/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.52it/s, curr_train_loss=0.34518850, val_loss=0.00000000]\n",
      "Validation Epoch [434/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.93it/s, val_loss=1.50886154]\n",
      "Training Epoch [435/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.75it/s, curr_train_loss=0.47550339, val_loss=0.00000000]\n",
      "Validation Epoch [435/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, val_loss=1.45293844]\n",
      "Training Epoch [436/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.57it/s, curr_train_loss=0.40650922, val_loss=0.00000000]\n",
      "Validation Epoch [436/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, val_loss=1.36255217]\n",
      "Training Epoch [437/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.21it/s, curr_train_loss=0.51934355, val_loss=0.00000000]\n",
      "Validation Epoch [437/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.10it/s, val_loss=1.18580806]\n",
      "Training Epoch [438/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.31it/s, curr_train_loss=0.39893588, val_loss=0.00000000]\n",
      "Validation Epoch [438/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.20687258]\n",
      "Training Epoch [439/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.15it/s, curr_train_loss=0.46336415, val_loss=0.00000000]\n",
      "Validation Epoch [439/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, val_loss=1.26906002]\n",
      "Training Epoch [440/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.14it/s, curr_train_loss=0.36159271, val_loss=0.00000000]\n",
      "Validation Epoch [440/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.65it/s, val_loss=1.02322984]\n",
      "Training Epoch [441/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.82it/s, curr_train_loss=0.39152285, val_loss=0.00000000]\n",
      "Validation Epoch [441/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.13it/s, val_loss=0.99832022]\n",
      "Training Epoch [442/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=0.22363760, val_loss=0.00000000]\n",
      "Validation Epoch [442/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, val_loss=1.13280308]\n",
      "Training Epoch [443/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, curr_train_loss=0.45339343, val_loss=0.00000000]\n",
      "Validation Epoch [443/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.04794991]\n",
      "Training Epoch [444/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.62it/s, curr_train_loss=0.40930444, val_loss=0.00000000]\n",
      "Validation Epoch [444/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.01it/s, val_loss=1.22112429]\n",
      "Training Epoch [445/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.47it/s, curr_train_loss=0.34721982, val_loss=0.00000000]\n",
      "Validation Epoch [445/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.55it/s, val_loss=1.20758128]\n",
      "Training Epoch [446/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, curr_train_loss=0.37081733, val_loss=0.00000000]\n",
      "Validation Epoch [446/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.07it/s, val_loss=1.07893324]\n",
      "Training Epoch [447/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.72it/s, curr_train_loss=0.20736113, val_loss=0.00000000]\n",
      "Validation Epoch [447/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.02it/s, val_loss=1.39631987]\n",
      "Training Epoch [448/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.68it/s, curr_train_loss=0.52094632, val_loss=0.00000000]\n",
      "Validation Epoch [448/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.70it/s, val_loss=1.31817889]\n",
      "Training Epoch [449/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, curr_train_loss=0.55646467, val_loss=0.00000000]\n",
      "Validation Epoch [449/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.31it/s, val_loss=1.40040195]\n",
      "Training Epoch [450/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, curr_train_loss=0.29986316, val_loss=0.00000000]\n",
      "Validation Epoch [450/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.10it/s, val_loss=1.26551723]\n",
      "Training Epoch [451/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, curr_train_loss=0.31835061, val_loss=0.00000000]\n",
      "Validation Epoch [451/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.01302063]\n",
      "Training Epoch [452/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.51it/s, curr_train_loss=0.50044429, val_loss=0.00000000]\n",
      "Validation Epoch [452/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.07693601]\n",
      "Training Epoch [453/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.90it/s, curr_train_loss=0.50818312, val_loss=0.00000000]\n",
      "Validation Epoch [453/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.72it/s, val_loss=1.26334035]\n",
      "Training Epoch [454/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.99it/s, curr_train_loss=0.60711622, val_loss=0.00000000]\n",
      "Validation Epoch [454/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.93it/s, val_loss=0.87889773]\n",
      "Training Epoch [455/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=0.41232792, val_loss=0.00000000]\n",
      "Validation Epoch [455/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.16it/s, val_loss=1.08786130]\n",
      "Training Epoch [456/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.14it/s, curr_train_loss=0.42786166, val_loss=0.00000000]\n",
      "Validation Epoch [456/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.43403864]\n",
      "Training Epoch [457/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, curr_train_loss=0.38142911, val_loss=0.00000000]\n",
      "Validation Epoch [457/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, val_loss=1.07986867]\n",
      "Training Epoch [458/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.74it/s, curr_train_loss=0.43109664, val_loss=0.00000000]\n",
      "Validation Epoch [458/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s, val_loss=1.28549850]\n",
      "Training Epoch [459/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.60it/s, curr_train_loss=0.26990545, val_loss=0.00000000]\n",
      "Validation Epoch [459/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.53it/s, val_loss=1.01222026]\n",
      "Training Epoch [460/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.73it/s, curr_train_loss=0.40402213, val_loss=0.00000000]\n",
      "Validation Epoch [460/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.62it/s, val_loss=1.13641560]\n",
      "Training Epoch [461/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, curr_train_loss=0.49273244, val_loss=0.00000000]\n",
      "Validation Epoch [461/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.63it/s, val_loss=0.93161225]\n",
      "Training Epoch [462/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, curr_train_loss=0.48415720, val_loss=0.00000000]\n",
      "Validation Epoch [462/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, val_loss=1.34346783]\n",
      "Training Epoch [463/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.42it/s, curr_train_loss=0.39928514, val_loss=0.00000000]\n",
      "Validation Epoch [463/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.83it/s, val_loss=1.14405143]\n",
      "Training Epoch [464/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, curr_train_loss=0.53119189, val_loss=0.00000000]\n",
      "Validation Epoch [464/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.69it/s, val_loss=1.04050171]\n",
      "Training Epoch [465/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.55it/s, curr_train_loss=0.25481883, val_loss=0.00000000]\n",
      "Validation Epoch [465/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.95it/s, val_loss=1.06860590]\n",
      "Training Epoch [466/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.31999016, val_loss=0.00000000]\n",
      "Validation Epoch [466/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.16893315]\n",
      "Training Epoch [467/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=0.38054654, val_loss=0.00000000]\n",
      "Validation Epoch [467/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.64it/s, val_loss=1.20497286]\n",
      "Training Epoch [468/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.23it/s, curr_train_loss=0.51446420, val_loss=0.00000000]\n",
      "Validation Epoch [468/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.56it/s, val_loss=1.19173086]\n",
      "Training Epoch [469/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.98it/s, curr_train_loss=0.46307129, val_loss=0.00000000]\n",
      "Validation Epoch [469/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.06it/s, val_loss=1.14803183]\n",
      "Training Epoch [470/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.50it/s, curr_train_loss=0.37882984, val_loss=0.00000000]\n",
      "Validation Epoch [470/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.72it/s, val_loss=1.27803588]\n",
      "Training Epoch [471/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.53it/s, curr_train_loss=0.34203708, val_loss=0.00000000]\n",
      "Validation Epoch [471/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.97it/s, val_loss=1.21310449]\n",
      "Training Epoch [472/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.10it/s, curr_train_loss=0.40036014, val_loss=0.00000000]\n",
      "Validation Epoch [472/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.11it/s, val_loss=1.55626035]\n",
      "Training Epoch [473/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.35997510, val_loss=0.00000000]\n",
      "Validation Epoch [473/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.25395977]\n",
      "Training Epoch [474/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, curr_train_loss=0.33541068, val_loss=0.00000000]\n",
      "Validation Epoch [474/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.93it/s, val_loss=1.25582671]\n",
      "Training Epoch [475/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.27it/s, curr_train_loss=0.42201892, val_loss=0.00000000]\n",
      "Validation Epoch [475/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.95it/s, val_loss=1.28783453]\n",
      "Training Epoch [476/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, curr_train_loss=0.38116688, val_loss=0.00000000]\n",
      "Validation Epoch [476/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=1.33465922]\n",
      "Training Epoch [477/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.39623246, val_loss=0.00000000]\n",
      "Validation Epoch [477/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.06it/s, val_loss=1.24502528]\n",
      "Training Epoch [478/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.40it/s, curr_train_loss=0.53359240, val_loss=0.00000000]\n",
      "Validation Epoch [478/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.15it/s, val_loss=1.48023665]\n",
      "Training Epoch [479/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=0.38997319, val_loss=0.00000000]\n",
      "Validation Epoch [479/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.42501986]\n",
      "Training Epoch [480/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, curr_train_loss=0.29875526, val_loss=0.00000000]\n",
      "Validation Epoch [480/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=1.48548520]\n",
      "Training Epoch [481/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.05it/s, curr_train_loss=0.43492603, val_loss=0.00000000]\n",
      "Validation Epoch [481/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.14721584]\n",
      "Training Epoch [482/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=0.34751377, val_loss=0.00000000]\n",
      "Validation Epoch [482/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.20124245]\n",
      "Training Epoch [483/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, curr_train_loss=0.24672249, val_loss=0.00000000]\n",
      "Validation Epoch [483/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.74it/s, val_loss=1.13529229]\n",
      "Training Epoch [484/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, curr_train_loss=0.57683104, val_loss=0.00000000]\n",
      "Validation Epoch [484/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.79it/s, val_loss=1.06957018]\n",
      "Training Epoch [485/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=0.27282643, val_loss=0.00000000]\n",
      "Validation Epoch [485/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.78it/s, val_loss=1.04898906]\n",
      "Training Epoch [486/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.11it/s, curr_train_loss=0.40112737, val_loss=0.00000000]\n",
      "Validation Epoch [486/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.03it/s, val_loss=1.27780855]\n",
      "Training Epoch [487/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.47it/s, curr_train_loss=0.35143608, val_loss=0.00000000]\n",
      "Validation Epoch [487/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.95it/s, val_loss=0.85874903]\n",
      "Training Epoch [488/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.51it/s, curr_train_loss=0.34454197, val_loss=0.00000000]\n",
      "Validation Epoch [488/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.30787551]\n",
      "Training Epoch [489/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.47it/s, curr_train_loss=0.37784728, val_loss=0.00000000]\n",
      "Validation Epoch [489/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.01it/s, val_loss=1.19026113]\n",
      "Training Epoch [490/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.54it/s, curr_train_loss=0.35167533, val_loss=0.00000000]\n",
      "Validation Epoch [490/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.64it/s, val_loss=1.20183754]\n",
      "Training Epoch [491/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.42it/s, curr_train_loss=0.25939304, val_loss=0.00000000]\n",
      "Validation Epoch [491/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.67it/s, val_loss=0.96590173]\n",
      "Training Epoch [492/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, curr_train_loss=0.57788569, val_loss=0.00000000]\n",
      "Validation Epoch [492/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.84it/s, val_loss=1.31591690]\n",
      "Training Epoch [493/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.51it/s, curr_train_loss=0.32586652, val_loss=0.00000000]\n",
      "Validation Epoch [493/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.64it/s, val_loss=0.94804937]\n",
      "Training Epoch [494/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.58it/s, curr_train_loss=0.21938986, val_loss=0.00000000]\n",
      "Validation Epoch [494/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.93it/s, val_loss=1.16105402]\n",
      "Training Epoch [495/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=0.52919668, val_loss=0.00000000]\n",
      "Validation Epoch [495/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.68it/s, val_loss=1.15553355]\n",
      "Training Epoch [496/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.53it/s, curr_train_loss=0.46313679, val_loss=0.00000000]\n",
      "Validation Epoch [496/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, val_loss=1.25053144]\n",
      "Training Epoch [497/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.80it/s, curr_train_loss=0.53123194, val_loss=0.00000000]\n",
      "Validation Epoch [497/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.06it/s, val_loss=1.25354433]\n",
      "Training Epoch [498/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=0.45498329, val_loss=0.00000000]\n",
      "Validation Epoch [498/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.19406736]\n",
      "Training Epoch [499/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.65it/s, curr_train_loss=0.55047166, val_loss=0.00000000]\n",
      "Validation Epoch [499/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.91it/s, val_loss=0.79344368]\n",
      "Training Epoch [500/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, curr_train_loss=0.44349477, val_loss=0.00000000]\n",
      "Validation Epoch [500/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.71it/s, val_loss=1.06155586]\n",
      "Training Epoch [501/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=0.41675720, val_loss=0.00000000]\n",
      "Validation Epoch [501/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.12it/s, val_loss=1.24028003]\n",
      "Training Epoch [502/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.34it/s, curr_train_loss=0.36060274, val_loss=0.00000000]\n",
      "Validation Epoch [502/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.91it/s, val_loss=0.99680591]\n",
      "Training Epoch [503/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.36it/s, curr_train_loss=0.46146429, val_loss=0.00000000]\n",
      "Validation Epoch [503/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, val_loss=1.35156262]\n",
      "Training Epoch [504/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.18it/s, curr_train_loss=0.63117594, val_loss=0.00000000]\n",
      "Validation Epoch [504/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.10it/s, val_loss=1.18480992]\n",
      "Training Epoch [505/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=0.30069637, val_loss=0.00000000]\n",
      "Validation Epoch [505/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, val_loss=0.95914495]\n",
      "Training Epoch [506/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=0.53359449, val_loss=0.00000000]\n",
      "Validation Epoch [506/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.73it/s, val_loss=0.90804672]\n",
      "Training Epoch [507/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, curr_train_loss=0.24546018, val_loss=0.00000000]\n",
      "Validation Epoch [507/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.62it/s, val_loss=1.18065572]\n",
      "Training Epoch [508/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=0.39893371, val_loss=0.00000000]\n",
      "Validation Epoch [508/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, val_loss=1.27727664]\n",
      "Training Epoch [509/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=0.32463589, val_loss=0.00000000]\n",
      "Validation Epoch [509/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.03it/s, val_loss=1.15752554]\n",
      "Training Epoch [510/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=0.44518602, val_loss=0.00000000]\n",
      "Validation Epoch [510/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.90it/s, val_loss=1.20745683]\n",
      "Training Epoch [511/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.97it/s, curr_train_loss=0.36548153, val_loss=0.00000000]\n",
      "Validation Epoch [511/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.98it/s, val_loss=1.24866700]\n",
      "Training Epoch [512/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.65it/s, curr_train_loss=0.41515911, val_loss=0.00000000]\n",
      "Validation Epoch [512/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.74it/s, val_loss=1.31111920]\n",
      "Training Epoch [513/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.73it/s, curr_train_loss=0.35859314, val_loss=0.00000000]\n",
      "Validation Epoch [513/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.48it/s, val_loss=1.20575953]\n",
      "Training Epoch [514/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.25066543, val_loss=0.00000000]\n",
      "Validation Epoch [514/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.14it/s, val_loss=1.23014140]\n",
      "Training Epoch [515/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, curr_train_loss=0.38725707, val_loss=0.00000000]\n",
      "Validation Epoch [515/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.84it/s, val_loss=1.05219531]\n",
      "Training Epoch [516/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.51it/s, curr_train_loss=0.40784520, val_loss=0.00000000]\n",
      "Validation Epoch [516/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=1.37517941]\n",
      "Training Epoch [517/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.12it/s, curr_train_loss=0.23673555, val_loss=0.00000000]\n",
      "Validation Epoch [517/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.77it/s, val_loss=1.35679364]\n",
      "Training Epoch [518/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, curr_train_loss=0.36867765, val_loss=0.00000000]\n",
      "Validation Epoch [518/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.74it/s, val_loss=1.47921419]\n",
      "Training Epoch [519/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, curr_train_loss=0.31239676, val_loss=0.00000000]\n",
      "Validation Epoch [519/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s, val_loss=1.35092044]\n",
      "Training Epoch [520/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=0.31727877, val_loss=0.00000000]\n",
      "Validation Epoch [520/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.00it/s, val_loss=1.31860495]\n",
      "Training Epoch [521/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, curr_train_loss=0.42529979, val_loss=0.00000000]\n",
      "Validation Epoch [521/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.32762897]\n",
      "Training Epoch [522/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, curr_train_loss=0.45362660, val_loss=0.00000000]\n",
      "Validation Epoch [522/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.57it/s, val_loss=1.42076123]\n",
      "Training Epoch [523/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.67it/s, curr_train_loss=0.36779559, val_loss=0.00000000]\n",
      "Validation Epoch [523/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.02it/s, val_loss=1.35185099]\n",
      "Training Epoch [524/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.40it/s, curr_train_loss=0.30411419, val_loss=0.00000000]\n",
      "Validation Epoch [524/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.86it/s, val_loss=1.34274876]\n",
      "Training Epoch [525/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.52it/s, curr_train_loss=0.29037037, val_loss=0.00000000]\n",
      "Validation Epoch [525/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.05it/s, val_loss=1.19789183]\n",
      "Training Epoch [526/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=0.25994781, val_loss=0.00000000]\n",
      "Validation Epoch [526/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.62it/s, val_loss=1.09175086]\n",
      "Training Epoch [527/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, curr_train_loss=0.33861974, val_loss=0.00000000]\n",
      "Validation Epoch [527/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.78it/s, val_loss=1.46372283]\n",
      "Training Epoch [528/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.18it/s, curr_train_loss=0.56182033, val_loss=0.00000000]\n",
      "Validation Epoch [528/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=1.37436306]\n",
      "Training Epoch [529/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.61it/s, curr_train_loss=0.30815890, val_loss=0.00000000]\n",
      "Validation Epoch [529/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, val_loss=1.55163038]\n",
      "Training Epoch [530/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=0.26953885, val_loss=0.00000000]\n",
      "Validation Epoch [530/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=0.93489653]\n",
      "Training Epoch [531/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, curr_train_loss=0.36145756, val_loss=0.00000000]\n",
      "Validation Epoch [531/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.10it/s, val_loss=1.02884018]\n",
      "Training Epoch [532/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.57698524, val_loss=0.00000000]\n",
      "Validation Epoch [532/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.18473256]\n",
      "Training Epoch [533/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.56it/s, curr_train_loss=0.26201147, val_loss=0.00000000]\n",
      "Validation Epoch [533/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.91it/s, val_loss=1.23487949]\n",
      "Training Epoch [534/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.78it/s, curr_train_loss=0.39932573, val_loss=0.00000000]\n",
      "Validation Epoch [534/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.01it/s, val_loss=1.01717794]\n",
      "Training Epoch [535/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, curr_train_loss=0.37639940, val_loss=0.00000000]\n",
      "Validation Epoch [535/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.59it/s, val_loss=1.27848649]\n",
      "Training Epoch [536/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.45076641, val_loss=0.00000000]\n",
      "Validation Epoch [536/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.64it/s, val_loss=1.10347033]\n",
      "Training Epoch [537/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, curr_train_loss=0.29614627, val_loss=0.00000000]\n",
      "Validation Epoch [537/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=0.98143077]\n",
      "Training Epoch [538/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.45it/s, curr_train_loss=0.64168769, val_loss=0.00000000]\n",
      "Validation Epoch [538/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.10it/s, val_loss=1.18686986]\n",
      "Training Epoch [539/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=0.30395028, val_loss=0.00000000]\n",
      "Validation Epoch [539/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.13098347]\n",
      "Training Epoch [540/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s, curr_train_loss=0.45030209, val_loss=0.00000000]\n",
      "Validation Epoch [540/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.29943728]\n",
      "Training Epoch [541/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.59it/s, curr_train_loss=0.41579211, val_loss=0.00000000]\n",
      "Validation Epoch [541/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.23557818]\n",
      "Training Epoch [542/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.57it/s, curr_train_loss=0.38196084, val_loss=0.00000000]\n",
      "Validation Epoch [542/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.98it/s, val_loss=1.10467362]\n",
      "Training Epoch [543/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, curr_train_loss=0.37917241, val_loss=0.00000000]\n",
      "Validation Epoch [543/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=1.26030576]\n",
      "Training Epoch [544/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, curr_train_loss=0.32789066, val_loss=0.00000000]\n",
      "Validation Epoch [544/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=1.15768957]\n",
      "Training Epoch [545/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=0.27536809, val_loss=0.00000000]\n",
      "Validation Epoch [545/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.76it/s, val_loss=1.11410403]\n",
      "Training Epoch [546/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=0.19920234, val_loss=0.00000000]\n",
      "Validation Epoch [546/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.89it/s, val_loss=1.10032666]\n",
      "Training Epoch [547/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.27it/s, curr_train_loss=0.36039653, val_loss=0.00000000]\n",
      "Validation Epoch [547/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.07it/s, val_loss=1.37162983]\n",
      "Training Epoch [548/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, curr_train_loss=0.30698788, val_loss=0.00000000]\n",
      "Validation Epoch [548/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.67it/s, val_loss=1.39758301]\n",
      "Training Epoch [549/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.66it/s, curr_train_loss=0.33522320, val_loss=0.00000000]\n",
      "Validation Epoch [549/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.15it/s, val_loss=1.41823161]\n",
      "Training Epoch [550/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, curr_train_loss=0.37865806, val_loss=0.00000000]\n",
      "Validation Epoch [550/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, val_loss=1.12281752]\n",
      "Training Epoch [551/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=0.43638819, val_loss=0.00000000]\n",
      "Validation Epoch [551/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, val_loss=1.14576864]\n",
      "Training Epoch [552/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.76it/s, curr_train_loss=0.25446159, val_loss=0.00000000]\n",
      "Validation Epoch [552/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.04it/s, val_loss=1.27797496]\n",
      "Training Epoch [553/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.63it/s, curr_train_loss=0.44711980, val_loss=0.00000000]\n",
      "Validation Epoch [553/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.99it/s, val_loss=1.13406527]\n",
      "Training Epoch [554/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=0.43255270, val_loss=0.00000000]\n",
      "Validation Epoch [554/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.78it/s, val_loss=1.19201398]\n",
      "Training Epoch [555/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, curr_train_loss=0.45316258, val_loss=0.00000000]\n",
      "Validation Epoch [555/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.08it/s, val_loss=1.28655684]\n",
      "Training Epoch [556/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.47it/s, curr_train_loss=0.38343862, val_loss=0.00000000]\n",
      "Validation Epoch [556/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.95it/s, val_loss=1.45073712]\n",
      "Training Epoch [557/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.67it/s, curr_train_loss=0.24798290, val_loss=0.00000000]\n",
      "Validation Epoch [557/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, val_loss=1.07444525]\n",
      "Training Epoch [558/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.59it/s, curr_train_loss=0.37171978, val_loss=0.00000000]\n",
      "Validation Epoch [558/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, val_loss=1.60545135]\n",
      "Training Epoch [559/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.41it/s, curr_train_loss=0.41268495, val_loss=0.00000000]\n",
      "Validation Epoch [559/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.13it/s, val_loss=1.40152669]\n",
      "Training Epoch [560/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, curr_train_loss=0.48677033, val_loss=0.00000000]\n",
      "Validation Epoch [560/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.85it/s, val_loss=1.35710299]\n",
      "Training Epoch [561/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.40it/s, curr_train_loss=0.37328845, val_loss=0.00000000]\n",
      "Validation Epoch [561/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.30965209]\n",
      "Training Epoch [562/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, curr_train_loss=0.54026842, val_loss=0.00000000]\n",
      "Validation Epoch [562/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.70it/s, val_loss=1.22876120]\n",
      "Training Epoch [563/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.81it/s, curr_train_loss=0.53400856, val_loss=0.00000000]\n",
      "Validation Epoch [563/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, val_loss=1.64423871]\n",
      "Training Epoch [564/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.16it/s, curr_train_loss=0.40713128, val_loss=0.00000000]\n",
      "Validation Epoch [564/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.60414326]\n",
      "Training Epoch [565/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.72it/s, curr_train_loss=0.43919709, val_loss=0.00000000]\n",
      "Validation Epoch [565/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.45352924]\n",
      "Training Epoch [566/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, curr_train_loss=0.44789448, val_loss=0.00000000]\n",
      "Validation Epoch [566/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.23it/s, val_loss=1.39708042]\n",
      "Training Epoch [567/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=0.38976094, val_loss=0.00000000]\n",
      "Validation Epoch [567/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.91it/s, val_loss=1.04648769]\n",
      "Training Epoch [568/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, curr_train_loss=0.42958516, val_loss=0.00000000]\n",
      "Validation Epoch [568/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.66it/s, val_loss=1.38953066]\n",
      "Training Epoch [569/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.60it/s, curr_train_loss=0.37198940, val_loss=0.00000000]\n",
      "Validation Epoch [569/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.76it/s, val_loss=1.32783997]\n",
      "Training Epoch [570/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s, curr_train_loss=0.29267016, val_loss=0.00000000]\n",
      "Validation Epoch [570/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, val_loss=1.05976677]\n",
      "Training Epoch [571/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.40it/s, curr_train_loss=0.24685116, val_loss=0.00000000]\n",
      "Validation Epoch [571/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.71it/s, val_loss=1.11068130]\n",
      "Training Epoch [572/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.36245009, val_loss=0.00000000]\n",
      "Validation Epoch [572/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.14it/s, val_loss=1.58533084]\n",
      "Training Epoch [573/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.43it/s, curr_train_loss=0.39230374, val_loss=0.00000000]\n",
      "Validation Epoch [573/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.73it/s, val_loss=1.16910326]\n",
      "Training Epoch [574/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, curr_train_loss=0.40976965, val_loss=0.00000000]\n",
      "Validation Epoch [574/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, val_loss=1.17417669]\n",
      "Training Epoch [575/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, curr_train_loss=0.26973215, val_loss=0.00000000]\n",
      "Validation Epoch [575/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.59it/s, val_loss=1.41808987]\n",
      "Training Epoch [576/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.54it/s, curr_train_loss=0.36896867, val_loss=0.00000000]\n",
      "Validation Epoch [576/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, val_loss=1.61887121]\n",
      "Training Epoch [577/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.34it/s, curr_train_loss=0.36869693, val_loss=0.00000000]\n",
      "Validation Epoch [577/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.03it/s, val_loss=1.39699292]\n",
      "Training Epoch [578/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, curr_train_loss=0.54399127, val_loss=0.00000000]\n",
      "Validation Epoch [578/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.51028669]\n",
      "Training Epoch [579/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.21it/s, curr_train_loss=0.49411240, val_loss=0.00000000]\n",
      "Validation Epoch [579/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, val_loss=1.09670973]\n",
      "Training Epoch [580/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=0.45204580, val_loss=0.00000000]\n",
      "Validation Epoch [580/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.80it/s, val_loss=1.37671900]\n",
      "Training Epoch [581/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, curr_train_loss=0.47065192, val_loss=0.00000000]\n",
      "Validation Epoch [581/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.10553157]\n",
      "Training Epoch [582/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, curr_train_loss=0.41557556, val_loss=0.00000000]\n",
      "Validation Epoch [582/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.65507722]\n",
      "Training Epoch [583/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.71it/s, curr_train_loss=0.55079722, val_loss=0.00000000]\n",
      "Validation Epoch [583/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.73it/s, val_loss=1.46110547]\n",
      "Training Epoch [584/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=0.38481563, val_loss=0.00000000]\n",
      "Validation Epoch [584/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, val_loss=1.41753769]\n",
      "Training Epoch [585/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, curr_train_loss=0.50552702, val_loss=0.00000000]\n",
      "Validation Epoch [585/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=1.10440195]\n",
      "Training Epoch [586/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, curr_train_loss=0.53013062, val_loss=0.00000000]\n",
      "Validation Epoch [586/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.06it/s, val_loss=1.24121118]\n",
      "Training Epoch [587/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, curr_train_loss=0.37381577, val_loss=0.00000000]\n",
      "Validation Epoch [587/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.65it/s, val_loss=1.57954562]\n",
      "Training Epoch [588/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, curr_train_loss=0.44287270, val_loss=0.00000000]\n",
      "Validation Epoch [588/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.01it/s, val_loss=1.31024873]\n",
      "Training Epoch [589/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.37it/s, curr_train_loss=0.43819112, val_loss=0.00000000]\n",
      "Validation Epoch [589/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=1.62159276]\n",
      "Training Epoch [590/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.64it/s, curr_train_loss=0.37788296, val_loss=0.00000000]\n",
      "Validation Epoch [590/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, val_loss=1.22149479]\n",
      "Training Epoch [591/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.47168544, val_loss=0.00000000]\n",
      "Validation Epoch [591/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, val_loss=1.35997164]\n",
      "Training Epoch [592/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.58it/s, curr_train_loss=0.31808454, val_loss=0.00000000]\n",
      "Validation Epoch [592/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.60it/s, val_loss=1.25150096]\n",
      "Training Epoch [593/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, curr_train_loss=0.27606714, val_loss=0.00000000]\n",
      "Validation Epoch [593/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=1.56136096]\n",
      "Training Epoch [594/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.66it/s, curr_train_loss=0.33101887, val_loss=0.00000000]\n",
      "Validation Epoch [594/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.74it/s, val_loss=1.32142878]\n",
      "Training Epoch [595/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.30it/s, curr_train_loss=0.36412209, val_loss=0.00000000]\n",
      "Validation Epoch [595/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.78it/s, val_loss=1.21753597]\n",
      "Training Epoch [596/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.09it/s, curr_train_loss=0.32697117, val_loss=0.00000000]\n",
      "Validation Epoch [596/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.68498504]\n",
      "Training Epoch [597/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.42it/s, curr_train_loss=0.22947191, val_loss=0.00000000]\n",
      "Validation Epoch [597/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, val_loss=1.78485668]\n",
      "Training Epoch [598/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.25it/s, curr_train_loss=0.67771101, val_loss=0.00000000]\n",
      "Validation Epoch [598/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.69it/s, val_loss=1.44710505]\n",
      "Training Epoch [599/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.11it/s, curr_train_loss=0.28061593, val_loss=0.00000000]\n",
      "Validation Epoch [599/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.64it/s, val_loss=1.61544323]\n",
      "Training Epoch [600/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=0.30411857, val_loss=0.00000000]\n",
      "Validation Epoch [600/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.91it/s, val_loss=1.51624370]\n",
      "Training Epoch [601/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=0.41494426, val_loss=0.00000000]\n",
      "Validation Epoch [601/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s, val_loss=1.50330424]\n",
      "Training Epoch [602/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=0.30234429, val_loss=0.00000000]\n",
      "Validation Epoch [602/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, val_loss=1.33842015]\n",
      "Training Epoch [603/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.28it/s, curr_train_loss=0.47253224, val_loss=0.00000000]\n",
      "Validation Epoch [603/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.70it/s, val_loss=1.43214762]\n",
      "Training Epoch [604/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.55it/s, curr_train_loss=0.56877297, val_loss=0.00000000]\n",
      "Validation Epoch [604/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.72it/s, val_loss=1.40479720]\n",
      "Training Epoch [605/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.62it/s, curr_train_loss=0.45714122, val_loss=0.00000000]\n",
      "Validation Epoch [605/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.68it/s, val_loss=1.18694496]\n",
      "Training Epoch [606/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=0.34382847, val_loss=0.00000000]\n",
      "Validation Epoch [606/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=1.39117062]\n",
      "Training Epoch [607/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, curr_train_loss=0.30883345, val_loss=0.00000000]\n",
      "Validation Epoch [607/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, val_loss=1.29697728]\n",
      "Training Epoch [608/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, curr_train_loss=0.39932519, val_loss=0.00000000]\n",
      "Validation Epoch [608/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.10it/s, val_loss=1.23110080]\n",
      "Training Epoch [609/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=0.31628871, val_loss=0.00000000]\n",
      "Validation Epoch [609/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=1.38970470]\n",
      "Training Epoch [610/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.34it/s, curr_train_loss=0.47734666, val_loss=0.00000000]\n",
      "Validation Epoch [610/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.61it/s, val_loss=1.17566359]\n",
      "Training Epoch [611/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.33it/s, curr_train_loss=0.33224463, val_loss=0.00000000]\n",
      "Validation Epoch [611/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.59it/s, val_loss=0.90298980]\n",
      "Training Epoch [612/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.09it/s, curr_train_loss=0.33716947, val_loss=0.00000000]\n",
      "Validation Epoch [612/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.20190001]\n",
      "Training Epoch [613/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.23it/s, curr_train_loss=0.33385888, val_loss=0.00000000]\n",
      "Validation Epoch [613/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.53it/s, val_loss=1.17952526]\n",
      "Training Epoch [614/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  5.84it/s, curr_train_loss=0.53567642, val_loss=0.00000000]\n",
      "Validation Epoch [614/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.93it/s, val_loss=1.14556384]\n",
      "Training Epoch [615/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.04it/s, curr_train_loss=0.41326541, val_loss=0.00000000]\n",
      "Validation Epoch [615/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.10it/s, val_loss=1.21646976]\n",
      "Training Epoch [616/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.18it/s, curr_train_loss=0.24726386, val_loss=0.00000000]\n",
      "Validation Epoch [616/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.40it/s, val_loss=1.42846501]\n",
      "Training Epoch [617/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.63it/s, curr_train_loss=0.29133630, val_loss=0.00000000]\n",
      "Validation Epoch [617/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.79it/s, val_loss=1.32088137]\n",
      "Training Epoch [618/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, curr_train_loss=0.47788280, val_loss=0.00000000]\n",
      "Validation Epoch [618/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.75it/s, val_loss=1.03875256]\n",
      "Training Epoch [619/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.11it/s, curr_train_loss=0.30161303, val_loss=0.00000000]\n",
      "Validation Epoch [619/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=1.48531115]\n",
      "Training Epoch [620/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=0.24736188, val_loss=0.00000000]\n",
      "Validation Epoch [620/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.98it/s, val_loss=1.24593735]\n",
      "Training Epoch [621/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.58it/s, curr_train_loss=0.26688361, val_loss=0.00000000]\n",
      "Validation Epoch [621/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.85it/s, val_loss=1.22095096]\n",
      "Training Epoch [622/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.51it/s, curr_train_loss=0.27483156, val_loss=0.00000000]\n",
      "Validation Epoch [622/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=1.21618128]\n",
      "Training Epoch [623/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, curr_train_loss=0.31671420, val_loss=0.00000000]\n",
      "Validation Epoch [623/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, val_loss=1.27452147]\n",
      "Training Epoch [624/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.33it/s, curr_train_loss=0.35707763, val_loss=0.00000000]\n",
      "Validation Epoch [624/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.65it/s, val_loss=1.28023493]\n",
      "Training Epoch [625/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, curr_train_loss=0.46889055, val_loss=0.00000000]\n",
      "Validation Epoch [625/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.57it/s, val_loss=1.58400583]\n",
      "Training Epoch [626/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.13it/s, curr_train_loss=0.27115369, val_loss=0.00000000]\n",
      "Validation Epoch [626/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.45656574]\n",
      "Training Epoch [627/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.01it/s, curr_train_loss=0.41825190, val_loss=0.00000000]\n",
      "Validation Epoch [627/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.27it/s, val_loss=1.23560429]\n",
      "Training Epoch [628/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=0.41601208, val_loss=0.00000000]\n",
      "Validation Epoch [628/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.76it/s, val_loss=1.21237838]\n",
      "Training Epoch [629/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, curr_train_loss=0.43726435, val_loss=0.00000000]\n",
      "Validation Epoch [629/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.30295527]\n",
      "Training Epoch [630/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, curr_train_loss=0.28730431, val_loss=0.00000000]\n",
      "Validation Epoch [630/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, val_loss=1.36264801]\n",
      "Training Epoch [631/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.23it/s, curr_train_loss=0.35765666, val_loss=0.00000000]\n",
      "Validation Epoch [631/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, val_loss=1.22581828]\n",
      "Training Epoch [632/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.51it/s, curr_train_loss=0.31216565, val_loss=0.00000000]\n",
      "Validation Epoch [632/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.81it/s, val_loss=1.22692907]\n",
      "Training Epoch [633/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=0.33042109, val_loss=0.00000000]\n",
      "Validation Epoch [633/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.11it/s, val_loss=1.65015244]\n",
      "Training Epoch [634/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.14it/s, curr_train_loss=0.49875051, val_loss=0.00000000]\n",
      "Validation Epoch [634/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.89it/s, val_loss=1.64660406]\n",
      "Training Epoch [635/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.29it/s, curr_train_loss=0.42285955, val_loss=0.00000000]\n",
      "Validation Epoch [635/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.57it/s, val_loss=1.31467855]\n",
      "Training Epoch [636/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.26it/s, curr_train_loss=0.27572274, val_loss=0.00000000]\n",
      "Validation Epoch [636/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.50it/s, val_loss=0.92354548]\n",
      "Training Epoch [637/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.32it/s, curr_train_loss=0.36683455, val_loss=0.00000000]\n",
      "Validation Epoch [637/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.74it/s, val_loss=1.47103298]\n",
      "Training Epoch [638/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  5.41it/s, curr_train_loss=0.38602242, val_loss=0.00000000]\n",
      "Validation Epoch [638/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.84it/s, val_loss=1.07617176]\n",
      "Training Epoch [639/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, curr_train_loss=0.26830378, val_loss=0.00000000]\n",
      "Validation Epoch [639/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.63it/s, val_loss=1.38326359]\n",
      "Training Epoch [640/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.91it/s, curr_train_loss=0.09114479, val_loss=0.00000000]\n",
      "Validation Epoch [640/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s, val_loss=1.18659794]\n",
      "Training Epoch [641/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, curr_train_loss=0.36991906, val_loss=0.00000000]\n",
      "Validation Epoch [641/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, val_loss=1.28016078]\n",
      "Training Epoch [642/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.46it/s, curr_train_loss=0.33788285, val_loss=0.00000000]\n",
      "Validation Epoch [642/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.75it/s, val_loss=1.20264375]\n",
      "Training Epoch [643/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  5.87it/s, curr_train_loss=0.49620312, val_loss=0.00000000]\n",
      "Validation Epoch [643/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.63it/s, val_loss=1.33922243]\n",
      "Training Epoch [644/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.26it/s, curr_train_loss=0.55651003, val_loss=0.00000000]\n",
      "Validation Epoch [644/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.75it/s, val_loss=0.97471207]\n",
      "Training Epoch [645/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.42it/s, curr_train_loss=0.39726871, val_loss=0.00000000]\n",
      "Validation Epoch [645/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, val_loss=1.02943027]\n",
      "Training Epoch [646/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s, curr_train_loss=0.18347426, val_loss=0.00000000]\n",
      "Validation Epoch [646/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=1.26576722]\n",
      "Training Epoch [647/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.08it/s, curr_train_loss=0.23252514, val_loss=0.00000000]\n",
      "Validation Epoch [647/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.01it/s, val_loss=1.53941166]\n",
      "Training Epoch [648/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, curr_train_loss=0.51725096, val_loss=0.00000000]\n",
      "Validation Epoch [648/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.61it/s, val_loss=1.48193944]\n",
      "Training Epoch [649/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.57it/s, curr_train_loss=0.25997844, val_loss=0.00000000]\n",
      "Validation Epoch [649/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.92it/s, val_loss=1.28476214]\n",
      "Training Epoch [650/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  5.85it/s, curr_train_loss=0.30113655, val_loss=0.00000000]\n",
      "Validation Epoch [650/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, val_loss=1.38672042]\n",
      "Training Epoch [651/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.15it/s, curr_train_loss=0.28812042, val_loss=0.00000000]\n",
      "Validation Epoch [651/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.55it/s, val_loss=1.07064390]\n",
      "Training Epoch [652/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  5.94it/s, curr_train_loss=0.33050472, val_loss=0.00000000]\n",
      "Validation Epoch [652/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.95it/s, val_loss=1.29545963]\n",
      "Training Epoch [653/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.57it/s, curr_train_loss=0.46204051, val_loss=0.00000000]\n",
      "Validation Epoch [653/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.69it/s, val_loss=1.39259899]\n",
      "Training Epoch [654/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, curr_train_loss=0.44560489, val_loss=0.00000000]\n",
      "Validation Epoch [654/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.22241414]\n",
      "Training Epoch [655/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.52it/s, curr_train_loss=0.28595462, val_loss=0.00000000]\n",
      "Validation Epoch [655/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.56it/s, val_loss=1.13466644]\n",
      "Training Epoch [656/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, curr_train_loss=0.33436215, val_loss=0.00000000]\n",
      "Validation Epoch [656/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.92it/s, val_loss=1.27247846]\n",
      "Training Epoch [657/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.15it/s, curr_train_loss=0.38444152, val_loss=0.00000000]\n",
      "Validation Epoch [657/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.14it/s, val_loss=1.22738111]\n",
      "Training Epoch [658/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, curr_train_loss=0.51186776, val_loss=0.00000000]\n",
      "Validation Epoch [658/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.80it/s, val_loss=1.12704432]\n",
      "Training Epoch [659/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=0.25496161, val_loss=0.00000000]\n",
      "Validation Epoch [659/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.85it/s, val_loss=1.51289105]\n",
      "Training Epoch [660/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=0.32114619, val_loss=0.00000000]\n",
      "Validation Epoch [660/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s, val_loss=1.32201755]\n",
      "Training Epoch [661/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=0.36332554, val_loss=0.00000000]\n",
      "Validation Epoch [661/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.47416162]\n",
      "Training Epoch [662/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, curr_train_loss=0.42336524, val_loss=0.00000000]\n",
      "Validation Epoch [662/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.72it/s, val_loss=1.36746109]\n",
      "Training Epoch [663/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.22it/s, curr_train_loss=0.23973499, val_loss=0.00000000]\n",
      "Validation Epoch [663/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.85it/s, val_loss=1.19958293]\n",
      "Training Epoch [664/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.41it/s, curr_train_loss=0.22898883, val_loss=0.00000000]\n",
      "Validation Epoch [664/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.01it/s, val_loss=1.40489531]\n",
      "Training Epoch [665/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.63it/s, curr_train_loss=0.28349483, val_loss=0.00000000]\n",
      "Validation Epoch [665/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, val_loss=1.32058501]\n",
      "Training Epoch [666/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.81it/s, curr_train_loss=0.27382439, val_loss=0.00000000]\n",
      "Validation Epoch [666/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.56it/s, val_loss=1.41656291]\n",
      "Training Epoch [667/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, curr_train_loss=0.43233788, val_loss=0.00000000]\n",
      "Validation Epoch [667/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.71it/s, val_loss=0.91459674]\n",
      "Training Epoch [668/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s, curr_train_loss=0.29883116, val_loss=0.00000000]\n",
      "Validation Epoch [668/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=1.50500822]\n",
      "Training Epoch [669/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.29it/s, curr_train_loss=0.38008323, val_loss=0.00000000]\n",
      "Validation Epoch [669/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.18868601]\n",
      "Training Epoch [670/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.31it/s, curr_train_loss=0.26378566, val_loss=0.00000000]\n",
      "Validation Epoch [670/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.09it/s, val_loss=1.73891771]\n",
      "Training Epoch [671/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.53it/s, curr_train_loss=0.23563717, val_loss=0.00000000]\n",
      "Validation Epoch [671/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.11it/s, val_loss=1.75757945]\n",
      "Training Epoch [672/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.53549701, val_loss=0.00000000]\n",
      "Validation Epoch [672/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=1.25329387]\n",
      "Training Epoch [673/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=0.45864174, val_loss=0.00000000]\n",
      "Validation Epoch [673/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.10it/s, val_loss=1.38437808]\n",
      "Training Epoch [674/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=0.40273187, val_loss=0.00000000]\n",
      "Validation Epoch [674/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.03it/s, val_loss=1.26111555]\n",
      "Training Epoch [675/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.29it/s, curr_train_loss=0.34296554, val_loss=0.00000000]\n",
      "Validation Epoch [675/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.59it/s, val_loss=1.13744020]\n",
      "Training Epoch [676/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, curr_train_loss=0.26136169, val_loss=0.00000000]\n",
      "Validation Epoch [676/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.08it/s, val_loss=1.16252947]\n",
      "Training Epoch [677/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, curr_train_loss=0.25394377, val_loss=0.00000000]\n",
      "Validation Epoch [677/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.02it/s, val_loss=1.27594793]\n",
      "Training Epoch [678/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.46it/s, curr_train_loss=0.63267195, val_loss=0.00000000]\n",
      "Validation Epoch [678/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s, val_loss=1.27189755]\n",
      "Training Epoch [679/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  5.58it/s, curr_train_loss=0.26642817, val_loss=0.00000000]\n",
      "Validation Epoch [679/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.71it/s, val_loss=1.15678930]\n",
      "Training Epoch [680/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=0.21284229, val_loss=0.00000000]\n",
      "Validation Epoch [680/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.58it/s, val_loss=1.08500361]\n",
      "Training Epoch [681/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.47096393, val_loss=0.00000000]\n",
      "Validation Epoch [681/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.15866017]\n",
      "Training Epoch [682/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=0.33703414, val_loss=0.00000000]\n",
      "Validation Epoch [682/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=1.34704328]\n",
      "Training Epoch [683/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.92it/s, curr_train_loss=0.24885698, val_loss=0.00000000]\n",
      "Validation Epoch [683/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.45it/s, val_loss=1.32953048]\n",
      "Training Epoch [684/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.18it/s, curr_train_loss=0.38878715, val_loss=0.00000000]\n",
      "Validation Epoch [684/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.64it/s, val_loss=1.14684224]\n",
      "Training Epoch [685/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  5.72it/s, curr_train_loss=0.42318359, val_loss=0.00000000]\n",
      "Validation Epoch [685/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.78it/s, val_loss=0.98114783]\n",
      "Training Epoch [686/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.39358968, val_loss=0.00000000]\n",
      "Validation Epoch [686/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.84it/s, val_loss=1.15019178]\n",
      "Training Epoch [687/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, curr_train_loss=0.43006897, val_loss=0.00000000]\n",
      "Validation Epoch [687/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.06it/s, val_loss=1.25569618]\n",
      "Training Epoch [688/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.53it/s, curr_train_loss=0.36983314, val_loss=0.00000000]\n",
      "Validation Epoch [688/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.74it/s, val_loss=1.13329279]\n",
      "Training Epoch [689/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.65it/s, curr_train_loss=0.31354573, val_loss=0.00000000]\n",
      "Validation Epoch [689/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, val_loss=1.12420428]\n",
      "Training Epoch [690/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.18it/s, curr_train_loss=0.17564391, val_loss=0.00000000]\n",
      "Validation Epoch [690/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.85it/s, val_loss=1.14055967]\n",
      "Training Epoch [691/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.57it/s, curr_train_loss=0.42995679, val_loss=0.00000000]\n",
      "Validation Epoch [691/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.74it/s, val_loss=1.16541004]\n",
      "Training Epoch [692/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.66it/s, curr_train_loss=0.50358164, val_loss=0.00000000]\n",
      "Validation Epoch [692/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.08it/s, val_loss=1.21911299]\n",
      "Training Epoch [693/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.15it/s, curr_train_loss=0.40630957, val_loss=0.00000000]\n",
      "Validation Epoch [693/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.79it/s, val_loss=1.23566508]\n",
      "Training Epoch [694/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.68it/s, curr_train_loss=0.29995939, val_loss=0.00000000]\n",
      "Validation Epoch [694/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.76it/s, val_loss=1.11592913]\n",
      "Training Epoch [695/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, curr_train_loss=0.32554427, val_loss=0.00000000]\n",
      "Validation Epoch [695/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s, val_loss=1.07285619]\n",
      "Training Epoch [696/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, curr_train_loss=0.33806211, val_loss=0.00000000]\n",
      "Validation Epoch [696/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.80it/s, val_loss=1.13434160]\n",
      "Training Epoch [697/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.19it/s, curr_train_loss=0.38598809, val_loss=0.00000000]\n",
      "Validation Epoch [697/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.14236140]\n",
      "Training Epoch [698/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=0.39401120, val_loss=0.00000000]\n",
      "Validation Epoch [698/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.83it/s, val_loss=0.85546011]\n",
      "Training Epoch [699/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=0.43194908, val_loss=0.00000000]\n",
      "Validation Epoch [699/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.95it/s, val_loss=1.18891490]\n",
      "Training Epoch [700/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, curr_train_loss=0.25915748, val_loss=0.00000000]\n",
      "Validation Epoch [700/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.42186594]\n",
      "Training Epoch [701/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.62it/s, curr_train_loss=0.40256432, val_loss=0.00000000]\n",
      "Validation Epoch [701/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.26it/s, val_loss=1.66410327]\n",
      "Training Epoch [702/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.23it/s, curr_train_loss=0.26903015, val_loss=0.00000000]\n",
      "Validation Epoch [702/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.93it/s, val_loss=1.37925386]\n",
      "Training Epoch [703/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.25it/s, curr_train_loss=0.34288773, val_loss=0.00000000]\n",
      "Validation Epoch [703/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.84it/s, val_loss=1.29918492]\n",
      "Training Epoch [704/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.39169043, val_loss=0.00000000]\n",
      "Validation Epoch [704/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.77738810]\n",
      "Training Epoch [705/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.85it/s, curr_train_loss=0.39431557, val_loss=0.00000000]\n",
      "Validation Epoch [705/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.04it/s, val_loss=1.54574573]\n",
      "Training Epoch [706/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.28it/s, curr_train_loss=0.37042928, val_loss=0.00000000]\n",
      "Validation Epoch [706/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.73it/s, val_loss=1.09983277]\n",
      "Training Epoch [707/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.84it/s, curr_train_loss=0.38628349, val_loss=0.00000000]\n",
      "Validation Epoch [707/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.62it/s, val_loss=1.21159053]\n",
      "Training Epoch [708/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, curr_train_loss=0.24017091, val_loss=0.00000000]\n",
      "Validation Epoch [708/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s, val_loss=1.00292242]\n",
      "Training Epoch [709/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  5.77it/s, curr_train_loss=0.40850377, val_loss=0.00000000]\n",
      "Validation Epoch [709/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s, val_loss=1.39810777]\n",
      "Training Epoch [710/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=0.19037868, val_loss=0.00000000]\n",
      "Validation Epoch [710/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.87it/s, val_loss=1.26702547]\n",
      "Training Epoch [711/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=0.50585288, val_loss=0.00000000]\n",
      "Validation Epoch [711/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.10it/s, val_loss=1.23126578]\n",
      "Training Epoch [712/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.18it/s, curr_train_loss=0.31653634, val_loss=0.00000000]\n",
      "Validation Epoch [712/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.91it/s, val_loss=1.25563002]\n",
      "Training Epoch [713/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, curr_train_loss=0.34972703, val_loss=0.00000000]\n",
      "Validation Epoch [713/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.27it/s, val_loss=1.15017223]\n",
      "Training Epoch [714/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.09it/s, curr_train_loss=0.41373557, val_loss=0.00000000]\n",
      "Validation Epoch [714/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.89it/s, val_loss=0.96317458]\n",
      "Training Epoch [715/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.30it/s, curr_train_loss=0.35284874, val_loss=0.00000000]\n",
      "Validation Epoch [715/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.96it/s, val_loss=1.02627468]\n",
      "Training Epoch [716/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, curr_train_loss=0.43514222, val_loss=0.00000000]\n",
      "Validation Epoch [716/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.99it/s, val_loss=1.06678975]\n",
      "Training Epoch [717/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.29it/s, curr_train_loss=0.27433777, val_loss=0.00000000]\n",
      "Validation Epoch [717/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=1.17749977]\n",
      "Training Epoch [718/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=0.34548324, val_loss=0.00000000]\n",
      "Validation Epoch [718/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.60it/s, val_loss=0.87108582]\n",
      "Training Epoch [719/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.56it/s, curr_train_loss=0.47488248, val_loss=0.00000000]\n",
      "Validation Epoch [719/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, val_loss=1.25286281]\n",
      "Training Epoch [720/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.13it/s, curr_train_loss=0.28027987, val_loss=0.00000000]\n",
      "Validation Epoch [720/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=0.96594191]\n",
      "Training Epoch [721/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=0.44254249, val_loss=0.00000000]\n",
      "Validation Epoch [721/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.75it/s, val_loss=1.04847300]\n",
      "Training Epoch [722/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=0.49379280, val_loss=0.00000000]\n",
      "Validation Epoch [722/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=1.13949490]\n",
      "Training Epoch [723/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.09it/s, curr_train_loss=0.42343006, val_loss=0.00000000]\n",
      "Validation Epoch [723/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, val_loss=1.25975931]\n",
      "Training Epoch [724/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.54it/s, curr_train_loss=0.34717378, val_loss=0.00000000]\n",
      "Validation Epoch [724/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=1.15990138]\n",
      "Training Epoch [725/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.31it/s, curr_train_loss=0.36265007, val_loss=0.00000000]\n",
      "Validation Epoch [725/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.60it/s, val_loss=1.21376300]\n",
      "Training Epoch [726/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.47it/s, curr_train_loss=0.24672313, val_loss=0.00000000]\n",
      "Validation Epoch [726/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.93it/s, val_loss=1.09979916]\n",
      "Training Epoch [727/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=0.28382650, val_loss=0.00000000]\n",
      "Validation Epoch [727/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.85it/s, val_loss=1.18323040]\n",
      "Training Epoch [728/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.56it/s, curr_train_loss=0.21319394, val_loss=0.00000000]\n",
      "Validation Epoch [728/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.63it/s, val_loss=1.08959866]\n",
      "Training Epoch [729/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=0.33456898, val_loss=0.00000000]\n",
      "Validation Epoch [729/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.14it/s, val_loss=1.20866597]\n",
      "Training Epoch [730/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.63it/s, curr_train_loss=0.30436718, val_loss=0.00000000]\n",
      "Validation Epoch [730/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.63it/s, val_loss=1.25850463]\n",
      "Training Epoch [731/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, curr_train_loss=0.36830860, val_loss=0.00000000]\n",
      "Validation Epoch [731/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=1.00415111]\n",
      "Training Epoch [732/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.04it/s, curr_train_loss=0.35559955, val_loss=0.00000000]\n",
      "Validation Epoch [732/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.06it/s, val_loss=1.29231083]\n",
      "Training Epoch [733/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  5.85it/s, curr_train_loss=0.48778707, val_loss=0.00000000]\n",
      "Validation Epoch [733/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.15969205]\n",
      "Training Epoch [734/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, curr_train_loss=0.38340542, val_loss=0.00000000]\n",
      "Validation Epoch [734/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.79it/s, val_loss=1.06290746]\n",
      "Training Epoch [735/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.08it/s, curr_train_loss=0.24182495, val_loss=0.00000000]\n",
      "Validation Epoch [735/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, val_loss=1.11590636]\n",
      "Training Epoch [736/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.32it/s, curr_train_loss=0.56895685, val_loss=0.00000000]\n",
      "Validation Epoch [736/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.85it/s, val_loss=1.16291809]\n",
      "Training Epoch [737/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.30it/s, curr_train_loss=0.29097569, val_loss=0.00000000]\n",
      "Validation Epoch [737/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.06it/s, val_loss=1.09113014]\n",
      "Training Epoch [738/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.12it/s, curr_train_loss=0.46267697, val_loss=0.00000000]\n",
      "Validation Epoch [738/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.04it/s, val_loss=1.04730368]\n",
      "Training Epoch [739/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.09it/s, curr_train_loss=0.30637416, val_loss=0.00000000]\n",
      "Validation Epoch [739/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.12098968]\n",
      "Training Epoch [740/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.07it/s, curr_train_loss=0.29950881, val_loss=0.00000000]\n",
      "Validation Epoch [740/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, val_loss=0.99167359]\n",
      "Training Epoch [741/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=0.30126935, val_loss=0.00000000]\n",
      "Validation Epoch [741/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=1.12890577]\n",
      "Training Epoch [742/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, curr_train_loss=0.32445404, val_loss=0.00000000]\n",
      "Validation Epoch [742/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.16it/s, val_loss=1.03518915]\n",
      "Training Epoch [743/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, curr_train_loss=0.31326118, val_loss=0.00000000]\n",
      "Validation Epoch [743/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.10it/s, val_loss=0.96662718]\n",
      "Training Epoch [744/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, curr_train_loss=0.35388008, val_loss=0.00000000]\n",
      "Validation Epoch [744/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.11it/s, val_loss=1.11562753]\n",
      "Training Epoch [745/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=0.51976669, val_loss=0.00000000]\n",
      "Validation Epoch [745/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.66it/s, val_loss=1.10404742]\n",
      "Training Epoch [746/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.51it/s, curr_train_loss=0.31122783, val_loss=0.00000000]\n",
      "Validation Epoch [746/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.96it/s, val_loss=0.97274184]\n",
      "Training Epoch [747/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.75it/s, curr_train_loss=0.36863491, val_loss=0.00000000]\n",
      "Validation Epoch [747/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, val_loss=1.05538738]\n",
      "Training Epoch [748/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.02it/s, curr_train_loss=0.26798180, val_loss=0.00000000]\n",
      "Validation Epoch [748/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s, val_loss=1.20714235]\n",
      "Training Epoch [749/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.76it/s, curr_train_loss=0.44589916, val_loss=0.00000000]\n",
      "Validation Epoch [749/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s, val_loss=0.95012891]\n",
      "Training Epoch [750/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, curr_train_loss=0.27299145, val_loss=0.00000000]\n",
      "Validation Epoch [750/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.95it/s, val_loss=1.12361860]\n",
      "Training Epoch [751/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.82it/s, curr_train_loss=0.25018257, val_loss=0.00000000]\n",
      "Validation Epoch [751/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.05it/s, val_loss=1.16820550]\n",
      "Training Epoch [752/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, curr_train_loss=0.50388390, val_loss=0.00000000]\n",
      "Validation Epoch [752/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.98it/s, val_loss=1.04879427]\n",
      "Training Epoch [753/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, curr_train_loss=0.38895339, val_loss=0.00000000]\n",
      "Validation Epoch [753/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s, val_loss=1.03856289]\n",
      "Training Epoch [754/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.59it/s, curr_train_loss=0.30015966, val_loss=0.00000000]\n",
      "Validation Epoch [754/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s, val_loss=1.19854367]\n",
      "Training Epoch [755/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.56it/s, curr_train_loss=0.31115332, val_loss=0.00000000]\n",
      "Validation Epoch [755/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s, val_loss=1.28624487]\n",
      "Training Epoch [756/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=0.42354450, val_loss=0.00000000]\n",
      "Validation Epoch [756/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.82it/s, val_loss=1.31464732]\n",
      "Training Epoch [757/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.37it/s, curr_train_loss=0.30000442, val_loss=0.00000000]\n",
      "Validation Epoch [757/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.09it/s, val_loss=1.12112224]\n",
      "Training Epoch [758/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=0.32618320, val_loss=0.00000000]\n",
      "Validation Epoch [758/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.80it/s, val_loss=1.09270620]\n",
      "Training Epoch [759/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, curr_train_loss=0.37774199, val_loss=0.00000000]\n",
      "Validation Epoch [759/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.63it/s, val_loss=1.05203390]\n",
      "Training Epoch [760/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.25it/s, curr_train_loss=0.33053890, val_loss=0.00000000]\n",
      "Validation Epoch [760/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.97it/s, val_loss=0.86308289]\n",
      "Training Epoch [761/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.45it/s, curr_train_loss=0.27909976, val_loss=0.00000000]\n",
      "Validation Epoch [761/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.03it/s, val_loss=1.29002607]\n",
      "Training Epoch [762/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, curr_train_loss=0.31113508, val_loss=0.00000000]\n",
      "Validation Epoch [762/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s, val_loss=1.18088067]\n",
      "Training Epoch [763/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, curr_train_loss=0.25870317, val_loss=0.00000000]\n",
      "Validation Epoch [763/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.09767902]\n",
      "Training Epoch [764/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, curr_train_loss=0.41111809, val_loss=0.00000000]\n",
      "Validation Epoch [764/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.06it/s, val_loss=0.74222237]\n",
      "Training Epoch [765/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.62it/s, curr_train_loss=0.31876665, val_loss=0.00000000]\n",
      "Validation Epoch [765/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, val_loss=1.15870440]\n",
      "Training Epoch [766/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.44it/s, curr_train_loss=0.25205931, val_loss=0.00000000]\n",
      "Validation Epoch [766/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.02it/s, val_loss=1.44659102]\n",
      "Training Epoch [767/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, curr_train_loss=0.33228794, val_loss=0.00000000]\n",
      "Validation Epoch [767/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.08it/s, val_loss=1.27388453]\n",
      "Training Epoch [768/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, curr_train_loss=0.37045082, val_loss=0.00000000]\n",
      "Validation Epoch [768/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s, val_loss=0.98279482]\n",
      "Training Epoch [769/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.35it/s, curr_train_loss=0.36130628, val_loss=0.00000000]\n",
      "Validation Epoch [769/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s, val_loss=1.18991625]\n",
      "Training Epoch [770/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s, curr_train_loss=0.31807339, val_loss=0.00000000]\n",
      "Validation Epoch [770/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.71it/s, val_loss=1.12730265]\n",
      "Training Epoch [771/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, curr_train_loss=0.40618172, val_loss=0.00000000]\n",
      "Validation Epoch [771/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.60it/s, val_loss=1.28003025]\n",
      "Training Epoch [772/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.05it/s, curr_train_loss=0.41868824, val_loss=0.00000000]\n",
      "Validation Epoch [772/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.10it/s, val_loss=1.27654290]\n",
      "Training Epoch [773/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.40it/s, curr_train_loss=0.24311066, val_loss=0.00000000]\n",
      "Validation Epoch [773/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.74it/s, val_loss=1.19886661]\n",
      "Training Epoch [774/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, curr_train_loss=0.41643178, val_loss=0.00000000]\n",
      "Validation Epoch [774/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.14it/s, val_loss=1.20573580]\n",
      "Training Epoch [775/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, curr_train_loss=0.36294448, val_loss=0.00000000]\n",
      "Validation Epoch [775/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.76it/s, val_loss=1.22605979]\n",
      "Training Epoch [776/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.29it/s, curr_train_loss=0.47152841, val_loss=0.00000000]\n",
      "Validation Epoch [776/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, val_loss=1.22376347]\n",
      "Training Epoch [777/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.23it/s, curr_train_loss=0.43101785, val_loss=0.00000000]\n",
      "Validation Epoch [777/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.01it/s, val_loss=1.29365933]\n",
      "Training Epoch [778/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.78it/s, curr_train_loss=0.40309677, val_loss=0.00000000]\n",
      "Validation Epoch [778/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.01it/s, val_loss=1.31454349]\n",
      "Training Epoch [779/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.48it/s, curr_train_loss=0.41383484, val_loss=0.00000000]\n",
      "Validation Epoch [779/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.62it/s, val_loss=1.22505093]\n",
      "Training Epoch [780/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.13it/s, curr_train_loss=0.37649605, val_loss=0.00000000]\n",
      "Validation Epoch [780/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s, val_loss=1.53236318]\n",
      "Training Epoch [781/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.64it/s, curr_train_loss=0.39803046, val_loss=0.00000000]\n",
      "Validation Epoch [781/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.82it/s, val_loss=1.17535996]\n",
      "Training Epoch [782/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.35it/s, curr_train_loss=0.25041026, val_loss=0.00000000]\n",
      "Validation Epoch [782/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, val_loss=1.01006436]\n",
      "Training Epoch [783/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.65it/s, curr_train_loss=0.40907937, val_loss=0.00000000]\n",
      "Validation Epoch [783/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.78it/s, val_loss=1.15562499]\n",
      "Training Epoch [784/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.34it/s, curr_train_loss=0.42371398, val_loss=0.00000000]\n",
      "Validation Epoch [784/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.16it/s, val_loss=1.26718223]\n",
      "Training Epoch [785/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, curr_train_loss=0.38461131, val_loss=0.00000000]\n",
      "Validation Epoch [785/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.94it/s, val_loss=1.11457622]\n",
      "Training Epoch [786/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.32it/s, curr_train_loss=0.35752019, val_loss=0.00000000]\n",
      "Validation Epoch [786/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.78it/s, val_loss=1.24665260]\n",
      "Training Epoch [787/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, curr_train_loss=0.21861947, val_loss=0.00000000]\n",
      "Validation Epoch [787/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.79it/s, val_loss=1.38663518]\n",
      "Training Epoch [788/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.63it/s, curr_train_loss=0.37120610, val_loss=0.00000000]\n",
      "Validation Epoch [788/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.91it/s, val_loss=1.56386471]\n",
      "Training Epoch [789/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.24it/s, curr_train_loss=0.40628365, val_loss=0.00000000]\n",
      "Validation Epoch [789/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.94it/s, val_loss=1.18199944]\n",
      "Training Epoch [790/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, curr_train_loss=0.32251537, val_loss=0.00000000]\n",
      "Validation Epoch [790/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.06it/s, val_loss=1.28278148]\n",
      "Training Epoch [791/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, curr_train_loss=0.19356169, val_loss=0.00000000]\n",
      "Validation Epoch [791/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.84it/s, val_loss=1.39722204]\n",
      "Training Epoch [792/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s, curr_train_loss=0.32962024, val_loss=0.00000000]\n",
      "Validation Epoch [792/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, val_loss=1.29798281]\n",
      "Training Epoch [793/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.27it/s, curr_train_loss=0.28322658, val_loss=0.00000000]\n",
      "Validation Epoch [793/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s, val_loss=1.23095143]\n",
      "Training Epoch [794/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.26it/s, curr_train_loss=0.39991596, val_loss=0.00000000]\n",
      "Validation Epoch [794/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.63it/s, val_loss=1.50184309]\n",
      "Training Epoch [795/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.78it/s, curr_train_loss=0.38264331, val_loss=0.00000000]\n",
      "Validation Epoch [795/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99it/s, val_loss=1.00815380]\n",
      "Training Epoch [796/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.41it/s, curr_train_loss=0.28605077, val_loss=0.00000000]\n",
      "Validation Epoch [796/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.60it/s, val_loss=1.09747088]\n",
      "Training Epoch [797/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.58it/s, curr_train_loss=0.23965378, val_loss=0.00000000]\n",
      "Validation Epoch [797/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, val_loss=1.17403340]\n",
      "Training Epoch [798/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.33it/s, curr_train_loss=0.33412269, val_loss=0.00000000]\n",
      "Validation Epoch [798/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, val_loss=1.37198746]\n",
      "Training Epoch [799/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.35it/s, curr_train_loss=0.24665247, val_loss=0.00000000]\n",
      "Validation Epoch [799/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.84it/s, val_loss=1.23741484]\n",
      "Training Epoch [800/800]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  6.91it/s, curr_train_loss=0.26814911, val_loss=0.00000000]\n",
      "Validation Epoch [800/800]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.83it/s, val_loss=1.18552518]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creat a tensorboard logger.\n",
    "# NOTE: In order to see the logs, run the following command in the terminal: tensorboard --logdir=./\n",
    "# Also, in order to reset the logs, delete the logs folder MANUALLY.\n",
    "# Pay attention that if you run this cell mutltiple times, the pretrained_encoder\n",
    "# is not reset, and will keep training from where it stopped. Thus, it could overfit.\n",
    "\n",
    "path = os.path.join('logs', 'pretrained_cls_logs')\n",
    "num_of_runs = len(os.listdir(path)) if os.path.exists(path) else 0\n",
    "path = os.path.join(path, f'run_{num_of_runs + 1}')\n",
    "tb_logger = SummaryWriter(path)\n",
    "\n",
    "batch_size = hparams.get('batch_size', 16)\n",
    "labled_train_loader = torch.utils.data.DataLoader(train_100_dataset, batch_size=batch_size, shuffle=True)\n",
    "labled_val_loader = torch.utils.data.DataLoader(val_100_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "epochs = hparams.get('epochs', 20)\n",
    "loss_func = nn.CrossEntropyLoss() # The loss function we use for classification.\n",
    "train_classifier(classifier_pretrained, labled_train_loader, labled_val_loader, loss_func, tb_logger, epochs=epochs, name='Pretrained')\n",
    "\n",
    "print(\"Finished training!\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "H-pm1MY_MNks"
   },
   "source": [
    "Let's have a look at the validation accuracy of the two different classifiers and compare them. And don't forget that you can also monitor your training in TensorBoard.\n",
    "\n",
    "We will only look at the test accuracy and compare our two classifiers with respect to that in the very end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "-e5Bd9KLMNkt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy when training from scratch: \u001b[92m59.0\u001b[0m%\n",
      "Validation accuracy with pretraining: \u001b[92m72.0\u001b[0m%\n"
     ]
    }
   ],
   "source": [
    "val_acc_scracth = classifier.getAcc(labled_val_loader)[1]*100\n",
    "color = 'green' if val_acc_scracth > 55 else 'red'\n",
    "print(f\"Validation accuracy when training from scratch: {bcolors.colorize(color, val_acc_scracth)}%\")\n",
    "\n",
    "val_acc_pretrained = classifier_pretrained.getAcc(labled_val_loader)[1]*100\n",
    "color = 'green' if val_acc_pretrained > 55 else 'red'\n",
    "print(f\"Validation accuracy with pretraining: {bcolors.colorize(color, val_acc_pretrained)}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zAp2OTyf4_5b"
   },
   "source": [
    "Now that everything is working, feel free to play around with different architectures. As you've seen, it's quite easy to define your model or do adpations there.\n",
    "\n",
    "To pass this submission, you will need to achieve an accuracy of **55%**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OmEYmRT-5S-e"
   },
   "source": [
    "# Save your model & Report Test Accuracy\n",
    "\n",
    "When you are finally done with your **hyperparameter tuning**, achieved **at least 55% validation accuracy** and are happy with your final model, you can save it here.\n",
    "\n",
    "Before that, please check again whether the number of parameters is below 5 Mio and the file size is below 20 MB.\n",
    "\n",
    "Once your final model is saved, we'll finally report the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "S69ETKxD5TcE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy when training from scratch: \u001b[92m71.0\u001b[0m%\n",
      "Test accuracy with pretraining: \u001b[92m78.0\u001b[0m%\n",
      "Validation Accuracy: \u001b[92m76.0\u001b[0m%\n",
      "# Paramters: Your model has \u001b[92m0.602\u001b[0m mio. params.\n",
      "Size: Great! Your model size is \u001b[92m4.6\u001b[0m MB and is less than 20 MB.\n",
      "Your model has been saved and is ready to be submitted.\n"
     ]
    }
   ],
   "source": [
    "from exercise_code.Util import test_and_save\n",
    "test_dl = torch.utils.data.DataLoader(test_100_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "test_acc = classifier.getAcc(test_dl)[1]*100\n",
    "color = 'green' if test_acc > 55 else 'red'\n",
    "print(f\"Test accuracy when training from scratch: {bcolors.colorize(color, test_acc)}%\")\n",
    "\n",
    "test_acc = classifier_pretrained.getAcc(test_dl)[1]*100\n",
    "color = 'green' if test_acc > 55 else 'red'\n",
    "print(f\"Test accuracy with pretraining: {bcolors.colorize(color, test_acc)}%\")\n",
    "\n",
    "test_and_save(classifier_pretrained, labled_val_loader, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "enZCnGL6MNkt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevant folders: ['exercise_code', 'models']\n",
      "notebooks files: ['Optional-BatchNormalization_Dropout.ipynb', '1_Autoencoder.ipynb']\n",
      "Adding folder exercise_code\n",
      "Adding folder models\n",
      "Adding notebook Optional-BatchNormalization_Dropout.ipynb\n",
      "Adding notebook 1_Autoencoder.ipynb\n",
      "Zipping successful! Zip is stored under: /home/timm_pop/Documents/i2dl/output/exercise_08.zip\n"
     ]
    }
   ],
   "source": [
    "# Now zip the folder for upload\n",
    "from exercise_code.submit import submit_exercise\n",
    "\n",
    "submit_exercise('../output/exercise_08')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "7fuo3Tf9MNku",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Congratulations on completing your first autoencoder and successfully transferring the weights to a classifier! It's remarkable how much easier this process becomes with the power of PyTorch, compared to working with plain NumPy, right?\n",
    "\n",
    "To complete the exercise, please submit your final model to [our submission portal](https://i2dl.vc.in.tum.de/) - you should be already familiar with the submission procedure. Next, it is time to get started with some more complex neural networks and tasks in the upcoming exercises. See you next week!\n",
    "\n",
    "# Submission Goals\n",
    "\n",
    "- Goal: Successfully implement a fully connected autoencoder for MNIST with Pytorch and transfer the encoder weights to a classifier.\n",
    "\n",
    "- Passing Criteria: There are no unit tests that check specific components of your code. The only thing that's required to pass the submission, is your model to reach at least **55% accuracy** on __our__ test dataset. The submission system will show you a number between 0 and 100 which corresponds to your accuracy.\n",
    "\n",
    "- Submission start: __June 15, 2023 10:00__\n",
    "- Submission deadline : __June 21, 2023 15:59__ \n",
    "- You can make **$\\infty$** submissions until the deadline. Your __best submission__ will be considered for the bonus."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Ar26mFO5MNku"
   },
   "source": [
    "# [Exercise Review](https://forms.gle/9SYivCPQZdktRDS29)\n",
    "\n",
    "We are always interested in your opinion. Now that you have finished this exercise, we would like you to give us some feedback about the time required to finish the submission and/or work through the notebooks. Please take the short time to fill out our [review form](https://forms.gle/9SYivCPQZdktRDS29) for this exercise so that we can do better next time! :)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "54970da6898dad277dbf355945c2dee7f942d2a31ec1fc1455b6d4f552d07b83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
